[{"path":"index.html","id":"about-this-book","chapter":"About this book","heading":"About this book","text":"Targeted Learning R: Causal Data Science tlverse Software\nEcosystem open source, reproducible electronic handbook applying \nTargeted Learning methodology practice using tlverse software\necosystem. work currently early draft\nphase available facilitate input community. view \ncontribute available content, consider visiting GitHub\nrepository.\n","code":""},{"path":"index.html","id":"outline","chapter":"About this book","heading":"0.1 Outline","text":"contents handbook meant serve reference guide \napplied research well materials can taught series short\ncourses focused applications Targeted Learning. section\nintroduces set distinct causal questions, motivated case study,\nalongside statistical methodology software assessing causal claim \ninterest. (evolving) set materials includesMotivation: need statistical\nrevolutionThe Roadmap introductory case study: WASH Beneifits dataIntroduction tlverse software\necosystemCross-validation origami\npackageEnsemble machine learning \nsl3 packageTargeted learning causal inference \ntmle3 packageOptimal treatments regimes \ntmle3mopttx packageStochastic treatment regimes \ntmle3shift packageCausal mediation analysis \ntmle3mediate packageCoda: need statistical\nrevolution","code":""},{"path":"index.html","id":"what-this-book-is-not","chapter":"About this book","heading":"What this book is not","text":"focus work providing -depth technical descriptions\ncurrent statistical methodology recent advancements. Instead, goal \nconvey key details state---art techniques manner \nclear complete, without burdening reader extraneous information.\nhope presentations herein serve references researchers\n– methodologists domain specialists alike – empower deploy\ncentral tools Targeted Learning efficient manner. technical\ndetails -depth descriptions classical theory recent advances\nfield Targeted Learning, interested reader invited consult\nvan der Laan Rose (2011) /van der Laan Rose (2018) appropriate. primary literature\nstatistical causal inference, machine learning, non/semiparametric theory\ninclude many recent advances Targeted Learning related areas.","code":""},{"path":"index.html","id":"about-the-authors","chapter":"About this book","heading":"About the authors","text":"","code":""},{"path":"index.html","id":"mark-van-der-laan","chapter":"About this book","heading":"Mark van der Laan","text":"Mark van der Laan, PhD, Professor Biostatistics Statistics UC\nBerkeley. research interests include statistical methods computational\nbiology, survival analysis, censored data, adaptive designs, targeted maximum\nlikelihood estimation, causal inference, data-adaptive loss-based learning, \nmultiple testing. research group developed loss-based super learning \nsemiparametric models, based cross-validation, generic optimal tool \nestimation infinite-dimensional parameters, nonparametric density\nestimation prediction censored uncensored data. Building \nwork, research group developed targeted maximum likelihood estimation\ntarget parameter data-generating distribution arbitrary\nsemiparametric nonparametric models, generic optimal methodology \nstatistical causal inference. recently, Mark’s group focused \npart development centralized, principled set software tools \ntargeted learning, tlverse.","code":""},{"path":"index.html","id":"jeremy-coyle","chapter":"About this book","heading":"Jeremy Coyle","text":"Jeremy Coyle, PhD, consulting data scientist statistical programmer,\ncurrently leading software development effort produced \ntlverse ecosystem R packages related software tools. Jeremy earned \nPhD Biostatistics UC Berkeley 2016, primarily supervision\nAlan Hubbard.","code":""},{"path":"index.html","id":"nima-hejazi","chapter":"About this book","heading":"Nima Hejazi","text":"Nima Hejazi PhD candidate biostatistics, working collaborative\ndirection Mark van der Laan Alan Hubbard. Nima affiliated UC\nBerkeley’s Center Computational Biology NIH Biomedical Big Data training\nprogram, well Fred Hutchinson Cancer Research Center. Previously,\nearned MA Biostatistics BA (majors Molecular Cell\nBiology, Psychology, Public Health), UC Berkeley. research\ninterests fall intersection causal inference machine learning,\ndrawing ideas non/semi-parametric estimation large, flexible\nstatistical models develop efficient robust statistical procedures \nevaluating complex target estimands observational randomized studies.\nParticular areas current emphasis include mediation/path analysis,\noutcome-dependent sampling designs, targeted loss-based estimation, vaccine\nefficacy trials. Nima also passionate statistical computing open\nsource software development applied statistics.","code":""},{"path":"index.html","id":"ivana-malenica","chapter":"About this book","heading":"Ivana Malenica","text":"Ivana Malenica PhD student biostatistics advised Mark van der Laan.\nIvana currently fellow Berkeley Institute Data Science, \nserving NIH Biomedical Big Data Freeport-McMoRan Genomic Engine fellow.\nearned Master’s Biostatistics Bachelor’s Mathematics, \nspent time Translational Genomics Research Institute. broadly,\nresearch interests span non/semi-parametric theory, probability theory,\nmachine learning, causal inference high-dimensional statistics. \ncurrent work involves complex dependent settings (dependence time \nnetwork) adaptive sequential designs.","code":""},{"path":"index.html","id":"rachael-phillips","chapter":"About this book","heading":"Rachael Phillips","text":"Rachael Phillips PhD student biostatistics, advised Alan Hubbard \nMark van der Laan. MA Biostatistics, BS Biology, BA \nMathematics. student targeted learning causal inference, Rachael’s\nresearch focuses statistical estimation inference realistic\nstatistical models. current projects involve personalized online machine\nlearning EHR streaming data vital signs, automated learning \nhighly adaptive lasso, causal effect estimation community-level\ninterventions. also working FDA-funded project led Dr. Susan\nGruber, Targeted Learning Framework Causal Effect Estimation Using\nReal-World Data. Rachael active contributor hal9001 sl3\nR packages tlverse.","code":""},{"path":"index.html","id":"alan-hubbard","chapter":"About this book","heading":"Alan Hubbard","text":"Alan Hubbard Professor Biostatistics, former head Division \nBiostatistics UC Berkeley, head data analytics core UC Berkeley’s\nSuperFund research program. current research interests include causal\ninference, variable importance analysis, statistical machine learning,\nestimation inference data-adaptive statistical target parameters, \ntargeted minimum loss-based estimation. Research group generally\nmotivated applications problems computational biology, epidemiology,\nprecision medicine.","code":""},{"path":"index.html","id":"repro","chapter":"About this book","heading":"0.2 Reproduciblity with the tlverse","text":"tlverse software ecosystem growing collection packages, several \nquite early software lifecycle. team best \nmaintain backwards compatibility. work reaches completion, \nspecific versions tlverse packages used archived tagged \nproduce .book written using bookdown, complete\nsource available GitHub.\nversion book built R version 4.1.0 (2021-05-18),\npandoc version 2.14.1, \nfollowing packages:","code":""},{"path":"index.html","id":"learn","chapter":"About this book","heading":"0.3 Learning resources","text":"effectively utilize handbook, reader need fully trained\nstatistician begin understanding applying methods. However, \nhighly recommended reader understanding basic statistical\nconcepts confounding, probability distributions, confidence intervals,\nhypothesis tests, regression. Advanced knowledge mathematical statistics\nmay useful necessary. Familiarity R programming\nlanguage essential. also recommend understanding introductory\ncausal inference.learning R programming language recommend following (free)\nintroductory resources:Software Carpentry’s Programming \nRSoftware Carpentry’s R Reproducible Scientific\nAnalysisGarret Grolemund Hadley Wickham’s R Data\nScienceFor general introduction causal inference, recommendMiguel . Hernán James M. Robins’ Causal Inference: ,\n2021Jason . Roy’s Crash Course Causality: Inferring Causal Effects \nObservational Data \nCoursera","code":""},{"path":"index.html","id":"setup","chapter":"About this book","heading":"0.4 Setup instructions","text":"","code":""},{"path":"index.html","id":"r-and-rstudio","chapter":"About this book","heading":"0.4.1 R and RStudio","text":"R RStudio separate downloads installations. R \nunderlying statistical computing environment. RStudio graphical integrated\ndevelopment environment (IDE) makes using R much easier \ninteractive. need install R install RStudio.","code":""},{"path":"index.html","id":"windows","chapter":"About this book","heading":"0.4.1.1 Windows","text":"","code":""},{"path":"index.html","id":"if-you-already-have-r-and-rstudio-installed","chapter":"About this book","heading":"0.4.1.1.1 If you already have R and RStudio installed","text":"Open RStudio, click “Help” > “Check updates”. new version \navailable, quit RStudio, download latest version RStudio.check version R using, start RStudio first thing\nappears console indicates version R \nrunning. Alternatively, can type sessionInfo(), also display\nversion R running. Go CRAN\nwebsite check whether \nrecent version available. , please download install . \ncan check \ninformation remove old versions system \nwish .","code":""},{"path":"index.html","id":"if-you-dont-have-r-and-rstudio-installed","chapter":"About this book","heading":"0.4.1.1.2 If you don’t have R and RStudio installed","text":"Download R \nCRAN website.Run .exe file just downloadedGo RStudio download pageUnder Installers select RStudio x.yy.zzz - Windows\nXP/Vista/7/8 (x, y, z represent version numbers)Double click file install itOnce ’s installed, open RStudio make sure works don’t get \nerror messages.","code":""},{"path":"index.html","id":"macos-mac-os-x","chapter":"About this book","heading":"0.4.1.2 macOS / Mac OS X","text":"","code":""},{"path":"index.html","id":"if-you-already-have-r-and-rstudio-installed-1","chapter":"About this book","heading":"0.4.1.2.1 If you already have R and RStudio installed","text":"Open RStudio, click “Help” > “Check updates”. new version \navailable, quit RStudio, download latest version RStudio.check version R using, start RStudio first thing\nappears terminal indicates version R running.\nAlternatively, can type sessionInfo(), also display \nversion R running. Go CRAN\nwebsite check whether \nrecent version available. , please download install .","code":""},{"path":"index.html","id":"if-you-dont-have-r-and-rstudio-installed-1","chapter":"About this book","heading":"0.4.1.2.2 If you don’t have R and RStudio installed","text":"Download R \nCRAN website.Select .pkg file latest R versionDouble click downloaded file install RIt also good idea install XQuartz (needed\npackages)Go RStudio download\npageUnder Installers select RStudio x.yy.zzz - Mac OS X 10.6+ (64-bit)\n(x, y, z represent version numbers)Double click file install RStudioOnce ’s installed, open RStudio make sure works don’t get \nerror messages.","code":""},{"path":"index.html","id":"linux","chapter":"About this book","heading":"0.4.1.3 Linux","text":"Follow instructions distribution\nCRAN, provide information\nget recent version R common distributions. \ndistributions, use package manager (e.g., Debian/Ubuntu run\nsudo apt-get install r-base, Fedora sudo yum install R), \ndon’t recommend approach versions provided \nusually date. case, make sure least R 3.3.1.Go RStudio download\npageUnder Installers select version matches distribution, \ninstall preferred method (e.g., Debian/Ubuntu sudo dpkg -  rstudio-x.yy.zzz-amd64.deb terminal).’s installed, open RStudio make sure works don’t get \nerror messages.setup instructions adapted written Data Carpentry: R\nData Analysis Visualization Ecological\nData.","code":""},{"path":"robust.html","id":"robust","chapter":"1 Robust Statistics and Reproducible Science","heading":"1 Robust Statistics and Reproducible Science","text":"“One enemy robust science humanity – appetite \nright, tendency find patterns noise, see supporting\nevidence already believe true, ignore facts \nfit.”— Nature Editorial (Anonymous) (2015b)Scientific research unique point history. need improve\nrigor reproducibility field greater ever; corroboration moves\nscience forward, yet growing alarm results reproduced \nvalidated, suggesting possibility many discoveries may false\n(Baker 2016). Consequences meeting need result \ndecline rate scientific progress, reputation sciences, \npublic’s trust scientific findings (Munafò et al. 2017; Nature Editorial (Anonymous) 2015a).“key question want answer seeing results scientific\nstudy whether can trust data analysis.”— Peng (2015)Unfortunately, current state, culture statistical data analysis\nenables, rather precludes, manner human bias may affect \nresults (ideally objective) data analytic efforts. significant degree \nhuman bias enters statistical analysis efforts form improper model\nselection. procedures estimation hypothesis testing derived\nbased choice statistical model; thus, obtaining valid estimates \nstatistical inference relies critically chosen statistical model\ncontaining accurate representation process generated data.\nConsider, example, hypothetical study treatment assigned \ngroup patients: treatment assigned randomly characteristics\nindividuals (.e., baseline covariates) used making treatment\ndecision? knowledge can incorporated statistical model.\nAlternatively, data observational study, \ncontrol treatment assignment mechanism. cases, available\nknowledge data-generating process (DGP) limited still. \ncase, statistical model contain possible\ndistributions data. practice, however, models selected based\nscientific knowledge available DGP; instead, models often\nselected based (1) philosophical leanings analyst, (2) \nrelative convenience implementation statistical methods admissible within\nchoice model, (3) results significance testing (.e.,\np-values) applied within choice model.practice “cargo-cult statistics — ritualistic miming statistics\nrather conscientious practice,” (Stark Saltelli 2018) characterized \narbitrary modeling choices, even though choices often result different\nanswers research question. , “increasingly often,\n[statistics] used instead aid abet weak science, role can perform\nwell used mechanically ritually,” opposed original purpose \nsafeguarding weak science providing formal techniques evaluating\nveracity claim using properly collected data (Stark Saltelli 2018). \npresents fundamental drive behind epidemic false findings \nscientific research suffering (van der Laan Starmans 2014).“suggest weak statistical understanding probably due \ninadequate”statistics lite” education. approach build \nappropriate mathematical fundamentals provide scientifically\nrigorous introduction statistics. Hence, students’ knowledge may remain\nimprecise, patchy, prone serious misunderstandings. approach\nachieves, however, providing students false confidence able\nuse inferential tools whereas usually interpret p-value\nprovided black box statistical software. educational problem\nremains unaddressed, poor statistical practices prevail regardless \nprocedures measures may favored /banned editorials.”— Szucs Ioannidis (2017)team University California, Berkeley uniquely positioned \nprovide education. Spearheaded Professor Mark van der Laan, \nspreading rapidly many students colleagues greatly\nenriched field, aptly named “Targeted Learning” methodology emphasizes \nfocus (.e., “targeting ”) scientific question hand, running counter\ncurrent culture problem “convenience statistics,” opens door\nbiased estimation, misleading analytic results, erroneous discoveries.\nTargeted Learning embraces fundamentals formalized field \nstatistics, notably including notions statistical model must\nrepresent real knowledge experiment generated data \ntarget parameter represents seeking learn data \nfeature distribution generated (van der Laan Starmans 2014). way,\nTargeted Learning defines truth establishes principled standard \nestimation, thereby curtailing --human biases (e.g., hindsight bias,\nconfirmation bias, outcome bias) infiltrating objective analytic\nefforts.“key effective classical [statistical] inference \nwell-defined questions analysis plan tests questions.”— Nosek et al. (2018)handbook aims provide practical training students, researchers,\nindustry professionals, academicians sciences (whether biological,\nphysical, economic, social), public health, statistics, numerous \nfields, equip necessary knowledge skills utilize \nmethodological developments Targeted Learning — technique provides\ntailored pre-specified machines answering queries — taking advantage \nestimators efficient, minimally biased, provide formal\nstatistical inference — every data analysis incorporates\nstate---art statistical methodology, ensuring compatibility \nguiding principles computational reproducibility.Just conscientious use modern statistical methodology necessary \nensure scientific practice thrives, robust, well-tested software plays \ncritical role allowing practitioners direct access published results\ngiven scientific investigation. fact, “article…scientific\npublication scholarship , merely advertising \nscholarship. actual scholarship complete software development\nenvironment complete set instructions generated figures,”\nthus making availability adoption robust statistical software key \nenhancing transparency inherent (assumed) aspect \nscientific process (Buckheit Donoho 1995).statistical methodology readily accessible practice, \ncrucial accompanied user-friendly software\n(Pullenayegum et al. 2016; Stromberg et al. 2004). tlverse software\necosystem, composed set package R language environment \nstatistical computing (R Core Team 2021), developed fulfill need Targeted\nLearning methodological framework. suite software tools\nfacilitate computationally reproducible efficient analyses, also \ntool Targeted Learning education, since workflow mirrors central\naspects statistical methodology. particular, programming paradigm\ncentral tlverse ecosystem focus implementing specific\nestimator small set related estimators. Instead, focus \nexposing statistical framework Targeted Learning — software\npackages tlverse ecosystem directly model key objects defined \nmathematical theoretical framework Targeted Learning. ’s ,\ntlverse software packages share core set design principles centered\nextensibility, allowing used conjunction \neven used cohesively building blocks formulating sophisticated\nstatistical analyses. introduction Targeted Learning framework, \nrecommend recent review paper \nCoyle et al. (2021).handbook, reader embark journey tlverse\necosystem. Guided R programming exercises, case studies, \nintuition-building explanations, readers learn use toolbox \napplying Targeted Learning statistical methodology, translate \nreal-world causal inference analyses. preliminaries required prior \nlearning endeavor – made available list recommended learning\nresources.","code":""},{"path":"data.html","id":"data","chapter":"2 Meet the Data","heading":"2 Meet the Data","text":"Targeted Learning learning data. ’ll use example datasets throughout book. introduce chapter.","code":""},{"path":"data.html","id":"learning-objectives","chapter":"2 Meet the Data","heading":"2.1 Learning Objectives","text":"end chapter able :Understand various datasets ’ll use case studiesHave vague understanding kinds scientific questions \nmight want answer ","code":""},{"path":"data.html","id":"data-schematic","chapter":"2 Meet the Data","heading":"2.2 Schematic Example","text":"entirely artificial example three variables ’s helpful illustrating key concepts.dataset loaded withHere’s table rows data:","code":"\ndata(schematic, package=\"tlverse\")    W A        Y\n1: 10 1  4.72968\n2:  6 0 -0.20798\n3:  5 0 -0.25256\n4:  9 0 -2.04532\n5:  5 0 -0.25444\n6:  6 1  0.73052"},{"path":"data.html","id":"schematic-variables","chapter":"2 Meet the Data","heading":"2.2.1 Schematic Variables","text":"variables interpreted follows:\\(W\\) — baseline covariate, case integer ranging 1 10. can think someone’s age feature person. Usually lot , case one.\\(\\) — treatment intervention, case ’s either 0 1. can think treatment ’re interested learning effects . can say 1 means person got treatment 0 means person didn’t (got placebo nothing )\\(Y\\) — outcome, case ’s continuous measure range roughly -4 4. can think outcome ’re interested , like death. Maybe ’s good outcome, hope giving treatment ’ll increase . Maybe ’s bad outcome, hope giving treatment ’ll decrease .’s simple, ’s easy visualize single plot:want use data figure effect treatment \\(\\) outcome \\(Y\\), adjusting covariate(s) \\(W\\) (’ll see ’s important later). Generally speaking, lot data questions can framed way. course, devil details. ’ll see later important get details correctly specified.","code":""},{"path":"data.html","id":"data-washb","chapter":"2 Meet the Data","heading":"2.3 WASH Benefits","text":"data come study effect water quality, sanitation, hand washing, nutritional interventions child development rural Bangladesh (WASH Benefits Bangladesh): cluster randomized controlled trial (Tofail et al. 2018). reference, trial registered ClinicalTrials.gov NCT01590095. study enrolled pregnant women first second trimester rural villages Gazipur, Kishoreganj, Mymensingh, Tangail districts central Bangladesh, average eight women per cluster. Groups eight geographically adjacent clusters block randomized, using random number generator, six intervention groups (received weekly visits community health promoter first 6 months every 2 weeks next 18 months) double-sized control group (intervention health promoter visit). book, concentrate child growth (size age) outcome interestThis dataset loaded withTODO: tableThe six intervention groups :chlorinated drinking water;improved sanitation;hand-washing soap;combined water, sanitation, hand washing;improved nutrition counseling provision lipid-based nutrient supplements; andcombined water, sanitation, handwashing, nutrition.28 variables measured. outcome, Y, weight--height Z-score (whz dat); treatment interest, , randomized treatment group (tr dat); adjustment set, W, consists simply everything else.","code":"\ndata(tlverse_washb)"},{"path":"data.html","id":"international-stroke-trial-rachael-to-replace-with-different-dataset-for-exercises","chapter":"2 Meet the Data","heading":"2.4 International Stroke Trial (Rachael to replace with different dataset for exercises)","text":"International Stroke Trial database contains individual patient data International Stroke Trial (IST), multi-national randomized trial conducted 1991 1996 (pilot phase 1991 1993) aimed assess whether early administration aspirin, heparin, aspirin heparin, neither influenced clinical course acute ischaemic stroke (P. Sandercock et al. 1997). IST dataset includes data 19,435 patients acute stroke, 99% complete follow-. De-identified data available download https://datashare..ed.ac.uk/handle/10283/128. study described detail P. . Sandercock, Niewada, Członkowska (2011). example data handbook considers sample 5,000 patients binary outcome recurrent ischemic stroke within 14 days randomization. Also example data, ensure subjects missing outcome.26 variables measured, outcome interest, Y, indicates recurrent ischemic stroke within 14 days randomization (DRSISC ist); treatment interest, , randomized aspirin vs. aspirin treatment allocation (RXASP ist); adjustment set, W, consists variables measured baseline.dataset loaded withLike , can summarize variables measured IST sample data set skimr:TODO: table","code":"\ndata(tlverse_ist)"},{"path":"roadmap.html","id":"roadmap","chapter":"3 The Roadmap for Targeted Learning","heading":"3 The Roadmap for Targeted Learning","text":"chapter …Translate scientific questions statistical questions.Define statistical model based knowledge experiment generated data.Identify causal parameter function observed data distribution.Explain following causal statistical assumptions implications: ..d., consistency, interference, positivity, SUTVA.","code":""},{"path":"roadmap.html","id":"introduction","chapter":"3 The Roadmap for Targeted Learning","heading":"3.1 Introduction","text":"roadmap statistical learning concerned translation real-world data applications mathematical statistical formulation relevant estimation problem. involves data random variable probability distribution, scientific knowledge represented statistical model, statistical target parameter representing answer question interest, notion estimator sampling distribution estimator.","code":""},{"path":"roadmap.html","id":"the-roadmap","chapter":"3 The Roadmap for Targeted Learning","heading":"3.2 The Roadmap","text":"Following roadmap process five steps.Data: Data random variable probability distribution, \\(O\\sim P_0\\)Model: statistical model \\(\\mathcal{M}\\) \\(P_0 \\\\mathcal{M}\\)Parameter: statistical target parameter \\(\\Psi\\) estimand \\(\\Psi(P_0)\\).Estimation: estimator \\(\\hat{\\Psi}\\) estimand \\(\\hat{\\Psi}(P_n)\\).Inference: measure uncertainty estimate \\(\\hat{\\Psi}(P_n)\\)","code":""},{"path":"roadmap.html","id":"schematic-example","chapter":"3 The Roadmap for Targeted Learning","heading":"3.3 Schematic Example","text":"Remember schematic last chapter? Let’s start roadmap going talk steps detail","code":""},{"path":"roadmap.html","id":"data-step","chapter":"3 The Roadmap for Targeted Learning","heading":"3.3.1 Data Step","text":"can describe data set observations individual (’s general say experimental unit) , schematic example, can denote observation like :\\[O \\equiv (W,,Y)\\]collection facts (\\(W\\), \\(\\), \\(Y\\)) individual observation \\(O\\). think set data set observations. think observation random draw distribution possible observations denote \\(P_0\\) (subscript \\(0\\) denotes real one, ’ll use subscripts denote theoretical estimated distributions). call \\(P_0\\) probability distribution data generating distribution (DGD).observation drawn sample important. ’s called experiment. translate real world experiment probability model outside scope book. now, ’ll focus call independent identically distributed (..d.) data. means unit \\(O\\) got drawn \\(P_0\\) way. sample can change another samples outcome, samples get drawn imaginary box. Options modifications methodology available complex biased samples, repeated measures, sampling concerns.Luckily us, just data schematic dataset.","code":""},{"path":"roadmap.html","id":"model-step","chapter":"3 The Roadmap for Targeted Learning","heading":"3.3.2 Model Step","text":"Just like set observations called dataset, set possible probability distributions. might think call distribution set, don’t, call model. denote \\(\\mathcal{M}\\) write:\\[P_0 \\\\mathcal{M}\\]indicate true DGD part model. important, model doesn’t contain truth, impossible us get right answer, even infinite data!Well, can say \\(\\mathcal{M}\\)? , can say sure \\(P_0\\) might look like. Given haven’t told much data experiment, really little! ’ll see later chapters statisticians want statistics small models, can quite sure don’t contain \\(P_0\\) , makes statistics easier. now ’ll just say \\(\\mathcal{M}\\) nonparametric, essentially means can’t make assumptions .truth , can make assumptions based observed data types belief ’ve observed values variables. example, think \\(\\) can 0 1, \\(W\\)ranges 1 10. also seems like \\(Y\\) varies small range, incorporate modeling assumption fairly confident ’s true range. don’t often write things part model explicitly, part .","code":""},{"path":"roadmap.html","id":"parameter-step","chapter":"3 The Roadmap for Targeted Learning","heading":"3.3.3 Parameter Step","text":"said want know effect treatment \\(\\) outcome \\(Y\\). ’s lot ways formalize mathematically, ’s one like:\\[\\Psi_{0,\\text{TSM}}=E_W[E_{Y|,W}[Y|=1,W]]\\]call Treatment Specific Mean (TSM):Basically, want know mean \\(Y\\) every \\(W\\), set \\(=1\\). want take mean across \\(W\\)s, call “marginalizing”. say call treatment specific mean ’s mean outcome \\(Y\\) ’d expect specific treatment \\(=1\\). tells us something treatment affects outcome. However, ’d often like compare outcomes two conditions. can use pair TSMs make Average Treatment Effect (ATE):\\[\\Psi_{0,\\text{ATE}}=E_W[E_{Y|,W}[Y|=1,W]]- E_W[E_{Y|,W}[Y|=0,W]]\\]Many types parameters like relative risks odds ratios can defined simple combinations TSMs. ’ll see later can use Delta Method estimate parameters like starting estimates TSMs.","code":""},{"path":"roadmap.html","id":"estimation-step","chapter":"3 The Roadmap for Targeted Learning","heading":"3.3.4 Estimation Step","text":"Explain plug-ins hereSay ’ll see next two chapters","code":""},{"path":"roadmap.html","id":"inference-step","chapter":"3 The Roadmap for Targeted Learning","heading":"3.3.5 Inference Step","text":"’ll cover later","code":""},{"path":"roadmap.html","id":"wash-benefits-example","chapter":"3 The Roadmap for Targeted Learning","heading":"3.4 WASH Benefits Example","text":"","code":""},{"path":"roadmap.html","id":"data-step-1","chapter":"3 The Roadmap for Targeted Learning","heading":"3.4.1 Data Step","text":"still say \\(O \\equiv (W,,Y)\\), except now \\(W\\) vector many covariates.purposes handbook, say sample generated ..d . study cluster design, actually case. , available options, account clustering data.","code":""},{"path":"roadmap.html","id":"model-step-1","chapter":"3 The Roadmap for Targeted Learning","heading":"3.4.2 Model Step","text":"still don’t know anything, ’ll stick nonparametric model \\(\\mathcal{M}\\).","code":""},{"path":"roadmap.html","id":"parameter-step-1","chapter":"3 The Roadmap for Targeted Learning","heading":"3.4.3 Parameter Step","text":"like estimate TSMs every treatment level, well ATEs treatment levels control treatment.","code":""},{"path":"roadmap.html","id":"estimation-step-1","chapter":"3 The Roadmap for Targeted Learning","heading":"3.4.4 Estimation Step","text":"","code":""},{"path":"roadmap.html","id":"inference-step-1","chapter":"3 The Roadmap for Targeted Learning","heading":"3.4.5 Inference Step","text":"","code":""},{"path":"roadmap.html","id":"causal-concerns","chapter":"3 The Roadmap for Targeted Learning","heading":"3.5 Causal Concerns","text":"Current roadmap text goes ","code":""},{"path":"roadmap.html","id":"exercises","chapter":"3 The Roadmap for Targeted Learning","heading":"3.6 Exercises","text":"","code":""},{"path":"tlverse.html","id":"tlverse","chapter":"4 Welcome to the tlverse","heading":"4 Welcome to the tlverse","text":"","code":""},{"path":"origami.html","id":"origami","chapter":"5 Cross-validation","heading":"5 Cross-validation","text":"","code":""},{"path":"origami.html","id":"learning-objectives-1","chapter":"5 Cross-validation","heading":"5.1 Learning Objectives","text":"end chapter able :Differentiate training, validation test sets.Understand concept loss function, risk cross-validation.Select loss function appropriate functional parameter \nestimated.Understand contrast different cross-validation schemes ..d. data.Understand contrast different cross-validation schemes time dependent\ndata.Setup proper fold structure, build custom fold-based function, \ncross-validate proposed function using origami R package.Setup proper cross-validation structure use Super Learner\nusing origami R package.","code":""},{"path":"origami.html","id":"roadmap-review","chapter":"5 Cross-validation","heading":"5.2 Roadmap Review","text":"","code":""},{"path":"origami.html","id":"we-want-to-fit-the-data-to-estimate-q","chapter":"5 Cross-validation","heading":"5.3 We want to fit the data to estimate Q","text":"","code":""},{"path":"origami.html","id":"we-can-propose-and-test-models","chapter":"5 Cross-validation","heading":"5.4 We can propose and test models","text":"","code":""},{"path":"origami.html","id":"schematic-example-1","chapter":"5 Cross-validation","heading":"5.5 schematic example","text":"","code":""},{"path":"origami.html","id":"show-overfit-on-test-set","chapter":"5 Cross-validation","heading":"5.6 show overfit on test set","text":"","code":""},{"path":"origami.html","id":"show-cross-validation","chapter":"5 Cross-validation","heading":"5.7 show cross-validation","text":"","code":""},{"path":"origami.html","id":"washb-example","chapter":"5 Cross-validation","heading":"5.8 washb example","text":"","code":""},{"path":"origami.html","id":"advanced-usage","chapter":"5 Cross-validation","heading":"5.9 advanced usage","text":"","code":""},{"path":"sl3.html","id":"sl3","chapter":"6 Super (Machine) Learning","heading":"6 Super (Machine) Learning","text":"","code":""},{"path":"sl3.html","id":"learning-objectives-2","chapter":"6 Super (Machine) Learning","heading":"Learning Objectives","text":"end chapter able :Select objective function () aligns intention \nanalysis (ii) optimized target parameter.Select objective function () aligns intention \nanalysis (ii) optimized target parameter.Assemble diverse library learners considered Super Learner\nensemble. particular, able :\nCustomize learner modifying ’s tuning parameters.\nCreate several different versions learner \nspecifying grid tuning parameters.\nCurate covariate screening pipelines order pass screener’s\noutput, subset covariates, input another learner \nuse subset covariates selected screener model data.\nAssemble diverse library learners considered Super Learner\nensemble. particular, able :Customize learner modifying ’s tuning parameters.Create several different versions learner \nspecifying grid tuning parameters.Curate covariate screening pipelines order pass screener’s\noutput, subset covariates, input another learner \nuse subset covariates selected screener model data.Specify learner ensembling (metalearner) corresponds\nobjective function.Specify learner ensembling (metalearner) corresponds\nobjective function.Fit Super Learner ensemble nested cross-validation obtain \nestimate performance ensemble --sample data.Fit Super Learner ensemble nested cross-validation obtain \nestimate performance ensemble --sample data.Obtain sl3 variable importance metrics.Obtain sl3 variable importance metrics.Interpret fit discrete continuous Super Learners’ \ncross-validated risk table coefficients.Interpret fit discrete continuous Super Learners’ \ncross-validated risk table coefficients.Justify base library machine learning algorithms ensembling\nlearner terms prediction problem, statistical model \\(\\M\\), data\nsparsity, dimensionality covariates.Justify base library machine learning algorithms ensembling\nlearner terms prediction problem, statistical model \\(\\M\\), data\nsparsity, dimensionality covariates.","code":""},{"path":"sl3.html","id":"roadmap-review-1","chapter":"6 Super (Machine) Learning","heading":"6.1 Roadmap Review","text":"","code":""},{"path":"sl3.html","id":"we-still-want-to-fit-the-data-to-estimate-q","chapter":"6 Super (Machine) Learning","heading":"6.2 We still want to fit the data to estimate Q","text":"","code":""},{"path":"sl3.html","id":"sl3-makes-that-process-easier","chapter":"6 Super (Machine) Learning","heading":"6.3 sl3 makes that process easier","text":"","code":""},{"path":"sl3.html","id":"schematic-example-2","chapter":"6 Super (Machine) Learning","heading":"6.4 schematic example","text":"TODO: define glm learners fit following:\nEY = 0.2(-10  + W - 0.2W^2 + 0.4A*W^2)","code":""},{"path":"sl3.html","id":"washb-example-1","chapter":"6 Super (Machine) Learning","heading":"6.5 washb example","text":"","code":""},{"path":"sl3.html","id":"advanced-usage-1","chapter":"6 Super (Machine) Learning","heading":"6.6 advanced usage","text":"","code":""},{"path":"tmle3.html","id":"tmle3","chapter":"7 The TMLE Framework","heading":"7 The TMLE Framework","text":"","code":""},{"path":"tmle3.html","id":"learn-tmle","chapter":"7 The TMLE Framework","heading":"7.1 Learning Objectives","text":"end chapter, able toUnderstand use TMLE effect estimation.Use tmle3 estimate Average Treatment Effect (ATE).Understand use tmle3 “Specs” objects.Fit tmle3 custom set target parameters.Use delta method estimate transformations target parameters.","code":""},{"path":"tmle3.html","id":"roadmap-review-2","chapter":"7 The TMLE Framework","heading":"7.2 Roadmap Review","text":"","code":""},{"path":"tmle3.html","id":"we-want-to-estimate-psi-better","chapter":"7 The TMLE Framework","heading":"7.3 We want to estimate psi better","text":"","code":""},{"path":"tmle3.html","id":"we-also-want-inference","chapter":"7 The TMLE Framework","heading":"7.4 We also want inference","text":"","code":""},{"path":"tmle3.html","id":"schematic-example-3","chapter":"7 The TMLE Framework","heading":"7.5 schematic example","text":"","code":""},{"path":"tmle3.html","id":"washb-example-2","chapter":"7 The TMLE Framework","heading":"7.6 washb example","text":"","code":""},{"path":"tmle3.html","id":"advanced-usage-2","chapter":"7 The TMLE Framework","heading":"7.7 advanced usage","text":"","code":""},{"path":"r6.html","id":"r6","chapter":"8 A Primer on the R6 Class System","heading":"8 A Primer on the R6 Class System","text":"central goal Targeted Learning statistical paradigm estimate\nscientifically relevant parameters realistic (usually nonparametric) models.tlverse designed using basic OOP principles R6 OOP framework.\n’ve tried make easy use tlverse packages without worrying\nmuch OOP, helpful intuition tlverse \nstructured. , briefly outline key concepts OOP. Readers\nfamiliar OOP basics invited skip section.","code":""},{"path":"r6.html","id":"classes-fields-and-methods","chapter":"8 A Primer on the R6 Class System","heading":"8.1 Classes, Fields, and Methods","text":"key concept OOP object, collection data functions\ncorresponds conceptual unit. Objects two main types \nelements:fields, can thought nouns, information object,\nandmethods, can thought verbs, actions object can\nperform.Objects members classes, define specific fields \nmethods . Classes can inherit elements classes (sometimes called\nbase classes) – accordingly, classes similar, exactly \n, can share parts definitions.Many different implementations OOP exist, variations \nconcepts implemented used. R several different implementations,\nincluding S3, S4, reference classes, R6. tlverse uses R6\nimplementation. R6, methods fields class object accessed using\n$ operator. thorough introduction R’s various OOP systems,\nsee http://adv-r..co.nz/OO-essentials.html, Hadley Wickham’s Advanced\nR (Wickham 2014).","code":""},{"path":"r6.html","id":"object-oriented-programming-python-and-r","chapter":"8 A Primer on the R6 Class System","heading":"8.2 Object Oriented Programming: Python and R","text":"OO concepts (classes inherentence) baked Python first\npublished version (version 0.9 1991). contrast, R gets OO “approach”\npredecessor, S, first released 1976. first 15 years, S\nsupport classes, , suddenly, S got two OO frameworks bolted \nrapid succession: informal classes S3 1991, formal classes \nS4 1998. process continues, new OO frameworks periodically\nreleased, try improve lackluster OO support R, reference\nclasses (R5, 2010) R6 (2014). , R6 behaves like Python\nclasses (also like OOP focused languages like C++ Java), including\nmethod definitions part class definitions, allowing objects \nmodified reference.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
