[
["index.html", "The Hitchhiker’s Guide to the tlverse or a Targeted Learning Practitioner’s Handbook Preface About this book Outline What this book is not About the authors Acknowledgements 0.1 Recommended Learning Resources 0.2 Setup instructions", " The Hitchhiker’s Guide to the tlverse or a Targeted Learning Practitioner’s Handbook Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips, Alan Hubbard, Mark van der Laan November 25, 2019 Preface About this book The Hitchhiker’s Guide to the tlverse, or a Targeted Learning Practitioner’s Handbook is an open-source and fully-reproducible electronic handbook for applying the targeted learning methodology in practice using the tlverse software ecosystem. This work is currently in an early draft phase and is available to facilitate input from the community. To view or contribute to the available content, consider visiting the GitHub repository for this site. Outline The contents of this handbook are meant to serve as a reference guide for applied research as well as materials that can be taught in a series of short courses focused on the applications of Targeted Learning. Each section introduces a set of distinct causal questions, motivated by a case study, alongside statistical methodology and software for assessing the causal claim of interest. The (evolving) set of materials includes Motivation: Why we need a statistical revolution The Roadmap and introductory case study: the WASH Beneifits data Introduction to the tlverse software ecosystem Ensemble machine learning with the sl3 package Targeted learning for causal inference with the tmle3 package Optimal treatments regimes and the tmle3mopttx package Stochastic treatment regimes and the tmle3shift package Coda: Why we need a statistical revolution What this book is not The focus of this work is not on providing in-depth technical descriptions of current statistical methodology or recent advancements. Instead, the goal is to convey key details of state-of-the-art techniques in an manner that is both clear and complete, without burdening the reader with extraneous information. We hope that the presentations herein will serve as references for researchers – methodologists and domain specialists alike – that empower them to deploy the central tools of Targeted Learning in an efficient manner. For technical details and in-depth descriptions of both classical theory and recent advances in the field of Targeted Learning, the interested reader is invited to consult van der Laan and Rose (2011) and/or van der Laan and Rose (2018) as appropriate. The primary literature in statistical causal inference, machine learning, and non/semiparametric theory include many of the most recent advances in Targeted Learning and related areas. About the authors Jeremy Coyle Jeremy R. Coyle, Ph.D., is a consulting data scientist and statistical programmer, currently leading the software development effort that has produced the tlverse ecosystem of R packages and related software tools. Jeremy earned his Ph.D. in Biostatistics from UC Berkeley in 2016, primarily under the supervision of Alan Hubbard. Nima Hejazi Nima S. Hejazi is a Ph.D. candidate in biostatistics with a designated emphasis in computational and genomic biology, working jointly with Mark van der Laan and Alan Hubbard. Nima is affiliated with UC Berkeley’s Center for Computational Biology and NIH Biomedical Big Data training program. His research interests span causal inference, nonparametric inference and machine learning, targeted loss-based estimation, survival analysis, statistical computing, reproducible research, and high-dimensional biology. He is also passionate about software development for applied statistics, including software design, automated testing, and reproducible coding practices. For more information, see https://nimahejazi.org. Ivana Malenica Ivana Malenica is a Ph.D. student in biostatistics advised by Mark van der Laan. Ivana is currently a fellow at the Berkeley Institute for Data Science, after serving as a NIH Biomedical Big Data and Freeport-McMoRan Genomic Engine fellow. She earned her Master’s in Biostatistics and Bachelor’s in Mathematics, and spent some time at the Translational Genomics Research Institute. Very broadly, her research interests span non/semi-parametric theory, probability theory, machine learning, causal inference and high-dimensional statistics. Most of her current work involves complex dependent settings (dependence through time and network) and adaptive sequential designs. Rachael Phillips Rachael is a Ph.D. student in biostatistics, advised by Alan Hubbard and Mark van der Laan. She has an M.A. in Biostatistics, B.S. in Biology with a Chemistry minor and a B.A. in Mathematics with a Spanish minor. Her research is applied, and specific to human health. Motivated by issues arising in healthcare, Rachael leverages strategies rooted in causal inference and nonparametric estimation to build clinician-tailored, machine-driven solutions. Her accompanying statistical interests include high-dimensional statistics and experimental design. She is also passionate about free, online-mediated education. She is affiliated with the UC Berkeley Center for Computational Biology, NIH Biomedical Big Data Training Program, and Superfund Research Program. Alan Hubbard Alan E. Hubbard is Professor of Biostatistics, former head of the Division of Biostatistics at UC Berkeley, and head of data analytics core at UC Berkeley’s SuperFund research program. His current research interests include causal inference, variable importance analysis, statistical machine learning, estimation of and inference for data-adaptive statistical target parameters, and targeted minimum loss-based estimation. Research in his group is generally motivated by applications to problems in computational biology, epidemiology, and precision medicine. Mark van der Laan Mark J. van der Laan, PhD, is Professor of Biostatistics and Statistics at UC Berkeley. His research interests include statistical methods in computational biology, survival analysis, censored data, adaptive designs, targeted maximum likelihood estimation, causal inference, data-adaptive loss-based learning, and multiple testing. His research group developed loss-based super learning in semiparametric models, based on cross-validation, as a generic optimal tool for the estimation of infinite-dimensional parameters, such as nonparametric density estimation and prediction with both censored and uncensored data. Building on this work, his research group developed targeted maximum likelihood estimation for a target parameter of the data-generating distribution in arbitrary semiparametric and nonparametric models, as a generic optimal methodology for statistical and causal inference. Most recently, Mark’s group has focused in part on the development of a centralized, principled set of software tools for targeted learning, the tlverse. For more information, see https://vanderlaan-lab.org. Acknowledgements 0.1 Recommended Learning Resources To effectively utilize this handbook, the reader need not be a fully trained statistician to begin understanding and applying these methods. However, it is highly recommended for the reader to have an understanding of basic statistical concepts such as confounding, probability distributions, confidence intervals, hypothesis tests, and regression. Advanced knowledge of mathematical statistics may be useful but is not necessary. Familiarity with the R programming language will be essential. We also recommend an understanding of introductory causal inference. For learning the R programming language we recommend the following (free) introductory resources: Software Carpentry’s Programming with R Software Carpentry’s R for Reproducible Scientific Analysis Garret Grolemund and Hadley Wickham’s R for Data Science For a general introduction to causal inference, we recommend Miguel A. Hernán and James M. Robins’ Causal Inference, forthcoming 2019 Jason A. Roy’s A Crash Course in Causality: Inferring Causal Effects from Observational Data on Coursera 0.2 Setup instructions 0.2.1 R and RStudio R and RStudio are separate downloads and installations. R is the underlying statistical computing environment. RStudio is a graphical integrated development environment (IDE) that makes using R much easier and more interactive. You need to install R before you install RStudio. 0.2.1.1 Windows 0.2.1.1.1 If you already have R and RStudio installed Open RStudio, and click on “Help” &gt; “Check for updates”. If a new version is available, quit RStudio, and download the latest version for RStudio. To check which version of R you are using, start RStudio and the first thing that appears in the console indicates the version of R you are running. Alternatively, you can type sessionInfo(), which will also display which version of R you are running. Go on the CRAN website and check whether a more recent version is available. If so, please download and install it. You can check here for more information on how to remove old versions from your system if you wish to do so. 0.2.1.1.2 If you don’t have R and RStudio installed Download R from the CRAN website. Run the .exe file that was just downloaded Go to the RStudio download page Under Installers select RStudio x.yy.zzz - Windows XP/Vista/7/8 (where x, y, and z represent version numbers) Double click the file to install it Once it’s installed, open RStudio to make sure it works and you don’t get any error messages. 0.2.1.2 macOS 0.2.1.2.1 If you already have R and RStudio installed Open RStudio, and click on “Help” &gt; “Check for updates”. If a new version is available, quit RStudio, and download the latest version for RStudio. To check the version of R you are using, start RStudio and the first thing that appears on the terminal indicates the version of R you are running. Alternatively, you can type sessionInfo(), which will also display which version of R you are running. Go on the CRAN website and check whether a more recent version is available. If so, please download and install it. 0.2.1.2.2 If you don’t have R and RStudio installed Download R from the CRAN website. Select the .pkg file for the latest R version Double click on the downloaded file to install R It is also a good idea to install XQuartz (needed by some packages) Go to the RStudio download page Under Installers select RStudio x.yy.zzz - Mac OS X 10.6+ (64-bit) (where x, y, and z represent version numbers) Double click the file to install RStudio Once it’s installed, open RStudio to make sure it works and you don’t get any error messages. 0.2.1.3 Linux Follow the instructions for your distribution from CRAN, they provide information to get the most recent version of R for common distributions. For most distributions, you could use your package manager (e.g., for Debian/Ubuntu run sudo apt-get install r-base, and for Fedora sudo yum install R), but we don’t recommend this approach as the versions provided by this are usually out of date. In any case, make sure you have at least R 3.3.1. Go to the RStudio download page Under Installers select the version that matches your distribution, and install it with your preferred method (e.g., with Debian/Ubuntu sudo dpkg -i rstudio-x.yy.zzz-amd64.deb at the terminal). Once it’s installed, open RStudio to make sure it works and you don’t get any error messages. These setup instructions are adapted from those written for Data Carpentry: R for Data Analysis and Visualization of Ecological Data. References "],
["motivation.html", "Motivation", " Motivation “One enemy of robust science is our humanity — our appetite for being right, and our tendency to find patterns in noise, to see supporting evidence for what we already believe is true, and to ignore the facts that do not fit.” — (“Let’s Think About Cognitive Bias” 2015) Scientific research is at a unique point in history. The need to improve rigor and reproducibility in our field is greater than ever; corroboration moves science forward, yet there is a growing alarm about results that cannot be reproduced and that report false discoveries (Baker 2016). Consequences of not meeting this need will result in further decline in the rate of scientific progression, the reputation of the sciences, and the public’s trust in its findings (Munafò et al. 2017; “How Scientists Fool Themselves – and How They Can Stop” 2015). “The key question we want to answer when seeing the results of any scientific study is whether we can trust the data analysis.” — Peng (2015) Unfortunately, at its current state the culture of data analysis and statistics actually enables human bias through improper model selection. All hypothesis tests and estimators are derived from statistical models, so to obtain valid estimates and inference it is critical that the statistical model contains the process that generated the data. Perhaps treatment was randomized or only depended on a small number of baseline covariates; this knowledge should and can be incorporated in the model. Alternatively, maybe the data is observational, and there is no knowledge about the data-generating process (DGP). If this is the case, then the statistical model should contain all data distributions. In practice; however, models are not selected based on knowledge of the DGP, instead models are often selected based on (1) the p-values they yield, (2) their convenience of implementation, and/or (3) an analysts loyalty to a particular model. This practice of “cargo-cult statistics — the ritualistic miming of statistics rather than conscientious practice,” (Stark and Saltelli 2018) is characterized by arbitrary modeling choices, even though these choices often result in different answers to the same research question. That is, “increasingly often, [statistics] is used instead to aid and abet weak science, a role it can perform well when used mechanically or ritually,” as opposed to its original purpose of safeguarding against weak science (Stark and Saltelli 2018). This presents a fundamental drive behind the epidemic of false findings that scientific research is suffering from (van der Laan and Starmans 2014). “We suggest that the weak statistical understanding is probably due to inadequate”statistics lite&quot; education. This approach does not build up appropriate mathematical fundamentals and does not provide scientifically rigorous introduction into statistics. Hence, students’ knowledge may remain imprecise, patchy, and prone to serious misunderstandings. What this approach achieves, however, is providing students with false confidence of being able to use inferential tools whereas they usually only interpret the p-value provided by black box statistical software. While this educational problem remains unaddressed, poor statistical practices will prevail regardless of what procedures and measures may be favored and/or banned by editorials.&quot; — Szucs and Ioannidis (2017) Our team at The University of California, Berkeley, is uniquely positioned to provide such an education. Spearheaded by Professor Mark van der Laan, and spreading rapidly by many of his students and colleagues who have greatly enriched the field, the aptly named “Targeted Learning” methodology targets the scientific question at hand and is counter to the current culture of “convenience statistics” which opens the door to biased estimation, misleading results, and false discoveries. Targeted Learning restores the fundamentals that formalized the field of statistics, such as the that facts that a statistical model represents real knowledge about the experiment that generated the data, and a target parameter represents what we are seeking to learn from the data as a feature of the distribution that generated it (van der Laan and Starmans 2014). In this way, Targeted Learning defines a truth and establishes a principled standard for estimation, thereby inhibiting these all-too-human biases (e.g., hindsight bias, confirmation bias, and outcome bias) from infiltrating analysis. “The key for effective classical [statistical] inference is to have well-defined questions and an analysis plan that tests those questions.” — Nosek et al. (2018) The objective for this handbook is to provide training to students, researchers, industry professionals, faculty in science, public health, statistics, and other fields to empower them with the necessary knowledge and skills to utilize the sound methodology of Targeted Learning — a technique that provides tailored pre-specified machines for answering queries, so that each data analysis is completely reproducible, and estimators are efficient, minimally biased, and provide formal statistical inference. Just as the conscientious use of modern statistical methodology is necessary to ensure that scientific practice thrives, it remains critical to acknowledge the role that robust software plays in allowing practitioners direct access to published results. We recall that “an article…in a scientific publication is not the scholarship itself, it is merely advertising of the scholarship. The actual scholarship is the complete software development environment and the complete set of instructions which generated the figures,” thus making the availability and adoption of robust statistical software key to enhancing the transparency that is an inherent aspect of science (Buckheit and Donoho 1995). For a statistical methodology to be readily accessible in practice, it is crucial that it is accompanied by robust user-friendly software (Pullenayegum et al. 2016; Stromberg and others 2004). The tlverse software ecosystem was developed to fulfill this need for the Targeted Learning methodology. Not only does this software facilitate computationally reproducible and efficient analyses, it is also a tool for Targeted Learning education since its workflow mirrors that of the methodology. In particular, the tlverse paradigm does not focus on implementing a specific estimator or a small set of related estimators. Instead, the focus is on exposing the statistical framework of Targeted Learning itself — all R packages in the tlverse ecosystem directly model the key objects defined in the mathematical and theoretical framework of Targeted Learning. What’s more, the tlverse R packages share a core set of design principles centered on extensibility, allowing for them to be used in conjunction with each other and built upon one other in a cohesive fashion. In this handbook, the reader will embark on a journey through the tlverse ecosystem. Guided by R programming exercises, case studies, and intuitive explanation readers will build a toolbox for applying the Targeted Learning statistical methodology, which will translate to real-world causal inference analyses. Some preliminaries are required prior to this learning endeavor – we have made available a list of recommended learning resources. References "],
["intro.html", "Chapter 1 The Roadmap for Targeted Learning 1.1 Learning Objectives 1.2 Introduction 1.3 The Roadmap 1.4 Summary of the Roadmap 1.5 Causal Target Parameters 1.6 The WASH Benefits Example Dataset", " Chapter 1 The Roadmap for Targeted Learning 1.1 Learning Objectives By the end of this chapter you will be able to: Translate scientific questions to statistical questions. Define a statistical model based on the knowledge of the experiment that generated the data. Identify a causal parameter as a function of the observed data distribution. Explain the following causal and statistical assumptions and their implications: i.i.d., consistency, interference, positivity, SUTVA. 1.2 Introduction The roadmap of statistical learning is concerned with the translation from real-world data applications to a mathematical and statistical formulation of the relevant estimation problem. This involves data as a random variable having a probability distribution, scientific knowledge represented by a statistical model, a statistical target parameter representing an answer to the question of interest, and the notion of an estimator and sampling distribution of the estimator. 1.3 The Roadmap Following the roadmap is a process of five stages. Data as a random variable with a probability distribution, \\(O \\sim P_0\\). The statistical model \\(\\mathcal{M}\\) such that \\(P_0 \\in \\mathcal{M}\\). The statistical target parameter \\(\\Psi\\) and estimand \\(\\Psi(P_0)\\). The estimator \\(\\hat{\\Psi}\\) and estimate \\(\\hat{\\Psi}(P_n)\\). A measure of uncertainty for the estimate \\(\\hat{\\Psi}(P_n)\\). (1) Data as a random variable with a probability distribution, \\(O \\sim P_0\\) The data set we’re confronted with is the result of an experiment and we can view the data as a random variable, \\(O\\), because if we repeat the experiment we would have a different realization of this experiment. In particular, if we repeat the experiment many times we could learn the probability distribution, \\(P_0\\), of our data. So, the observed data \\(O\\) with probability distribution \\(P_0\\) are \\(n\\) independent identically distributed (i.i.d.) observations of the random variable \\(O; O_1, \\ldots, O_n\\). Note that while not all data are i.i.d., there are ways to handle non-i.i.d. data, such as establishing conditional independence, stratifying data to create sets of identically distributed data, etc. It is crucial that researchers be absolutely clear about what they actually know about the data-generating distribution for a given problem of interest. Unfortunately, communication between statisticians and researchers is often fraught with misinterpretation. The roadmap provides a mechanism by which to ensure clear communication between research and statistician – it truly helps with this communication! The empirical probability measure, \\(P_n\\) Once we have \\(n\\) of such i.i.d. observations we have an empirical probability measure, \\(P_n\\). The empirical probability measure is an approximation of the true probability measure \\(P_0\\), allowing us to learn from our data. For example, we can define the empirical probability measure of a set, \\(A\\), to be the proportion of observations which end up in \\(A\\). That is, \\[\\begin{equation*} P_n(A) = \\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{I}(O_i \\in A) \\end{equation*}\\] In order to start learning something, we need to ask “What do we know about the probability distribution of the data?” This brings us to Step 2. (2) The statistical model \\(\\mathcal{M}\\) such that \\(P_0 \\in \\mathcal{M}\\) The statistical model \\(\\mathcal{M}\\) is defined by the question we asked at the end of . It is defined as the set of possible probability distributions for our observed data. Often \\(\\mathcal{M}\\) is very large (possibly infinite-dimensional), to reflect the fact that statistical knowledge is limited. In the case that \\(\\mathcal{M}\\) is infinite-dimensional, we deem this a nonparametric statistical model. Alternatively, if the probability distribution of the data at hand is described by a finite number of parameters, then the statistical model is parametric. In this case, we prescribe to the belief that the random variable \\(O\\) being observed has, e.g., a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\). More formally, a parametric model may be defined \\[\\begin{equation*} \\mathcal{M} = \\{P_{\\theta} : \\theta \\in \\mathcal{R}^d \\} \\end{equation*}\\] Sadly, the assumption that the data-generating distribution has a specific, parametric forms is all-too-common, even when such is a leap of faith. This practice of oversimplification in the current culture of data analysis typically derails any attempt at trying to answer the scientific question at hand; alas, such statements as the ever-popular quip of Box that “All models are wrong but some are useful,” encourage the data analyst to make arbitrary choices even when that often force significant differences in answers to the same estimation problem. The Targeted Learning paradigm does not suffer from this bias since it defines the statistical model through a representation of the true data-generating distribution corresponding to the observed data. Now, on to Step 3: ``What are we trying to learn from the data?&quot; (3) The statistical target parameter \\(\\Psi\\) and estimand \\(\\Psi(P_0)\\) The statistical target parameter, \\(\\Psi\\), is defined as a mapping from the statistical model, \\(\\mathcal{M}\\), to the parameter space (i.e., a real number) \\(\\mathcal{R}\\). That is, \\(\\Psi: \\mathcal{M}\\rightarrow\\mathbb{R}\\). The target parameter may be seen as a representation of the quantity that we wish to learn from the data, the answer to a well-specified (often causal) question of interest. In contrast to purely statistical target parameters, causal target parameters require identification from the observed data, based on causal models that include several untestable assumptions, described in more detail in the section on causal target parameters. For a simple example, consider a data set which contains observations of a survival time on every subject, for which our question of interest is “What’s the probability that someone lives longer than five years?” We have, \\[\\begin{equation*} \\Psi(P_0) = \\mathbb{P}(O &gt; 5) \\end{equation*}\\] This answer to this question is the estimand, \\(\\Psi(P_0)\\), which is the quantity we’re trying to learn from the data. Once we have defined \\(O\\), \\(\\mathcal{M}\\) and \\(\\Psi(P_0)\\) we have formally defined the statistical estimation problem. (4) The estimator \\(\\hat{\\Psi}\\) and estimate \\(\\hat{\\Psi}(P_n)\\) To obtain a good approximation of the estimand, we need an estimator, an a priori-specified algorithm defined as a mapping from the set of possible empirical distributions, \\(P_n\\), which live in a non-parametric statistical model, \\(\\mathcal{M}_{NP}\\) (\\(P_n \\in \\mathcal{M}_{NP}\\)), to the parameter space of the parameter of interest. That is, \\(\\hat{\\Psi} : \\mathcal{M}_{NP} \\rightarrow \\mathbb{R}^d\\). The estimator is a function that takes as input the observed data, a realization of \\(P_n\\), and gives as output a value in the parameter space, which is the estimate, \\(\\hat{\\Psi}(P_n)\\). Where the estimator may be seen as an operator that maps the observed data and corresponding empirical distribution to a value in the parameter space, the numerical output that produced such a function is the estimate. Thus, it is an element of the parameter space based on the empirical probability distribution of the observed data. If we plug in a realization of \\(P_n\\) (based on a sample size \\(n\\) of the random variable \\(O\\)), we get back an estimate \\(\\hat{\\Psi}(P_n)\\) of the true parameter value \\(\\Psi(P_0)\\). In order to quantify the uncertainty in our estimate of the target parameter (i.e., to construct statistical inference), an understanding of the sampling distribution of our estimator will be necessary. This brings us to Step 5. (5) A measure of uncertainty for the estimate \\(\\hat{\\Psi}(P_n)\\) Since the estimator \\(\\hat{\\Psi}\\) is a function of the empirical distribution \\(P_n\\), the estimator itself is a random variable with a sampling distribution. So, if we repeat the experiment of drawing \\(n\\) observations we would every time end up with a different realization of our estimate and our estimator has a sampling distribution. The sampling distribution of an estimator can be theoretically validated to be approximately normally distributed by a Central Limit Theorem (CLT). A class of Central Limit Theorems (CLTs) are statements regarding the convergence of the sampling distribution of an estimator to a normal distribution. In general, we will construct estimators whose limit sampling distributions may be shown to be approximately normal distributed as sample size increases. For large enough \\(n\\) we have, \\[\\begin{equation*} \\hat{\\Psi}(P_n) \\sim N \\left(\\Psi(P_0), \\frac{\\sigma^2}{n}\\right), \\end{equation*}\\] permitting statistical inference. Now, we can proceed to quantify the uncertainty of our chosen estimator by construction of hypothesis tests and confidence intervals. For example, we may construct a confidence interval at level \\((1 - \\alpha)\\) for our estimand, \\(\\Psi(P_0)\\): \\[\\begin{equation*} \\hat{\\Psi}(P_n) \\pm z_{1 - \\frac{\\alpha}{2}} \\left(\\frac{\\sigma}{\\sqrt{n}}\\right), \\end{equation*}\\] where \\(z_{1 - \\frac{\\alpha}{2}}\\) is the \\((1 - \\frac{\\alpha}{2})^\\text{th}\\) quantile of the standard normal distribution. Often, we will be interested in constructing 95% confidence intervals, corresponding to mass \\(\\alpha = 0.05\\) in either tail of the limit distribution; thus, we will typically take \\(z_{1 - \\frac{\\alpha}{2}} \\approx 1.96\\). Note: we will typically have to estimate the standard error, \\(\\frac{\\sigma}{\\sqrt{n}}\\). A 95% confidence interval means that if we were to take 100 different samples of size \\(n\\) and compute a 95% confidence interval for each sample then approximately 95 of the 100 confidence intervals would contain the estimand, \\(\\Psi(P_0)\\). More practically, this means that there is a 95% probability (or 95% confidence) that the confidence interval procedure will contain the true estimand. However, any single estimated confidence interval either will contain the true estimand or will not. 1.4 Summary of the Roadmap Data, \\(O\\), is viewed as a random variable that has a probability distribution. We often have \\(n\\) units of independent identically distributed units with probability distribution \\(P_0\\) (\\(O_1, \\ldots, O_n \\sim P_0\\)). We have statistical knowledge about the experiment that generated this data. In other words, we make a statement that the true data distribution \\(P_0\\) falls in a certain set called a statistical model, \\(\\mathcal{M}\\). Often these sets are very large because statistical knowledge is very limited so these statistical models are often infinite dimensional models. Our statistical query is, “What are we trying to learn from the data?” denoted by the statistical target parameter, \\(\\Psi\\), which maps the \\(P_0\\) into the estimand, \\(\\Psi(P_0)\\). At this point the statistical estimation problem is formally defined and now we will need statistical theory to guide us in the construction of estimators. There’s a lot of statistical theory we will review in this course that, in particular, relies on the Central Limit Theorem, allowing us to come up with estimators that are approximately normally distributed and also allowing us to come with statistical inference (i.e., confidence intervals and hypothesis tests). 1.5 Causal Target Parameters 1.5.1 The Causal Model The next step in the roadmap is to use a causal framework to formalize the experiment and thereby define the parameter of interest. Causal graphs are one useful tool to express what we know about the causal relations among variables that are relevant to the question under study (Pearl 2009). While directed acyclic graphs (DAGs) provide a convenient means by which to visualize causal relations between variables, the same causal relations among variables can be represented via a set of structural equations: \\[\\begin{align*} W &amp;= f_W(U_W) \\\\ A &amp;= f_A(W, U_A) \\\\ Y &amp;= f_Y(W, A, U_Y), \\end{align*}\\] where \\(U_W\\), \\(U_A\\), and \\(U_Y\\) represent the unmeasured exogenous background characteristics that influence the value of each variable. In the NPSEM, \\(f_W\\), \\(f_A\\) and \\(f_Y\\) denote that each variable (for \\(W\\), \\(A\\) and \\(Y\\), respectively) is a function of its parents and unmeasured background characteristics, but note that there is no imposition of any particular functional constraints. For this reason, they are called non-parametric structural equation models (NPSEMs). The DAG and set of nonparametric structural equations represent exactly the same information and so may be used interchangeably. The first hypothetical experiment we will consider is assigning exposure to the whole population and observing the outcome, and then assigning no exposure to the whole population and observing the outcome. On the nonparametric structural equations, this corresponds to a comparison of the outcome distribution in the population under two interventions: \\(A\\) is set to \\(1\\) for all individuals, and \\(A\\) is set to \\(0\\) for all individuals. These interventions imply two new nonparametric structural equation models. For the case \\(A = 1\\), we have \\[\\begin{align*} W &amp;= f_W(U_W) \\\\ A &amp;= 1 \\\\ Y(1) &amp;= f_Y(W, 1, U_Y), \\end{align*}\\] and for the case \\(A=0\\), \\[\\begin{align*} W &amp;= f_W(U_W) \\\\ A &amp;= 0 \\\\ Y(0) &amp;= f_Y(W, 0, U_Y). \\end{align*}\\] In these equations, \\(A\\) is no longer a function of \\(W\\) because we have intervened on the system, setting \\(A\\) deterministically to either of the values \\(1\\) or \\(0\\). The new symbols \\(Y(1)\\) and \\(Y(0)\\) indicate the outcome variable in our population if it were generated by the respective NPSEMs above; these are often called counterfactuals (since they run contrary-to-fact). The difference between the means of the outcome under these two interventions defines a parameter that is often called the “average treatment effect” (ATE), denoted \\[\\begin{equation}\\label{eqn:ate} ATE = \\mathbb{E}_X(Y(1)-Y(0)), \\end{equation}\\] where \\(\\mathbb{E}_X\\) is the mean under the theoretical (unobserved) full data \\(X = (W, Y(1), Y(0))\\). 1.5.2 Identifiability Because we can never observe both \\(Y(0)\\) (the counterfactual outcome when \\(A=0\\)) and \\(Y(1)\\) (similarly, the counterfactual outcome when \\(A=1\\)), we cannot estimate directly. Instead, we have to make assumptions under which this quantity may be estimated from the observed data \\(O \\sim P_0\\) under the data-generating distribution \\(P_0\\). Fortunately, given the causal model specified in the NPSEM above, we can, with a handful of untestable assumptions, estimate the ATE, even from observational data. These assumptions may be summarized as follows The causal graph implies \\(Y(a) \\perp A\\) for all \\(a \\in \\mathcal{A}\\), which is the randomization assumption. In the case of observational data, the analogous assumption is strong ignorability or no unmeasured confounding \\(Y(a) \\perp A \\mid W\\) for all \\(a \\in \\mathcal{A}\\); Although not represented in the causal graph, also required is the assumption of no interference between units, that is, the outcome for unit \\(i\\) \\(Y_i\\) is not affected by exposure for unit \\(j\\) \\(A_j\\) unless \\(i=j\\); Consistency of the treatment mechanism is also required, i.e., the outcome for unit \\(i\\) is \\(Y_i(a)\\) whenever \\(A_i = a\\), an assumption also known as “no other versions of treatment”; It is also necessary that all observed units, across strata defined by \\(W\\), have a bounded (non-deterministic) probability of receiving treatment – that is, \\(0 &lt; \\mathbb{P}(A = a \\mid W) &lt; 1\\) for all \\(a\\) and \\(W\\)). This assumption is referred to as positivity or overlap. Remark: Together, (2) and (3), the assumptions of no interference and consistency, respectively, are jointly referred to as the stable unit treatment value assumption (SUTVA). Given these assumptions, the ATE may be re-written as a function of \\(P_0\\), specifically \\[\\begin{equation}\\label{eqn:estimand} ATE = \\mathbb{E}_0(Y(1) - Y(0)) = \\mathbb{E}_0 \\left(\\mathbb{E}_0[Y \\mid A = 1, W] - \\mathbb{E}_0[Y \\mid A = 0, W]\\right), \\end{equation}\\] or the difference in the predicted outcome values for each subject, under the contrast of treatment conditions (\\(A = 0\\) vs. \\(A = 1\\)), in the population, averaged over all observations. Thus, a parameter of a theoretical “full” data distribution can be represented as an estimand of the observed data distribution. Significantly, there is nothing about the representation in that requires parameteric assumptions; thus, the regressions on the right hand side may be estimated freely with machine learning. With different parameters, there will be potentially different identifiability assumptions and the resulting estimands can be functions of different components of \\(P_0\\). We discuss several more complex estimands in later sections of this workshop. 1.6 The WASH Benefits Example Dataset The data come from a study of the effect of water quality, sanitation, hand washing, and nutritional interventions on child development in rural Bangladesh (WASH Benefits Bangladesh): a cluster-randomised controlled trial (“Temporary,” n.d.). The study enrolled pregnant women in their first or second trimester from the rural villages of Gazipur, Kishoreganj, Mymensingh, and Tangail districts of central Bangladesh, with an average of eight women per cluster. Groups of eight geographically adjacent clusters were block-randomised, using a random number generator, into six intervention groups (all of which received weekly visits from a community health promoter for the first 6 months and every 2 weeks for the next 18 months) and a double-sized control group (no intervention or health promoter visit). The six intervention groups were: chlorinated drinking water; improved sanitation; handwashing with soap; combined water, sanitation, and hand washing; improved nutrition through counseling and provision of lipid-based nutrient supplements; and combined water, sanitation, handwashing, and nutrition. In the workshop, we concentrate on child growth (size for age) as the outcome of interest. For reference, this trial was registered with ClinicalTrials.gov as NCT01590095. library(tidyverse) library(data.table) library(knitr) library(kableExtra) # read in data dat &lt;- fread(&quot;https://raw.githubusercontent.com/tlverse/tlverse-data/master/wash-benefits/washb_data.csv&quot;, stringsAsFactors = TRUE) head(dat) %&gt;% kable(digits = 4) %&gt;% kableExtra:::kable_styling(fixed_thead = T) %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;300px&quot;) whz tr fracode month aged sex momage momedu momheight hfiacat Nlt18 Ncomp watmin elec floor walls roof asset_wardrobe asset_table asset_chair asset_khat asset_chouki asset_tv asset_refrig asset_bike asset_moto asset_sewmach asset_mobile 0.00 Control N05265 9 268 male 30 Primary (1-5y) 146.40 Food Secure 3 11 0 1 0 1 1 0 1 1 1 0 1 0 0 0 0 1 -1.16 Control N05265 9 286 male 25 Primary (1-5y) 148.75 Moderately Food Insecure 2 4 0 1 0 1 1 0 1 0 1 1 0 0 0 0 0 1 -1.05 Control N08002 9 264 male 25 Primary (1-5y) 152.15 Food Secure 1 10 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 -1.26 Control N08002 9 252 female 28 Primary (1-5y) 140.25 Food Secure 3 5 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 -0.59 Control N06531 9 336 female 19 Secondary (&gt;5y) 150.95 Food Secure 2 7 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 -0.51 Control N06531 9 304 male 20 Secondary (&gt;5y) 154.20 Severely Food Insecure 0 3 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 1 For the purposes of this workshop, we we start by treating the data as independent and identically distributed (i.i.d.) random draws from a very large target population. We could, with available options, account for the clustering of the data (within sampled geographic units), but, for simplification, we avoid these details in these workshop presentations, although modifications of our methodology for biased samples, repeated measures, etc., are available. We have 28 variables measured, of which 1 variable is set to be the outcome of interest. This outcome, \\(Y\\), is the weight-for-height Z-score (whz in dat); the treatment of interest, \\(A\\), is the randomized treatment group (tr in dat); and the adjustment set, \\(W\\), consists simply of everything else. This results in our observed data structure being \\(n\\) i.i.d. copies of \\(O_i = (W_i, A_i, Y_i)\\), for \\(i = 1, \\ldots, n\\). Using the skimr package, we can quickly summarize the variables measured in the WASH Benefits data set: library(skimr) skim(dat) (#tab:skim_washb_data)Data summary Name dat Number of rows 4695 Number of columns 28 _______________________ Column type frequency: factor 5 numeric 23 ________________________ Group variables None Variable type: factor skim_variable n_missing complete_rate ordered n_unique top_counts tr 0 1 FALSE 7 Con: 1178, Nut: 598, Han: 590, San: 590 fracode 0 1 FALSE 20 N08: 367, N06: 338, N06: 331, N06: 325 sex 0 1 FALSE 2 fem: 2352, mal: 2343 momedu 0 1 FALSE 3 Sec: 2513, Pri: 1448, No : 734 hfiacat 0 1 FALSE 4 Foo: 3249, Mod: 879, Mil: 410, Sev: 157 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist whz 0 1.00 -0.59 1.03 -4.67 -1.28 -0.6 0.08 4.97 ▁▆▇▁▁ month 0 1.00 6.45 3.33 1.00 4.00 6.0 9.00 12.00 ▇▇▅▇▇ aged 0 1.00 266.32 52.17 42.00 230.00 266.0 303.00 460.00 ▁▂▇▅▁ momage 18 1.00 23.91 5.24 14.00 20.00 23.0 27.00 60.00 ▇▇▁▁▁ momheight 31 0.99 150.50 5.23 120.65 147.05 150.6 154.06 168.00 ▁▁▆▇▁ Nlt18 0 1.00 1.60 1.25 0.00 1.00 1.0 2.00 10.00 ▇▂▁▁▁ Ncomp 0 1.00 11.04 6.35 2.00 6.00 10.0 14.00 52.00 ▇▃▁▁▁ watmin 0 1.00 0.95 9.48 0.00 0.00 0.0 1.00 600.00 ▇▁▁▁▁ elec 0 1.00 0.60 0.49 0.00 0.00 1.0 1.00 1.00 ▆▁▁▁▇ floor 0 1.00 0.11 0.31 0.00 0.00 0.0 0.00 1.00 ▇▁▁▁▁ walls 0 1.00 0.72 0.45 0.00 0.00 1.0 1.00 1.00 ▃▁▁▁▇ roof 0 1.00 0.99 0.12 0.00 1.00 1.0 1.00 1.00 ▁▁▁▁▇ asset_wardrobe 0 1.00 0.17 0.37 0.00 0.00 0.0 0.00 1.00 ▇▁▁▁▂ asset_table 0 1.00 0.73 0.44 0.00 0.00 1.0 1.00 1.00 ▃▁▁▁▇ asset_chair 0 1.00 0.73 0.44 0.00 0.00 1.0 1.00 1.00 ▃▁▁▁▇ asset_khat 0 1.00 0.61 0.49 0.00 0.00 1.0 1.00 1.00 ▅▁▁▁▇ asset_chouki 0 1.00 0.78 0.41 0.00 1.00 1.0 1.00 1.00 ▂▁▁▁▇ asset_tv 0 1.00 0.30 0.46 0.00 0.00 0.0 1.00 1.00 ▇▁▁▁▃ asset_refrig 0 1.00 0.08 0.27 0.00 0.00 0.0 0.00 1.00 ▇▁▁▁▁ asset_bike 0 1.00 0.32 0.47 0.00 0.00 0.0 1.00 1.00 ▇▁▁▁▃ asset_moto 0 1.00 0.07 0.25 0.00 0.00 0.0 0.00 1.00 ▇▁▁▁▁ asset_sewmach 0 1.00 0.06 0.25 0.00 0.00 0.0 0.00 1.00 ▇▁▁▁▁ asset_mobile 0 1.00 0.86 0.35 0.00 1.00 1.0 1.00 1.00 ▁▁▁▁▇ A convenient summary of the relevant variables is given just above, complete with a small visualization describing the marginal characteristics of each covariate. Note that the asset variables reflect socio-economic status of the study participants. Notice also the uniform distribution of the treatment groups (with twice as many controls); this is, of course, by design. References "],
["tlverse.html", "Chapter 2 Welcome to the tlverse 2.1 Learning Objectives 2.2 What is the tlverse? 2.3 tlverse components 2.4 Installation", " Chapter 2 Welcome to the tlverse 2.1 Learning Objectives Understand the tlverse ecosystem conceptually Identify the core components of the tlverse Install tlverse R packages Understand the Targeted Learning roadmap Learn about the WASH Benefits example data 2.2 What is the tlverse? The tlverse is a new framework for doing Targeted Learning in R, inspired by the tidyverse ecosystem of R packages. By analogy to the tidyverse: The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. So, the tlverse is an opinionated collection of R packages for Targeted Learning sharing an underlying philosophy, grammar, and set of data structures 2.3 tlverse components These are the main packages that represent the core of the tlverse: sl3: Modern Super Learning with Pipelines What? A modern object-oriented re-implementation of the Super Learner algorithm, employing recently developed paradigms for R programming. Why? A design that leverages modern tools for fast computation, is forward-looking, and can form one of the cornerstones of the tlverse. tmle3: An Engine for Targeted Learning What? A generalized framework that simplifies Targeted Learning by identifying and implementing a series of common statistical estimation procedures. Why? A common interface and engine that accommodates current algorithmic approaches to Targeted Learning and is still flexible enough to remain the engine even as new techniques are developed. In addition to the engines that drive development in the tlverse, there are some supporting packages – in particular, we have two… origami: A Generalized Framework for Cross-Validation What? A generalized framework for flexible cross-validation Why? Cross-validation is a key part of ensuring error estimates are honest and preventing overfitting. It is an essential part of the both the Super Learner algorithm and Targeted Learning. delayed: Parallelization Framework for Dependent Tasks What? A framework for delayed computations (futures) based on task dependencies. Why? Efficient allocation of compute resources is essential when deploying large-scale, computationally intensive algorithms. A key principle of the tlverse is extensibility. That is, we want to support new Targeted Learning estimators as they are developed. The model for this is new estimators are implemented in additional packages using the core packages above. There are currently two featured examples of this: tmle3mopttx: Optimal Treatments in tlverse What? Learn an optimal rule and estimate the mean outcome under the rule Why? Optimal Treatment is a powerful tool in precision healthcare and other settings where a one-size-fits-all treatment approach is not appropriate. tmle3shift: Shift Interventions in tlverse What? Shift interventions for continuous treatments Why? Not all treatment variables are discrete. Being able to estimate the effects of continuous treatment represents a powerful extension of the Targeted Learning approach. 2.4 Installation The tlverse ecosystem of packages are currently hosted at https://github.com/tlverse, not yet on CRAN. You can use the devtools package to install them: install.packages(&quot;devtools&quot;) devtools::install_github(&quot;tlverse/tlverse&quot;) The tlverse depends on a large number of other packages that are also hosted on GitHub. Because of this, you may see the following error: Error: HTTP error 403. API rate limit exceeded for 71.204.135.82. (But here&#39;s the good news: Authenticated requests get a higher rate limit. Check out the documentation for more details.) Rate limit remaining: 0/60 Rate limit reset at: 2019-03-04 19:39:05 UTC To increase your GitHub API rate limit - Use `usethis::browse_github_pat()` to create a Personal Access Token. - Use `usethis::edit_r_environ()` and add the token as `GITHUB_PAT`. This just means that R tried to install too many packages from GitHub in too short of a window. To fix this, you need to tell R how to use GitHub as your user (you’ll need a GitHub user account). Follow these two steps: Use usethis::browse_github_pat() to create a Personal Access Token. Use usethis::edit_r_environ() and add the token as GITHUB_PAT. "],
["ensemble-machine-learning.html", "Chapter 3 Ensemble Machine Learning 3.1 Learning Objectives 3.2 Introduction 3.3 Basic Implementation 3.4 Cross-validated Super Learner 3.5 Variable Importance Measures with sl3 3.6 Exercise 1 – Predicting Myocardial Infarction with sl3 3.7 Super Learning of a Conditional Density 3.8 Exercise 2 – Estimating the Propensity Score with sl3 3.9 Super Learning of an Optimal Individualized Treatment Rule 3.10 Exercise 3 – Estimating the Blip 3.11 Concluding Remarks 3.12 Appendix", " Chapter 3 Ensemble Machine Learning Rachael Phillips Based on the sl3 R package by Jeremy Coyle, Nima Hejazi, Ivana Malenica, and Oleg Sofrygin. Updated: 2019-11-25 3.1 Learning Objectives By the end of this chapter you will be able to: Select a loss function that is appropriate for the functional parameter to be estimated. Assemble an ensemble of learners based on the properties that identify what features they support. Customize learner hyperparameters to incorporate a diversity of different settings. Select a subset of available covariates and pass only those variables to the modeling algorithm. Fit an ensemble with nested cross-validation to obtain an estimate of the performance of the ensemble itself. Obtain sl3 variable importance metrics. Interpret the discrete and continuous super learner fits. Rationalize the need to remove bias from the super learner to make an optimal bias–variance tradeoff for the parameter of interest. 3.2 Introduction In Chapter 1, we introduced the road map for targeted learning as a general template to translate real-world data applications into formal statistical estimation problems. The first steps of this roadmap define the statistical estimation problem, which establish Data as a realization of a random variable, or equivalently, an outcome of a particular experiment. A statistical model, representing the true knowledge about the data-generating experiment. A translation of the scientific question, which is often causal, into a target parameter. Note that if the target parameter is causal, step 3 also requires establishing identifiability of the target quantity from the observed data distribution, under possible non-testable assumptions that may not necessarily be reasonable. Still, the target quantity does have a valid statistical interpretation. See causal target parameters for more detail on causal models and identifiability. Now that we have defined the statistical estimation problem, we are ready to construct the TMLE; an asymptotically linear and efficient substitution estimator of this target quantity. The first step in this estimation procedure is an initial estimate of the data-generating distribution, or the relevant part of this distribution that is needed to evaluate the target parameter. For this initial estimation, we use the Super Learner (van der Laan, Polley, and Hubbard 2007). The super learner provides an important step in creating a robust estimator. It is a loss-function-based tool that uses cross-validation to obtain the best prediction of our target parameter, based on a weighted average of a library of machine learning algorithms. This library of machine learning algorithms consists of functions (“learners” in the sl3 nomenclature) that we think might be consistent with the true data-generating distribution. The ensembling of algorithms with weights (“metalearning” in the sl3 nomenclature) has been shown to be adaptive and robust, even in small samples (Polley and van der Laan 2010). The Super Learner has been proven to be asymptotically as accurate as the best possible prediction algorithm in the library (van der Laan and Dudoit 2003; van der Vaart, Dudoit, and van der Laan 2006). 3.2.1 Background A loss function \\(L\\) is defined as a function of the observed data and a candidate parameter value \\(\\psi\\), which has unknown true value \\(\\psi_0\\), \\(L(\\psi)(O)\\). We can estimate the loss by substituting the empirical distribution \\(P_n\\) for the true (but unknown) distribution of the observed data \\(P_0\\). A valid loss function will have expectation (risk) that is minimized at the true value of the parameter \\(\\psi_0\\). For example, the conditional mean minimizes the risk of the squared error loss. Thus, it is a valid loss function when estimating the conditional mean. The discrete super learner, or cross-validation selector, is the algorithm in the library that minimizes the cross-validated empirical risk. The cross-validated empirical risk of an algorithm is defined as the empirical mean over a validation sample of the loss of the algorithm fitted on the training sample, averaged across the splits of the data. The continuous/ensemble super learner is a weighted average of the library of algorithms, where the weights are chosen to minimize the cross-validated empirical risk of the library. Restricting the weights to be positive and sum to one (i.e., a convex combination) has been shown to improve upon the discrete super learner (Polley and van der Laan 2010; van der Laan, Polley, and Hubbard 2007). This notion of weighted combinations was introduced in Wolpert (1992) for neural networks and adapted for regressions in Breiman (1996). For more detail on super learner we refer the reader to van der Laan, Polley, and Hubbard (2007) and Polley and van der Laan (2010). The optimality results for the cross-validation selector among a family of algorithms were established in van der Laan and Dudoit (2003) and extended in van der Vaart, Dudoit, and van der Laan (2006). 3.3 Basic Implementation We begin by illustrating the basic functionality of the Super Learner algorithm as implemented in sl3. The sl3 implementation consists of the following steps: Load the necessary libraries and data Define the machine learning task Make a super learner by creating library of base learners and a metalearner Train the super learner on the machine learning task Obtain predicted values 3.3.1 WASH Benefits Study Example Using the WASH data, we are interested in predicting weight-for-height z-score whz using the available covariate data. Let’s begin! 0. Load the necessary libraries and data First, we will load the relevant R packages, set a seed, and load the data. library(here) library(data.table) library(knitr) library(kableExtra) library(tidyverse) library(origami) library(SuperLearner) library(sl3) set.seed(7194) # load data set and take a peek washb_data &lt;- fread(&quot;https://raw.githubusercontent.com/tlverse/tlverse-data/master/wash-benefits/washb_data.csv&quot;, stringsAsFactors = TRUE) head(washb_data) %&gt;% kable(digits = 4) %&gt;% kableExtra:::kable_styling(fixed_thead = T) %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;300px&quot;) whz tr fracode month aged sex momage momedu momheight hfiacat Nlt18 Ncomp watmin elec floor walls roof asset_wardrobe asset_table asset_chair asset_khat asset_chouki asset_tv asset_refrig asset_bike asset_moto asset_sewmach asset_mobile 0.00 Control N05265 9 268 male 30 Primary (1-5y) 146.40 Food Secure 3 11 0 1 0 1 1 0 1 1 1 0 1 0 0 0 0 1 -1.16 Control N05265 9 286 male 25 Primary (1-5y) 148.75 Moderately Food Insecure 2 4 0 1 0 1 1 0 1 0 1 1 0 0 0 0 0 1 -1.05 Control N08002 9 264 male 25 Primary (1-5y) 152.15 Food Secure 1 10 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 -1.26 Control N08002 9 252 female 28 Primary (1-5y) 140.25 Food Secure 3 5 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 -0.59 Control N06531 9 336 female 19 Secondary (&gt;5y) 150.95 Food Secure 2 7 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 -0.51 Control N06531 9 304 male 20 Secondary (&gt;5y) 154.20 Severely Food Insecure 0 3 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 1 1. Define the machine learning task To define the machine learning “task” (predict weight-for-height z-score whz using the available covariate data), we need to create an sl3_Task object. The sl3_Task keeps track of the roles the variables play in the machine learning problem, the data, and any metadata (e.g., observational-level weights, id, offset). # specify the outcome and covariates outcome &lt;- &quot;whz&quot; covars &lt;- colnames(washb_data)[-which(names(washb_data) == outcome)] # create the sl3 task washb_task &lt;- make_sl3_Task( data = washb_data, covariates = covars, outcome = outcome ) Warning in .subset2(public_bind_env, &quot;initialize&quot;)(...): Missing Covariate Data Found. Imputing covariates using sl3_process_missing. This warning is important. The task just imputed missing covariates for us. Specifically, for each covariate column with missing values, sl3 uses the median to impute missing continuous covariates, and the mode to impute binary or categorical covariates. Also, for each covariate column with missing values, sl3 adds an additional column indicating whether or not the value was imputed, which is particularly handy when the missingness in the data might be informative. Also, notice that we did not specify the number of folds, or the loss function in the task. The default cross-validation scheme is V-fold, with the number of folds \\(V=10\\). Let’s visualize our washb_task. washb_task A sl3 Task with 4695 obs and these nodes: $covariates [1] &quot;tr&quot; &quot;fracode&quot; &quot;month&quot; &quot;aged&quot; [5] &quot;sex&quot; &quot;momage&quot; &quot;momedu&quot; &quot;momheight&quot; [9] &quot;hfiacat&quot; &quot;Nlt18&quot; &quot;Ncomp&quot; &quot;watmin&quot; [13] &quot;elec&quot; &quot;floor&quot; &quot;walls&quot; &quot;roof&quot; [17] &quot;asset_wardrobe&quot; &quot;asset_table&quot; &quot;asset_chair&quot; &quot;asset_khat&quot; [21] &quot;asset_chouki&quot; &quot;asset_tv&quot; &quot;asset_refrig&quot; &quot;asset_bike&quot; [25] &quot;asset_moto&quot; &quot;asset_sewmach&quot; &quot;asset_mobile&quot; &quot;delta_momage&quot; [29] &quot;delta_momheight&quot; $outcome [1] &quot;whz&quot; $id NULL $weights NULL $offset NULL 2. Make a super learner Now that we have defined our machine learning problem with the task, we are ready to “make” the super learner. This requires specification of A library of base learning algorithms that we think might be consistent with the true data-generating distribution. A metalearner, to ensemble the base learners. We might also incorporate Feature selection, to pass only a subset of the predictors to the algorithm. Hyperparameter specification, to tune base learners. Learners have properties that indicate what features they support. We may use sl3_list_properties() to get a list of all properties supported by at least one learner. sl3_list_properties() [1] &quot;binomial&quot; &quot;categorical&quot; &quot;continuous&quot; [4] &quot;cv&quot; &quot;density&quot; &quot;ids&quot; [7] &quot;multivariate_outcome&quot; &quot;offset&quot; &quot;preprocessing&quot; [10] &quot;timeseries&quot; &quot;weights&quot; &quot;wrapper&quot; Since we have a continuous outcome, we may identify the learners that support this outcome type with sl3_list_learners(). sl3_list_learners(&quot;continuous&quot;) [1] &quot;Lrnr_arima&quot; &quot;Lrnr_bartMachine&quot; [3] &quot;Lrnr_bilstm&quot; &quot;Lrnr_caret&quot; [5] &quot;Lrnr_condensier&quot; &quot;Lrnr_dbarts&quot; [7] &quot;Lrnr_earth&quot; &quot;Lrnr_expSmooth&quot; [9] &quot;Lrnr_gam&quot; &quot;Lrnr_gbm&quot; [11] &quot;Lrnr_glm&quot; &quot;Lrnr_glm_fast&quot; [13] &quot;Lrnr_glmnet&quot; &quot;Lrnr_grf&quot; [15] &quot;Lrnr_h2o_glm&quot; &quot;Lrnr_h2o_grid&quot; [17] &quot;Lrnr_hal9001&quot; &quot;Lrnr_HarmonicReg&quot; [19] &quot;Lrnr_lstm&quot; &quot;Lrnr_mean&quot; [21] &quot;Lrnr_nnls&quot; &quot;Lrnr_optim&quot; [23] &quot;Lrnr_pkg_SuperLearner&quot; &quot;Lrnr_pkg_SuperLearner_method&quot; [25] &quot;Lrnr_pkg_SuperLearner_screener&quot; &quot;Lrnr_polspline&quot; [27] &quot;Lrnr_randomForest&quot; &quot;Lrnr_ranger&quot; [29] &quot;Lrnr_rpart&quot; &quot;Lrnr_rugarch&quot; [31] &quot;Lrnr_solnp&quot; &quot;Lrnr_stratified&quot; [33] &quot;Lrnr_svm&quot; &quot;Lrnr_tsDyn&quot; [35] &quot;Lrnr_xgboost&quot; Now that we have an idea of some learners, we can construct them using the make_learner function. # choose base learners lrnr_glm &lt;- make_learner(Lrnr_glm) lrnr_mean &lt;- make_learner(Lrnr_mean) lrnr_glmnet &lt;- make_learner(Lrnr_glmnet) We can customize learner hyperparameters to incorporate a diversity of different settings. Documentation for the learners and their hyperparameters can be found in the sl3 Learners Reference. We can also include learners from the SuperLearner R package. lrnr_ranger100 &lt;- make_learner(Lrnr_ranger, num.trees = 100) lrnr_hal_simple &lt;- make_learner(Lrnr_hal9001, degrees = 1, n_folds = 2) lrnr_gam &lt;- Lrnr_pkg_SuperLearner$new(&quot;SL.gam&quot;) lrnr_bayesglm &lt;- Lrnr_pkg_SuperLearner$new(&quot;SL.bayesglm&quot;) Are you interested in creating a new base learning algorithm? If so, instructions are provided in Defining New sl3 Learners. In order to assemble the library of learners, we need to “stack” them together. A Stack is a special learner and it has the same interface as all other learners. What makes a stack special is that it combines multiple learners by training them simultaneously, so that their predictions can be either combined or compared. stack &lt;- make_learner( Stack, lrnr_glm, lrnr_mean, lrnr_ranger100, lrnr_glmnet, lrnr_gam, lrnr_bayesglm ) We will fit a non-negative least squares metalearner using Lrnr_nnls. Note that any learner can be used as a metalearner. Lrnr_nnls is a solid choice for a metalearner, since it creates a convex combination of the learners when combining them. To metalearner &lt;- make_learner(Lrnr_nnls) We can optionally select a subset of available covariates and pass only those variables to the modeling algorithm. Let’s consider screening covariates based on their correlation with our outcome of interest (cor.test p-value \\(\\leq 0.1\\)). screen_cor &lt;- Lrnr_pkg_SuperLearner_screener$new(&quot;screen.corP&quot;) # which covariates are selected on the full data? screen_cor$train(washb_task) [1] &quot;Lrnr_pkg_SuperLearner_screener_screen.corP&quot; $selected [1] &quot;tr&quot; &quot;fracode&quot; &quot;aged&quot; &quot;momage&quot; [5] &quot;momedu&quot; &quot;momheight&quot; &quot;hfiacat&quot; &quot;Nlt18&quot; [9] &quot;elec&quot; &quot;floor&quot; &quot;walls&quot; &quot;asset_wardrobe&quot; [13] &quot;asset_table&quot; &quot;asset_chair&quot; &quot;asset_khat&quot; &quot;asset_chouki&quot; [17] &quot;asset_tv&quot; &quot;asset_refrig&quot; &quot;asset_moto&quot; &quot;asset_sewmach&quot; [21] &quot;asset_mobile&quot; To “pipe” only the selected covariates to the modeling algorithm, we need to make a Pipeline, which is a just set of learners to be fit sequentially, where the fit from one learner is used to define the task for the next learner. Note the difference between Pipeline and Stack here- one is necessary in order to define a sequential process, whereas the other one establishes parallel function of learners. cor_pipeline &lt;- make_learner(Pipeline, screen_cor, stack) Now our learners will be preceded by a screening step. We also consider the original stack, just to compare how the feature selection methods perform in comparison to the methods without feature selection. Analogous to what we have seen before, we have to stack the pipeline and original stack together, so we may use them as base learners in our super learner. fancy_stack &lt;- make_learner(Stack, cor_pipeline, stack) # we can visualize the stack dt_stack &lt;- delayed_learner_train(fancy_stack, washb_task) plot(dt_stack, color = FALSE, height = &quot;400px&quot;, width = &quot;100%&quot;) In the above plot, we visualize the super learner, which we can see has 10 realizations of the stack and a separate hold-out (the top branch of the figure) that will not be used to fit the super learner. We have made a library/stack of base learners and a metalearner, so we are ready to make the super learner. The super learner algorithm fits a metalearner on the validation-set predictions. sl &lt;- make_learner(Lrnr_sl, learners = fancy_stack, metalearner = metalearner ) # we can visualize the super learner dt_sl &lt;- delayed_learner_train(sl, washb_task) plot(dt_sl, color = FALSE, height = &quot;400px&quot;, width = &quot;100%&quot;) 3. Train the super learner on the machine learning task The super learner algorithm fits a metalearner on the validation-set predictions in a cross-validated manner, thereby avoiding overfitting. This procedure is referred to as the continuous super learner. The cross-validation selector, or discrete super learner, is the base learner with the lowest cross-validated risk. Now we are ready to “train” our super learner on our sl3_task object, washb_task. sl_fit &lt;- sl$train(washb_task) 4. Obtain predicted values Now that we have fit the super learner, we are ready to obtain our predicted values for each subject. sl_preds &lt;- sl_fit$predict() head(sl_preds) [1] -0.5201573 -0.8543260 -0.7429792 -0.7272020 -0.6556788 -0.7117084 We can also obtain a summary of the results. sl_fit_summary &lt;- sl_fit$print() [1] &quot;SuperLearner:&quot; List of 2 $ : chr &quot;Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)&quot; $ : chr &quot;Stack&quot; [1] &quot;Lrnr_nnls&quot; lrnrs 1: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_glm_TRUE 2: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_mean 3: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_ranger_100_TRUE_1 4: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 5: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.gam 6: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.bayesglm 7: Stack_Lrnr_glm_TRUE 8: Stack_Lrnr_mean 9: Stack_Lrnr_ranger_100_TRUE_1 10: Stack_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 11: Stack_Lrnr_pkg_SuperLearner_SL.gam 12: Stack_Lrnr_pkg_SuperLearner_SL.bayesglm weights 1: 0.00000000 2: 0.00000000 3: 0.17342182 4: 0.00000000 5: 0.17987021 6: 0.00000000 7: 0.00000000 8: 0.00000000 9: 0.30318912 10: 0.32937954 11: 0.01884654 12: 0.00000000 [1] &quot;Cross-validated risk (MSE, squared error loss):&quot; learner 1: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_glm_TRUE 2: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_mean 3: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_ranger_100_TRUE_1 4: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 5: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.gam 6: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.bayesglm 7: Stack_Lrnr_glm_TRUE 8: Stack_Lrnr_mean 9: Stack_Lrnr_ranger_100_TRUE_1 10: Stack_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 11: Stack_Lrnr_pkg_SuperLearner_SL.gam 12: Stack_Lrnr_pkg_SuperLearner_SL.bayesglm 13: SuperLearner coefficients mean_risk SE_risk fold_SD fold_min_risk fold_max_risk 1: NA 1.015128 0.02363317 0.07629401 0.8927540 1.131594 2: NA 1.065282 0.02502664 0.09191791 0.9264292 1.196647 3: NA 1.021171 0.02353389 0.08317719 0.8643945 1.145790 4: NA 1.012707 0.02358999 0.07889114 0.8822292 1.130821 5: NA 1.015128 0.02363317 0.07629401 0.8927540 1.131594 6: NA 1.015119 0.02363328 0.07631510 0.8926608 1.131570 7: NA 1.018612 0.02380402 0.07799191 0.8956048 1.134940 8: NA 1.065282 0.02502664 0.09191791 0.9264292 1.196647 9: NA 1.016318 0.02352572 0.08838491 0.8627786 1.149107 10: NA 1.012243 0.02359241 0.07932272 0.8826677 1.130974 11: NA 1.018612 0.02380402 0.07799191 0.8956048 1.134940 12: NA 1.018596 0.02380414 0.07801948 0.8954820 1.134909 13: NA 1.006093 0.02339310 0.08215784 0.8648589 1.129938 From the table of the printed super learner fit, we note that the super learner had a mean risk of 1.0060928 and that this ensemble weighted the ranger and glmnet learners highest while not weighting the mean learner highly. We can also see that the glmnet learner had the lowest cross-validated mean risk, thus making it the cross-validated selector (or the discrete super learner). The mean risk of the (continuous) super learner is calculated using the hold-out set that we visualized in the plot above. 3.4 Cross-validated Super Learner We can cross-validate the super learner to see how well the super learner performs on unseen data, and obtain an estimate of the cross-validated risk of the super learner. This estimation procedure requires an “external” layer of cross-validation, also called nested cross-validation, which involves setting aside a separate holdout sample that we don’t use to fit the super learner. This external cross validation procedure may also incorporate 10 folds, which is the default in sl3. However, we will incorporate 2 outer/external folds of cross-validation for computational efficiency. We also need to specify a loss function to evaluate super learner. Documentation for the available loss functions can be found in the sl3 Loss Function Reference. washb_task_new &lt;- make_sl3_Task( data = washb_data, covariates = covars, outcome = outcome, folds = make_folds(washb_data, fold_fun = folds_vfold, V = 2) ) Warning in .subset2(public_bind_env, &quot;initialize&quot;)(...): Missing Covariate Data Found. Imputing covariates using sl3_process_missing. CVsl_fancy &lt;- CV_lrnr_sl(sl_fit, washb_task_new, loss_squared_error) CVsl_fancy %&gt;% kable(digits = 4) %&gt;% kableExtra:::kable_styling(fixed_thead = T) %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;300px&quot;) learner coefficients mean_risk SE_risk fold_SD fold_min_risk fold_max_risk Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_glm_TRUE NA 1.0228 0.0238 0.0192 1.0092 1.0364 Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_mean NA 1.0650 0.0250 0.0342 1.0409 1.0892 Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_ranger_100_TRUE_1 NA 1.0376 0.0241 0.0098 1.0307 1.0446 Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE NA 1.0155 0.0236 0.0261 0.9970 1.0339 Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.gam NA 1.0228 0.0238 0.0192 1.0092 1.0364 Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.bayesglm NA 1.0227 0.0238 0.0193 1.0091 1.0364 Stack_Lrnr_glm_TRUE NA 1.0325 0.0258 0.0363 1.0069 1.0582 Stack_Lrnr_mean NA 1.0650 0.0250 0.0342 1.0409 1.0892 Stack_Lrnr_ranger_100_TRUE_1 NA 1.0218 0.0238 0.0175 1.0094 1.0342 Stack_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE NA 1.0159 0.0236 0.0268 0.9970 1.0349 Stack_Lrnr_pkg_SuperLearner_SL.gam NA 1.0325 0.0258 0.0363 1.0069 1.0582 Stack_Lrnr_pkg_SuperLearner_SL.bayesglm NA 1.0325 0.0258 0.0364 1.0067 1.0582 SuperLearner NA 1.0121 0.0235 0.0261 0.9936 1.0306 3.5 Variable Importance Measures with sl3 Variable importance can be interesting and informative. The sl3 varimp function returns a table with variables listed in decreasing order of importance, in which the measure of importance is based on a risk difference between the learner fit with a permuted covariate and the learner fit with the true covariate, across all covariates. In this manner, the larger the risk difference, the more important the variable is in the prediction. Let’s explore the sl3 variable importance measurements for the washb data. washb_varimp &lt;- varimp(sl_fit, loss_squared_error) washb_varimp %&gt;% kable(digits = 4) %&gt;% kableExtra:::kable_styling(fixed_thead = T) %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;300px&quot;) X risk_diff aged 0.0372 momedu 0.0072 tr 0.0065 asset_refrig 0.0056 month 0.0042 momheight 0.0035 Nlt18 0.0030 elec 0.0025 fracode 0.0022 asset_chair 0.0017 momage 0.0016 asset_moto 0.0011 sex 0.0010 asset_table 0.0010 asset_chouki 0.0008 floor 0.0008 asset_khat 0.0006 hfiacat 0.0005 asset_bike 0.0005 asset_wardrobe 0.0004 asset_sewmach 0.0004 watmin 0.0001 delta_momage 0.0000 roof -0.0001 asset_mobile -0.0002 delta_momheight -0.0003 walls -0.0005 asset_tv -0.0009 Ncomp -0.0013 3.6 Exercise 1 – Predicting Myocardial Infarction with sl3 Answer the questions below to predict myocardial infarction (mi) using the available covariate data. Thanks to Professor David Benkeser at Emory University for making the this Cardiovascular Health Study (CHS) data easily accessible. # load the data set db_data &lt;- url(&quot;https://raw.githubusercontent.com/benkeser/sllecture/master/chspred.csv&quot;) chspred &lt;- read_csv(file = db_data, col_names = TRUE) # take a quick peek head(chspred) %&gt;% kable(digits = 4) %&gt;% kableExtra:::kable_styling(fixed_thead = T) %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;300px&quot;) waist alcoh hdl beta smoke ace ldl bmi aspirin gend age estrgn glu ins cysgfr dm fetuina whr hsed race logcystat logtrig logcrp logcre health logkcal sysbp mi 110.1642 0.0000 66.4974 0 0 1 114.2162 27.9975 0 0 73.5179 0 159.9314 70.3343 75.0078 1 0.1752 1.1690 1 1 -0.3420 5.4063 2.0126 -0.6739 0 4.3926 177.1345 0 89.9763 0.0000 50.0652 0 0 0 103.7766 20.8931 0 0 61.7723 0 153.3888 33.9695 82.7433 1 0.5717 0.9011 0 0 -0.0847 4.8592 3.2933 -0.5551 1 6.2071 136.3742 0 106.1941 8.4174 40.5059 0 0 0 165.7158 28.4554 1 1 72.9312 0 121.7145 -17.3017 74.6989 0 0.3517 1.1797 0 1 -0.4451 4.5088 0.3013 -0.0115 0 6.7320 135.1993 0 90.0566 0.0000 36.1750 0 0 0 45.2035 23.9608 0 0 79.1191 0 53.9691 11.7315 95.7823 0 0.5439 1.1360 0 0 -0.4807 5.1832 3.0243 -0.5751 1 7.3972 139.0182 0 78.6143 2.9790 71.0642 0 1 0 131.3121 10.9656 0 1 69.0179 0 94.3153 9.7112 72.7109 0 0.4916 1.1028 1 0 0.3121 4.2190 -0.7057 0.0053 1 8.2779 88.0470 0 91.6593 0.0000 59.4963 0 0 0 171.1872 29.1317 0 1 81.8346 0 212.9066 -28.2269 69.2184 1 0.4621 0.9529 1 0 -0.2872 5.1773 0.9705 0.2127 1 5.9942 69.5943 0 Create an sl3 task, setting myocardial infarction mi as the outcome and using all available covariate data. Make a library of seven relatively fast base learning algorithms (i.e., do not consider BART or HAL). Customize hyperparameters for one of your learners. Feel free to use learners from sl3 or SuperLearner. You may use the same base learning library that is presented above. Incorporate feature selection with the SuperLearner screener screen.corP. Fit the metalearning step with non-negative least squares, Lrnr_nnls. With the metalearner and base learners, make the super learner and train it on the task. Print your super learner fit by calling print() with $. Cross-validate your super learner fit to see how well it performs on unseen data. Specify loss_squared_error as the loss function to evaluate the super learner. 3.7 Super Learning of a Conditional Density 3.8 Exercise 2 – Estimating the Propensity Score with sl3 3.9 Super Learning of an Optimal Individualized Treatment Rule 3.10 Exercise 3 – Estimating the Blip 3.11 Concluding Remarks The general ensemble learning approach of super learner can be applied to a diversity of estimation and prediction problems that can be defined by a loss function. We just discussed conditional mean estimation, and in the appendix we delve into prediction of a conditional density, and the optimal individualized treatment rule. Plug-in estimators of the estimand are desirable because a plug-in estimator respects both the local and global constraints of the statistical model. We could just plug-in the estimator returned by Super Learner; however, this is problematic because the Super Learner estimators are trading off bias and variance in an optimal way and as a result their bias is essentially the rate of convergence of these algorithms, which is always slower than \\(1/\\sqrt{n}\\). Therefore, if we plug-in the estimator returned by super learner into the target parameter mapping, we would end up with an estimator which has the same bias as what we plugged in, which is greater than \\(1/\\sqrt{n}\\). Thus, we end up with an estimator which is not asymptotically normal, since it does not converge to the estimand at \\(1/\\sqrt{n}\\) rate. An asymptotically linear estimator has no meaningful bias ($ &lt; 1/$), and can be written as an empirical mean in first order of a function of the data, the influence curve, plus some negligible remainder term. Once an estimator is asymptotically linear with an influence curve it’s normally distributed, so the standardized estimator converges to a normal distribution with mean 0 and variance is the variance of the influence curve. Thus, it is advantageous to construct asymptotically linear estimators since they permit formal statistical inference. Among the class of regular asymptotically linear estimators, there is an optimal estimator which is an efficient estimator, and that’s the one with influence curve equal to the canonical gradient of the path-wise derivative of the target parameter. The canonical gradient is the direction of the path through the data distribution where the parameter is steepest. An estimator is efficient if and only if is asymptotically linear with influence curve equal to the canonical gradient. One can calculate the canonical gradient with the statistical model and the statistical target parameter. Techniques for calculating the canonical gradient entail projecting an initial gradient on the tangent space of the model at the particular distribution in the model in which you want to calculate the canonical gradient. Now we know what it takes to construct an efficient estimator. Namely, we need to construct an estimator which is asymptotically linear with influence curve the canonical gradient. There are three general classes of estimators which succeed in constructing asymptotically linear estimators: (1) the one-step estimator, but it is not a plug-in estimator; (2) the targeted maximum likelihood estimator, which is a super learner targeted towards the target parameter and it is a plug-in estimator; and (3) estimating equation based estimators, which use the canonical gradient but as an estimating function in the target parameter. In the chapters that follow, we focus on the targeted maximum likelihood estimator and the targeted minimum loss-based estimator, both referred to as TMLE. 3.12 Appendix 3.12.1 Exercise 1 Solution Here is a potential solution to (Exercise 1 – Predicting Myocardial Infarction with sl3)(???). chspred_task &lt;- make_sl3_Task( data = chspred, covariates = head(colnames(chspred), -1), outcome = &quot;mi&quot; ) glm_learner &lt;- Lrnr_glm$new() lasso_learner &lt;- Lrnr_glmnet$new(alpha = 1) ridge_learner &lt;- Lrnr_glmnet$new(alpha = 0) enet_learner &lt;- Lrnr_glmnet$new(alpha = 0.5) curated_glm_learner &lt;- Lrnr_glm_fast$new(formula = &quot;mi ~ smoke + beta + waist&quot;) mean_learner &lt;- Lrnr_mean$new() # That is one mean learner! glm_fast_learner &lt;- Lrnr_glm_fast$new() ranger_learner &lt;- Lrnr_ranger$new() svm_learner &lt;- Lrnr_svm$new() xgb_learner &lt;- Lrnr_xgboost$new() screen_cor &lt;- Lrnr_pkg_SuperLearner_screener$new(&quot;screen.corP&quot;) glm_pipeline &lt;- make_learner(Pipeline, screen_cor, glm_learner) stack &lt;- make_learner( Stack, glm_pipeline, glm_learner, lasso_learner, ridge_learner, enet_learner, curated_glm_learner, mean_learner, glm_fast_learner, ranger_learner, svm_learner, xgb_learner ) metalearner &lt;- make_learner(Lrnr_nnls) sl &lt;- Lrnr_sl$new( learners = stack, metalearner = metalearner ) sl_fit &lt;- sl$train(task) sl_fit$print() CVsl &lt;- CV_lrnr_sl(sl_fit, chspred_task, loss_squared_error) CVsl 3.12.2 Exercise 2 Solution Here’s a potential solution to (Exercise 2)(???). 3.12.3 Exercise 3 Solution Here’s a potential solution to the (Exercise 3)(???). References "],
["the-tmle-framework.html", "Chapter 4 The TMLE Framework 4.1 Learning Objectives 4.2 Example: tmle3 for ATE 4.3 tmle3 Components 4.4 Fitting tmle3 with multiple parameters 4.5 Exercise 4.6 Summary", " Chapter 4 The TMLE Framework Jeremy Coyle Based on the tmle3 R package. 4.1 Learning Objectives Use tmle3 to estimate an Average Treatment Effect (ATE) Understand tmle3 “Specs” Fit tmle3 for a custom set of parameters Use the delta method to estimate transformations of parameters 4.2 Example: tmle3 for ATE We’ll illustrate the most basic use of TMLE using the WASH Benefits data introduced earlier and estimating an Average Treatment Effect (ATE). As a reminder, the ATE is identified with the following statistical parameter (under assumptions): \\(ATE = \\mathbb{E}_0(Y(1)-Y(0)) = \\mathbb{E}_0 \\left(\\mathbb{E}_0[Y \\mid A=1,W] - \\mathbb{E}_0[Y \\mid A=0,W] \\right),\\) 4.2.1 Load the Data We’ll use the same WASH Benefits data as the earlier chapters: library(here) library(data.table) library(tidyverse) library(tmle3) library(sl3) washb_data &lt;- fread(&quot;https://raw.githubusercontent.com/tlverse/tlverse-data/master/wash-benefits/washb_data.csv&quot;, stringsAsFactors = TRUE) 4.2.2 Define the variable roles We’ll use the common W (covariates), A (treatment/intervention), Y (outcome) data structure. tmle3 needs to know what variables in the dataset correspond to each of these roles. We use a list of character vectors to tell it. We call this a “Node List” as it corresponds to the nodes in a Directed Acyclic Graph (DAG), a way of displaying causal relationships between variables. node_list &lt;- list( W = c( &quot;month&quot;, &quot;aged&quot;, &quot;sex&quot;, &quot;momage&quot;, &quot;momedu&quot;, &quot;momheight&quot;, &quot;hfiacat&quot;, &quot;Nlt18&quot;, &quot;Ncomp&quot;, &quot;watmin&quot;, &quot;elec&quot;, &quot;floor&quot;, &quot;walls&quot;, &quot;roof&quot;, &quot;asset_wardrobe&quot;, &quot;asset_table&quot;, &quot;asset_chair&quot;, &quot;asset_khat&quot;, &quot;asset_chouki&quot;, &quot;asset_tv&quot;, &quot;asset_refrig&quot;, &quot;asset_bike&quot;, &quot;asset_moto&quot;, &quot;asset_sewmach&quot;, &quot;asset_mobile&quot; ), A = &quot;tr&quot;, Y = &quot;whz&quot; ) 4.2.3 Handle Missingness Currently, missingness in tmle3 is handled in a fairly simple way: Missing covariates are median (for continuous) or mode (for discrete) imputed, and additional covariates indicating imputation are generated Observations missing either treatment or outcome variables are excluded. We plan to implement IPCW-TMLE to more efficiently handle missingness in the treatment and outcome variables. These steps are implemented in the process_missing function in tmle3: processed &lt;- process_missing(washb_data, node_list) washb_data &lt;- processed$data node_list &lt;- processed$node_list 4.2.4 Create a “Spec” Object tmle3 is general, and allows most components of the TMLE procedure to be specified in a modular way. However, most end-users will not be interested in manually specifying all of these components. Therefore, tmle3 implements a tmle3_Spec object that bundles a set ofcomponents into a specification that, with minimal additional detail, can be run by an end-user. We’ll start with using one of the specs, and then work our way down into the internals of tmle3. ate_spec &lt;- tmle_ATE( treatment_level = &quot;Nutrition + WSH&quot;, control_level = &quot;Control&quot; ) 4.2.5 Define the learners Currently, the only other thing a user must define are the sl3 learners used to estimate the relevant factors of the likelihood: Q and g. This takes the form of a list of sl3 learners, one for each likelihood factor to be estimated with sl3: # choose base learners lrnr_mean &lt;- make_learner(Lrnr_mean) lrnr_xgboost &lt;- make_learner(Lrnr_xgboost) # define metalearners appropriate to data types ls_metalearner &lt;- make_learner(Lrnr_nnls) mn_metalearner &lt;- make_learner(Lrnr_solnp, metalearner_linear_multinomial, loss_loglik_multinomial) sl_Y &lt;- Lrnr_sl$new(learners = list(lrnr_mean, lrnr_xgboost), metalearner = ls_metalearner) sl_A &lt;- Lrnr_sl$new(learners = list(lrnr_mean, lrnr_xgboost), metalearner = mn_metalearner) learner_list &lt;- list(A = sl_A, Y = sl_Y) Here, we use a Super Learner as defined in the previous chapter. In the future, we plan to include reasonable defaults learners. 4.2.6 Fit the TMLE We now have everything we need to fit the tmle using tmle3: tmle_fit &lt;- tmle3(ate_spec, washb_data, node_list, learner_list) 4.2.7 Evaluate the Estimates We can see the summary results by printing the fit object. Alternatively, we can extra results from the summary by indexing into it: print(tmle_fit) A tmle3_Fit that took 1 step(s) type param init_est tmle_est 1: ATE ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] 0.002440166 0.002494379 se lower upper psi_transformed lower_transformed 1: 0.05066932 -0.09681566 0.1018044 0.002494379 -0.09681566 upper_transformed 1: 0.1018044 estimates &lt;- tmle_fit$summary$psi_transformed print(estimates) [1] 0.002494379 4.3 tmle3 Components Now that we’ve successfully used a spec to obtain a TML estimate, let’s look under the hood at the components. The spec has a number of functions that generate the objects necessary to define and fit a TMLE. 4.3.1 tmle3_task First is, a tmle3_Task, analogous to an sl3_Task, containing the data we’re fitting the TMLE to, as well as an NP-SEM generated from the node_list defined above, describing the variables and their relationships. tmle_task &lt;- ate_spec$make_tmle_task(washb_data, node_list) tmle_task$npsem $W tmle3_Node: W Variables: month, aged, sex, momedu, hfiacat, Nlt18, Ncomp, watmin, elec, floor, walls, roof, asset_wardrobe, asset_table, asset_chair, asset_khat, asset_chouki, asset_tv, asset_refrig, asset_bike, asset_moto, asset_sewmach, asset_mobile, momage, momheight, delta_momage, delta_momheight Parents: $A tmle3_Node: A Variables: tr Parents: W $Y tmle3_Node: Y Variables: whz Parents: A, W 4.3.2 Initial Likelihood Next, is an object representing the likelihood, factorized according to the NPSEM described above: initial_likelihood &lt;- ate_spec$make_initial_likelihood( tmle_task, learner_list ) print(initial_likelihood) W: Lf_emp A: LF_fit Y: LF_fit These components of the likelihood indicate how the factors were estimated: the marginal distribution of \\(W\\) was estimated using NP-MLE, and the conditional distributions of \\(A\\) and \\(Y\\) were estimated using sl3 fits (as defined with the learner_list) above. We can use this in tandem with the tmle_task object to obtain likelihood estimates for each observation: initial_likelihood$get_likelihoods(tmle_task) W A Y 1: 0.0002129925 0.2482971 -0.6616029 2: 0.0002129925 0.2540885 -0.6351630 3: 0.0002129925 0.2578671 -0.6232142 4: 0.0002129925 0.2756704 -0.6033917 5: 0.0002129925 0.2532059 -0.5480529 --- 4691: 0.0002129925 0.1337394 -0.4698893 4692: 0.0002129925 0.1263632 -0.4882987 4693: 0.0002129925 0.1265693 -0.5709865 4694: 0.0002129925 0.1678060 -0.8143882 4695: 0.0002129925 0.1295294 -0.5452056 4.3.3 Targeted Likelihood (updater) We also need to define a “Targeted Likelihood” object. This is a special type of likelihood that is able to be updated using an tmle3_Update object. This object defines the update strategy (e.g. submodel, loss function, CV-TMLE or not, etc). targeted_likelihood &lt;- Targeted_Likelihood$new(initial_likelihood) When constructing the targeted likelihood, you can specify different update options. See the documentation for tmle3_Update for details of the different options. For example, you can disable CV-TMLE (the default in tmle3) as follows: targeted_likelihood_no_cv &lt;- Targeted_Likelihood$new(initial_likelihood, updater = list(cvtmle = FALSE) ) 4.3.4 Parameter Mapping Finally, we need to define the parameters of interest. Here, the spec defines a single parameter, the ATE. In the next section, we’ll see how to add additional parameters. tmle_params &lt;- ate_spec$make_params(tmle_task, targeted_likelihood) print(tmle_params) [[1]] Param_ATE: ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] 4.3.5 Putting it all together Having used the spec to manually generate all these components, we can now manually fit a tmle3: tmle_fit_manual &lt;- fit_tmle3( tmle_task, targeted_likelihood, tmle_params, targeted_likelihood$updater ) print(tmle_fit_manual) A tmle3_Fit that took 1 step(s) type param init_est tmle_est 1: ATE ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] 0.002365312 0.007351927 se lower upper psi_transformed lower_transformed 1: 0.0508875 -0.09238574 0.1070896 0.007351927 -0.09238574 upper_transformed 1: 0.1070896 The result is equivalent to fitting using the tmle3 function as above. 4.4 Fitting tmle3 with multiple parameters Above, we fit a tmle3 with just one parameter. tmle3 also supports fitting multiple parameters simultaneously. To illustrate this, we’ll use the tmle_TSM_all spec: tsm_spec &lt;- tmle_TSM_all() targeted_likelihood &lt;- Targeted_Likelihood$new(initial_likelihood) all_tsm_params &lt;- tsm_spec$make_params(tmle_task, targeted_likelihood) print(all_tsm_params) [[1]] Param_TSM: E[Y_{A=Control}] [[2]] Param_TSM: E[Y_{A=Handwashing}] [[3]] Param_TSM: E[Y_{A=Nutrition}] [[4]] Param_TSM: E[Y_{A=Nutrition + WSH}] [[5]] Param_TSM: E[Y_{A=Sanitation}] [[6]] Param_TSM: E[Y_{A=WSH}] [[7]] Param_TSM: E[Y_{A=Water}] This spec generates a Treatment Specific Mean (TSM) for each level of the exposure variable. Note that we must first generate a new targeted likelihood, as the old one was targeted to the ATE. However, we can recycle the initial likelihood we fit above, saving us a super learner step. 4.4.1 Delta Method We can also define parameters based on Delta Method Transformations of other parameters. For instance, we can estimate a ATE using the delta method and two of the above TSM parameters: ate_param &lt;- define_param( Param_delta, targeted_likelihood, delta_param_ATE, list(all_tsm_params[[1]], all_tsm_params[[4]]) ) print(ate_param) Param_delta: E[Y_{A=Nutrition + WSH}] - E[Y_{A=Control}] This can similarly be used to estimate other derived parameters like Relative Risks, and Population Attributable Risks 4.4.2 Fit We can now fit a TMLE simultaneously for all TSM parameters, as well as the above defined ATE parameter all_params &lt;- c(all_tsm_params, ate_param) tmle_fit_multiparam &lt;- fit_tmle3( tmle_task, targeted_likelihood, all_params, targeted_likelihood$updater ) print(tmle_fit_multiparam) A tmle3_Fit that took 1 step(s) type param init_est tmle_est 1: TSM E[Y_{A=Control}] -0.597539939 -0.623611880 2: TSM E[Y_{A=Handwashing}] -0.609703345 -0.631852129 3: TSM E[Y_{A=Nutrition}] -0.605359130 -0.629177873 4: TSM E[Y_{A=Nutrition + WSH}] -0.595174627 -0.616086726 5: TSM E[Y_{A=Sanitation}] -0.591126610 -0.585274354 6: TSM E[Y_{A=WSH}] -0.534109850 -0.454598371 7: TSM E[Y_{A=Water}] -0.579807128 -0.527605528 8: ATE E[Y_{A=Nutrition + WSH}] - E[Y_{A=Control}] 0.002365312 0.007525155 se lower upper psi_transformed lower_transformed 1: 0.02971645 -0.68185506 -0.5653687 -0.623611880 -0.68185506 2: 0.04178946 -0.71375797 -0.5499463 -0.631852129 -0.71375797 3: 0.04249393 -0.71246444 -0.5458913 -0.629177873 -0.71246444 4: 0.04143352 -0.69729494 -0.5348785 -0.616086726 -0.69729494 5: 0.04254009 -0.66865139 -0.5018973 -0.585274354 -0.66865139 6: 0.04544601 -0.54367092 -0.3655258 -0.454598371 -0.54367092 7: 0.03884802 -0.60374624 -0.4514648 -0.527605528 -0.60374624 8: 0.05087455 -0.09218712 0.1072374 0.007525155 -0.09218712 upper_transformed 1: -0.5653687 2: -0.5499463 3: -0.5458913 4: -0.5348785 5: -0.5018973 6: -0.3655258 7: -0.4514648 8: 0.1072374 4.5 Exercise We’ll use data from the Collaborative Perinatal Project (CPP), available in the sl3 package. To simplify this example, we define a binary intervention variable, parity01 – an indicator of having one or more children before the current child and a binary outcome, haz01 – an indicator of having an above average height for age. # load the data set data(cpp) cpp &lt;- cpp[!is.na(cpp[, &quot;haz&quot;]), ] cpp$parity01 &lt;- as.numeric(cpp$parity &gt; 0) cpp[is.na(cpp)] &lt;- 0 cpp$haz01 &lt;- as.numeric(cpp$haz &gt; 0) We’re interested in using this simplified data to estimate an Average Treatment Effect (ATE): \\[\\Psi(P_0) = E_0(E_0[Y|A=1,W]-E_0[Y|A=0,W])\\] Define the variable roles \\((W,A,Y)\\) by creating a list of these nodes. Include the following baseline covariates in \\(W\\): apgar1, apgar5, gagebrth, mage, meducyrs, sexn. Both \\(A\\) and \\(Y\\) are specified above. Implement a tmle3_Spec object that bundles a set of components into a specification. We are interested in specifying the ATE, for which we use tmle_ATE(). Define sl3 base learners to estimate \\(Q = E(Y \\mid A,Y)\\) and \\(g=P(A \\mid W)\\). Define metalearners appropriate for data types. Define a Super Learner for estimating \\(Q\\) and another for estimating \\(g\\). Create a list of the two Super Learners defined in Step 5 and call this object. The list names should be A (defining the Super Learner for estimating \\(g\\)) and Y (defining the Super Learner for estimating \\(Q\\)). Fit the tmle with the tmle3 function. At a minimum, this function will requires specification of (1) the tmle3_Spec, which we defined in Step 2; the data; (3) the list of nodes, which defined the varible roles in Step 1; and (4) the list of Super Learners for estimating \\(g\\) and \\(Q\\), which we defined in Step 6. Note: Like before, you will need to make a data copy to deal with data.table weirdness (cpp2 &lt;- data.table::copy(cpp)) and use cpp2 to fit the tmle. Interpret the tmle3 fit both causally and statistically. 4.6 Summary tmle3 is a general purpose framework for generating TML estimates. The easiest way to use it is to use a predefined spec, allowing you to just fill in the blanks for the data, variable roles, and sl3 learners. However, digging under the hood allows users to specify a wide range of TMLEs. In the next sections, we’ll see how this framework can be used to estimate advanced parameters such as optimal treatments and shift interventions. "],
["r6.html", "Chapter 5 A Primer on the R6 Class System 5.1 Classes, Fields, and Methods 5.2 Object Oriented Programming: Python and R", " Chapter 5 A Primer on the R6 Class System A central goal of the Targeted Learning statistical paradigm is to estimate scientifically relevant parameters in realistic (usually nonparametric) models. The tlverse is designed using basic OOP principles and the R6 OOP framework. While we’ve tried to make it easy to use the tlverse packages without worrying much about OOP, it is helpful to have some intuition about how the tlverse is structured. Here, we briefly outline some key concepts from OOP. Readers familiar with OOP basics are invited to skip this section. 5.1 Classes, Fields, and Methods The key concept of OOP is that of an object, a collection of data and functions that corresponds to some conceptual unit. Objects have two main types of elements: fields, which can be thought of as nouns, are information about an object, and methods, which can be thought of as verbs, are actions an object can perform. Objects are members of classes, which define what those specific fields and methods are. Classes can inherit elements from other classes (sometimes called base classes) – accordingly, classes that are similar, but not exactly the same, can share some parts of their definitions. Many different implementations of OOP exist, with variations in how these concepts are implemented and used. R has several different implementations, including S3, S4, reference classes, and R6. The tlverse uses the R6 implementation. In R6, methods and fields of a class object are accessed using the $ operator. For a more thorough introduction to R’s various OOP systems, see http://adv-r.had.co.nz/OO-essentials.html, from Hadley Wickham’s Advanced R (Wickham 2014). 5.2 Object Oriented Programming: Python and R OO concepts (classes with inherentence) were baked into Python from the first published version (version 0.9 in 1991). In contrast, R gets its OO “approach” from its predecessor, S, first released in 1976. For the first 15 years, S had no support for classes, then, suddenly, S got two OO frameworks bolted on in rapid succession: informal classes with S3 in 1991, and formal classes with S4 in 1998. This process continues, with new OO frameworks being periodically released, to try to improve the lackluster OO support in R, with reference classes (R5, 2010) and R6 (2014). Of these, R6 behaves most like Python classes (and also most like OOP focused languages like C++ and Java), including having method definitions be part of class definitions, and allowing objects to be modified by reference. References "],
["references.html", "References", " References "]
]
