[
["index.html", "The Hitchhiker’s Guide to the tlverse or a Targeted Learning Practitioner’s Handbook Preface About this book 0.1 Outline What this book is not About the authors 0.2 Learning resources 0.3 Setup instructions", " The Hitchhiker’s Guide to the tlverse or a Targeted Learning Practitioner’s Handbook Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips, Alan Hubbard, Mark van der Laan February 21, 2020 Preface About this book The Hitchhiker’s Guide to the tlverse, or a Targeted Learning Practitioner’s Handbook is an open-source and fully-reproducible electronic handbook for applying the targeted learning methodology in practice using the tlverse software ecosystem. This work is currently in an early draft phase and is available to facilitate input from the community. To view or contribute to the available content, consider visiting the GitHub repository for this site. 0.1 Outline The contents of this handbook are meant to serve as a reference guide for applied research as well as materials that can be taught in a series of short courses focused on the applications of Targeted Learning. Each section introduces a set of distinct causal questions, motivated by a case study, alongside statistical methodology and software for assessing the causal claim of interest. The (evolving) set of materials includes Motivation: Why we need a statistical revolution The Roadmap and introductory case study: the WASH Beneifits data Introduction to the tlverse software ecosystem Ensemble machine learning with the sl3 package Targeted learning for causal inference with the tmle3 package Optimal treatments regimes and the tmle3mopttx package Stochastic treatment regimes and the tmle3shift package Coda: Why we need a statistical revolution What this book is not The focus of this work is not on providing in-depth technical descriptions of current statistical methodology or recent advancements. Instead, the goal is to convey key details of state-of-the-art techniques in an manner that is both clear and complete, without burdening the reader with extraneous information. We hope that the presentations herein will serve as references for researchers – methodologists and domain specialists alike – that empower them to deploy the central tools of Targeted Learning in an efficient manner. For technical details and in-depth descriptions of both classical theory and recent advances in the field of Targeted Learning, the interested reader is invited to consult van der Laan and Rose (2011) and/or van der Laan and Rose (2018) as appropriate. The primary literature in statistical causal inference, machine learning, and non/semiparametric theory include many of the most recent advances in Targeted Learning and related areas. About the authors Jeremy Coyle Jeremy R. Coyle, Ph.D., is a consulting data scientist and statistical programmer, currently leading the software development effort that has produced the tlverse ecosystem of R packages and related software tools. Jeremy earned his Ph.D. in Biostatistics from UC Berkeley in 2016, primarily under the supervision of Alan Hubbard. Nima Hejazi Nima S. Hejazi is a Ph.D. candidate in biostatistics with a designated emphasis in computational and genomic biology, working jointly with Mark van der Laan and Alan Hubbard. Nima is affiliated with UC Berkeley’s Center for Computational Biology and NIH Biomedical Big Data training program. His research interests span causal inference, nonparametric inference and machine learning, targeted loss-based estimation, survival analysis, statistical computing, reproducible research, and high-dimensional biology. He is also passionate about software development for applied statistics, including software design, automated testing, and reproducible coding practices. For more information, see https://nimahejazi.org. Ivana Malenica Ivana Malenica is a Ph.D. student in biostatistics advised by Mark van der Laan. Ivana is currently a fellow at the Berkeley Institute for Data Science, after serving as a NIH Biomedical Big Data and Freeport-McMoRan Genomic Engine fellow. She earned her Master’s in Biostatistics and Bachelor’s in Mathematics, and spent some time at the Translational Genomics Research Institute. Very broadly, her research interests span non/semi-parametric theory, probability theory, machine learning, causal inference and high-dimensional statistics. Most of her current work involves complex dependent settings (dependence through time and network) and adaptive sequential designs. Rachael Phillips Rachael is a Ph.D. student in biostatistics, advised by Alan Hubbard and Mark van der Laan. She has an M.A. in Biostatistics, B.S. in Biology with a Chemistry minor and a B.A. in Mathematics with a Spanish minor. Rachael’s research focuses on narrowing the gap between the theory and application of modern statistics for real-world data science. Specifically, Rachael is motivated by issues arising in healthcare, and she leverages strategies rooted in causal inference and nonparametric estimation to build clinician-tailored, machine-driven solutions. Rachael is also passionate about free, online-mediated education and its corresponding pedagogy. Alan Hubbard Alan E. Hubbard is Professor of Biostatistics, former head of the Division of Biostatistics at UC Berkeley, and head of data analytics core at UC Berkeley’s SuperFund research program. His current research interests include causal inference, variable importance analysis, statistical machine learning, estimation of and inference for data-adaptive statistical target parameters, and targeted minimum loss-based estimation. Research in his group is generally motivated by applications to problems in computational biology, epidemiology, and precision medicine. Mark van der Laan Mark J. van der Laan, PhD, is Professor of Biostatistics and Statistics at UC Berkeley. His research interests include statistical methods in computational biology, survival analysis, censored data, adaptive designs, targeted maximum likelihood estimation, causal inference, data-adaptive loss-based learning, and multiple testing. His research group developed loss-based super learning in semiparametric models, based on cross-validation, as a generic optimal tool for the estimation of infinite-dimensional parameters, such as nonparametric density estimation and prediction with both censored and uncensored data. Building on this work, his research group developed targeted maximum likelihood estimation for a target parameter of the data-generating distribution in arbitrary semiparametric and nonparametric models, as a generic optimal methodology for statistical and causal inference. Most recently, Mark’s group has focused in part on the development of a centralized, principled set of software tools for targeted learning, the tlverse. For more information, see https://vanderlaan-lab.org. 0.2 Learning resources To effectively utilize this handbook, the reader need not be a fully trained statistician to begin understanding and applying these methods. However, it is highly recommended for the reader to have an understanding of basic statistical concepts such as confounding, probability distributions, confidence intervals, hypothesis tests, and regression. Advanced knowledge of mathematical statistics may be useful but is not necessary. Familiarity with the R programming language will be essential. We also recommend an understanding of introductory causal inference. For learning the R programming language we recommend the following (free) introductory resources: Software Carpentry’s Programming with R Software Carpentry’s R for Reproducible Scientific Analysis Garret Grolemund and Hadley Wickham’s R for Data Science For a general introduction to causal inference, we recommend Miguel A. Hernán and James M. Robins’ Causal Inference, forthcoming 2020 Jason A. Roy’s A Crash Course in Causality: Inferring Causal Effects from Observational Data on Coursera 0.3 Setup instructions 0.3.1 R and RStudio R and RStudio are separate downloads and installations. R is the underlying statistical computing environment. RStudio is a graphical integrated development environment (IDE) that makes using R much easier and more interactive. You need to install R before you install RStudio. 0.3.1.1 Windows 0.3.1.1.1 If you already have R and RStudio installed Open RStudio, and click on “Help” &gt; “Check for updates”. If a new version is available, quit RStudio, and download the latest version for RStudio. To check which version of R you are using, start RStudio and the first thing that appears in the console indicates the version of R you are running. Alternatively, you can type sessionInfo(), which will also display which version of R you are running. Go on the CRAN website and check whether a more recent version is available. If so, please download and install it. You can check here for more information on how to remove old versions from your system if you wish to do so. 0.3.1.1.2 If you don’t have R and RStudio installed Download R from the CRAN website. Run the .exe file that was just downloaded Go to the RStudio download page Under Installers select RStudio x.yy.zzz - Windows XP/Vista/7/8 (where x, y, and z represent version numbers) Double click the file to install it Once it’s installed, open RStudio to make sure it works and you don’t get any error messages. 0.3.1.2 macOS 0.3.1.2.1 If you already have R and RStudio installed Open RStudio, and click on “Help” &gt; “Check for updates”. If a new version is available, quit RStudio, and download the latest version for RStudio. To check the version of R you are using, start RStudio and the first thing that appears on the terminal indicates the version of R you are running. Alternatively, you can type sessionInfo(), which will also display which version of R you are running. Go on the CRAN website and check whether a more recent version is available. If so, please download and install it. 0.3.1.2.2 If you don’t have R and RStudio installed Download R from the CRAN website. Select the .pkg file for the latest R version Double click on the downloaded file to install R It is also a good idea to install XQuartz (needed by some packages) Go to the RStudio download page Under Installers select RStudio x.yy.zzz - Mac OS X 10.6+ (64-bit) (where x, y, and z represent version numbers) Double click the file to install RStudio Once it’s installed, open RStudio to make sure it works and you don’t get any error messages. 0.3.1.3 Linux Follow the instructions for your distribution from CRAN, they provide information to get the most recent version of R for common distributions. For most distributions, you could use your package manager (e.g., for Debian/Ubuntu run sudo apt-get install r-base, and for Fedora sudo yum install R), but we don’t recommend this approach as the versions provided by this are usually out of date. In any case, make sure you have at least R 3.3.1. Go to the RStudio download page Under Installers select the version that matches your distribution, and install it with your preferred method (e.g., with Debian/Ubuntu sudo dpkg -i rstudio-x.yy.zzz-amd64.deb at the terminal). Once it’s installed, open RStudio to make sure it works and you don’t get any error messages. These setup instructions are adapted from those written for Data Carpentry: R for Data Analysis and Visualization of Ecological Data. References "],
["motivation.html", "Motivation", " Motivation “One enemy of robust science is our humanity — our appetite for being right, and our tendency to find patterns in noise, to see supporting evidence for what we already believe is true, and to ignore the facts that do not fit.” — (“Let’s Think About Cognitive Bias” 2015) Scientific research is at a unique point in history. The need to improve rigor and reproducibility in our field is greater than ever; corroboration moves science forward, yet there is a growing alarm about results that cannot be reproduced and that report false discoveries (Baker 2016). Consequences of not meeting this need will result in further decline in the rate of scientific progression, the reputation of the sciences, and the public’s trust in its findings (Munafò et al. 2017; “How Scientists Fool Themselves – and How They Can Stop” 2015). “The key question we want to answer when seeing the results of any scientific study is whether we can trust the data analysis.” — Peng (2015) Unfortunately, at its current state the culture of data analysis and statistics actually enables human bias through improper model selection. All hypothesis tests and estimators are derived from statistical models, so to obtain valid estimates and inference it is critical that the statistical model contains the process that generated the data. Perhaps treatment was randomized or only depended on a small number of baseline covariates; this knowledge should and can be incorporated in the model. Alternatively, maybe the data is observational, and there is no knowledge about the data-generating process (DGP). If this is the case, then the statistical model should contain all data distributions. In practice; however, models are not selected based on knowledge of the DGP, instead models are often selected based on (1) the p-values they yield, (2) their convenience of implementation, and/or (3) an analysts loyalty to a particular model. This practice of “cargo-cult statistics — the ritualistic miming of statistics rather than conscientious practice,” (Stark and Saltelli 2018) is characterized by arbitrary modeling choices, even though these choices often result in different answers to the same research question. That is, “increasingly often, [statistics] is used instead to aid and abet weak science, a role it can perform well when used mechanically or ritually,” as opposed to its original purpose of safeguarding against weak science (Stark and Saltelli 2018). This presents a fundamental drive behind the epidemic of false findings that scientific research is suffering from (van der Laan and Starmans 2014). “We suggest that the weak statistical understanding is probably due to inadequate”statistics lite&quot; education. This approach does not build up appropriate mathematical fundamentals and does not provide scientifically rigorous introduction into statistics. Hence, students’ knowledge may remain imprecise, patchy, and prone to serious misunderstandings. What this approach achieves, however, is providing students with false confidence of being able to use inferential tools whereas they usually only interpret the p-value provided by black box statistical software. While this educational problem remains unaddressed, poor statistical practices will prevail regardless of what procedures and measures may be favored and/or banned by editorials.&quot; — Szucs and Ioannidis (2017) Our team at The University of California, Berkeley, is uniquely positioned to provide such an education. Spearheaded by Professor Mark van der Laan, and spreading rapidly by many of his students and colleagues who have greatly enriched the field, the aptly named “Targeted Learning” methodology targets the scientific question at hand and is counter to the current culture of “convenience statistics” which opens the door to biased estimation, misleading results, and false discoveries. Targeted Learning restores the fundamentals that formalized the field of statistics, such as the that facts that a statistical model represents real knowledge about the experiment that generated the data, and a target parameter represents what we are seeking to learn from the data as a feature of the distribution that generated it (van der Laan and Starmans 2014). In this way, Targeted Learning defines a truth and establishes a principled standard for estimation, thereby inhibiting these all-too-human biases (e.g., hindsight bias, confirmation bias, and outcome bias) from infiltrating analysis. “The key for effective classical [statistical] inference is to have well-defined questions and an analysis plan that tests those questions.” — Nosek et al. (2018) The objective for this handbook is to provide training to students, researchers, industry professionals, faculty in science, public health, statistics, and other fields to empower them with the necessary knowledge and skills to utilize the sound methodology of Targeted Learning — a technique that provides tailored pre-specified machines for answering queries, so that each data analysis is completely reproducible, and estimators are efficient, minimally biased, and provide formal statistical inference. Just as the conscientious use of modern statistical methodology is necessary to ensure that scientific practice thrives, it remains critical to acknowledge the role that robust software plays in allowing practitioners direct access to published results. We recall that “an article…in a scientific publication is not the scholarship itself, it is merely advertising of the scholarship. The actual scholarship is the complete software development environment and the complete set of instructions which generated the figures,” thus making the availability and adoption of robust statistical software key to enhancing the transparency that is an inherent aspect of science (Buckheit and Donoho 1995). For a statistical methodology to be readily accessible in practice, it is crucial that it is accompanied by robust user-friendly software (Pullenayegum et al. 2016; Stromberg and others 2004). The tlverse software ecosystem was developed to fulfill this need for the Targeted Learning methodology. Not only does this software facilitate computationally reproducible and efficient analyses, it is also a tool for Targeted Learning education since its workflow mirrors that of the methodology. In particular, the tlverse paradigm does not focus on implementing a specific estimator or a small set of related estimators. Instead, the focus is on exposing the statistical framework of Targeted Learning itself — all R packages in the tlverse ecosystem directly model the key objects defined in the mathematical and theoretical framework of Targeted Learning. What’s more, the tlverse R packages share a core set of design principles centered on extensibility, allowing for them to be used in conjunction with each other and built upon one other in a cohesive fashion. In this handbook, the reader will embark on a journey through the tlverse ecosystem. Guided by R programming exercises, case studies, and intuitive explanation readers will build a toolbox for applying the Targeted Learning statistical methodology, which will translate to real-world causal inference analyses. Some preliminaries are required prior to this learning endeavor – we have made available a list of recommended learning resources. References "],
["intro.html", "Chapter 1 The Roadmap for Targeted Learning 1.1 Learning Objectives 1.2 Introduction 1.3 The Roadmap 1.4 Summary of the Roadmap 1.5 Causal Target Parameters", " Chapter 1 The Roadmap for Targeted Learning 1.1 Learning Objectives By the end of this chapter you will be able to: Translate scientific questions to statistical questions. Define a statistical model based on the knowledge of the experiment that generated the data. Identify a causal parameter as a function of the observed data distribution. Explain the following causal and statistical assumptions and their implications: i.i.d., consistency, interference, positivity, SUTVA. 1.2 Introduction The roadmap of statistical learning is concerned with the translation from real-world data applications to a mathematical and statistical formulation of the relevant estimation problem. This involves data as a random variable having a probability distribution, scientific knowledge represented by a statistical model, a statistical target parameter representing an answer to the question of interest, and the notion of an estimator and sampling distribution of the estimator. 1.3 The Roadmap Following the roadmap is a process of five stages. Data as a random variable with a probability distribution, \\(O \\sim P_0\\). The statistical model \\(\\mathcal{M}\\) such that \\(P_0 \\in \\mathcal{M}\\). The statistical target parameter \\(\\Psi\\) and estimand \\(\\Psi(P_0)\\). The estimator \\(\\hat{\\Psi}\\) and estimate \\(\\hat{\\Psi}(P_n)\\). A measure of uncertainty for the estimate \\(\\hat{\\Psi}(P_n)\\). (1) Data: A random variable with a probability distribution, \\(O \\sim P_0\\) The data set we’re confronted with is the result of an experiment and we can view the data as a random variable, \\(O\\), because if we repeat the experiment we would have a different realization of this experiment. In particular, if we repeat the experiment many times we could learn the probability distribution, \\(P_0\\), of our data. So, the observed data \\(O\\) with probability distribution \\(P_0\\) are \\(n\\) independent identically distributed (i.i.d.) observations of the random variable \\(O; O_1, \\ldots, O_n\\). Note that while not all data are i.i.d., there are ways to handle non-i.i.d. data, such as establishing conditional independence, stratifying data to create sets of identically distributed data, etc. It is crucial that researchers be absolutely clear about what they actually know about the data-generating distribution for a given problem of interest. Unfortunately, communication between statisticians and researchers is often fraught with misinterpretation. The roadmap provides a mechanism by which to ensure clear communication between research and statistician – it truly helps with this communication! The empirical probability measure, \\(P_n\\) Once we have \\(n\\) of such i.i.d. observations we have an empirical probability measure, \\(P_n\\). The empirical probability measure is an approximation of the true probability measure \\(P_0\\), allowing us to learn from our data. For example, we can define the empirical probability measure of a set, \\(A\\), to be the proportion of observations which end up in \\(A\\). That is, \\[\\begin{equation*} P_n(A) = \\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{I}(O_i \\in A) \\end{equation*}\\] In order to start learning something, we need to ask “What do we know about the probability distribution of the data?” This brings us to Step 2. (2) The statistical model \\(\\mathcal{M}\\) such that \\(P_0 \\in \\mathcal{M}\\) The statistical model \\(\\mathcal{M}\\) is defined by the question we asked at the end of . It is defined as the set of possible probability distributions for our observed data. Often \\(\\mathcal{M}\\) is very large (possibly infinite-dimensional), to reflect the fact that statistical knowledge is limited. In the case that \\(\\mathcal{M}\\) is infinite-dimensional, we deem this a nonparametric statistical model. Alternatively, if the probability distribution of the data at hand is described by a finite number of parameters, then the statistical model is parametric. In this case, we prescribe to the belief that the random variable \\(O\\) being observed has, e.g., a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\). More formally, a parametric model may be defined \\[\\begin{equation*} \\mathcal{M} = \\{P_{\\theta} : \\theta \\in \\mathcal{R}^d \\} \\end{equation*}\\] Sadly, the assumption that the data-generating distribution has a specific, parametric forms is all-too-common, even when such is a leap of faith. This practice of oversimplification in the current culture of data analysis typically derails any attempt at trying to answer the scientific question at hand; alas, such statements as the ever-popular quip of Box that “All models are wrong but some are useful,” encourage the data analyst to make arbitrary choices even when that often force significant differences in answers to the same estimation problem. The Targeted Learning paradigm does not suffer from this bias since it defines the statistical model through a representation of the true data-generating distribution corresponding to the observed data. Now, on to Step 3: ``What are we trying to learn from the data?&quot; (3) The statistical target parameter \\(\\Psi\\) and estimand \\(\\Psi(P_0)\\) The statistical target parameter, \\(\\Psi\\), is defined as a mapping from the statistical model, \\(\\mathcal{M}\\), to the parameter space (i.e., a real number) \\(\\mathcal{R}\\). That is, \\(\\Psi: \\mathcal{M}\\rightarrow\\mathbb{R}\\). The estimand may be seen as a representation of the quantity that we wish to learn from the data, the answer to a well-specified (often causal) question of interest. In contrast to purely statistical estimands, causal estimands require identification from the observed data, based on causal models that include several untestable assumptions, described in more detail in the section on causal target parameters. For a simple example, consider a data set which contains observations of a survival time on every subject, for which our question of interest is “What’s the probability that someone lives longer than five years?” We have, \\[\\begin{equation*} \\Psi(P_0) = \\mathbb{P}(O &gt; 5) \\end{equation*}\\] This answer to this question is the estimand, \\(\\Psi(P_0)\\), which is the quantity we’re trying to learn from the data. Once we have defined \\(O\\), \\(\\mathcal{M}\\) and \\(\\Psi(P_0)\\) we have formally defined the statistical estimation problem. (4) The estimator \\(\\hat{\\Psi}\\) and estimate \\(\\hat{\\Psi}(P_n)\\) To obtain a good approximation of the estimand, we need an estimator, an a priori-specified algorithm defined as a mapping from the set of possible empirical distributions, \\(P_n\\), which live in a non-parametric statistical model, \\(\\mathcal{M}_{NP}\\) (\\(P_n \\in \\mathcal{M}_{NP}\\)), to the parameter space of the parameter of interest. That is, \\(\\hat{\\Psi} : \\mathcal{M}_{NP} \\rightarrow \\mathbb{R}^d\\). The estimator is a function that takes as input the observed data, a realization of \\(P_n\\), and gives as output a value in the parameter space, which is the estimate, \\(\\hat{\\Psi}(P_n)\\). Where the estimator may be seen as an operator that maps the observed data and corresponding empirical distribution to a value in the parameter space, the numerical output that produced such a function is the estimate. Thus, it is an element of the parameter space based on the empirical probability distribution of the observed data. If we plug in a realization of \\(P_n\\) (based on a sample size \\(n\\) of the random variable \\(O\\)), we get back an estimate \\(\\hat{\\Psi}(P_n)\\) of the true parameter value \\(\\Psi(P_0)\\). In order to quantify the uncertainty in our estimate of the target parameter (i.e., to construct statistical inference), an understanding of the sampling distribution of our estimator will be necessary. This brings us to Step 5. (5) A measure of uncertainty for the estimate \\(\\hat{\\Psi}(P_n)\\) Since the estimator \\(\\hat{\\Psi}\\) is a function of the empirical distribution \\(P_n\\), the estimator itself is a random variable with a sampling distribution. So, if we repeat the experiment of drawing \\(n\\) observations we would every time end up with a different realization of our estimate and our estimator has a sampling distribution. The sampling distribution of an estimator can be theoretically validated to be approximately normally distributed by a Central Limit Theorem (CLT). A class of Central Limit Theorems (CLTs) are statements regarding the convergence of the sampling distribution of an estimator to a normal distribution. In general, we will construct estimators whose limit sampling distributions may be shown to be approximately normal distributed as sample size increases. For large enough \\(n\\) we have, \\[\\begin{equation*} \\hat{\\Psi}(P_n) \\sim N \\left(\\Psi(P_0), \\frac{\\sigma^2}{n}\\right), \\end{equation*}\\] permitting statistical inference. Now, we can proceed to quantify the uncertainty of our chosen estimator by construction of hypothesis tests and confidence intervals. For example, we may construct a confidence interval at level \\((1 - \\alpha)\\) for our estimand, \\(\\Psi(P_0)\\): \\[\\begin{equation*} \\hat{\\Psi}(P_n) \\pm z_{1 - \\frac{\\alpha}{2}} \\left(\\frac{\\sigma}{\\sqrt{n}}\\right), \\end{equation*}\\] where \\(z_{1 - \\frac{\\alpha}{2}}\\) is the \\((1 - \\frac{\\alpha}{2})^\\text{th}\\) quantile of the standard normal distribution. Often, we will be interested in constructing 95% confidence intervals, corresponding to mass \\(\\alpha = 0.05\\) in either tail of the limit distribution; thus, we will typically take \\(z_{1 - \\frac{\\alpha}{2}} \\approx 1.96\\). Note: we will typically have to estimate the standard error, \\(\\frac{\\sigma}{\\sqrt{n}}\\). A 95% confidence interval means that if we were to take 100 different samples of size \\(n\\) and compute a 95% confidence interval for each sample then approximately 95 of the 100 confidence intervals would contain the estimand, \\(\\Psi(P_0)\\). More practically, this means that there is a 95% probability (or 95% confidence) that the confidence interval procedure will contain the true estimand. However, any single estimated confidence interval either will contain the true estimand or will not. 1.4 Summary of the Roadmap Data, \\(O\\), is viewed as a random variable that has a probability distribution. We often have \\(n\\) units of independent identically distributed units with probability distribution \\(P_0\\) (\\(O_1, \\ldots, O_n \\sim P_0\\)). We have statistical knowledge about the experiment that generated this data. In other words, we make a statement that the true data distribution \\(P_0\\) falls in a certain set called a statistical model, \\(\\mathcal{M}\\). Often these sets are very large because statistical knowledge is very limited so these statistical models are often infinite dimensional models. Our statistical query is, “What are we trying to learn from the data?” denoted by the statistical target parameter, \\(\\Psi\\), which maps the \\(P_0\\) into the estimand, \\(\\Psi(P_0)\\). At this point the statistical estimation problem is formally defined and now we will need statistical theory to guide us in the construction of estimators. There’s a lot of statistical theory we will review in this course that, in particular, relies on the Central Limit Theorem, allowing us to come up with estimators that are approximately normally distributed and also allowing us to come with statistical inference (i.e., confidence intervals and hypothesis tests). 1.5 Causal Target Parameters In many cases, we are interested in questions that ask questions regarding the effect of an intervention on a future outcome of interest. These questions can be represented as causal estimands and 1.5.1 The Causal Model After formalizing the data and the statistical model, we can define a causal model to express causal parameters of interest. Directed acyclic graphs (DAGs) are one useful tool to express what we know about the causal relations among variables. Ignoring exogenous \\(U\\) terms (explained below), we assume the following ordering of the variables in the observed data \\(O\\). While directed acyclic graphs (DAGs) like above provide a convenient means by which to visualize causal relations between variables, the same causal relations among variables can be represented via a set of structural equations, which define the non-parametric structural equation model (NPSEM): \\[\\begin{align*} W &amp;= f_W(U_W) \\\\ A &amp;= f_A(W, U_A) \\\\ Y &amp;= f_Y(W, A, U_Y), \\end{align*}\\] where \\(U_W\\), \\(U_A\\), and \\(U_Y\\) represent the unmeasured exogenous background characteristics that influence the value of each variable. In the NPSEM, \\(f_W\\), \\(f_A\\) and \\(f_Y\\) denote that each variable (for \\(W\\), \\(A\\) and \\(Y\\), respectively) is a function of its parents and unmeasured background characteristics, but note that there is no imposition of any particular functional constraints(e.g., linear, logit-linear, only one interaction, etc.). For this reason, they are called non-parametric structural equation models (NPSEMs). The DAG and set of nonparametric structural equations represent exactly the same information and so may be used interchangeably. The first hypothetical experiment we will consider is assigning exposure to the whole population and observing the outcome, and then assigning no exposure to the whole population and observing the outcome. On the nonparametric structural equations, this corresponds to a comparison of the outcome distribution in the population under two interventions: \\(A\\) is set to \\(1\\) for all individuals, and \\(A\\) is set to \\(0\\) for all individuals. These interventions imply two new nonparametric structural equation models. For the case \\(A = 1\\), we have \\[\\begin{align*} W &amp;= f_W(U_W) \\\\ A &amp;= 1 \\\\ Y(1) &amp;= f_Y(W, 1, U_Y), \\end{align*}\\] and for the case \\(A=0\\), \\[\\begin{align*} W &amp;= f_W(U_W) \\\\ A &amp;= 0 \\\\ Y(0) &amp;= f_Y(W, 0, U_Y). \\end{align*}\\] In these equations, \\(A\\) is no longer a function of \\(W\\) because we have intervened on the system, setting \\(A\\) deterministically to either of the values \\(1\\) or \\(0\\). The new symbols \\(Y(1)\\) and \\(Y(0)\\) indicate the outcome variable in our population if it were generated by the respective NPSEMs above; these are often called counterfactuals (since they run contrary-to-fact). The difference between the means of the outcome under these two interventions defines a parameter that is often called the “average treatment effect” (ATE), denoted \\[\\begin{equation}\\label{eqn:ate} ATE = \\mathbb{E}_X(Y(1)-Y(0)), \\end{equation}\\] where \\(\\mathbb{E}_X\\) is the mean under the theoretical (unobserved) full data \\(X = (W, Y(1), Y(0))\\). Note, we can define much more complicated interventions on NPSEM’s, such as interventions based upon rules (themselves based upon covariates), stochastic rules, etc. and each results in a different targeted parameter and entails different identifiability assumptions discussed below. 1.5.2 Identifiability Because we can never observe both \\(Y(0)\\) (the counterfactual outcome when \\(A=0\\)) and \\(Y(1)\\) (similarly, the counterfactual outcome when \\(A=1\\)), we cannot estimate directly. Instead, we have to make assumptions under which this quantity may be estimated from the observed data \\(O \\sim P_0\\) under the data-generating distribution \\(P_0\\). Fortunately, given the causal model specified in the NPSEM above, we can, with a handful of untestable assumptions, estimate the ATE, even from observational data. These assumptions may be summarized as follows The causal graph implies \\(Y(a) \\perp A\\) for all \\(a \\in \\mathcal{A}\\), which is the randomization assumption. In the case of observational data, the analogous assumption is strong ignorability or no unmeasured confounding \\(Y(a) \\perp A \\mid W\\) for all \\(a \\in \\mathcal{A}\\); Although not represented in the causal graph, also required is the assumption of no interference between units, that is, the outcome for unit \\(i\\) \\(Y_i\\) is not affected by exposure for unit \\(j\\) \\(A_j\\) unless \\(i=j\\); Consistency of the treatment mechanism is also required, i.e., the outcome for unit \\(i\\) is \\(Y_i(a)\\) whenever \\(A_i = a\\), an assumption also known as “no other versions of treatment”; It is also necessary that all observed units, across strata defined by \\(W\\), have a bounded (non-deterministic) probability of receiving treatment – that is, \\(0 &lt; \\mathbb{P}(A = a \\mid W) &lt; 1\\) for all \\(a\\) and \\(W\\)). This assumption is referred to as positivity or overlap. Remark: Together, (2) and (3), the assumptions of no interference and consistency, respectively, are jointly referred to as the stable unit treatment value assumption (SUTVA). Given these assumptions, the ATE may be re-written as a function of \\(P_0\\), specifically \\[\\begin{equation}\\label{eqn:estimand} ATE = \\mathbb{E}_0(Y(1) - Y(0)) = \\mathbb{E}_0 \\left(\\mathbb{E}_0[Y \\mid A = 1, W] - \\mathbb{E}_0[Y \\mid A = 0, W]\\right), \\end{equation}\\] or the difference in the predicted outcome values for each subject, under the contrast of treatment conditions (\\(A = 0\\) vs. \\(A = 1\\)), in the population, averaged over all observations. Thus, a parameter of a theoretical “full” data distribution can be represented as an estimand of the observed data distribution. Significantly, there is nothing about the representation in that requires parameteric assumptions; thus, the regressions on the right hand side may be estimated freely with machine learning. With different parameters, there will be potentially different identifiability assumptions and the resulting estimands can be functions of different components of \\(P_0\\). We discuss several more complex estimands in later sections of this handbook. "],
["tlverse.html", "Chapter 2 Welcome to the tlverse 2.1 Learning Objectives 2.2 What is the tlverse? 2.3 tlverse components 2.4 Installation", " Chapter 2 Welcome to the tlverse 2.1 Learning Objectives Understand the tlverse ecosystem conceptually Identify the core components of the tlverse Install tlverse R packages Understand the Targeted Learning roadmap Learn about the WASH Benefits example data 2.2 What is the tlverse? The tlverse is a new framework for doing Targeted Learning in R, inspired by the tidyverse ecosystem of R packages. By analogy to the tidyverse: The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. So, the tlverse is an opinionated collection of R packages for Targeted Learning sharing an underlying philosophy, grammar, and set of data structures 2.3 tlverse components These are the main packages that represent the core of the tlverse: sl3: Modern Super Learning with Pipelines What? A modern object-oriented re-implementation of the Super Learner algorithm, employing recently developed paradigms for R programming. Why? A design that leverages modern tools for fast computation, is forward-looking, and can form one of the cornerstones of the tlverse. tmle3: An Engine for Targeted Learning What? A generalized framework that simplifies Targeted Learning by identifying and implementing a series of common statistical estimation procedures. Why? A common interface and engine that accommodates current algorithmic approaches to Targeted Learning and is still flexible enough to remain the engine even as new techniques are developed. In addition to the engines that drive development in the tlverse, there are some supporting packages – in particular, we have two… origami: A Generalized Framework for Cross-Validation What? A generalized framework for flexible cross-validation Why? Cross-validation is a key part of ensuring error estimates are honest and preventing overfitting. It is an essential part of the both the Super Learner algorithm and Targeted Learning. delayed: Parallelization Framework for Dependent Tasks What? A framework for delayed computations (futures) based on task dependencies. Why? Efficient allocation of compute resources is essential when deploying large-scale, computationally intensive algorithms. A key principle of the tlverse is extensibility. That is, we want to support new Targeted Learning estimators as they are developed. The model for this is new estimators are implemented in additional packages using the core packages above. There are currently two featured examples of this: tmle3mopttx: Optimal Treatments in tlverse What? Learn an optimal rule and estimate the mean outcome under the rule Why? Optimal Treatment is a powerful tool in precision healthcare and other settings where a one-size-fits-all treatment approach is not appropriate. tmle3shift: Shift Interventions in tlverse What? Shift interventions for continuous treatments Why? Not all treatment variables are discrete. Being able to estimate the effects of continuous treatment represents a powerful extension of the Targeted Learning approach. 2.4 Installation The tlverse ecosystem of packages are currently hosted at https://github.com/tlverse, not yet on CRAN. You can use the devtools package to install them: install.packages(&quot;devtools&quot;) devtools::install_github(&quot;tlverse/tlverse&quot;) The tlverse depends on a large number of other packages that are also hosted on GitHub. Because of this, you may see the following error: Error: HTTP error 403. API rate limit exceeded for 71.204.135.82. (But here&#39;s the good news: Authenticated requests get a higher rate limit. Check out the documentation for more details.) Rate limit remaining: 0/60 Rate limit reset at: 2019-03-04 19:39:05 UTC To increase your GitHub API rate limit - Use `usethis::browse_github_pat()` to create a Personal Access Token. - Use `usethis::edit_r_environ()` and add the token as `GITHUB_PAT`. This just means that R tried to install too many packages from GitHub in too short of a window. To fix this, you need to tell R how to use GitHub as your user (you’ll need a GitHub user account). Follow these two steps: Type usethis::browse_github_pat() in your R console, which will direct you to GitHub’s page to create a New Personal Access Token. Create a Personal Access Token simply by clicking “Generate token” at the bottom of the page. Copy your Personal Access Token, a long string of lowercase letters and numbers. Type usethis::edit_r_environ() in your R console, which will open your .Renviron file in the source window of RStudio. If you are not able to access your .Renviron file with this command, then try inputting Sys.setenv(GITHUB_PAT = ) with your Personal Access Token inserted as a string after the equals symbol; and if this does not error, then skip to step 8. In your .Renviron file, type GITHUB_PAT= and then paste your Personal Access Token after the equals symbol with no space. In your .Renviron file, press the enter key to ensure that your .Renviron ends with a newline. Save your .Renviron file. Restart R for changes to take effect. You can restart R via the drop-down menu on the “Session” tab. The “Session” tab is at the top of the RStudio interface. After following these steps, you should be able to successfully install the package which threw the error above. "],
["data.html", "Chapter 3 Datasets 3.1 WASH Benefits Example Dataset 3.2 International Stroke Trial Example Dataset 3.3 Veterans’ Administration Lung Cancer Trial Dataset", " Chapter 3 Datasets 3.1 WASH Benefits Example Dataset The data come from a study of the effect of water quality, sanitation, hand washing, and nutritional interventions on child development in rural Bangladesh (WASH Benefits Bangladesh): a cluster randomized controlled trial (“Temporary,” n.d.). The study enrolled pregnant women in their first or second trimester from the rural villages of Gazipur, Kishoreganj, Mymensingh, and Tangail districts of central Bangladesh, with an average of eight women per cluster. Groups of eight geographically adjacent clusters were block randomized, using a random number generator, into six intervention groups (all of which received weekly visits from a community health promoter for the first 6 months and every 2 weeks for the next 18 months) and a double-sized control group (no intervention or health promoter visit). The six intervention groups were: chlorinated drinking water; improved sanitation; hand-washing with soap; combined water, sanitation, and hand washing; improved nutrition through counseling and provision of lipid-based nutrient supplements; and combined water, sanitation, handwashing, and nutrition. In the handbook, we concentrate on child growth (size for age) as the outcome of interest. For reference, this trial was registered with ClinicalTrials.gov as NCT01590095. library(tidyverse) # read in data dat &lt;- read_csv(&quot;https://raw.githubusercontent.com/tlverse/tlverse-data/master/wash-benefits/washb_data.csv&quot;) dat # A tibble: 4,695 x 28 whz tr fracode month aged sex momage momedu momheight hfiacat Nlt18 &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 0 Cont… N05265 9 268 male 30 Prima… 146. Food S… 3 2 -1.16 Cont… N05265 9 286 male 25 Prima… 149. Modera… 2 3 -1.05 Cont… N08002 9 264 male 25 Prima… 152. Food S… 1 4 -1.26 Cont… N08002 9 252 fema… 28 Prima… 140. Food S… 3 5 -0.59 Cont… N06531 9 336 fema… 19 Secon… 151. Food S… 2 6 -0.51 Cont… N06531 9 304 male 20 Secon… 154. Severe… 0 7 -2.46 Cont… N08002 9 336 fema… 19 Prima… 151. Food S… 2 8 -0.6 Cont… N06528 9 312 fema… 25 No ed… 142. Food S… 2 9 -0.23 Cont… N06528 9 322 male 30 Secon… 153. Food S… 1 10 -0.14 Cont… N06453 9 376 male 30 No ed… 156. Modera… 2 # … with 4,685 more rows, and 17 more variables: Ncomp &lt;dbl&gt;, watmin &lt;dbl&gt;, # elec &lt;dbl&gt;, floor &lt;dbl&gt;, walls &lt;dbl&gt;, roof &lt;dbl&gt;, asset_wardrobe &lt;dbl&gt;, # asset_table &lt;dbl&gt;, asset_chair &lt;dbl&gt;, asset_khat &lt;dbl&gt;, asset_chouki &lt;dbl&gt;, # asset_tv &lt;dbl&gt;, asset_refrig &lt;dbl&gt;, asset_bike &lt;dbl&gt;, asset_moto &lt;dbl&gt;, # asset_sewmach &lt;dbl&gt;, asset_mobile &lt;dbl&gt; For the purposes of this handbook, we start by treating the data as independent and identically distributed (i.i.d.) random draws from a very large target population. We could, with available options, account for the clustering of the data (within sampled geographic units), but, for simplification, we avoid these details in the handbook, although modifications of our methodology for biased samples, repeated measures, etc., are available. We have 28 variables measured, of which 1 variable is set to be the outcome of interest. This outcome, \\(Y\\), is the weight-for-height Z-score (whz in dat); the treatment of interest, \\(A\\), is the randomized treatment group (tr in dat); and the adjustment set, \\(W\\), consists simply of everything else. This results in our observed data structure being \\(n\\) i.i.d. copies of \\(O_i = (W_i, A_i, Y_i)\\), for \\(i = 1, \\ldots, n\\). Using the skimr package, we can quickly summarize the variables measured in the WASH Benefits data set: library(skimr) skim(dat) (#tab:skim_washb_data)Data summary Name dat Number of rows 4695 Number of columns 28 _______________________ Column type frequency: character 5 numeric 23 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace tr 0 1 3 15 0 7 0 fracode 0 1 2 6 0 20 0 sex 0 1 4 6 0 2 0 momedu 0 1 12 15 0 3 0 hfiacat 0 1 11 24 0 4 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist whz 0 1.00 -0.59 1.03 -4.67 -1.28 -0.6 0.08 4.97 ▁▆▇▁▁ month 0 1.00 6.45 3.33 1.00 4.00 6.0 9.00 12.00 ▇▇▅▇▇ aged 0 1.00 266.32 52.17 42.00 230.00 266.0 303.00 460.00 ▁▂▇▅▁ momage 18 1.00 23.91 5.24 14.00 20.00 23.0 27.00 60.00 ▇▇▁▁▁ momheight 31 0.99 150.50 5.23 120.65 147.05 150.6 154.06 168.00 ▁▁▆▇▁ Nlt18 0 1.00 1.60 1.25 0.00 1.00 1.0 2.00 10.00 ▇▂▁▁▁ Ncomp 0 1.00 11.04 6.35 2.00 6.00 10.0 14.00 52.00 ▇▃▁▁▁ watmin 0 1.00 0.95 9.48 0.00 0.00 0.0 1.00 600.00 ▇▁▁▁▁ elec 0 1.00 0.60 0.49 0.00 0.00 1.0 1.00 1.00 ▆▁▁▁▇ floor 0 1.00 0.11 0.31 0.00 0.00 0.0 0.00 1.00 ▇▁▁▁▁ walls 0 1.00 0.72 0.45 0.00 0.00 1.0 1.00 1.00 ▃▁▁▁▇ roof 0 1.00 0.99 0.12 0.00 1.00 1.0 1.00 1.00 ▁▁▁▁▇ asset_wardrobe 0 1.00 0.17 0.37 0.00 0.00 0.0 0.00 1.00 ▇▁▁▁▂ asset_table 0 1.00 0.73 0.44 0.00 0.00 1.0 1.00 1.00 ▃▁▁▁▇ asset_chair 0 1.00 0.73 0.44 0.00 0.00 1.0 1.00 1.00 ▃▁▁▁▇ asset_khat 0 1.00 0.61 0.49 0.00 0.00 1.0 1.00 1.00 ▅▁▁▁▇ asset_chouki 0 1.00 0.78 0.41 0.00 1.00 1.0 1.00 1.00 ▂▁▁▁▇ asset_tv 0 1.00 0.30 0.46 0.00 0.00 0.0 1.00 1.00 ▇▁▁▁▃ asset_refrig 0 1.00 0.08 0.27 0.00 0.00 0.0 0.00 1.00 ▇▁▁▁▁ asset_bike 0 1.00 0.32 0.47 0.00 0.00 0.0 1.00 1.00 ▇▁▁▁▃ asset_moto 0 1.00 0.07 0.25 0.00 0.00 0.0 0.00 1.00 ▇▁▁▁▁ asset_sewmach 0 1.00 0.06 0.25 0.00 0.00 0.0 0.00 1.00 ▇▁▁▁▁ asset_mobile 0 1.00 0.86 0.35 0.00 1.00 1.0 1.00 1.00 ▁▁▁▁▇ A convenient summ ary of the r elevant variable s is give n just a bove, com plete with a small visu alization de scribing the mar ginal cha racteris tics of e ach covariate. Note t hat the *ass et* variables re flect soc io-econo mic statu s of the study participant s. Notice al so the uniform d istributi on of th e treatme nt groups (with twice as ma ny controls) ; this is, of co urse, by design. 3.2 International Stroke Trial Example Dataset The International Stroke Trial database contains individual patient data from the International Stroke Trial (IST), a multi-national randomized trial conducted between 1991 and 1996 (pilot phase between 1991 and 1993) that aimed to assess whether early administration of aspirin, heparin, both aspirin and heparin, or neither influenced the clinical course of acute ischaemic stroke (Sandercock et al. 1997). The IST dataset includes data on 19,435 patients with acute stroke, with 99% complete follow-up. De-identified data are available for download at https://datashare.is.ed.ac.uk/handle/10283/128. This study is described in more detail in Sandercock, Niewada, and Członkowska (2011). The example data for this handbook considers a sample of 5,000 patients and the binary outcome of recurrent ischemic stroke within 14 days after randomization. Also in this example data, we ensure that we have subjects with a missing outcome. library(tidyverse) # read in data ist &lt;- read_csv(&quot;https://raw.githubusercontent.com/tlverse/tlverse-handbook/master/data/ist_sample.csv&quot;) ist # A tibble: 5,000 x 26 RDELAY RCONSC SEX AGE RSLEEP RATRIAL RCT RVISINF RHEP24 RASP3 RSBP &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; 1 46 F F 85 N N N N Y N 150 2 33 F M 71 Y Y Y Y N Y 180 3 6 D M 88 N Y N N N N 140 4 8 F F 68 Y N Y Y N N 118 5 13 F M 60 N N Y N N N 140 6 16 F F 71 Y N Y N N N 160 7 6 F M 71 Y N N N N Y 130 8 15 F M 84 N N Y N Y N 160 9 9 D F 81 N N N N N Y 138 10 20 F F 70 Y N N N N N 170 # … with 4,990 more rows, and 15 more variables: RDEF1 &lt;chr&gt;, RDEF2 &lt;chr&gt;, # RDEF3 &lt;chr&gt;, RDEF4 &lt;chr&gt;, RDEF5 &lt;chr&gt;, RDEF6 &lt;chr&gt;, RDEF7 &lt;chr&gt;, # RDEF8 &lt;chr&gt;, STYPE &lt;chr&gt;, RXHEP &lt;chr&gt;, REGION &lt;chr&gt;, # MISSING_RATRIAL_RASP3 &lt;dbl&gt;, MISSING_RHEP24 &lt;dbl&gt;, RXASP &lt;dbl&gt;, # DRSISC &lt;dbl&gt; We have 26 variables measured, and the outcome of interest, \\(Y\\), indicates recurrent ischemic stroke within 14 days after randomization (DRSISC in ist); the treatment of interest, \\(A\\), is the randomized aspirin vs. no aspirin treatment allocation (RXASP in ist); and the adjustment set, \\(W\\), consists of all other variables measured at baseline. In this data, the outcome is occasionally missing, but there is no need to create a variable indicating this missingness (such as \\(\\Delta\\)) for analyses in the tlverse, since it is automatically detected when NA are present in the outcome. This observed data structure can be denoted as \\(n\\) i.i.d. copies of \\(O_i = (W_i, A_i, \\Delta_i, \\Delta Y_i)\\), for \\(i = 1, \\ldots, n\\), where \\(\\Delta\\) denotes the binary indicator that the outcome is observed. Like before, we can summarize the variables measured in the IST sample data set with skimr: skim(ist) (#tab:skim_ist_data)Data summary Name ist Number of rows 5000 Number of columns 26 _______________________ Column type frequency: character 19 numeric 7 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace RCONSC 0 1 1 1 0 3 0 SEX 0 1 1 1 0 2 0 RSLEEP 0 1 1 1 0 2 0 RATRIAL 0 1 1 1 0 3 0 RCT 0 1 1 1 0 2 0 RVISINF 0 1 1 1 0 2 0 RHEP24 0 1 1 1 0 3 0 RASP3 0 1 1 1 0 3 0 RDEF1 0 1 1 1 0 3 0 RDEF2 0 1 1 1 0 3 0 RDEF3 0 1 1 1 0 3 0 RDEF4 0 1 1 1 0 3 0 RDEF5 0 1 1 1 0 3 0 RDEF6 0 1 1 1 0 3 0 RDEF7 0 1 1 1 0 3 0 RDEF8 0 1 1 1 0 3 0 STYPE 0 1 3 4 0 5 0 RXHEP 0 1 1 1 0 4 0 REGION 0 1 10 26 0 7 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist RDELAY 0 1 20.14 12.43 1 9 19 29 48 ▇▆▆▃▂ AGE 0 1 71.93 11.65 16 65 74 81 99 ▁▁▃▇▂ RSBP 0 1 160.62 27.84 71 140 160 180 290 ▁▇▇▁▁ MISSING_RATRIAL_RASP3 0 1 0.05 0.22 0 0 0 0 1 ▇▁▁▁▁ MISSING_RHEP24 0 1 0.02 0.13 0 0 0 0 1 ▇▁▁▁▁ RXASP 0 1 0.50 0.50 0 0 0 1 1 ▇▁▁▁▇ DRSISC 10 1 0.02 0.15 0 0 0 0 1 ▇▁▁▁▁ 3.3 Veterans’ Administration Lung Cancer Trial Dataset This data corresponds to a study conducted by the US Veterans Administration. Male patients with advanced inoperable lung cancer were given either the standard therapy or a test chemotherapy. The primary goal of the study was to assess if the test chemotherapy improved survival. This data set has been published in Kalbfleisch and Prentice (2011) and it is available in the MASS and survival R packages. Time to death was recorded for 128 patients, and 9 patients left the study before death. Various covariates were also documented for each patient. library(tidyverse) # read in data vet &lt;- read_csv(&quot;https://raw.githubusercontent.com/tlverse/tlverse-handbook/master/data/veteran.csv&quot;) vet # A tibble: 137 x 9 X1 trt celltype time status karno diagtime age prior &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 1 1 squamous 72 1 60 7 69 0 2 2 1 squamous 411 1 70 5 64 10 3 3 1 squamous 228 1 60 3 38 0 4 4 1 squamous 126 1 60 9 63 10 5 5 1 squamous 118 1 70 11 65 10 6 6 1 squamous 10 1 20 5 49 0 7 7 1 squamous 82 1 40 10 69 10 8 8 1 squamous 110 1 80 29 68 0 9 9 1 squamous 314 1 50 18 43 0 10 10 1 squamous 100 0 70 6 70 0 # … with 127 more rows A snapshot of the data set in shown below: skim(vet) (#tab:skim_vet_data)Data summary Name vet Number of rows 137 Number of columns 9 _______________________ Column type frequency: character 1 numeric 8 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace celltype 0 1 5 9 0 4 0 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist X1 0 1 69.00 39.69 1 35 69 103 137 ▇▇▇▇▇ trt 0 1 1.50 0.50 1 1 1 2 2 ▇▁▁▁▇ time 0 1 121.63 157.82 1 25 80 144 999 ▇▁▁▁▁ status 0 1 0.93 0.25 0 1 1 1 1 ▁▁▁▁▇ karno 0 1 58.57 20.04 10 40 60 75 99 ▁▅▇▇▂ diagtime 0 1 8.77 10.61 1 3 5 11 87 ▇▁▁▁▁ age 0 1 58.31 10.54 34 51 62 66 81 ▃▂▅▇▁ prior 0 1 2.92 4.56 0 0 0 10 10 ▇▁▁▁▃ References "],
["sl3.html", "Chapter 4 Super (Machine) Learning 4.1 Learning Objectives 4.2 Motivation 4.3 Introduction 4.4 sl3 “Microwave Dinner” Implementation 4.5 Cross-validated Super Learner 4.6 Variable Importance Measures with sl3 4.7 Exercises 4.8 Concluding Remarks 4.9 Appendix", " Chapter 4 Super (Machine) Learning Rachael Phillips Based on the sl3 R package by Jeremy Coyle, Nima Hejazi, Ivana Malenica, and Oleg Sofrygin. Updated: 2020-02-21 4.1 Learning Objectives By the end of this chapter you will be able to: Select a loss function that is appropriate for the functional parameter to be estimated. Assemble an ensemble of learners based on the properties that identify what features they support. Customize learner hyperparameters to incorporate a diversity of different settings. Select a subset of available covariates and pass only those variables to the modeling algorithm. Fit an ensemble with nested cross-validation to obtain an estimate of the performance of the ensemble itself. Obtain sl3 variable importance metrics. Interpret the discrete and continuous Super Learner fits. Rationalize the need to remove bias from the Super Learner to make an optimal bias–variance tradeoff for the parameter of interest. 4.2 Motivation A common task in statistical data analysis is estimator selection (e.g., for prediction). There is no universally optimal machine learning algorithm for density estimation or prediction. For some data, one needs learners that can model a complex function. For others, possibly as a result of noise or insufficient sample size, a simple, parametric model might fit best. The Super Learner, an ensemble learner, solves this issue, by allowing a combination of learners from the simplest (intercept-only) to most complex (neural nets, random forests, SVM, etc). It works by using cross-validation in a manner which guarantees that the resulting fit will be as good as possible, given the learners provided. 4.3 Introduction In Chapter 1, we introduced the Roadmap for Targeted Learning as a general template to translate real-world data applications into formal statistical estimation problems. The first steps of this roadmap define the statistical estimation problem, which establish Data as a realization of a random variable, or equivalently, an outcome of a particular experiment. A statistical model, representing the true knowledge about the data-generating experiment. A translation of the scientific question, which is often causal, into a target parameter. Note that if the target parameter is causal, step 3 also requires establishing identifiability of the target quantity from the observed data distribution, under possible non-testable assumptions that may not necessarily be reasonable. Still, the target quantity does have a valid statistical interpretation. See causal target parameters for more detail on causal models and identifiability. Now that we have defined the statistical estimation problem, we are ready to construct the TMLE; an asymptotically linear and efficient substitution estimator of this target quantity. The first step in this estimation procedure is an initial estimate of the data-generating distribution, or the relevant part of this distribution that is needed to evaluate the target parameter. For this initial estimation, we use the Super Learner (van der Laan, Polley, and Hubbard 2007). The Super Learner provides an important step in creating a robust estimator. It is a loss-function-based tool that uses cross-validation to obtain the best prediction of our target parameter, based on a weighted average of a library of machine learning algorithms. The library of machine learning algorithms consists of functions (“learners” in the sl3 nomenclature) that we think might be consistent with the true data-generating distribution (i.e. algorithms selected based on contextual knowledge of the experiment that generated the data). Also, the library should contain a large set of “default” algorithms that may range from a simple linear regression model to multi-step algorithms involving screening covariates, penalizations, optimizing tuning parameters, etc. The ensembling of the collection of algorithms with weights (“metalearning” in the sl3 nomenclature) has been shown to be adaptive and robust, even in small samples (Polley and van der Laan 2010). The Super Learner is proven to be asymptotically as accurate as the best possible prediction algorithm in the library (van der Laan and Dudoit 2003; van der Vaart, Dudoit, and van der Laan 2006). 4.3.1 Background A loss function \\(L\\) is defined as a function of the observed data and a candidate parameter value \\(\\psi\\), which has unknown true value \\(\\psi_0\\), \\(L(\\psi)(O)\\). We can estimate the loss by substituting the empirical distribution \\(P_n\\) for the true (but unknown) distribution of the observed data \\(P_0\\). A valid loss function will have expectation (risk) that is minimized at the true value of the parameter \\(\\psi_0\\). For example, the conditional mean minimizes the risk of the squared error loss. Thus, it is a valid loss function when estimating the conditional mean. The discrete Super Learner, or cross-validation selector, is the algorithm in the library that minimizes the cross-validated empirical risk. The cross-validated empirical risk of an algorithm is defined as the empirical mean over a validation sample of the loss of the algorithm fitted on the training sample, averaged across the splits of the data. The continuous/ensemble Super Learner, often referred to as Super Learner is a weighted average of the library of algorithms, where the weights are chosen to minimize the cross-validated empirical risk of the library. Restricting the weights to be positive and sum to one (i.e., a convex combination) has been shown to improve upon the discrete Super Learner (Polley and van der Laan 2010; van der Laan, Polley, and Hubbard 2007). This notion of weighted combinations was introduced in Wolpert (1992) for neural networks and adapted for regressions in Breiman (1996). Cross-validation is proven to be optimal for selection among estimators. This result was established through the oracle inequality for the cross-validation selector among a collection of candidate estimators (van der Laan and Dudoit 2003; van der Vaart, Dudoit, and van der Laan 2006). The only condition is that loss function is uniformly bounded, which is guaranteed in sl3. 4.3.1.1 General Overview of the Algorithm What is cross-validation and how does it work? There are many different cross-validation schemes, designed to accommodate different study designs and data structures. The figure below shows an example of 10-fold cross-validation. General step-by-step overview of the Super Learner algorithm: Break up the sample evenly into V-folds (say V=10). For each of these 10 folds, remove that portion of the sample (kept out as validation sample) and the remaining will be used to fit learners (training sample). Fit each learner on the training sample (note, some learners will have their own internal cross-validation procedure or other methods to select tuning parameters). For each observation in the corresponding validation sample, predict the outcome using each of the learners, so if there are \\(p\\) learners, then there would be \\(p\\) predictions. Take out another validation sample and repeat until each of the V-sets of data are removed. Compare the cross-validated fit of the learners across all observations based on specified loss function (e.g., squared error, negative log-likelihood, …) by calculating the corresponding average loss (risk). Either: choose the learner with smallest risk and apply that learner to entire data set (resulting SL fit), do a weighted average of the learners to minimize the cross-validated risk (construct an ensemble of learners), by re-fitting the learners on the original data set, and use the weights above to get the SL fit. This entire procedure can be itself cross-validated to get a consistent estimate of the future performance of the Super Learner, and we implement this procedure later in this chapter. 4.3.2 Super Learner for Prediction Say we observe a learning data set \\(X_i=(Y_i,W_i)\\), for \\(i=1, ..., n\\), where \\(Y_i\\) is the outcome of interest, \\(W_i\\) is a \\(p\\)-dimensional set of covariates, and our objective is to estimate the function \\(\\psi_0(W) = E(Y|W)\\). This function can be expressed as the minimizer of the expected loss: \\(\\psi_0(W) = \\text{argmin}_{\\psi} E[L(X,\\psi(W))]\\). Here, the loss function is represented as \\(L\\) (e.g., squared error loss, \\(L: (Y-\\psi(W))^2)\\)). For prediction, one can use the cross-validated risk to empirically determine the relative performance of the Super Learner . When we have tested different algorithms on actual data and looked at the performance (e.g., MSE of prediction), never does one algorithm always win. Below, we show the results of such a study, comparing the fits of several different learners, including the SL algorithms. For more detail on Super Learner we refer the reader to van der Laan, Polley, and Hubbard (2007) and Polley and van der Laan (2010). The optimality results for the cross-validation selector among a family of algorithms were established in van der Laan and Dudoit (2003) and extended in van der Vaart, Dudoit, and van der Laan (2006). 4.4 sl3 “Microwave Dinner” Implementation We begin by illustrating the core functionality of the super learner algorithm as implemented in sl3. For those who are interested in the internals of sl3, see this sl3 introductory tutorial. The sl3 implementation consists of the following steps: Load the necessary libraries and data Define the machine learning task Make a super learner by creating library of base learners and a metalearner Train the super learner on the machine learning task Obtain predicted values 4.4.1 WASH Benefits Study Example Using the WASH data, we are interested in predicting weight-for-height z-score whz using the available covariate data. More information on this dataset, and all other data that we will work with in this handbook, is contained in Chapter 3. Let’s begin! 0. Load the necessary libraries and data First, we will load the relevant R packages, set a seed, and load the data. If you would like to use newer sl3 functionality that is available in the devel branch of the sl3 GitHub repository, you need to install that version of the package (e.g. devtools::install_github(tlverse/sl3@devel)), re-start your R session, and then re-load the sl3 package. library(data.table) library(tidyverse) library(origami) library(SuperLearner) library(sl3) library(ggplot2) library(knitr) library(kableExtra) set.seed(7194) # my lucky seed! or is it 9174? or 4917? many lucky seeds, thanks lysdexia! # load data set and take a peek washb_data &lt;- fread(&quot;https://raw.githubusercontent.com/tlverse/tlverse-data/master/wash-benefits/washb_data.csv&quot;, stringsAsFactors = TRUE) head(washb_data) %&gt;% kable(digits = 4) %&gt;% kableExtra:::kable_styling(fixed_thead = T) %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;300px&quot;) whz tr fracode month aged sex momage momedu momheight hfiacat Nlt18 Ncomp watmin elec floor walls roof asset_wardrobe asset_table asset_chair asset_khat asset_chouki asset_tv asset_refrig asset_bike asset_moto asset_sewmach asset_mobile 0.00 Control N05265 9 268 male 30 Primary (1-5y) 146.40 Food Secure 3 11 0 1 0 1 1 0 1 1 1 0 1 0 0 0 0 1 -1.16 Control N05265 9 286 male 25 Primary (1-5y) 148.75 Moderately Food Insecure 2 4 0 1 0 1 1 0 1 0 1 1 0 0 0 0 0 1 -1.05 Control N08002 9 264 male 25 Primary (1-5y) 152.15 Food Secure 1 10 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 -1.26 Control N08002 9 252 female 28 Primary (1-5y) 140.25 Food Secure 3 5 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 -0.59 Control N06531 9 336 female 19 Secondary (&gt;5y) 150.95 Food Secure 2 7 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 -0.51 Control N06531 9 304 male 20 Secondary (&gt;5y) 154.20 Severely Food Insecure 0 3 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 1 1. Define the machine learning task To define the machine learning “task” (predict weight-for-height z-score whz using the available covariate data), we need to create an sl3_Task object. The sl3_Task keeps track of the roles the variables play in the machine learning problem, the data, and any metadata (e.g., observational-level weights, id, offset). Also, if we had missing outcomes, we would need to set drop_missing_outcome = TRUE when we create the task. In the next analysis, with the IST stroke trial data, we do have a missing outcome. In the following chapter, we estimate the missingness mechanism and account for it in the TMLE. # specify the outcome and covariates outcome &lt;- &quot;whz&quot; covars &lt;- colnames(washb_data)[-which(names(washb_data) == outcome)] # create the sl3 task washb_task &lt;- make_sl3_Task( data = washb_data, covariates = covars, outcome = outcome ) Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. This warning is important. The task just imputed missing covariates for us. Specifically, for each covariate column with missing values, sl3 uses the median to impute missing continuous covariates, and the mode to impute binary and categorical covariates. Also, for each covariate column with missing values, sl3 adds an additional column indicating whether or not the value was imputed, which is particularly handy when the missingness in the data might be informative. Also, notice that we did not specify the number of folds, or the loss function in the task. The default cross-validation scheme is V-fold, with the number of folds \\(V=10\\). Let’s visualize our washb_task. washb_task A sl3 Task with 4695 obs and these nodes: $covariates [1] &quot;tr&quot; &quot;fracode&quot; &quot;month&quot; &quot;aged&quot; [5] &quot;sex&quot; &quot;momage&quot; &quot;momedu&quot; &quot;momheight&quot; [9] &quot;hfiacat&quot; &quot;Nlt18&quot; &quot;Ncomp&quot; &quot;watmin&quot; [13] &quot;elec&quot; &quot;floor&quot; &quot;walls&quot; &quot;roof&quot; [17] &quot;asset_wardrobe&quot; &quot;asset_table&quot; &quot;asset_chair&quot; &quot;asset_khat&quot; [21] &quot;asset_chouki&quot; &quot;asset_tv&quot; &quot;asset_refrig&quot; &quot;asset_bike&quot; [25] &quot;asset_moto&quot; &quot;asset_sewmach&quot; &quot;asset_mobile&quot; &quot;delta_momage&quot; [29] &quot;delta_momheight&quot; $outcome [1] &quot;whz&quot; $id NULL $weights NULL $offset NULL 2. Make a Super Learner Now that we have defined our machine learning problem with the task, we are ready to “make” the Super Learner. This requires specification of A library of base learning algorithms that we think might be consistent with the true data-generating distribution. A metalearner, to ensemble the base learners. We might also incorporate Feature selection, to pass only a subset of the predictors to the algorithm. Hyperparameter specification, to tune base learners. Learners have properties that indicate what features they support. We may use sl3_list_properties() to get a list of all properties supported by at least one learner. sl3_list_properties() [1] &quot;binomial&quot; &quot;categorical&quot; &quot;continuous&quot; [4] &quot;cv&quot; &quot;density&quot; &quot;ids&quot; [7] &quot;multivariate_outcome&quot; &quot;offset&quot; &quot;preprocessing&quot; [10] &quot;timeseries&quot; &quot;weights&quot; &quot;wrapper&quot; Since we have a continuous outcome, we may identify the learners that support this outcome type with sl3_list_learners(). sl3_list_learners(&quot;continuous&quot;) [1] &quot;Lrnr_arima&quot; &quot;Lrnr_bartMachine&quot; [3] &quot;Lrnr_bilstm&quot; &quot;Lrnr_caret&quot; [5] &quot;Lrnr_condensier&quot; &quot;Lrnr_dbarts&quot; [7] &quot;Lrnr_earth&quot; &quot;Lrnr_expSmooth&quot; [9] &quot;Lrnr_gam&quot; &quot;Lrnr_gbm&quot; [11] &quot;Lrnr_glm&quot; &quot;Lrnr_glm_fast&quot; [13] &quot;Lrnr_glmnet&quot; &quot;Lrnr_grf&quot; [15] &quot;Lrnr_h2o_glm&quot; &quot;Lrnr_h2o_grid&quot; [17] &quot;Lrnr_hal9001&quot; &quot;Lrnr_HarmonicReg&quot; [19] &quot;Lrnr_lstm&quot; &quot;Lrnr_mean&quot; [21] &quot;Lrnr_nnls&quot; &quot;Lrnr_optim&quot; [23] &quot;Lrnr_pkg_SuperLearner&quot; &quot;Lrnr_pkg_SuperLearner_method&quot; [25] &quot;Lrnr_pkg_SuperLearner_screener&quot; &quot;Lrnr_polspline&quot; [27] &quot;Lrnr_randomForest&quot; &quot;Lrnr_ranger&quot; [29] &quot;Lrnr_rpart&quot; &quot;Lrnr_rugarch&quot; [31] &quot;Lrnr_screener_corP&quot; &quot;Lrnr_screener_corRank&quot; [33] &quot;Lrnr_screener_randomForest&quot; &quot;Lrnr_solnp&quot; [35] &quot;Lrnr_stratified&quot; &quot;Lrnr_svm&quot; [37] &quot;Lrnr_tsDyn&quot; &quot;Lrnr_xgboost&quot; Now that we have an idea of some learners, we can construct them using the make_learner function. # choose base learners lrnr_glm &lt;- make_learner(Lrnr_glm) lrnr_mean &lt;- make_learner(Lrnr_mean) We can customize learner hyperparameters to incorporate a diversity of different settings. Documentation for the learners and their hyperparameters can be found in the sl3 Learners Reference. lrnr_ranger50 &lt;- make_learner(Lrnr_ranger, num.trees = 50) lrnr_hal_simple &lt;- make_learner(Lrnr_hal9001, max_degree = 2, n_folds = 2) lrnr_lasso &lt;- make_learner(Lrnr_glmnet) # alpha default is 1 lrnr_ridge &lt;- make_learner(Lrnr_glmnet, alpha = 0) lrnr_elasticnet &lt;- make_learner(Lrnr_glmnet, alpha = .5) We can also include learners from the SuperLearner R package. lrnr_bayesglm &lt;- Lrnr_pkg_SuperLearner$new(&quot;SL.bayesglm&quot;) Here is a fun trick to create customized learners over a grid of parameters. # I like to crock pot my super learners grid_params &lt;- list(cost = c(0.01, 0.1, 1, 10, 100, 1000), gamma = c(0.001, 0.01, 0.1, 1), kernel = c(&quot;polynomial&quot;, &quot;radial&quot;, &quot;sigmoid&quot;), degree = c(1, 2, 3)) grid &lt;- expand.grid(grid_params, KEEP.OUT.ATTRS = FALSE) params_default &lt;- list(nthread = getOption(&quot;sl.cores.learners&quot;, 1)) svm_learners &lt;- apply(grid, MARGIN = 1, function(params_tune) { do.call(Lrnr_svm$new, c(params_default, as.list(params_tune)))}) grid_params &lt;- list(max_depth = c(2, 4, 6, 8), eta = c(0.001, 0.01, 0.1, 0.2, 0.3), nrounds = c(20, 50)) grid &lt;- expand.grid(grid_params, KEEP.OUT.ATTRS = FALSE) params_default &lt;- list(nthread = getOption(&quot;sl.cores.learners&quot;, 1)) xgb_learners &lt;- apply(grid, MARGIN = 1, function(params_tune) { do.call(Lrnr_xgboost$new, c(params_default, as.list(params_tune)))}) Did you see Lrnr_caret when we called sl3_list_learners(c(&quot;binomial&quot;))? All we need to specify is the algorithm to use, which is passed as method to caret::train(). The default method for parameter selection criterion with is set to “CV” instead of the caret::train() default boot. The summary metric to used to select the optimal model is RMSE for continuous outcomes and Accuracy for categorical and binomial outcomes. # I have no idea how to tune a neural net (or BART machine..) lrnr_caret_nnet &lt;- make_learner(Lrnr_caret, algorithm = &quot;nnet&quot;) lrnr_caret_bartMachine &lt;- make_learner(Lrnr_caret, algorithm = &quot;bartMachine&quot;, method = &quot;boot&quot;, metric = &quot;Accuracy&quot;, tuneLength = 10) In order to assemble the library of learners, we need to “stack” them together. A Stack is a special learner and it has the same interface as all other learners. What makes a stack special is that it combines multiple learners by training them simultaneously, so that their predictions can be either combined or compared. stack &lt;- make_learner( Stack, lrnr_glm, lrnr_mean, lrnr_ridge, lrnr_lasso, xgb_learners[[10]] ) We can optionally select a subset of available covariates and pass only those variables to the modeling algorithm. Let’s consider screening covariates based on their randomForest variable importance ranking (ordered by mean decrease in accuracy). We select the top 5 most important covariates according to this ranking, and we decreased the ntree to 20. Before you think it – I will confess. Bob Ross and I both know that 20 trees makes for a lonely forest, and I shouldn’t even consider it, but these are the sacrifices I have to make for this chapter to build in under 50 minutes! screen_rf &lt;- make_learner(Lrnr_screener_randomForest, nVar = 5, ntree = 20) # which covariates are selected on the full data? screen_rf$train(washb_task) [1] &quot;Lrnr_screener_randomForest_5_20&quot; $selected [1] &quot;month&quot; &quot;aged&quot; &quot;momage&quot; &quot;momheight&quot; &quot;Ncomp&quot; To “pipe” only the selected covariates to the modeling algorithm, we need to make a Pipeline, which is a just set of learners to be fit sequentially, where the fit from one learner is used to define the task for the next learner. screen_rf_pipeline &lt;- make_learner(Pipeline, screen_rf, stack) Now our learners will be preceded by a screening step. We also consider the original stack, to compare how the feature selection methods perform in comparison to the methods without feature selection, and because Analogous to what we have seen before, we have to stack the pipeline and original stack together, so we may use them as base learners in our super learner. fancy_stack &lt;- make_learner(Stack, screen_rf_pipeline, stack) # we can visualize the stack dt_stack &lt;- delayed_learner_train(fancy_stack, washb_task) plot(dt_stack, color = FALSE, height = &quot;400px&quot;, width = &quot;90%&quot;) We will use the default metalearner, which uses Lrnr_solnp() to provide fitting procedures for a pairing of loss function and metalearner function. This default metalearner selects a loss and metalearner pairing based on the outcome type. Note that any learner can be used as a metalearner. We have made a library/stack of base learners, so we are ready to make the super learner. The super learner algorithm fits a metalearner on the validation-set predictions. sl &lt;- make_learner(Lrnr_sl, learners = fancy_stack ) We can also use Lrnr_cv to build a super learner, cross-validate a stack of learners to compare performance of the learners in the stack, or cross-validate any single learner (see “Cross-validation” section of this sl3 introductory tutorial). Furthermore, we can Define New sl3 Learners which can be used in all the places you could otherwise use any other sl3 learners, including Pipelines, Stacks, and the Super Learner. In the plot below, we visualize the steps for executing the Super Learner in the tlverse/delayed framework. For those like myself who are not particularly keen on understanding the intricacies of delayed, let’s focus on the main point of this figure: we can see there are 10 realizations of the stack which represent the 10 cross-validation folds and there is a separate hold-out (top branch of the figure) that will not be used to fit the Super Learner. dt_sl &lt;- delayed_learner_train(sl, washb_task) plot(dt_sl, color = FALSE, height = &quot;400px&quot;, width = &quot;90%&quot;) 3. Train the Super Learner on the machine learning task The Super Learner algorithm fits a metalearner on the validation-set predictions in a cross-validated manner, thereby avoiding overfitting. Now we are ready to “train” our Super Learner on our sl3_task object, washb_task. sl_fit &lt;- sl$train(washb_task) 4. Obtain predicted values Now that we have fit the super learner, we are ready to calculate the predicted outcome for each subject. # we did it! now we have super learner predictions sl_preds &lt;- sl_fit$predict() head(sl_preds) [1] -0.6572217 -0.7660477 -0.6521127 -0.6462359 -0.6195269 -0.6839711 We can also obtain a summary of the results. sl_fit_summary &lt;- sl_fit$print() [1] &quot;SuperLearner:&quot; List of 2 $ : chr &quot;Pipeline(Lrnr_screener_randomForest_5_20-&gt;Stack)&quot; $ : chr &quot;Stack&quot; [1] &quot;Lrnr_solnp_TRUE_TRUE_FALSE_1e-05&quot; $pars [1] 0.0013486709 0.0002294201 0.0001768752 0.0001665152 0.2286322960 [6] 0.2979424581 0.0002294201 0.2191514207 0.2501995013 0.0019234224 $convergence [1] 0 $values [1] 1.020035 1.010054 1.010048 $lagrange [,1] [1,] -0.04740648 $hessian [,1] [,2] [,3] [,4] [,5] [,6] [1,] 1.00974248 0.13249645 0.09823899 0.10363942 0.17609925 0.43104241 [2,] 0.13249645 0.73762049 0.07504570 0.07290893 0.02991314 0.09721084 [3,] 0.09823899 0.07504570 0.95668110 -0.05117700 0.09966022 0.35333187 [4,] 0.10363942 0.07290893 -0.05117700 0.94019327 0.09669620 0.35045454 [5,] 0.17609925 0.02991314 0.09966022 0.09669620 0.42745931 0.20603649 [6,] 0.43104241 0.09721084 0.35333187 0.35045454 0.20603649 0.87166098 [7,] 0.13249645 -0.26237951 0.07504570 0.07290893 0.02991314 0.09721084 [8,] 0.34502893 0.08191711 0.26822846 0.26529947 0.12428914 0.02919522 [9,] 0.35997841 0.09956026 0.29114455 0.28869573 0.01534115 0.06243311 [10,] 0.14291213 0.06050399 0.07211645 0.06915000 0.50374678 0.10299597 [,7] [,8] [,9] [,10] [1,] 0.13249645 0.34502893 0.35997841 0.14291213 [2,] -0.26237951 0.08191711 0.09956026 0.06050399 [3,] 0.07504570 0.26822846 0.29114455 0.07211645 [4,] 0.07290893 0.26529947 0.28869573 0.06915000 [5,] 0.02991314 0.12428914 0.01534115 0.50374678 [6,] 0.09721084 0.02919522 0.06243311 0.10299597 [7,] 0.73762049 0.08191711 0.09956026 0.06050399 [8,] 0.08191711 1.10449178 0.12576713 0.13105060 [9,] 0.09956026 0.12576713 1.12174190 0.24106070 [10,] 0.06050399 0.13105060 0.24106070 0.73078218 $ineqx0 NULL $nfuneval [1] 198 $outer.iter [1] 2 $elapsed Time difference of 0.0471673 secs $vscale [1] 1.010054 0.000010 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 [9] 1.000000 1.000000 1.000000 1.000000 $coefficients Pipeline(Lrnr_screener_randomForest_5_20-&gt;Stack)_Lrnr_glm_TRUE 0.001349754 Pipeline(Lrnr_screener_randomForest_5_20-&gt;Stack)_Lrnr_mean 0.000000000 Pipeline(Lrnr_screener_randomForest_5_20-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_0_100_TRUE 0.000000000 Pipeline(Lrnr_screener_randomForest_5_20-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 0.000000000 Pipeline(Lrnr_screener_randomForest_5_20-&gt;Stack)_Lrnr_xgboost_20_1_4_0.1 0.228815859 Stack_Lrnr_glm_TRUE 0.298181669 Stack_Lrnr_mean 0.000000000 Stack_Lrnr_glmnet_NULL_deviance_10_0_100_TRUE 0.219327372 Stack_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 0.250400380 Stack_Lrnr_xgboost_20_1_4_0.1 0.001924967 $training_offset [1] FALSE $name [1] &quot;solnp&quot; [1] &quot;Cross-validated risk (MSE, squared error loss):&quot; learner 1: Pipeline(Lrnr_screener_randomForest_5_20-&gt;Stack)_Lrnr_glm_TRUE 2: Pipeline(Lrnr_screener_randomForest_5_20-&gt;Stack)_Lrnr_mean 3: Pipeline(Lrnr_screener_randomForest_5_20-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_0_100_TRUE 4: Pipeline(Lrnr_screener_randomForest_5_20-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 5: Pipeline(Lrnr_screener_randomForest_5_20-&gt;Stack)_Lrnr_xgboost_20_1_4_0.1 6: Stack_Lrnr_glm_TRUE 7: Stack_Lrnr_mean 8: Stack_Lrnr_glmnet_NULL_deviance_10_0_100_TRUE 9: Stack_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 10: Stack_Lrnr_xgboost_20_1_4_0.1 11: SuperLearner coefficients mean_risk SE_risk fold_SD fold_min_risk fold_max_risk 1: 0.001349754 1.035485 0.02446142 0.06008226 0.9352596 1.119394 2: 0.000000000 1.065401 0.02503198 0.05999366 0.9689145 1.143488 3: 0.000000000 1.035453 0.02446251 0.06004142 0.9355128 1.119090 4: 0.000000000 1.035561 0.02445962 0.06024201 0.9352523 1.119179 5: 0.228815859 1.044729 0.02405570 0.06265341 0.9211017 1.117049 6: 0.298181669 1.018949 0.02372195 0.05817436 0.9095780 1.088981 7: 0.000000000 1.065401 0.02503198 0.05999366 0.9689145 1.143488 8: 0.219327372 1.013888 0.02361492 0.05606207 0.9196952 1.092918 9: 0.250400380 1.013000 0.02350220 0.05724862 0.9187793 1.095675 10: 0.001924967 1.035503 0.02371762 0.06206027 0.9341196 1.119005 11: NA 1.010056 0.02346050 0.05809852 0.9055184 1.087513 From the table of the printed Super Learner fit, we note that the Super Learner had a mean risk of 1.0100564 and that this ensemble weighted the ranger and glmnet learners highest while not weighting the mean learner highly. We can also see that the glmnet learner had the lowest cross-validated mean risk, thus making it the cross-validated selector (or the discrete Super Learner). The mean risk of the Super Learner is calculated using the hold-out set that we visualized in the dt_sl plot. 4.5 Cross-validated Super Learner We can cross-validate the Super Learner to see how well the Super Learner performs on unseen data, and obtain an estimate of the cross-validated risk of the Super Learner. This estimation procedure requires an “external” layer of cross-validation, also called nested cross-validation, which involves setting aside a separate holdout sample that we don’t use to fit the Super Learner. This external cross validation procedure may also incorporate 10 folds, which is the default in sl3. However, we will incorporate 2 outer/external folds of cross-validation for computational efficiency. We also need to specify a loss function to evaluate Super Learner. Documentation for the available loss functions can be found in the sl3 Loss Function Reference. washb_task_new &lt;- make_sl3_Task( data = washb_data, covariates = covars, outcome = outcome, folds = origami::make_folds(washb_data, fold_fun = folds_vfold, V = 2) ) Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. CVsl &lt;- CV_lrnr_sl(sl_fit, washb_task_new, loss_squared_error) CVsl %&gt;% kable(digits = 4) %&gt;% kableExtra:::kable_styling(fixed_thead = T) %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;300px&quot;) learner coefficients mean_risk SE_risk fold_SD fold_min_risk fold_max_risk Pipeline(Lrnr_screener_randomForest_5_20-&gt;Stack)_Lrnr_glm_TRUE 0.0475 1.0373 0.0245 0.0461 1.0048 1.0699 Pipeline(Lrnr_screener_randomForest_5_20-&gt;Stack)_Lrnr_mean 0.0000 1.0652 0.0250 0.0515 1.0288 1.1017 Pipeline(Lrnr_screener_randomForest_5_20-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_0_100_TRUE 0.0005 1.0372 0.0245 0.0468 1.0041 1.0704 Pipeline(Lrnr_screener_randomForest_5_20-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 0.0095 1.0374 0.0245 0.0461 1.0047 1.0700 Pipeline(Lrnr_screener_randomForest_5_20-&gt;Stack)_Lrnr_xgboost_20_1_4_0.1 0.1162 1.0552 0.0241 0.0578 1.0143 1.0961 Stack_Lrnr_glm_TRUE 0.0180 1.0368 0.0242 0.0239 1.0199 1.0537 Stack_Lrnr_mean 0.0000 1.0652 0.0250 0.0515 1.0288 1.1017 Stack_Lrnr_glmnet_NULL_deviance_10_0_100_TRUE 0.2476 1.0217 0.0238 0.0362 0.9961 1.0472 Stack_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 0.4878 1.0184 0.0236 0.0364 0.9926 1.0441 Stack_Lrnr_xgboost_20_1_4_0.1 0.0730 1.0417 0.0236 0.0441 1.0106 1.0729 SuperLearner NA 1.0237 0.0237 0.0487 0.9893 1.0582 4.6 Variable Importance Measures with sl3 Variable importance can be interesting and informative. It can also be contradictory and confusing. Nevertheless, we like it, and so do collaborators, so we created a variable importance function in sl3! The sl3 varimp function returns a table with variables listed in decreasing order of importance (i.e. most important on the first row). The measure of importance in sl3 is based on a risk difference between the learner fit with a permuted covariate and the learner fit with the true covariate, across all covariates. In this manner, the larger the risk difference, the more important the variable is in the prediction. The intuition of this measure is that it calculates the risk (in terms of the average loss in predictive accuracy) of losing one covariate, while keeping everything else fixed, and compares it to the risk if the covariate was not lost. If this risk difference is zero then losing that covariate had no impact, and is thus not important by this measure. We do this across all of the covariates. As stated above, we don’t actually remove the covariate, we just permute/shuffle it, but the idea is that this shuffling distorts potentially meaningful information that was present in the covariate. This idea of permuting instead of removing saves a lot of time, and is also incorporated in the randomForest variable importance measures. Let’s explore the sl3 variable importance measurements for the washb data. washb_varimp &lt;- varimp(sl_fit, loss_squared_error) washb_varimp %&gt;% kable(digits = 4) %&gt;% kableExtra:::kable_styling(fixed_thead = T) %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;300px&quot;) X risk_diff aged 0.0368 momedu 0.0066 month 0.0042 asset_refrig 0.0041 asset_chair 0.0037 momheight 0.0033 Nlt18 0.0026 momage 0.0020 tr 0.0019 floor 0.0017 asset_table 0.0015 walls 0.0013 hfiacat 0.0011 elec 0.0010 asset_wardrobe 0.0009 asset_mobile 0.0004 asset_chouki 0.0004 delta_momheight 0.0003 asset_khat 0.0002 asset_moto 0.0002 asset_sewmach 0.0001 fracode 0.0001 asset_bike 0.0001 roof -0.0001 sex -0.0001 asset_tv -0.0002 Ncomp -0.0003 delta_momage -0.0003 watmin -0.0009 # plot variable importance washb_varimp %&gt;% mutate(name = forcats::fct_reorder(X, risk_diff)) %&gt;% ggplot(aes(x = risk_diff, y = name)) + geom_dotplot(binaxis = &quot;y&quot;) + labs(x = &quot;Risk Difference&quot;, y = &quot;Covariate&quot;, title = &quot;sl3 Variable Importance for WASH Benefits Example Data&quot;) `stat_bindot()` using `bins = 30`. Pick better value with `binwidth`. 4.7 Exercises 4.7.1 Predicting Myocardial Infarction with sl3 Follow the steps below to predict myocardial infarction (mi) using the available covariate data. We thank Prof. David Benkeser at Emory University for making the this Cardiovascular Health Study (CHS) data accessible. # load the data set db_data &lt;- url(&quot;https://raw.githubusercontent.com/benkeser/sllecture/master/chspred.csv&quot;) chspred &lt;- read_csv(file = db_data, col_names = TRUE) # take a quick peek head(chspred) %&gt;% kable(digits = 4) %&gt;% kableExtra:::kable_styling(fixed_thead = T) %&gt;% scroll_box(width = &quot;100%&quot;, height = &quot;300px&quot;) waist alcoh hdl beta smoke ace ldl bmi aspirin gend age estrgn glu ins cysgfr dm fetuina whr hsed race logcystat logtrig logcrp logcre health logkcal sysbp mi 110.1642 0.0000 66.4974 0 0 1 114.2162 27.9975 0 0 73.5179 0 159.9314 70.3343 75.0078 1 0.1752 1.1690 1 1 -0.3420 5.4063 2.0126 -0.6739 0 4.3926 177.1345 0 89.9763 0.0000 50.0652 0 0 0 103.7766 20.8931 0 0 61.7723 0 153.3888 33.9695 82.7433 1 0.5717 0.9011 0 0 -0.0847 4.8592 3.2933 -0.5551 1 6.2071 136.3742 0 106.1941 8.4174 40.5059 0 0 0 165.7158 28.4554 1 1 72.9312 0 121.7145 -17.3017 74.6989 0 0.3517 1.1797 0 1 -0.4451 4.5088 0.3013 -0.0115 0 6.7320 135.1993 0 90.0566 0.0000 36.1750 0 0 0 45.2035 23.9608 0 0 79.1191 0 53.9691 11.7315 95.7823 0 0.5439 1.1360 0 0 -0.4807 5.1832 3.0243 -0.5751 1 7.3972 139.0182 0 78.6143 2.9790 71.0642 0 1 0 131.3121 10.9656 0 1 69.0179 0 94.3153 9.7112 72.7109 0 0.4916 1.1028 1 0 0.3121 4.2190 -0.7057 0.0053 1 8.2779 88.0470 0 91.6593 0.0000 59.4963 0 0 0 171.1872 29.1317 0 1 81.8346 0 212.9066 -28.2269 69.2184 1 0.4621 0.9529 1 0 -0.2872 5.1773 0.9705 0.2127 1 5.9942 69.5943 0 Create an sl3 task, setting myocardial infarction mi as the outcome and using all available covariate data. Make a library of seven relatively fast base learning algorithms (i.e., do not consider BART or HAL). Customize hyperparameters for one of your learners. Feel free to use learners from sl3 or SuperLearner. You may use the same base learning library that is presented above. Incorporate feature selection with the screener screen.corP. Fit the metalearning step with the default metalearner. With the metalearner and base learners, make the Super Learner and train it on the task. Print your Super Learner fit by calling print() with $. Cross-validate your Super Learner fit to see how well it performs on unseen data. Specify loss_squared_error as the loss function to evaluate the Super Learner. Use the varimp() function to identify the most important predictor of myocardial infarction. 4.7.2 Predicting Recurrent Ischemic Stroke in an RCT with sl3 For this exercise, we will work with a random sample of 5,000 patients who participated in the International Stroke Trial (IST). This data is described in Chapter 3.2 of the tlverse handbook. Train a Super Learner to predict recurrent stroke DRSISC with the available covariate data (the 25 other variables). Of course, you can consider feature selection in the machine learning algorithms. In this data, the outcome is occasionally missing, so be sure to specify drop_missing_outcome = TRUE when defining the task. Use the SL-based predictions to calculate the area under the ROC curve (AUC). Calculate the cross-validated AUC to evaluate the performance of the Super Learner on unseen data. Which covariates are most predictive of 14-day recurrent stroke? ist_data &lt;- data.table(read.csv(&quot;https://raw.githubusercontent.com/tlverse/tlverse-handbook/master/data/ist_sample.csv&quot;)) # number 3 help ist_task_CVsl &lt;- make_sl3_Task( data = ist_data, outcome = &quot;DRSISC&quot;, covariates = colnames(ist_data)[-which(names(ist_data) == &quot;DRSISC&quot;)], drop_missing_outcome = TRUE, folds = origami::make_folds( n = sum(!is.na(ist_data$DRSISC)), fold_fun = folds_vfold, V = 5 ) ) 4.8 Concluding Remarks The general ensemble learning approach of Super Learner can be applied to a diversity of estimation and prediction problems that can be defined by a loss function. We just discussed conditional mean estimation, outcome prediction and variable importance. In future updates of this chapter, we will delve into prediction of a conditional density, and the optimal individualized treatment rule. If we plug in the estimator returned by super learner into the target parameter mapping, then we would end up with an estimator that has the same bias as what we plugged in, and would not be asymptotically linear. It also would not be a plug-in estimator or efficient. An asymptotically linear estimator is important to have, since they converge to the estimand at \\(\\frac{1}{\\sqrt{n}}\\) rate, and thereby permit formal statistical inference (i.e. confidence intervals and \\(p\\)-values). Plug-in estimators of the estimand are desirable because they respect both the local and global constraints of the statistical model (e.g. bounds), and have they have better finite-sample properties. An efficient estimator is optimal in the sense that it has the lowest possible variance, and is thus the most precise. An estimator is efficient if and only if is asymptotically linear with influence curve equal to the canonical gradient. The canonical gradient is a mathematical object that is specific to the target estimand, and it provides information on the level of difficulty of the estimation problem. The canonical gradient is shown in the chapters that follow. Practitioner’s do not need to know how to calculate a canonical gradient in order to understand efficiency and use Targeted Maximum Likelihood Estimation (TMLE). Metaphorically, you do not need to be Yoda in order to be a Jedi. TMLE is a general strategy that succeeds in constructing efficient and asymptotically linear plug-in estimators. Super Learner is fantastic for pure prediction, and for obtaining an initial estimate in the first step of TMLE, but we need the second step of TMLE to have the desirable statistical properties mentioned above. In the chapters that follow, we focus on the targeted maximum likelihood estimator and the targeted minimum loss-based estimator, both referred to as TMLE. 4.9 Appendix 4.9.1 Exercise 1 Solution Here is a potential solution to the (sl3 Exercise 1 – Predicting Myocardial Infarction with sl3)(???). library(sl3) library(origami) library(data.table) library(tidyverse) library(ggplot2) db_data &lt;- url(&quot;https://raw.githubusercontent.com/benkeser/sllecture/master/chspred.csv&quot;) chspred &lt;- read_csv(file = db_data, col_names = TRUE) # make task chspred_task &lt;- make_sl3_Task( data = chspred, covariates = head(colnames(chspred), -1), outcome = &quot;mi&quot; ) # make learners glm_learner &lt;- Lrnr_glm$new() lasso_learner &lt;- Lrnr_glmnet$new(alpha = 1) ridge_learner &lt;- Lrnr_glmnet$new(alpha = 0) enet_learner &lt;- Lrnr_glmnet$new(alpha = 0.5) # curated_glm_learner uses formula = &quot;mi ~ smoke + beta + waist&quot; curated_glm_learner &lt;- Lrnr_glm_fast$new(covariates = c(&quot;smoke, beta, waist&quot;)) mean_learner &lt;- Lrnr_mean$new() # That is one mean learner! glm_fast_learner &lt;- Lrnr_glm_fast$new() ranger_learner &lt;- Lrnr_ranger$new() svm_learner &lt;- Lrnr_svm$new() xgb_learner &lt;- Lrnr_xgboost$new() # screening screen_cor &lt;- make_learner(Lrnr_screener_corP) glm_pipeline &lt;- make_learner(Pipeline, screen_cor, glm_learner) # stack learners together stack &lt;- make_learner( Stack, glm_pipeline, glm_learner, lasso_learner, ridge_learner, enet_learner, curated_glm_learner, mean_learner, glm_fast_learner, ranger_learner, svm_learner, xgb_learner ) # make and train super learner sl &lt;- Lrnr_sl$new( learners = stack ) sl_fit &lt;- sl$train(chspred_task) sl_fit$print() CVsl &lt;- CV_lrnr_sl(sl_fit, chspred_task, loss_squared_error) CVsl importance &lt;- varimp(sl_fit, loss_squared_error) importance %&gt;% mutate(name = forcats::fct_reorder(X, risk_diff)) %&gt;% ggplot(aes(x = risk_diff, y = name)) + geom_dotplot(binaxis = &quot;y&quot;) + labs(x = &quot;Risk Difference&quot;, y = &quot;Covariate&quot;, title = &quot;sl3 Variable Importance for Myocardian Infarction Prediction&quot;) 4.9.2 Exercise 2 Solution Here is a potential solution to the (sl3 Exercise 2 – Predicting Recurrent Ischemic Stroke in an RCT with sl3)(???). library(sl3) library(origami) library(data.table) library(tidyverse) library(ROCR) # for AUC calculation library(ggplot2) ist_data &lt;- data.table(read.csv(&quot;https://raw.githubusercontent.com/tlverse/tlverse-handbook/master/data/ist_sample.csv&quot;)) # stack ist_task &lt;- make_sl3_Task( data = ist_data, outcome = &quot;DRSISC&quot;, covariates = colnames(ist_data)[-which(names(ist_data) == &quot;DRSISC&quot;)], drop_missing_outcome = TRUE ) # learner library lrnr_glm &lt;- Lrnr_glm$new() lrnr_lasso &lt;- Lrnr_glmnet$new(alpha = 1) lrnr_ridge &lt;- Lrnr_glmnet$new(alpha = 0) lrnr_enet &lt;- Lrnr_glmnet$new(alpha = 0.5) lrnr_mean &lt;- Lrnr_mean$new() lrnr_ranger &lt;- Lrnr_ranger$new() lrnr_svm &lt;- Lrnr_svm$new() # xgboost grid grid_params &lt;- list(max_depth = c(2, 5, 8), eta = c(0.01, 0.15, 0.3)) grid &lt;- expand.grid(grid_params, KEEP.OUT.ATTRS = FALSE) params_default &lt;- list(nthread = getOption(&quot;sl.cores.learners&quot;, 1)) xgb_learners &lt;- apply(grid, MARGIN = 1, function(params_tune) { do.call(Lrnr_xgboost$new, c(params_default, as.list(params_tune)))}) learners &lt;- unlist(list(xgb_learners, lrnr_ridge, lrnr_mean, lrnr_lasso, lrnr_glm, lrnr_enet, lrnr_ranger, lrnr_svm), recursive = TRUE) # super learner sl &lt;- Lrnr_sl$new(learners) sl_fit &lt;- sl$train(ist_task) # AUC preds &lt;- sl_fit$predict() obs &lt;- c(na.omit(ist_data$DRSISC)) AUC &lt;- performance(prediction(sl_preds, obs), measure = &quot;auc&quot;)@y.values[[1]] plot(performance(prediction(sl_preds, obs), &quot;tpr&quot;, &quot;fpr&quot;)) # CVsl ist_task_CVsl &lt;- make_sl3_Task( data = ist_data, outcome = &quot;DRSISC&quot;, covariates = colnames(ist_data)[-which(names(ist_data) == &quot;DRSISC&quot;)], drop_missing_outcome = TRUE, folds = origami::make_folds( n = sum(!is.na(ist_data$DRSISC)), fold_fun = folds_vfold, V = 5 ) ) CVsl &lt;- CV_lrnr_sl(sl_fit, ist_task_CVsl, loss_loglik_binomial) CVsl # sl3 variable importance plot importance &lt;- varimp(sl_fit, loss_loglik_binomial) importance %&gt;% mutate(name = forcats::fct_reorder(X, risk_diff)) %&gt;% ggplot(aes(x = risk_diff, y = name)) + geom_dotplot(binaxis = &quot;y&quot;) + labs(x = &quot;Risk Difference&quot;, y = &quot;Covariate&quot;, title = &quot;sl3 Variable Importance for Predicting Recurrent Ischemic Stroke&quot;) References "],
["tmle3.html", "Chapter 5 The TMLE Framework 5.1 Learning Objectives 5.2 Introduction 5.3 Easy-Bake Example: tmle3 for ATE 5.4 tmle3 Components 5.5 Fitting tmle3 with multiple parameters 5.6 Exercises 5.7 Summary", " Chapter 5 The TMLE Framework Jeremy Coyle Based on the tmle3 R package. 5.1 Learning Objectives Use tmle3 to estimate an Average Treatment Effect (ATE) Understand tmle3 “Specs” Fit tmle3 for a custom set of parameters Use the delta method to estimate transformations of parameters 5.2 Introduction The first step in the estimation procedure is an initial estimate of the data-generating distribution, or the relevant part of this distribution that is needed to evaluate the target parameter. For this initial estimation, we use the super learner (van der Laan, Polley, and Hubbard 2007), as described in the previous section. With the initial estimate of relevant parts of the data-generating distribution necessary to evaluate the target parameter, we are ready to construct the TMLE! 5.2.1 Substitution Estimators Beyond a fit of the prediction function, one might also want to estimate more targeted parameters specific to certain scientific questions. The approach is to plug into the estimand of interest estimates of the relevant distributions. Sometimes, we can use simple empirical distributions, but averaging some function over the observations (e.g., giving weight \\(1/n\\) for all observations). Other parts of the distribution, like conditional means or probabilities, the estimate will require some sort of smoothing due to the curse of dimensionality. We give one example using an example of the average treatment effect (see above): \\(\\Psi(P_0) = \\Psi(Q_0) = \\mathbb{E}_0 \\big[\\mathbb{E}_0[Y \\mid A = 1, W] - \\mathbb{E}_0[Y \\mid A = 0, W]\\big]\\), where \\(Q_0\\) represents both the distribution of \\(Y \\mid A,W\\) and distribution of \\(W\\). Let \\(\\bar{Q}_0(A,W) \\equiv \\mathbb{E}_0(Y \\mid A,W)\\) and \\(Q_{0,W}(w) = P_0 (W=w)\\), then \\[ \\Psi(Q_0) = \\sum_w \\{ \\bar{Q}_0(1,w)-\\bar{Q}_0(0,w)\\} Q_{0,W}(w) \\] The Substitution Estimator plugs in the empirical distribution (weight \\(1/n\\) for each observation) for \\(Q_{0,W}(W_i)\\), and some estimate of the regression of \\(Y\\) on \\((A,W)\\) (say SL fit): \\[ \\Psi(Q_n) = \\frac{1}{n} \\sum_{i=1}^n \\{ \\bar{Q}_n(1,W_i)-\\bar{Q}_n(0,W_i)\\} \\] Thus, it becomes the average of the differences in predictions from the fit keeping the observed \\(W\\), but first replacing \\(A=1\\) and then the same but all \\(A=0\\). 5.2.2 TMLE Though using SL over an arbitrary parametric regression is an improvement, it’s not sufficient to have the properties of an estimator one needs for rigorous inference. Because the variance-bias trade-off in the SL is focused on the prediction model, it can, for instance, under-fit portions of the distributions that are critical for estimating the parameter of interest, \\(\\Psi(P_0)\\). TMLE keeps the benefits of substitution estimators (it is one), but augments the original estimates to correct for this issue and also results in an asymptotically linear (and thus normally-distributed) estimator with consistent Wald-style confidence intervals. Produces a well-defined, unbiased, efficient substitution estimator of target parameters of a data-generating distribution. Updates an initial (super learner) estimate of the relevant part of the data-generating distribution possibly using an estimate of a nuisance parameter (like the model of intervention given covariates). Removes asymptotic residual bias of initial estimator for the target parameter, if it uses a consistent estimator of \\(g_0\\). If initial estimator was consistent for the target parameter, the additional fitting of the data in the targeting step may remove finite sample bias, and preserves consistency property of the initial estimator. If the initial estimator and the estimator of \\(g_0\\) are both consistent, then it is also asymptotically efficient according to semi-parametric statistical model efficiency theory. Thus, every effort is made to achieve minimal bias and the asymptotic semi-parametric efficiency bound for the variance. There are different types of TMLE, sometimes for the same set of parameters, but below is an example of the algorithm for estimating the ATE. In this case, one can present the estimator as: \\[ \\Psi(Q^{\\star}_n) = \\frac{1}{n} \\sum_{i=1}^n \\{ \\bar{Q}^{\\star}_n(1,W_i) - \\bar{Q}^{\\star}_n(0,W_i)\\} \\] where \\(\\bar{Q}^{\\star}_n(A,W)\\) is the TMLE augmented estimate. \\(f(\\bar{Q}^{\\star}_n(A,W)) = f(\\bar{Q}_n(A,W)) + \\epsilon_n \\cdot h_n(A,W)\\), where \\(f(\\cdot)\\) is the appropriate link function (e.g., logit), \\(\\epsilon_n\\) is an estimated coefficient and \\(h_n(A,W)\\) is a “clever covariate”. In this case, \\(h_n(A,W) = \\frac{A}{g_n(W)}-\\frac{1-A}{1-g_n(W)}\\), with \\(g_n(W) = \\mathbb{P}(A=1 \\mid W)\\) being the estimated (also by SL) propensity score, so the estimator depends both on initial SL fit of the outcome regression (\\(\\bar{Q}_0\\)) and an SL fit of the propensity score (\\(g_n\\)). There are further robust augmentations that are used in tlverse, such as an added layer of cross-validation to avoid over-fitting bias (CV-TMLE), and so called methods that can more robustly estimated several parameters simultaneously (e.g., the points on a survival curve). 5.2.3 Inference The estimators we discuss are asymptotically linear, meaning that the difference in the estimate \\(\\Psi(P_n)\\) and the true parameter (\\(\\Psi(P_0)\\)) can be represented in first order by a i.i.d. sum: \\[\\begin{equation}\\label{eqn:IC} \\Psi(P_n) - \\Psi(P_0) = \\frac{1}{n} \\sum_{i=1}^n IC(O_i; \\nu) + o_p(1/\\sqrt{n}) \\end{equation}\\] where \\(IC(O_i; \\nu)\\) (the influence curve or function) is a function of the data and possibly other nuisance parameters \\(\\nu\\). Importantly, such estimators have mean-zero Gaussian limiting distributions; thus, in the univariate case, one has that \\[\\begin{equation}\\label{eqn:limit_dist} \\sqrt{n}(\\Psi(P_n) - \\Psi(P_0)) \\xrightarrow[]{D}N(0,\\mathbb{V} IC(O_i; \\nu)), \\end{equation}\\] so that inference for the estimator of interest may be obtained in terms of the influence function. For this simple case, a 95% confidence interval may be derived as: \\[\\begin{equation}\\label{eqn:CI} \\Psi(P^{\\star}_n) \\pm z_{1 - \\frac{\\alpha}{2}} \\sqrt{\\frac{\\hat{\\sigma}^2}{n}}, \\end{equation}\\] where \\(SE=\\sqrt{\\frac{\\hat{\\sigma}^2}{n}}\\) and \\(\\hat{\\sigma}^2\\) is the sample variance of the estimated IC’s: \\(IC(O; \\hat{\\nu})\\). One can use the functional delta method to derive the influence curve if a parameter of interest may be written as a function of other asymptotically linear estimators. Thus, we can derive robust inference for parameters that are estimated by fitting complex, machine learning algorithms and these methods are computationally quick (do not rely on re-sampling based methods like the bootstrap). 5.3 Easy-Bake Example: tmle3 for ATE We’ll illustrate the most basic use of TMLE using the WASH Benefits data introduced earlier and estimating an Average Treatment Effect (ATE). As a reminder, the ATE is identified with the following statistical parameter (under assumptions): \\(ATE = \\mathbb{E}_0(Y(1)-Y(0)) = \\mathbb{E}_0 \\left(\\mathbb{E}_0[Y \\mid A=1,W] - \\mathbb{E}_0[Y \\mid A=0,W] \\right),\\) 5.3.1 Load the Data We’ll use the same WASH Benefits data as the earlier chapters: library(here) here() starts at /home/travis/build/tlverse/tlverse-handbook library(data.table) library(tidyverse) library(tmle3) library(sl3) washb_data &lt;- fread(&quot;https://raw.githubusercontent.com/tlverse/tlverse-data/master/wash-benefits/washb_data.csv&quot;, stringsAsFactors = TRUE) 5.3.2 Define the variable roles We’ll use the common W (covariates), A (treatment/intervention), Y (outcome) data structure. tmle3 needs to know what variables in the dataset correspond to each of these roles. We use a list of character vectors to tell it. We call this a “Node List” as it corresponds to the nodes in a Directed Acyclic Graph (DAG), a way of displaying causal relationships between variables. node_list &lt;- list( W = c( &quot;month&quot;, &quot;aged&quot;, &quot;sex&quot;, &quot;momage&quot;, &quot;momedu&quot;, &quot;momheight&quot;, &quot;hfiacat&quot;, &quot;Nlt18&quot;, &quot;Ncomp&quot;, &quot;watmin&quot;, &quot;elec&quot;, &quot;floor&quot;, &quot;walls&quot;, &quot;roof&quot;, &quot;asset_wardrobe&quot;, &quot;asset_table&quot;, &quot;asset_chair&quot;, &quot;asset_khat&quot;, &quot;asset_chouki&quot;, &quot;asset_tv&quot;, &quot;asset_refrig&quot;, &quot;asset_bike&quot;, &quot;asset_moto&quot;, &quot;asset_sewmach&quot;, &quot;asset_mobile&quot; ), A = &quot;tr&quot;, Y = &quot;whz&quot; ) 5.3.3 Handle Missingness Currently, missingness in tmle3 is handled in a fairly simple way: Missing covariates are median (for continuous) or mode (for discrete) imputed, and additional covariates indicating imputation are generated Observations missing either treatment or outcome variables are excluded. We implemented IPCW-TMLE to more efficiently handle missingness in the outcome variable, and we plan to implement an IPCW-TMLE to handle missingness in the treatment variable as well. These steps are implemented in the process_missing function in tmle3: processed &lt;- process_missing(washb_data, node_list) washb_data &lt;- processed$data node_list &lt;- processed$node_list 5.3.4 Create a “Spec” Object tmle3 is general, and allows most components of the TMLE procedure to be specified in a modular way. However, most end-users will not be interested in manually specifying all of these components. Therefore, tmle3 implements a tmle3_Spec object that bundles a set ofcomponents into a specification that, with minimal additional detail, can be run by an end-user. We’ll start with using one of the specs, and then work our way down into the internals of tmle3. ate_spec &lt;- tmle_ATE( treatment_level = &quot;Nutrition + WSH&quot;, control_level = &quot;Control&quot; ) 5.3.5 Define the learners Currently, the only other thing a user must define are the sl3 learners used to estimate the relevant factors of the likelihood: Q and g. This takes the form of a list of sl3 learners, one for each likelihood factor to be estimated with sl3: # choose base learners lrnr_mean &lt;- make_learner(Lrnr_mean) lrnr_xgboost &lt;- make_learner(Lrnr_xgboost) # define metalearners appropriate to data types ls_metalearner &lt;- make_learner(Lrnr_nnls) mn_metalearner &lt;- make_learner(Lrnr_solnp, metalearner_linear_multinomial, loss_loglik_multinomial) sl_Y &lt;- Lrnr_sl$new(learners = list(lrnr_mean, lrnr_xgboost), metalearner = ls_metalearner) sl_A &lt;- Lrnr_sl$new(learners = list(lrnr_mean, lrnr_xgboost), metalearner = mn_metalearner) learner_list &lt;- list(A = sl_A, Y = sl_Y) Here, we use a Super Learner as defined in the previous chapter. In the future, we plan to include reasonable defaults learners. 5.3.6 Fit the TMLE We now have everything we need to fit the tmle using tmle3: tmle_fit &lt;- tmle3(ate_spec, washb_data, node_list, learner_list) 5.3.7 Evaluate the Estimates We can see the summary results by printing the fit object. Alternatively, we can extra results from the summary by indexing into it: print(tmle_fit) A tmle3_Fit that took 1 step(s) type param init_est tmle_est 1: ATE ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] 0.002245848 0.001732742 se lower upper psi_transformed lower_transformed 1: 0.05054199 -0.09732774 0.1007932 0.001732742 -0.09732774 upper_transformed 1: 0.1007932 estimates &lt;- tmle_fit$summary$psi_transformed print(estimates) [1] 0.001732742 5.4 tmle3 Components Now that we’ve successfully used a spec to obtain a TML estimate, let’s look under the hood at the components. The spec has a number of functions that generate the objects necessary to define and fit a TMLE. 5.4.1 tmle3_task First is, a tmle3_Task, analogous to an sl3_Task, containing the data we’re fitting the TMLE to, as well as an NP-SEM generated from the node_list defined above, describing the variables and their relationships. tmle_task &lt;- ate_spec$make_tmle_task(washb_data, node_list) tmle_task$npsem $W tmle3_Node: W Variables: month, aged, sex, momedu, hfiacat, Nlt18, Ncomp, watmin, elec, floor, walls, roof, asset_wardrobe, asset_table, asset_chair, asset_khat, asset_chouki, asset_tv, asset_refrig, asset_bike, asset_moto, asset_sewmach, asset_mobile, momage, momheight, delta_momage, delta_momheight Parents: $A tmle3_Node: A Variables: tr Parents: W $Y tmle3_Node: Y Variables: whz Parents: A, W 5.4.2 Initial Likelihood Next, is an object representing the likelihood, factorized according to the NPSEM described above: initial_likelihood &lt;- ate_spec$make_initial_likelihood( tmle_task, learner_list ) print(initial_likelihood) W: Lf_emp A: LF_fit Y: LF_fit These components of the likelihood indicate how the factors were estimated: the marginal distribution of \\(W\\) was estimated using NP-MLE, and the conditional distributions of \\(A\\) and \\(Y\\) were estimated using sl3 fits (as defined with the learner_list) above. We can use this in tandem with the tmle_task object to obtain likelihood estimates for each observation: initial_likelihood$get_likelihoods(tmle_task) W A Y 1: 0.0002129925 0.2484696 -0.6588400 2: 0.0002129925 0.2538779 -0.6324714 3: 0.0002129925 0.2574065 -0.6205549 4: 0.0002129925 0.2740319 -0.6007859 5: 0.0002129925 0.2530537 -0.5455965 --- 4691: 0.0002129925 0.1333180 -0.4676440 4692: 0.0002129925 0.1264298 -0.4860036 4693: 0.0002129925 0.1266223 -0.5684683 4694: 0.0002129925 0.1651308 -0.8112128 4695: 0.0002129925 0.1293865 -0.5427569 5.4.3 Targeted Likelihood (updater) We also need to define a “Targeted Likelihood” object. This is a special type of likelihood that is able to be updated using an tmle3_Update object. This object defines the update strategy (e.g. submodel, loss function, CV-TMLE or not, etc). targeted_likelihood &lt;- Targeted_Likelihood$new(initial_likelihood) When constructing the targeted likelihood, you can specify different update options. See the documentation for tmle3_Update for details of the different options. For example, you can disable CV-TMLE (the default in tmle3) as follows: targeted_likelihood_no_cv &lt;- Targeted_Likelihood$new(initial_likelihood, updater = list(cvtmle = FALSE) ) 5.4.4 Parameter Mapping Finally, we need to define the parameters of interest. Here, the spec defines a single parameter, the ATE. In the next section, we’ll see how to add additional parameters. tmle_params &lt;- ate_spec$make_params(tmle_task, targeted_likelihood) print(tmle_params) [[1]] Param_ATE: ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] 5.4.5 Putting it all together Having used the spec to manually generate all these components, we can now manually fit a tmle3: tmle_fit_manual &lt;- fit_tmle3( tmle_task, targeted_likelihood, tmle_params, targeted_likelihood$updater ) print(tmle_fit_manual) A tmle3_Fit that took 1 step(s) type param init_est tmle_est 1: ATE ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] 0.002358927 0.007006704 se lower upper psi_transformed lower_transformed 1: 0.05058957 -0.09214703 0.1061604 0.007006704 -0.09214703 upper_transformed 1: 0.1061604 The result is equivalent to fitting using the tmle3 function as above. 5.5 Fitting tmle3 with multiple parameters Above, we fit a tmle3 with just one parameter. tmle3 also supports fitting multiple parameters simultaneously. To illustrate this, we’ll use the tmle_TSM_all spec: tsm_spec &lt;- tmle_TSM_all() targeted_likelihood &lt;- Targeted_Likelihood$new(initial_likelihood) all_tsm_params &lt;- tsm_spec$make_params(tmle_task, targeted_likelihood) print(all_tsm_params) [[1]] Param_TSM: E[Y_{A=Control}] [[2]] Param_TSM: E[Y_{A=Handwashing}] [[3]] Param_TSM: E[Y_{A=Nutrition}] [[4]] Param_TSM: E[Y_{A=Nutrition + WSH}] [[5]] Param_TSM: E[Y_{A=Sanitation}] [[6]] Param_TSM: E[Y_{A=WSH}] [[7]] Param_TSM: E[Y_{A=Water}] This spec generates a Treatment Specific Mean (TSM) for each level of the exposure variable. Note that we must first generate a new targeted likelihood, as the old one was targeted to the ATE. However, we can recycle the initial likelihood we fit above, saving us a super learner step. 5.5.1 Delta Method We can also define parameters based on Delta Method Transformations of other parameters. For instance, we can estimate a ATE using the delta method and two of the above TSM parameters: ate_param &lt;- define_param( Param_delta, targeted_likelihood, delta_param_ATE, list(all_tsm_params[[1]], all_tsm_params[[4]]) ) print(ate_param) Param_delta: E[Y_{A=Nutrition + WSH}] - E[Y_{A=Control}] This can similarly be used to estimate other derived parameters like Relative Risks, and Population Attributable Risks 5.5.2 Fit We can now fit a TMLE simultaneously for all TSM parameters, as well as the above defined ATE parameter all_params &lt;- c(all_tsm_params, ate_param) tmle_fit_multiparam &lt;- fit_tmle3( tmle_task, targeted_likelihood, all_params, targeted_likelihood$updater ) print(tmle_fit_multiparam) A tmle3_Fit that took 1 step(s) type param init_est tmle_est 1: TSM E[Y_{A=Control}] -0.594949980 -0.625731170 2: TSM E[Y_{A=Handwashing}] -0.607080549 -0.638880647 3: TSM E[Y_{A=Nutrition}] -0.602748061 -0.613618088 4: TSM E[Y_{A=Nutrition + WSH}] -0.592591053 -0.618684459 5: TSM E[Y_{A=Sanitation}] -0.588553965 -0.592844699 6: TSM E[Y_{A=WSH}] -0.531691134 -0.451988985 7: TSM E[Y_{A=Water}] -0.577265042 -0.528469505 8: ATE E[Y_{A=Nutrition + WSH}] - E[Y_{A=Control}] 0.002358927 0.007046711 se lower upper psi_transformed lower_transformed 1: 0.02981337 -0.68416430 -0.5672980 -0.625731170 -0.68416430 2: 0.04206983 -0.72133600 -0.5564253 -0.638880647 -0.72133600 3: 0.04291806 -0.69773593 -0.5295002 -0.613618088 -0.69773593 4: 0.04100600 -0.69905474 -0.5383142 -0.618684459 -0.69905474 5: 0.04203562 -0.67523300 -0.5104564 -0.592844699 -0.67523300 6: 0.04525364 -0.54068449 -0.3632935 -0.451988985 -0.54068449 7: 0.03881870 -0.60455276 -0.4523863 -0.528469505 -0.60455276 8: 0.05057609 -0.09208061 0.1061740 0.007046711 -0.09208061 upper_transformed 1: -0.5672980 2: -0.5564253 3: -0.5295002 4: -0.5383142 5: -0.5104564 6: -0.3632935 7: -0.4523863 8: 0.1061740 5.6 Exercises 5.6.1 Estimation of the ATE with tmle3 Follow the steps below to estimate an average treatment effect using data from the Collaborative Perinatal Project (CPP), available in the sl3 package. To simplify this example, we define a binary intervention variable, parity01 – an indicator of having one or more children before the current child and a binary outcome, haz01 – an indicator of having an above average height for age. # load the data set data(cpp) cpp &lt;- cpp[!is.na(cpp[, &quot;haz&quot;]), ] cpp$parity01 &lt;- as.numeric(cpp$parity &gt; 0) cpp[is.na(cpp)] &lt;- 0 cpp$haz01 &lt;- as.numeric(cpp$haz &gt; 0) Define the variable roles \\((W,A,Y)\\) by creating a list of these nodes. Include the following baseline covariates in \\(W\\): apgar1, apgar5, gagebrth, mage, meducyrs, sexn. Both \\(A\\) and \\(Y\\) are specified above. Define a tmle3_Spec object for the ATE, tmle_ATE(). Using the same base learning libraries defined above, specify sl3 base learners for estimation of \\(Q = E(Y|A,Y)\\) and \\(g=P(A|W)\\). Define the metalearner like below. metalearner &lt;- make_learner(Lrnr_solnp, loss_function = loss_loglik_binomial, learner_function = metalearner_logistic_binomial ) Define one super learner for estimating \\(Q\\) and another for estimating \\(g\\). Use the metalearner above for both \\(Q\\) and \\(g\\) super learners. Create a list of the two super learners defined in Step 5 and call this object learner_list. The list names should be A (defining the super learner for estimating \\(g\\)) and Y (defining the super learner for estimating \\(Q\\)). Fit the tmle with the tmle3 function by specifying (1) the tmle3_Spec, which we defined in Step 2; (2) the data; (3) the list of nodes, which we specified in Step 1; and (4) the list of super learners for estimating \\(g\\) and \\(Q\\), which we defined in Step 6. Note: Like before, you will need to make a data copy to deal with data.table weirdness (cpp2 &lt;- data.table::copy(cpp)) and use cpp2 as the data. 5.6.2 Estimation of Strata-Specific ATEs with tmle3 For this exercise, we will work with a random sample of 5,000 patients who participated in the International Stroke Trial (IST). This data is described in the Chapter 3.2 of the tlverse handbook. We included the data below and a summarized description that is relevant for this exercise. The outcome, \\(Y\\), indicates recurrent ischemic stroke within 14 days after randomization (DRSISC); the treatment of interest, \\(A\\), is the randomized aspirin vs. no aspirin treatment allocation (RXASP in ist); and the adjustment set, \\(W\\), consists simply of other variables measured at baseline. In this data, the outcome is occasionally missing, but there is no need to create a variable indicating this missingness (such as \\(\\Delta\\)) for analyses in the tlverse, since the missingness is automatically detected when NA are present in the outcome. Covariates with missing values (RATRIAL, RASP3 and RHEP24) have already been imputed. Additional covariates were created (MISSING_RATRIAL_RASP3 and MISSING_RHEP24), which indicate whether or not the covariate was imputed. The missingness was identical for RATRIAL and RASP3, which is why only one covariate indicating imputation for these two covariates was created. Estimate the average effect of randomized asprin treatment (RXASP = 1) on recurrent ischemic stroke. Even though the missingness mechanism on \\(Y\\), \\(\\Delta\\), does not need to be specified in the node list, it does still need to be accounted for in the TMLE. In other words, for this estimation problem, \\(\\Delta\\) is a relevant factor of the likelihood in addition to \\(Q\\), \\(g\\). Thus, when defining the list of sl3 learners for each likelihood factor, be sure to include a list of learners for estimation of \\(\\Delta\\), say sl_Delta, and specify something like learner_list &lt;- list(A = sl_A, delta_Y = sl_Delta, Y = sl_Y). Recall that this RCT was conducted internationally. Suposse there is concern that the dose of asprin may have varied across geographical regions, and an average across all geographical regions may not be warranted. Calculate the strata specific ATEs according to geographical region (REGION). ist_data &lt;- data.table(read.csv(&quot;https://raw.githubusercontent.com/tlverse/deming2019-workshop/master/data/ist_sample.csv&quot;)) 5.7 Summary tmle3 is a general purpose framework for generating TML estimates. The easiest way to use it is to use a predefined spec, allowing you to just fill in the blanks for the data, variable roles, and sl3 learners. However, digging under the hood allows users to specify a wide range of TMLEs. In the next sections, we’ll see how this framework can be used to estimate advanced parameters such as optimal treatments and shift interventions. References "],
["optimal-individualized-treatment-regimes.html", "Chapter 6 Optimal Individualized Treatment Regimes 6.1 Learning Objectives 6.2 Introduction to Optimal Individualized Interventions 6.3 Data Structure and Notation 6.4 Defining the Causal Effect of an Optimal Individualized Intervention 6.5 Interpreting the Causal Effect of an Optimal Individualized Intervention 6.6 Evaluating the Causal Effect of an OIT with Binary Treatment 6.7 Evaluating the Causal Effect of an optimal ITR with Categorical Treatment 6.8 Extensions to Causal Effect of an OIT 6.9 Variable Importance Analysis with OIT 6.10 Real World Data and tmle3mopttx 6.11 Exercises", " Chapter 6 Optimal Individualized Treatment Regimes Ivana Malenica Based on the tmle3mopttx R package by Ivana Malenica, Jeremy Coyle, and Mark van der Laan. Updated: 2020-02-21 6.1 Learning Objectives Differentiate dynamic and optimal dynamic treatment regimes from static interventions. Understand the benefits and challenges associated with using optimal individualized treatment regimes in practice. Contrast the impact of implementing an optimal individualized treatment in the population with static and dynamic regimes. Estimate causal effects under optimal individualized treatment regimes with the tmle3mopttx R package. Contrast the population impact of implementing optimal individualized treatment based on sub-optimal rules. Construct realistic optimal individualized treatments that respect real data and subject-matter knowledge limitations on interventions. Understand and implement variable importance analysis defined in terms of optimal individualized treatment interventions. 6.2 Introduction to Optimal Individualized Interventions Identifying which intervention will be effective for which patient based on lifestyle, genetic and environmental factors is a common goal in precision medicine. To put it in context, Abacavir and Tenofovir are commonly prescribed as part of the antiretroviral therapy to Human Immunodeficiency Virus (HIV) patients. However, not all individuals benefit from the two medications equally. In particular, patients with renal dysfunction might further deteriorate if prescribed Tenofovir, due to the high nephrotoxicity caused by the medication. While Tenofovir is still highly effective treatment option for HIV patients, in order to maximize the patient’s well-being, it would be beneficial to prescribe Tenofovir only to individuals with healthy kidney function. Along the same lines, one might seek to improve retention in HIV care. In a randomized clinical trial, several interventions show efficacy- including appointment reminders through text messages, small cash incentives for on time clinic visits, and peer health workers. Ideally, we want to improve effectiveness by assigning each patient the intervention they are most likely to benefit from, as well as improve efficiency by not allocating resources to individuals that do not need them, or would not benefit from it. Figure 6.1: Illustration of a Dynamic Treatment Regime in a Clinical Setting One opts to administer the intervention to individuals who will profit from it, instead of assigning treatment on a population level. But how do we know which intervention works for which patient? This aim motivates a different type of intervention, as opposed to the static exposures we might be used to. In particular, in this chapter we learn about dynamic or individualized interventions that tailor the treatment decision based on the collected covariates. Formally, dynamic treatments represent interventions that at each treatment-decision stage are allowed to respond to the currently available treatment and covariate history. In the statistics community such a treatment strategy is termed an individualized treatment regime (ITR), and the (counterfactual) population mean outcome under an ITR is the value of the ITR (“On the Application of Probability Theory to Agricultural Experiments. Essay on Principles. Section 9.” 1990; Robins 1986; Pearl 2009b). Even more, suppose one wishes to maximize the population mean of an outcome, where for each individual we have access to some set of measured covariates. This means, for example, that we can learn for which individual characteristics assigning treatment increases the probability of a beneficial outcome for each individual. An ITR with the maximal value is referred to as an optimal ITR or the optimal individualized treatment. Consequently, the value of an optimal ITR is termed the optimal value, or the mean under the optimal individualized treatment. The problem of estimating the optimal individualized treatment has received much attention in the statistics literature over the years, especially with the advancement of precision medicine; see Murphy (2003), Robins (2004), Zhang et al. (2016), Zhao et al. (2012), Chakraborty and Moodie (2013) and Robins and Rotnitzky (2014) to name a few. However, much of the early work depends on parametric assumptions. As such, even in a randomized trial, the statistical inference for the optimal individualized treatment relies on assumptions that are generally believed to be false, and can lead to biased results. In this chapter, we consider estimation of the mean outcome under the optimal individualized treatment where the candidate rules are restricted to depend only on user-supplied subset of the baseline covariates. The estimation problem is addressed in a statistical model for the data distribution that is nonparametric, and at most places restrictions on the probability of a patient receiving treatment given covariates (as in a randomized trial). As such, we don’t need to make any assumptions about the relationship of the outcome with the treatment and covariates, or the relationship between the treatment and covariates. Further, we provide a Targeted Maximum Likelihood Estimator for the mean under the optimal individualized treatment that allows us to generate valid inference for our parameter, without having any parametric assumptions. For a technical presentation of the algorithm, the interested reader is invited to further consult van der Laan and Luedtke (2015) and Luedtke and van der Laan (2016). 6.3 Data Structure and Notation Suppose we observe \\(n\\) independent and identically distributed observations of the form \\(O=(W,A,Y) \\sim P_0\\). We denote \\(A\\) as categorical treatment, and \\(Y\\) as the final outcome. In particular, we define \\(A \\in \\mathcal{A}\\) where \\(\\mathcal{A} \\equiv \\{a_1, \\cdots, a_{n_A} \\}\\) and \\(n_A = |\\mathcal{A}|\\), with \\(n_A\\) denoting the number of categories (possibly only two, for a binary setup). Note that we treat \\(W\\) as vector-valued, representing all of our collected baseline covariates. Therefore, for a single random individual \\(i\\), we have that their observed data is \\(O_i\\): with corresponding baseline covariates \\(W_i\\), treatment \\(A_i\\), and final outcome \\(Y_i\\). We say that \\(O \\sim P_0\\), or that all data was drawn from some probability distribution \\(P_0\\). We emphasize that we make no assumptions about the distribution of \\(P_0\\), so that \\(P_0 \\in \\mathcal{M}\\), where \\(\\mathcal{M}\\) is the fully nonparametric model. As previously mentioned, this means that we make no assumptions on the relationship between \\(Y\\) and \\(A\\) and \\(W\\), but might be able to say something about the relationship of \\(A\\) and \\(W\\), as is the case of a randomized trial. We can assume a nonparametric structural equation model (NPSEM) to describe generation of \\(O\\), as described by Pearl (2009a). Specifically, we have that: \\[\\begin{align*}\\label{eqn:npsem} W &amp;= f_W(U_W) \\\\ A &amp;= f_A(W, U_A) \\\\ Y &amp;= f_Y(A, W, U_Y), \\end{align*}\\] where the collection \\(f=(f_W,f_A,f_Y)\\) denotes unspecified or partially specified functions. In particular, NPSEM parameterizes \\(P_0\\) in terms of the distribution of random variables \\(O\\) and \\(U\\), where \\(U=(U_W,U_A,U_Y)\\) are the exogenous random variables. We can define counterfactuals \\(Y_{d(W)}\\) defined by a modified system in which the equation for \\(A\\) is replaced by the rule \\(d(W)\\), dependent on covariates \\(W\\). The likelihood of the data admits a factorization, implied by the time ordering of \\(O\\). We denote the density of \\(O\\) as \\(p_0\\), corresponding to the distribution \\(P_0\\) and dominating measure \\(\\mu\\). \\[\\begin{equation*}\\label{eqn:likelihood_factorization} p_0(O) = p_{Y,0}(Y|A,W) p_{A,0}(A|W) p_{W,0}(W) = q_{Y,0}(Y|A,W) q_{A,0}(A|W) q_{W,0}(W), \\end{equation*}\\] where \\(p_{Y,0}(Y|A,W)\\) is the conditional density of \\(Y\\) given \\((A, W)\\) with respect to some dominating measure \\(\\mu_Y\\), \\(p_{A,0}\\) is the conditional density of \\(A\\) given \\(W\\) with respect to dominating measure \\(\\mu_A\\), and \\(p_{W,0}\\) is the density of \\(W\\) with respect to dominating measure \\(\\mu_W\\). Consequently, we define \\(P_{Y,0}(Y|A,W)=Q_{Y,0}(Y|A,W)\\), \\(P_{A,0}(A|W)=g_0(A|W)\\) and \\(P_{W,0}(W)=Q_{W,0}(W)\\) as the corresponding conditional distributions of \\(Y\\), \\(A\\) and \\(W\\). For notational simplicity, we define \\(\\bar{Q}_{Y,0}(A,W) \\equiv E_0[Y|A,W]\\) as the conditional expectation of \\(Y\\) given \\((A,W)\\). In addition, we denote \\(V\\) as \\(V \\in W\\), defining a subset of the baseline covariates the optimal individualized rule depends on. Note that \\(V\\) could be all of \\(W\\), or an empty set, depending on the subject matter knowledge. In particular, a researcher might want to consider known effect modifiers available at the time of treatment decision as possible \\(V\\) covariates. Defining \\(V\\) allows us to consider possibly sub-optimal rules that are easier to estimate, and thereby allows for statistical inference for the counterfactual mean outcome under the sub-optimal rule. 6.4 Defining the Causal Effect of an Optimal Individualized Intervention Consider dynamic treatment rules \\(V \\rightarrow d(V) \\in \\{a_1, \\cdots, a_{n_A} \\} \\times \\{1\\}\\), for assigning treatment \\(A\\) based on \\(V \\in W\\). As mentioned in the previous section, causal effects are defined in terms of hypothetical interventions on the NPSEM (). Our modified system then takes the following form: \\[\\begin{align*}\\label{eqn:npsem_causal} W &amp;= f_W(U_W) \\\\ A &amp;= d(V) \\\\ Y_{d(V)} &amp;= f_Y(d(V), W, U_Y), \\end{align*}\\] where the dynamic treatment regime may be viewed as an intervention in which \\(A\\) is set equal to a value based on a hypothetical regime \\(d(V)\\), and \\(Y_{d(V)}\\) is the corresponding outcome under \\(d(V)\\). We denote the distribution of the counterfactual quantities as \\(P_{0,d(V)}\\). The goal of any causal analysis motivated by such dynamic, or optimal individualized intervention, is to estimate a parameter defined as the counterfactual mean of the outcome with respect to the modified intervention distribution (either dynamic or optimal dynamic). We are primarily interested in the value of an individualized rule, \\(E_0[Y_{d(V)}]\\). The optimal rule is the rule with the maximal value: \\[d_{opt}(V) \\equiv \\text{argmax}_{d(V) \\in \\mathcal{D}} E_0[Y_{d(V)}]\\] where \\(\\mathcal{D}\\) represents the set of possible rules, \\(d\\), implied by \\(V\\). We note that, in case the problem at hand requires minimizing the mean of an outcome, our optimal individualized rule will be the rule with the minimal value instead. Finally, our target parameter can be expressed as \\[\\psi_0 := E_0[Y_{d_{opt}(V)}].\\] The optimal individualized rule, as well as the value of a rule, are causal parameters based on the unobserved counterfactuals. In order for the causal quantities to be estimated from the observed data, they need to be identified with statistical parameters. This step of the roadmap requires me make few assumptions: Consistency: \\(Y^{d(v_i)}_i = Y_i\\) in the event \\(A_i = d(v_i)\\), for \\(i = 1, \\ldots, n\\). Stable unit value treatment assumption (SUTVA): \\(Y^{d(v_i)}_i\\) does not depend on \\(d(v_j)\\) for \\(i = 1, \\ldots, n\\) and \\(j \\neq i\\), or lack of interference. Strong ignorability: \\(A \\perp \\!\\!\\! \\perp Y^{d(v)} \\mid W\\), for all \\(a \\in \\mathcal{A}\\). Positivity (or overlap): \\(P_0(\\min_{a \\in \\mathcal{A}} g_0(a|W) &gt; 0)=1\\) Under the above causal assumptions, we can identify \\(P_{0,d}\\) with observed data using the G-computation formula: \\[P_{0,d_{opt}}(O) = Q_{Y,0}(Y|A=d_{opt}(V),W)g_0(A=d_{opt}(V)|W)Q_{W,0}(W).\\] The value of an individualized rule can now be expressed as \\[E_0[Y_{d(V)}] = E_{0,W}[\\bar{Q}_{Y,0}(A=d(V),W)],\\] which, under causal assumptions, can is interpreted as the mean outcome if (possibly contrary to fact), treatment was assigned according to the rule. Finally, the statistical counterpart to the causal parameter of interest is defined as \\[\\psi_0 = E_{0,W}[\\bar{Q}_{Y,0}(A=d_{opt}(V),W)].\\] Inference for the optimal value has been shown to be difficult at exceptional laws, defined as probability distributions for which treatment is neither beneficial nor harmful. Inference is similarly difficult in finite samples if the treatment effect is very small in all strata, even though valid asymptotic estimators exist in this setting. With that in mind, we address the estimation problem under the assumption of non-exceptional laws in effect. Many methods for learning the optimal rule from data have been developed (Murphy 2003, @robins2004, @laber2012, @kosorok2012, @moodie2013). In this chapter, we focus on the methods discussed in Luedtke and van der Laan (2016) and van der Laan and Luedtke (2015). Note however, that tmle3mopttx also supports the widely used Q-learning approach, where the optimal individualized rule is based on the initial estimate of \\(\\bar{Q}_{Y,0}(A,W)\\) (Sutton, Barto, and others 1998). We follow the methodology outlined in Luedtke and van der Laan (2016) and van der Laan and Luedtke (2015), where we learn the optimal ITR using Super Learner (van der Laan, Polley, and Hubbard 2007), and estimate its value with cross-validated Targeted Minimum Loss-based Estimation (CV-TMLE) (Zheng and van der Laan 2010). In great generality, we first need to estimate the true individual treatment regime, \\(d_0(V)\\), which corresponds to dynamic treatment rule (\\(d(V)\\)) that takes a subset of covariates \\(V \\in W\\) and assigns treatment to each individual based on their observed covariates \\(v\\). With the estimate of the true optimal ITR in hand, we can estimate its corresponding value. 6.4.1 Binary treatment How do we estimate the optimal individualized treatment regime? In the case of a binary treatment, a key quantity for optimal ITR is the blip function. One can show that any optimal ITR assigns treatment to individuals falling in strata in which the stratum specific average treatment effect, the blip function, is positive and does not assign treatment to individuals for which this quantity is negative. Therefore for a binary treatment, under causal assumptions, we define the blip function as: \\[\\bar{Q}_0(V) \\equiv E_0[Y_1-Y_0|V] \\equiv E_0[\\bar{Q}_{Y,0}(1,W) - \\bar{Q}_{Y,0}(0,W) | V],\\] or the average treatment effect within a stratum of \\(V\\). The note that the optimal individualized rule can now be derived as \\(d_{opt}(V) = I(\\bar{Q}_{0}(V) &gt; 0)\\). The package tmle3mopttx relies on using the Super Learner to estimate the blip function, as it easily extends to more general categorical treatment. With that in mind, the loss function utilized for learning the optimal individualized rule corresponds to conditional mean type losses. It is however worth mentioning that Luedtke and van der Laan (2016) present three different approaches for learning the optimal rule. Namely, they focus on: Super Learning the Blip Function, Super Learning the Weighted Classification Problem, Joint Super Learner of the Blip and Weighted Classification Problem. We refer the interested reader to Luedtke and van der Laan (2016) for further reference on advantages of each approach. Relying on the Targeted Maximum Likelihood (TML) estimator and the Super Learner estimate of the blip function, we follow the below steps in order to obtain value of the ITR: Estimate \\(\\bar{Q}_{Y,0}(A,W)\\) and \\(g_0(A|W)\\) using sl3. We denote such estimates as \\(\\bar{Q}_{Y,n}(A,W)\\) and \\(g_n(A|W)\\). Apply the doubly robust Augmented-Inverse Probability Weighted (A-IPW) transform to our outcome, where we define: \\[D_{\\bar{Q}_Y,g,a}(O) \\equiv \\frac{I(A=a)}{g(A|W)} (Y-\\bar{Q}_Y(A,W)) + \\bar{Q}_Y(A=a,W)\\] Note that under the randomization and positivity assumptions we have that \\(E[D_{\\bar{Q}_Y,g,a}(O) | V] = E[Y_a |V]\\). We emphasize the double robust nature of the A-IPW transform- consistency of \\(E[Y_a |V]\\) will depend on correct estimation of either \\(\\bar{Q}_{Y,0}(A,W)\\) or \\(g_0(A|W)\\). As such, in a randomized trial, we are guaranteed a consistent estimate of \\(E[Y_a |V]\\) even if we get \\(\\bar{Q}_{Y,0}(A,W)\\) wrong! Using this transform, we can define the following contrast: \\(D_{\\bar{Q}_Y,g}(O) = D_{\\bar{Q}_Y,g,a=1}(O) - D_{\\bar{Q}_Y,g,a=0}(O)\\) We estimate the blip function, \\(\\bar{Q}_{0,a}(V)\\), by regressing \\(D_{\\bar{Q}_Y,g}(O)\\) on \\(V\\) using the specified sl3 library of learners and an appropriate loss function. Our estimated rule is \\(d(V) = \\text{argmax}_{a \\in \\mathcal{A}} \\bar{Q}_{0,a}(V)\\). We obtain inference for the mean outcome under the estimated optimal rule using CV-TMLE. 6.4.2 Categorical treatment In line with the approach considered for binary treatment, we extend the blip function to allow for categorical treatment. We denote such blip function extensions as pseudo-blips, which are our new estimation targets in a categorical setting. We define pseudo-blips as vector-valued entities where the output for a given \\(V\\) is a vector of length equal to the number of treatment categories, \\(n_A\\). As such, we define it as: \\[\\bar{Q}_0^{pblip}(V) = \\{\\bar{Q}_{0,a}^{pblip}(V): a \\in \\mathcal{A} \\}\\] We implement three different pseudo-blips in tmle3mopttx. Blip1 corresponds to choosing a reference category of treatment, and defining the blip for all other categories relative to the specified reference. Hence we have that: \\[\\bar{Q}_{0,a}^{pblip-ref}(V) \\equiv E_0(Y_a-Y_0|V)\\] where \\(Y_0\\) is the specified reference category with \\(A=0\\). Note that, for the case of binary treatment, this strategy reduces to the approach described for the binary setup. Blip2 approach corresponds to defining the blip relative to the average of all categories. As such, we can define \\(\\bar{Q}_{0,a}^{pblip-avg}(V)\\) as: \\[\\bar{Q}_{0,a}^{pblip-avg}(V) \\equiv E_0(Y_a- \\frac{1}{n_A} \\sum_{a \\in \\mathcal{A}} Y_a|V)\\] In the case where subject-matter knowledge regarding which reference category to use is not available, blip2 might be a viable option. Blip3 reflects an extension of Blip2, where the average is now a weighted average: \\[\\bar{Q}_{0,a}^{pblip-wavg}(V) \\equiv E_0(Y_a- \\frac{1}{n_A} \\sum_{a \\in \\mathcal{A}} Y_{a} P(A=a|V) |V)\\] Just like in the binary case, pseudo-blips are estimated by regressing contrasts composed using the A-IPW transform on \\(V\\). 6.4.3 Note on Inference In a randomized trial, statistical inference relies on the second-order difference between the estimator of the optimal individualized treatment and the optimal individualized treatment itself to be asymptotically negligible. This is a reasonable condition if we consider rules that depend on small number of covariates, or if we are willing to make smoothness assumptions. Alternatively, we can consider TMLEs and statistical inference for data-adaptive target parameters defined in terms of an estimate of the optimal individualized treatment. In particular, instead of trying to estimate the mean under the true optimal individualized treatment, we aim to estimate the mean under the estimated optimal individualized treatment. As such, we develop cross-validated TMLE approach that provides asymptotic inference under minimal conditions for the mean under the estimate of the optimal individualized treatment. In particular, considering the data adaptive parameter allows us to avoid consistency and rate condition for the fitted optimal rule, as required for asymptotic linearity of the TMLE of the mean under the actual, true optimal rule. Practically, the estimated (data-adaptive) rule should be preferred, as this possibly sub-optimal rule is the one implemented in the population. 6.4.4 Why CV-TMLE? As discussed in van der Laan and Luedtke (2015), CV-TMLE is necessary as the non-cross-validated TMLE is biased upward for the mean outcome under the rule, and therefore overly optimistic. More generally however, using CV-TMLE allows us more freedom in estimation and therefore greater data adaptivity, without sacrificing inference. 6.5 Interpreting the Causal Effect of an Optimal Individualized Intervention In summary, the mean outcome under the optimal individualized treatment is a counterfactual quantity of interest representing what the mean outcome would have been if everybody, contrary to the fact, received treatment that optimized their outcome. The optimal individualized treatment regime is a rule that optimizes the mean outcome under the dynamic treatment, where the candidate rules are restricted to only respond to a user-supplied subset of the baseline and intermediate covariates. In essence, our target parameter answers the key aim of precision medicine: allocating the available treatment by tailoring it to the individual characteristics of the patient, with the goal of optimizing the final outcome. 6.6 Evaluating the Causal Effect of an OIT with Binary Treatment Finally, we demonstrate how to evaluate the mean outcome under the optimal individualized treatment using tmle3mopptx. To start, let’s load the packages we’ll use and set a seed: library(here) library(data.table) library(sl3) library(tmle3) library(tmle3mopttx) library(devtools) set.seed(111) 6.6.1 Simulated Data First, we load the simulated data. We will start with the more general setup where the treatment is a binary variable; later in the chapter we will consider another data-generating distribution where \\(A\\) is categorical. In this example, our data generating distribution is of the following form: \\[\\begin{align*} W &amp;\\sim \\mathcal{N}(\\bf{0},I_{3 \\times 3})\\\\ P(A=1|W) &amp;= \\frac{1}{1+\\exp^{(-0.8*W_1)}}\\\\ P(Y=1|A,W) &amp;= 0.5\\text{logit}^{-1}[-5I(A=1)(W_1-0.5)+5I(A=0)(W_1-0.5)] + 0.5\\text{logit}^{-1}(W_2W_3) \\end{align*}\\] data(&quot;data_bin&quot;) The above composes our observed data structure \\(O = (W, A, Y)\\). Note that the mean under the true optimal rule is \\(\\psi=0.578\\) for this data generating distribution. To formally express this fact using the tlverse grammar introduced by the tmle3 package, we create a single data object and specify the functional relationships between the nodes in the directed acyclic graph (DAG) via nonparametric structural equation models (NPSEMs), reflected in the node list that we set up: # organize data and nodes for tmle3 data &lt;- data_bin node_list &lt;- list( W = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;), A = &quot;A&quot;, Y = &quot;Y&quot; ) We now have an observed data structure (data) and a specification of the role that each variable in the data set plays as the nodes in a DAG. 6.6.2 Constructing Optimal Stacked Regressions with sl3 To easily incorporate ensemble machine learning into the estimation procedure, we rely on the facilities provided in the sl3 R package. Using the framework provided by the sl3 package, the nuisance parameters of the TML estimator may be fit with ensemble learning, using the cross-validation framework of the Super Learner algorithm of van der Laan, Polley, and Hubbard (2007). # Define sl3 library and metalearners: lrn_xgboost_50 &lt;- Lrnr_xgboost$new(nrounds = 50) lrn_xgboost_100 &lt;- Lrnr_xgboost$new(nrounds = 100) lrn_xgboost_500 &lt;- Lrnr_xgboost$new(nrounds = 500) lrn_mean &lt;- Lrnr_mean$new() lrn_glm &lt;- Lrnr_glm_fast$new() ## Define the Q learner: Q_learner &lt;- Lrnr_sl$new( learners = list(lrn_xgboost_50, lrn_xgboost_100, lrn_xgboost_500, lrn_mean, lrn_glm), metalearner = Lrnr_nnls$new() ) ## Define the g learner: g_learner &lt;- Lrnr_sl$new( learners = list(lrn_xgboost_100, lrn_glm), metalearner = Lrnr_nnls$new() ) ## Define the B learner: b_learner &lt;- Lrnr_sl$new( learners = list(lrn_xgboost_50, lrn_xgboost_100, lrn_xgboost_500,lrn_mean, lrn_glm), metalearner = Lrnr_nnls$new() ) As seen above, we generate three different ensemble learners that must be fit, corresponding to the learners for the outcome regression (Q), propensity score (g), and the blip function (B). We make the above explicit with respect to standard notation by bundling the ensemble learners into a list object below: # specify outcome and treatment regressions and create learner list learner_list &lt;- list(Y = Q_learner, A = g_learner, B = b_learner) The learner_list object above specifies the role that each of the ensemble learners we’ve generated is to play in computing initial estimators. Recall that we need initial estimators of relevant parts of the likelihood in order to building a TMLE for the parameter of interest. In particular, learner_list makes explicit the fact that our Y is used in fitting the outcome regression, while A is used in fitting the treatment mechanism regression, and finally B is used in fitting the blip function. 6.6.3 Targeted Estimation of the Mean under the Optimal Individualized Interventions Effects To start, we will initialize a specification for the TMLE of our parameter of interest simply by calling tmle3_mopttx_blip_revere. We specify the argument V = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;) when initializing the tmle3_Spec object in order to communicate that we’re interested in learning a rule dependent on V covariates. Note that we don’t have to specify V- this will result in a rule that is not based on any collected covariates. We also need to specify the type of pseudo-blip we will use in this estimation problem, the list of learners used to estimate the blip function, whether we want to maximize or minimize the final outcome, and few other more advanced features including searching for a less complex rule and realistic interventions. # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_blip_revere( V = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;), type = &quot;blip1&quot;, learners = learner_list, maximize = TRUE, complex = TRUE, realistic = FALSE ) As seen above, the tmle3_mopttx_blip_revere specification object (like all tmle3_Spec objects) does not store the data for our specific analysis of interest. Later, we’ll see that passing a data object directly to the tmle3 wrapper function, alongside the instantiated tmle_spec, will serve to construct a tmle3_Task object internally. We elaborate more on the initialization specifications. In initializing the specification for the TMLE of our parameter of interest, we have specified the set of covariates the rule depends on (V), the type of pseudo-blip to use (type), and the learners used for estimating the relevant parts of the likelihood and the blip function. In addition, we need to specify whether we want to maximize the mean outcome under the rule (maximize), and whether we want to estimate the rule under all the covariates \\(V\\) provided by the user (complex). If FALSE, tmle3mopttx will instead consider all the possible rules under a smaller set of covariates including the static rules, and optimize the mean outcome over all the subsets of \\(V\\). As such, while the user might have provided a full set of collected covariates as input for \\(V\\), it is possible that the true rule only depends on a subset of the set provided by the user. In that case, our returned mean under the optimal individualized rule will be based on the smaller subset. In addition, we provide an option to search for realistic optimal individualized interventions via the realistic specification. If TRUE, only treatments supported by the data will be considered, therefore alleviating concerns regarding practical positivity issues. We explore all the important extensions of tmle3mopttx in later sections. # fit the TML estimator fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=NULL}] 0.4289592 0.5701264 0.02749039 0.5162462 0.6240065 psi_transformed lower_transformed upper_transformed 1: 0.5701264 0.5162462 0.6240065 We can see that the estimate of \\(psi_0\\) is \\(0.56\\), and that the confidence interval covers our true mean under the true optimal individualized treatment. 6.7 Evaluating the Causal Effect of an optimal ITR with Categorical Treatment In this section, we consider how to evaluate the mean outcome under the optimal individualized treatment when \\(A\\) has more than two categories. While the procedure is analogous to the previously described binary treatment, we now need to pay attention to the type of blip we define in the estimation stage, as well as how we construct our learners. 6.7.1 Simulated Data First, we load the simulated data. Here, our data generating distribution was of the following form: \\[\\begin{align*} W &amp;\\sim \\mathcal{N}(\\bf{0},I_{4 \\times 4})\\\\ P(A=a|W) &amp;= \\frac{1}{1+\\exp^{(-0.8*W_1)}}\\\\ P(Y=1|A,W) = 0.5\\text{logit}^{-1}[15I(A=1)(W_1-0.5) - 3I(A=2)(2W_1+0.5) + 3I(A=3)(3W_1-0.5)] +\\text{logit}^{-1}(W_2W_1) \\end{align*}\\] We can just load the data available as part of the package as follows: data(&quot;data_cat_realistic&quot;) The above composes our observed data structure \\(O = (W, A, Y)\\). Note that the mean under the true optimal rule is \\(\\psi=0.658\\), which is the quantity we aim to estimate. # organize data and nodes for tmle3 data &lt;- data_cat_realistic node_list &lt;- list( W = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;, &quot;W4&quot;), A = &quot;A&quot;, Y = &quot;Y&quot; ) 6.7.2 Constructing Optimal Stacked Regressions with sl3 # Initialize few of the learners: lrn_xgboost_50 &lt;- Lrnr_xgboost$new(nrounds = 50) lrn_xgboost_100 &lt;- Lrnr_xgboost$new(nrounds = 100) lrn_xgboost_500 &lt;- Lrnr_xgboost$new(nrounds = 500) lrn_mean &lt;- Lrnr_mean$new() lrn_glm &lt;- Lrnr_glm_fast$new() ## Define the Q learner, which is just a regular learner: Q_learner &lt;- Lrnr_sl$new( learners = list(lrn_xgboost_50, lrn_xgboost_100, lrn_xgboost_500, lrn_mean, lrn_glm), metalearner = Lrnr_nnls$new() ) # Define the g learner, which is a multinomial learner: #specify the appropriate loss of the multinomial learner: mn_metalearner &lt;- make_learner(Lrnr_solnp, loss_function = loss_loglik_multinomial, learner_function = metalearner_linear_multinomial) g_learner &lt;- make_learner(Lrnr_sl, list(lrn_xgboost_100, lrn_xgboost_500, lrn_mean), mn_metalearner) # Define the Blip learner, which is a multivariate learner: learners &lt;- list(lrn_xgboost_50, lrn_xgboost_100, lrn_xgboost_500, lrn_mean, lrn_glm) b_learner &lt;- create_mv_learners(learners = learners) As seen above, we generate three different ensemble learners that must be fit, corresponding to the learners for the outcome regression, propensity score, and the blip function. Note that we need to estimate \\(g_0(A|W)\\) for a categorical \\(A\\) – therefore, we use the multinomial Super Learner option available within the sl3 package with learners that can address multi-class classification problems. In order to see which learners can be used to estimate \\(g_0(A|W)\\) in sl3, we run the following: # See which learners support multi-class classification: sl3_list_learners(c(&quot;categorical&quot;)) [1] &quot;Lrnr_bartMachine&quot; &quot;Lrnr_caret&quot; [3] &quot;Lrnr_dbarts&quot; &quot;Lrnr_gam&quot; [5] &quot;Lrnr_glmnet&quot; &quot;Lrnr_grf&quot; [7] &quot;Lrnr_h2o_glm&quot; &quot;Lrnr_h2o_grid&quot; [9] &quot;Lrnr_independent_binomial&quot; &quot;Lrnr_mean&quot; [11] &quot;Lrnr_multivariate&quot; &quot;Lrnr_optim&quot; [13] &quot;Lrnr_polspline&quot; &quot;Lrnr_pooled_hazards&quot; [15] &quot;Lrnr_randomForest&quot; &quot;Lrnr_ranger&quot; [17] &quot;Lrnr_rpart&quot; &quot;Lrnr_screener_corP&quot; [19] &quot;Lrnr_screener_corRank&quot; &quot;Lrnr_screener_randomForest&quot; [21] &quot;Lrnr_solnp&quot; &quot;Lrnr_svm&quot; [23] &quot;Lrnr_xgboost&quot; Note that since the corresponding blip will be vector valued, we will have a column for each additional level of treatment. As such, we need to create multivariate learners with the helper function create_mv_learners that takes a list of initialized learners as input. We make the above explicit with respect to standard notation by bundling the ensemble learners into a list object below: # specify outcome and treatment regressions and create learner list learner_list &lt;- list(Y = Q_learner, A = g_learner, B = b_learner) 6.7.3 Targeted Estimation of the Mean under the Optimal Individualized Interventions Effects # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_blip_revere( V = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;, &quot;W4&quot;), type = &quot;blip2&quot;, learners = learner_list, maximize = TRUE, complex = TRUE, realistic = FALSE ) # fit the TML estimator fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=NULL}] 0.5403829 0.6062191 0.07230925 0.4644956 0.7479426 psi_transformed lower_transformed upper_transformed 1: 0.6062191 0.4644956 0.7479426 We can see that the estimate of \\(psi_0\\) is \\(0.60\\), and that the confidence interval covers our true mean under the true optimal individualized treatment. 6.8 Extensions to Causal Effect of an OIT In this section, we consider two extensions to the procedure described for estimating the value of the OIT. First one considers a setting where the user might be interested in a grid of possible sub-optimal rules, corresponding to potentially limited knowledge of potential effect modifiers. The second extension concerns implementation of a realistic optimal individual interventions where certain regimes might be preferred, but due to practical or global positivity restraints are not realistic to implement. 6.8.1 Simpler Rules In order to not only consider the most ambitious fully \\(V\\)-optimal rule, we define \\(S\\)-optimal rules as the optimal rule that considers all possible subsets of \\(V\\) covariates, with card(\\(S\\)) \\(\\leq\\) card(\\(V\\)) and \\(\\emptyset \\in S\\). This allows us to consider sub-optimal rules that are easier to estimate and potentially provide more realistic rules- as such, we allow for statistical inference for the counterfactual mean outcome under the sub-optimal rule. Within the tmle3mopttx paradigm, we just need to change the complex parameter to FALSE: # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_blip_revere( V = c(&quot;W4&quot;, &quot;W3&quot;, &quot;W2&quot;, &quot;W1&quot;), type = &quot;blip2&quot;, learners = learner_list, maximize = TRUE, complex = FALSE, realistic = FALSE ) # fit the TML estimator fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=1}] 0.4804483 0.5637601 0.09817383 0.3713429 0.7561773 psi_transformed lower_transformed upper_transformed 1: 0.5637601 0.3713429 0.7561773 Therefore even though the user specified all baseline covariates as the basis for rule estimation, a simpler rule based on only \\(W_2\\) and \\(W_1\\) is sufficient to maximize the mean under the optimal individualized treatment. 6.8.2 Realistic Optimal Individual Regimes In addition to considering less complex rules, tmle3mopttx also provides an option to estimate the mean under the realistic, or implementable, optimal individualized treatment. It is often the case that assigning particular regime might have the ability to fully maximize (or minimize) the desired outcome, but due to global or practical positivity constrains, such treatment can never be implemented in real life (or is highly unlikely). As such, specifying realistic to TRUE, we consider possibly suboptimal treatments that optimize the outcome in question while being supported by the data. # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_blip_revere( V = c(&quot;W4&quot;, &quot;W3&quot;, &quot;W2&quot;, &quot;W1&quot;), type = &quot;blip2&quot;, learners = learner_list, maximize = TRUE, complex = TRUE, realistic = TRUE ) # fit the TML estimator fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=NULL}] 0.5557853 0.659876 0.02138151 0.617969 0.701783 psi_transformed lower_transformed upper_transformed 1: 0.659876 0.617969 0.701783 # How many individuals got assigned each treatment? table(tmle_spec$return_rule) 2 3 503 497 6.8.3 Q-learning Alternatively, we could estimate the mean under the optimal individualized treatment using Q-learning. The optimal rule can be learned through fitting the likelihood, and consequently estimating the optimal rule under this fit of the likelihood (Sutton, Barto, and others 1998, @murphy2003). Below we outline how to use tmle3mopttx package in order to estimate the mean under the ITR using Q-learning. As demonstrated in the previous sections, we first need to initialize a specification for the TMLE of our parameter of interest. As opposed to the previous section however, we will now use tmle3_mopttx_Q instead of tmle3_mopttx_blip_revere in order to indicate that we want to use Q-learning instead of TMLE. # initialize a tmle specification tmle_spec_Q &lt;- tmle3_mopttx_Q(maximize = TRUE) # Define data: tmle_task &lt;- tmle_spec_Q$make_tmle_task(data, node_list) # Define likelihood: initial_likelihood &lt;- tmle_spec_Q$make_initial_likelihood(tmle_task, learner_list) # Estimate the parameter: Q_learning(tmle_spec_Q, initial_likelihood, tmle_task)[1] [1] 0.4744045 6.9 Variable Importance Analysis with OIT Suppose one wishes to assess the importance of each observed covariate, in terms of maximizing (or minimizing) the population mean of an outcome under an optimal individualized treatment regime. In particular, a covariate that maximizes (or minimizes) the population mean outcome the most under an optimal individualized treatment out of all other considered covariates under optimal assignment might be considered more important for the outcome. To put it in context, perhaps optimal allocation of treatment 1, denoted \\(A_1\\), results in a larger mean outcome than optimal allocation of another treatment (\\(A_2\\)). Therefore, we would label \\(A_1\\) as having a higher variable importance with regard to maximizing (minimizing) the mean outcome under the optimal individualized treatment. 6.9.1 Simulated Data In order to run tmle3mopttx variable importance measure, we need to consider covariates to be categorical variables. For illustration purpose, we bin baseline covariates corresponding to the data-generating distribution described in section 5.7.1: # bin baseline covariates to 3 categories: data$W1 &lt;- ifelse(data$W1 &lt; quantile(data$W1)[2], 1, ifelse(data$W1 &lt; quantile(data$W1)[3], 2, 3)) node_list &lt;- list( W = c(&quot;W3&quot;, &quot;W4&quot;, &quot;W2&quot;), A = c(&quot;W1&quot;, &quot;A&quot;), Y = &quot;Y&quot; ) Note that our node list now includes \\(W_1\\) as treatments as well! Don’t worry, we will still properly adjust for all baseline covariates. 6.9.2 Variable Importance using Targeted Estimation of the value of the ITR In the previous sections we have seen how to obtain a contrast between the mean under the optimal individualized rule and the mean under the observed outcome for a single covariate- we are now ready to run the variable importance analysis for all of our specified covariates. In order to run the variable importance analysis, we first need to initialize a specification for the TMLE of our parameter of interest as we have done before. In addition, we need to specify the data and the corresponding list of nodes, as well as the appropriate learners for the outcome regression, propensity score, and the blip function. Finally, we need to specify whether we should adjust for all the other covariates we are assessing variable importance for. We will adjust for all \\(W\\)s in our analysis, and if adjust_for_other_A=TRUE, also for all \\(A\\) covariates that are not treated as exposure in the variable importance loop. To start, we will initialize a specification for the TMLE of our parameter of interest (called a tmle3_Spec in the tlverse nomenclature) simply by calling tmle3_mopttx_vim. First, we indicate the method used for learning the optimal individualized treatment by specifying the method argument of tmle3_mopttx_vim. If method=&quot;Q&quot;, then we will be using Q-learning for rule estimation, and we do not need to specify V, type and learners arguments in the spec, since they are not important for Q-learning. However, if method=&quot;SL&quot;, which corresponds to learning the optimal individualized treatment using the above outlined methodology, then we need to specify the type of pseudo-blip we will use in this estimation problem, whether we want to maximize or minimize the outcome, complex and realistic rules. Finally, for method=&quot;SL&quot; we also need to communicate that we’re interested in learning a rule dependent on V covariates by specifying the V argument. For both method=&quot;Q&quot; and method=&quot;SL&quot;, we need to indicate whether we want to maximize or minimize the mean under the optimal individualized rule. Finally, we also need to specify whether the final comparison of the mean under the optimal individualized rule and the mean under the observed outcome should be on the multiplicative scale (risk ratio) or linear (similar to average treatment effect). # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_vim( V=c(&quot;W2&quot;), type = &quot;blip2&quot;, learners = learner_list, contrast = &quot;multiplicative&quot;, maximize = FALSE, method = &quot;SL&quot;, complex = TRUE, realistic = FALSE ) # fit the TML estimator vim_results &lt;- tmle3_vim(tmle_spec, data, node_list, learner_list, adjust_for_other_A = TRUE ) print(vim_results) type param init_est tmle_est se lower 1: RR RR(E[Y_{A=NULL}]/E[Y]) 0.003486027 0.08520227 0.03306423 0.02039758 2: RR RR(E[Y_{A=NULL}]/E[Y]) -0.022962590 -0.06289586 0.04934050 -0.15960148 upper psi_transformed lower_transformed upper_transformed A 1: 0.15000696 1.0889373 1.0206070 1.161842 A 2: 0.03380975 0.9390413 0.8524835 1.034388 W1 W Z_stat p_nz p_nz_corrected 1: W3,W4,W2,W1 2.576872 0.004984944 0.009969889 2: W3,W4,W2,A -1.274731 0.101202255 0.101202255 The final result of tmle3_vim with the tmle3mopttx spec is an ordered list of mean outcomes under the optimal individualized treatment for all categorical covariates in our dataset. 6.10 Real World Data and tmle3mopttx Finally, we cement everything we learned so far with a real data application. As in the previous sections, we will be using the WASH Benefits data, corresponding to the Effect of water quality, sanitation, hand washing, and nutritional interventions on child development in rural Bangladesh trial. The main aim of the cluster-randomized controlled trial was to assess the impact of six intervention groups, including: chlorinated drinking water improved sanitation handwashing with soap combined water, sanitation, and handwashing improved nutrition through counselling and provision of lipid-based nutrient supplements combined water, sanitation, handwashing, and nutrition. We aim to estimate the optimal ITR and the corresponding value under the optimal ITR for the main intervention in WASH Benefits data. To start, let’s load the data, convert all columns to be of class numeric, and take a quick look at it: washb_data &lt;- fread(&quot;https://raw.githubusercontent.com/tlverse/tlverse-data/master/wash-benefits/washb_data.csv&quot;, stringsAsFactors = TRUE) washb_data &lt;- washb_data[!is.na(momage), lapply(.SD, as.numeric)] head(washb_data, 3) whz tr fracode month aged sex momage momedu momheight hfiacat Nlt18 Ncomp 1: 0.00 1 4 9 268 2 30 2 146.40 1 3 11 2: -1.16 1 4 9 286 2 25 2 148.75 3 2 4 3: -1.05 1 20 9 264 2 25 2 152.15 1 1 10 watmin elec floor walls roof asset_wardrobe asset_table asset_chair 1: 0 1 0 1 1 0 1 1 2: 0 1 0 1 1 0 1 0 3: 0 0 0 1 1 0 0 1 asset_khat asset_chouki asset_tv asset_refrig asset_bike asset_moto 1: 1 0 1 0 0 0 2: 1 1 0 0 0 0 3: 0 1 0 0 0 0 asset_sewmach asset_mobile 1: 0 1 2: 0 1 3: 0 1 As before, we specify the NPSEM via the node_list object. Our outcome of interest is the weight-for-height Z-score which we seek to maximize, whereas our treatment is the six intervention groups aimed at improving living conditions. All the other collected baseline covariates correspond to \\(W\\). node_list &lt;- list(W = names(washb_data)[!(names(washb_data) %in% c(&quot;whz&quot;, &quot;tr&quot;))], A = &quot;tr&quot;, Y = &quot;whz&quot;) We pick few potential effect modifiers, including mother’s education, current living conditions (floor), and possession of material items including the refrigerator. We concentrate of these covariates as they might be indicative of the socio-economic status of individuals involved in the trial. table(washb_data$momedu) 1 2 3 733 1441 2503 table(washb_data$floor) 0 1 4177 500 table(washb_data$asset_refrig) 0 1 4305 372 summary(washb_data$whz) Min. 1st Qu. Median Mean 3rd Qu. Max. -4.6700 -1.2800 -0.6000 -0.5859 0.0800 4.9700 # Initialize few of the learners: lrn_xgboost_50 &lt;- Lrnr_xgboost$new(nrounds = 50) lrn_xgboost_100 &lt;- Lrnr_xgboost$new(nrounds = 100) lrn_mean &lt;- Lrnr_mean$new() ## Define the Q learner, which is just a regular learner: Q_learner &lt;- Lrnr_sl$new( learners = list(lrn_xgboost_50, lrn_xgboost_100, lrn_mean), metalearner = Lrnr_nnls$new() ) # Define the g learner, which is a multinomial learner: #specify the appropriate loss of the multinomial learner: mn_metalearner &lt;- make_learner(Lrnr_solnp, loss_function = loss_loglik_multinomial, learner_function = metalearner_linear_multinomial) g_learner &lt;- make_learner(Lrnr_sl, list(lrn_xgboost_100, lrn_mean), mn_metalearner) # Define the Blip learner, which is a multivariate learner: learners &lt;- list(lrn_xgboost_50, lrn_xgboost_100, lrn_mean) b_learner &lt;- create_mv_learners(learners = learners) learner_list &lt;- list(Y = Q_learner, A = g_learner, B = b_learner) # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_blip_revere( V = c(&quot;momedu&quot;, &quot;floor&quot;, &quot;asset_refrig&quot;), type = &quot;blip2&quot;, learners = learner_list, maximize = TRUE, complex = TRUE, realistic = FALSE ) # fit the TML estimator fit &lt;- tmle3(tmle_spec, data=washb_data, node_list, learner_list) Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. Warning in process_data(data, nodes, column_names = column_names, flag = flag, : Missing covariate data detected: imputing covariates. fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=NULL}] -0.5476712 -0.4628141 0.04414454 -0.5493358 -0.3762924 psi_transformed lower_transformed upper_transformed 1: -0.4628141 -0.5493358 -0.3762924 6.11 Exercises 6.11.1 Review of Key Concepts What is the difference between dynamic and optimal individualized regimes? What’s the intuition behind using different blip types? Why did we switch from blip1 to blip2 when considering categorical treatment? What are some of the advantages of each? Look back at the results generated in section 5.7.1, and compare then to the mean under the optimal individualized treatment in section 5.6. Why do you think the estimate if higher under the less complex rule? How does the set of covariates picked by tmle3mopttx compare to the baseline covariates the true rule depends on? Compare the distribution of treatments assigned under the true optimal individualized treatment (section 5.6) and realistic optimal individualized treatment (section 5.7.2). Referring back to the data-generating distribution, why do you think the distribution of allocated treatment changed? Using the same simulation, perform a variable importance analysis using Q-learning. How do the results change and why? 6.11.2 The Ideas in Action Using the WASH benefits data, extract the optimal ITR for exact individual. Which intervention is the most dominant? Why do you think that is? Consider simpler rules for the WASH benefits data example. What set of rules are picked? Using the WASH benefits data, estimate the realistic optimal ITR and the corresponding value of the realistic ITR. Did the results change? Change the treatment to Mother’s education (momedu), and estimate the value under the ITR in this setting. What do the results indicate? Can we intervene on such a variable? 6.11.3 Advanced Topics How can we extend the current approach to include exceptional laws? How can we extend the current approach to incorporate resource constraints? How can we extend the current approach to continuous interventions? References "],
["stochastic-treatment-regimes.html", "Chapter 7 Stochastic Treatment Regimes 7.1 Learning Objectives 7.2 Introduction to Stochastic Interventions 7.3 Data Structure and Notation 7.4 Defining the Causal Effect of a Stochastic Intervention 7.5 Interpreting the Causal Effect of a Stochastic Intervention 7.6 Evaluating the Causal Effect of a Stochastic Intervention 7.7 Extensions: Variable Importance Analysis with Stochastic Interventions 7.8 Exercises", " Chapter 7 Stochastic Treatment Regimes Nima Hejazi Based on the tmle3shift R package by Nima Hejazi, Jeremy Coyle, and Mark van der Laan. Updated: 2020-02-21 7.1 Learning Objectives Differentiate stochastic treatment regimes from static, dynamic, and optimal treatment regimes. Describe how estimating causal effects of stochastic interventions informs a real-world data analysis. Contrast a population level stochastic intervention policy from a modified treatment policy. Estimate causal effects under stochastic treatment regimes with the tmle3shift R package. Specify a grid of counterfactual shift interventions to be used for defining a set of stochastic intervention policies. Interpret a set of effect estimates from a grid of counterfactual shift interventions. Construct marginal structural models to measure variable importance in terms of stochastic interventions, using a grid of shift interventions. Implement a shift intervention at the individual level, to facilitate shifting each individual to a value that’s supported by the data. Define novel shift intervention functions to extend the tmle3shift R package. 7.2 Introduction to Stochastic Interventions Stochastic treatment regimes present a relatively simple, yet extremely flexible manner by which realistic causal effects (and contrasts thereof) may be defined. Importantly, stochastic treatment regimes may be applied to nearly any manner of treatment variable – continuous, ordinal, categorical, binary – allowing for a rich set of causal effects to be defined through this formalism. In this chapter, we examine a simple example of stochastic treatment regimes in the context of a continuous treatment variable of interest, defining an intuitive causal effect through which to examine stochastic interventions more generally. In later sections, we introduce numerous extensions based on this broad class of interventions – from stochastic interventions on binary treatment variables to stochastic mediation effects and data-adaptive inference for stochastic intervention effects. As a first step to using stochastic treatment regimes in practice, we present the tmle3shift R package, which features an implementation of a recently developed algorithm for computing targeted minimum loss-based estimates of a causal effect based on a stochastic treatment regime that shifts the natural value of the treatment based on a shifting function \\(d(A,W)\\). For a comprehensive technical presentation of some of the material in this chapter, the interested reader is invited to consult Díaz and van der Laan (2018). Additional background on the field of Targeted Learning, as well as prior work on stochastic treatment regimes, is available in van der Laan and Rose (2011), van der Laan and Rose (2018), and Díaz and van der Laan (2012). While stochastic treatment regimes are arguably the most general of the classes of interventions through which causal effects may be defined, such interventions are conceptually simple. 7.3 Data Structure and Notation Consider \\(n\\) observed units \\(O_1, \\ldots, O_n\\), where each random variable \\(O = (W, A, Y)\\) corresponds to a single observational unit. Let \\(W\\) denote baseline covariates (e.g., age, sex, education level), \\(A\\) an intervention variable of interest (e.g., nutritional supplements), and \\(Y\\) an outcome of interest (e.g., disease status). Though it need not be the case, let \\(A\\) be continuous-valued, i.e. \\(A \\in \\mathbb{R}\\). Let \\(O_i \\sim \\mathcal{P} \\in \\mathcal{M}\\), where \\(\\mathcal{M}\\) is the nonparametric statistical model defined as the set of continuous densities on \\(O\\) with respect to some dominating measure. To formalize the definition of stochastic interventions and their corresponding causal effects, we introduce a nonparametric structural equation model (NPSEM), based on Pearl (2009a), to define how the system changes under posited interventions: \\[\\begin{align*}\\label{eqn:npsem} W &amp;= f_W(U_W) \\\\ A &amp;= f_A(W, U_A) \\\\ Y &amp;= f_Y(A, W, U_Y), \\end{align*}\\] where the set of structural equations provide a mechanistic model by which the observed data \\(O\\) is assumed to have been generated. There are several standard assumptions embedded in the NPSEM – specifically, a temporal ordering that supposes that \\(Y\\) occurs after \\(A\\), which occurs after \\(W\\); each variable (i.e., \\(\\{W, A, Y\\}\\)) is assumed to have been generated from its corresponding deterministic function (i.e., \\(\\{f_W, f_A, f_Y\\}\\)) of the observed variables that precede it temporally, as well as an exogenous variable, denoted by \\(U\\); lastly, each exogenous variable is assumed to contain all unobserved causes of the corresponding observed variable. The likelihood of the data \\(O\\) admits a factorization, wherein, for \\(p_0^O\\), the density of \\(O\\) with respect to the product measure, the density evaluated on a particular observation \\(o\\) may be a written \\[\\begin{equation*}\\label{eqn:likelihood_factorization} p_0^O(x) = q^O_{0,Y}(y \\mid A = a, W = w) q^O_{0,A}(a \\mid W = w) q^O_{0,W}(w), \\end{equation*}\\] where \\(q_{0, Y}\\) is the conditional density of \\(Y\\) given \\((A, W)\\) with respect to some dominating measure, \\(q_{0, A}\\) is the conditional density of \\(A\\) given \\(W\\) with respect to dominating measure \\(\\mu\\), and \\(q_{0, W}\\) is the density of \\(W\\) with respect to dominating measure \\(\\nu\\). Further, for ease of notation, let \\(Q(A, W) = \\mathbb{E}[Y \\mid A, W]\\), \\(g(A \\mid W) = \\mathbb{P}(A \\mid W)\\), and \\(q_W\\) the marginal distribution of \\(W\\). These components of the likelihood will be essential in developing an understanding of the manner in which stochastic treatment regimes pertrub a system and how a corresponding causal effect may be evaluated. Importantly, the NPSEM parameterizes \\(p_0^O\\) in terms of the distribution of random variables \\((O, U)\\) modeled by the system of equations. In turn, this implies a model for the distribution of counterfactual random variables generated by interventions on the data-generating process. 7.4 Defining the Causal Effect of a Stochastic Intervention As causal effects are defined in terms of hypothetical interventions on the NPSEM (), we may consider stochastic interventions in two equivalent ways: (1) where the equation \\(f_A\\), giving rise to \\(A\\), is replaced by a probabilistic mechanism \\(g_{\\delta}(A \\mid W)\\) that differs from the original \\(g(A \\mid W)\\), or (2) where the observed value \\(A\\) is replaced by a new value \\(A_{d(A,W)}\\) based on applying a user-defined function \\(d(A,W)\\) to \\(A\\). In the former case, the stochastically modified value of the treatment \\(A_{\\delta}\\) is drawn from a user-specified distribution \\(g_\\delta(A \\mid W)\\), which may depend on the original distribution \\(g(A \\mid W)\\) and is indexed by a user-specified parameter \\(\\delta\\). In this case, the stochastically modified value of the treatment \\(A_{\\delta} \\sim g_{\\delta}(\\cdot \\mid W)\\). Alternatively, in the latter case, the stochastic treatment regime may be viewed as an intervention in which \\(A\\) is set equal to a value based on a hypothetical regime \\(d(A, W)\\), where regime \\(d\\) depends on the treatment level \\(A\\) that would be assigned in the absence of the regime as well as the covariates \\(W\\). In either case, one may view the stochastic intervention as generating a counterfactual random variable \\(Y_{d(A,W)} := f_Y(d(A,W), W, U_Y) \\equiv Y_{g_{\\delta}} := f_Y(A_{\\delta}, W, U_Y)\\), where the counterfactual outcome \\(Y_{d(A,W)} \\sim \\mathcal{P}_0^{\\delta}\\). Stochastic interventions of this second variety may be referred to as depending on the natural value of treatment or as modified treatment policies. Haneuse and Rotnitzky (2013) and Young, Hernán, and Robins (2014) provide a discussion of the critical differences and similarities in the identification and interpretation of these two classes of stochastic intervention. In the sequel, we will restrict our attention to a simple stochastic treatment regime that has been characterized as a modified treatment policy (MTP). Letting \\(A\\) denote a continuous-valued treatment, such as the taking of nutritional supplements (e.g., number of vitamin pills) and assume that the distribution of \\(A\\) conditional on \\(W = w\\) has support in the interval \\((l(w), u(w))\\). That is, the minimum observed number of pills taken \\(A\\) for an individual with covariates \\(W = w\\) is \\(l(w)\\); similarly, the maximum is \\(u(w)\\). Then, a simple stochastic intervention, based on a shift \\(\\delta\\), may be defined \\[\\begin{equation}\\label{eqn:shift} d(a, w) = \\begin{cases} a - \\delta &amp; \\text{if } a &gt; l(w) + \\delta \\\\ a &amp; \\text{if } a \\leq l(w) + \\delta, \\end{cases} \\end{equation}\\] where \\(0 \\leq \\delta \\leq u(w)\\) is an arbitrary pre-specified value that defines the degree to which the observed value \\(A\\) is to be shifted, where possible. Such a stochastic treatment regime may be interpreted as the result of a clinic policy that encourages individuals to consume \\(\\delta\\) more vitamin pills than they would normally, i.e., based on their baseline characteristics. The interpretation of this stochastic intervention may be made more interesting by allowing the modification \\(\\delta\\) that it engenders to be a function of the baseline covariates \\(W\\), thereby allowing for the number of vitamin pills taken to be a function of covariates such as age, sex, comorbidities, etc. This class of stochastic interventions was first introduced by Díaz and van der Laan (2012) and has been further discussed in Haneuse and Rotnitzky (2013), Díaz and van der Laan (2018), and Hejazi et al. (n.d.). Note that this intervention may be written in a manner consistent with the first class of stochastic treatment regimes discussed as well – that is, as per Díaz and van der Laan (2012), \\(\\mathbb{P}_{\\delta}(g_0)(A = a \\mid W) = g_0(a - \\delta(W) \\mid W)\\). The goal of any causal analysis motivated by such a stochastic intervention is to estimate a parameter defined as the counterfactual mean of the outcome with respect to the stochastically modified intervention distribution. In particular, the target causal estimand of our analysis is \\(\\psi_{0, \\delta} := \\mathbb{E}_{P_0^{\\delta}}\\{Y_{d(A,W)}\\}\\), the mean of the counterfactual outcome variable \\(Y_{d(A, W)}\\). In prior work, Díaz and van der Laan (2012) showed that the causal quantity of interest \\(\\mathbb{E}_0 \\{Y_{d(A, W)}\\}\\) is identified by a functional of the distribution of \\(O\\): \\[\\begin{align*}\\label{eqn:identification2012} \\psi_{0,d} = \\int_{\\mathcal{W}} \\int_{\\mathcal{A}} &amp; \\mathbb{E}_{P_0} \\{Y \\mid A = d(a, w), W = w\\} \\cdot \\\\ &amp;q_{0, A}^O(a \\mid W = w) \\cdot q_{0, W}^O(w) d\\mu(a)d\\nu(w). \\end{align*}\\] If the identification conditions may be assumed to hold, then the statistical parameter in matches exactly the counterfactual outcome \\(\\psi_{0, \\delta}\\) under such an intervention, allowing for the causal effect to be learned from the observed data \\(O\\). Díaz and van der Laan (2012) provide a derivation based on the efficient influence function (EIF) in the nonparametric model \\(\\mathcal{M}\\) and develop several estimators of this quantity, including substitution, inverse probability weighted (IPW), augmented inverse probability weighted (AIPW), and targeted maximum likelihood (TML) estimators, allowing for semiparametric-efficient estimation and inference on the quantity of interest. As per Díaz and van der Laan (2018), the statistical target parameter may also be denoted \\(\\Psi(P_0) = \\mathbb{E}_{P_0}{\\overline{Q}(d(A, W), W)}\\), where \\(\\overline{Q}(d(A, W), W)\\) is the counterfactual outcome value of a given individual under the stochastic intervention distribution. Although the focus of this work is neither the establishment of identification results nor the development of theoretical details, we review the necessary identification details for the counterfactual mean under a stochastic intervention here, in the interest of completeness. Paraphrasing from Díaz and van der Laan (2012) and Díaz and van der Laan (2018), four standard assumptions are necessary in order to establish identifiability of the causal parameter from the observed data via the statistical functional – these are Consistency: \\(Y^{d(a_i, w_i)}_i = Y_i\\) in the event \\(A_i = d(a_i, w_i)\\), for \\(i = 1, \\ldots, n\\) Stable unit value treatment assumption (SUTVA): \\(Y^{d(a_i, w_i)}_i\\) does not depend on \\(d(a_j, w_j)\\) for \\(i = 1, \\ldots, n\\) and \\(j \\neq i\\), or lack of interference (Rubin 1978, 1980). Strong ignorability: \\(A_i \\indep Y^{d(a_i, w_i)}_i \\mid W_i\\), for \\(i = 1, \\ldots, n\\). Positivity (or overlap)_: \\(a_i \\in \\mathcal{A} \\implies d(a_i, w_i) \\in \\mathcal{A}\\) for all \\(w \\in \\mathcal{W}\\), where \\(\\mathcal{A}\\) denotes the support of \\(A \\mid W = w_i \\quad \\forall i = 1, \\ldots n\\). With the identification assumptions satisfied, Díaz and van der Laan (2012) and Díaz and van der Laan (2018) provide an efficient influence function with respect to the nonparametric model \\(\\mathcal{M}\\) as \\[\\begin{equation*}\\label{eqn:eif} D(P_0)(x) = H(a, w)({y - \\overline{Q}(a, w)}) + \\overline{Q}(d(a, w), w) - \\Psi(P_0), \\end{equation*}\\] where the auxiliary covariate \\(H(a,w)\\) may be expressed \\[\\begin{equation*}\\label{eqn:aux_covar_full} H(a,w) = \\mathbb{I}(a + \\delta &lt; u(w)) \\frac{g_0(a - \\delta \\mid w)} {g_0(a \\mid w)} + \\mathbb{I}(a + \\delta \\geq u(w)), \\end{equation*}\\] which may be reduced to \\[\\begin{equation*}\\label{eqn:aux_covar_simple} H(a,w) = \\frac{g_0(a - \\delta \\mid w)}{g_0(a \\mid w)} + 1 \\end{equation*}\\] in the case that the treatment is within the limits that arise from conditioning on \\(W\\), i.e., for \\(A_i \\in (u(w) - \\delta, u(w))\\). The efficient influence function allows the construction of a semiparametric-efficient estimators may be constructed. In the sequel, we focus on a targeted maximum likelihood (TML) estimator, for which Díaz and van der Laan (2018) give a recipe: Construct initial estimators \\(g_n\\) of \\(g_0(A, W)\\) and \\(Q_n\\) of \\(\\overline{Q}_0(A, W)\\), perhaps using data-adaptive regression techniques. For each observation \\(i\\), compute an estimate \\(H_n(a_i, w_i)\\) of the auxiliary covariate \\(H(a_i,w_i)\\). Estimate the parameter \\(\\epsilon\\) in the logistic regression model \\[ \\text{logit}\\overline{Q}_{\\epsilon, n}(a, w) = \\text{logit}\\overline{Q}_n(a, w) + \\epsilon H_n(a, w),\\] or an alternative regression model incorporating weights. Compute TML estimator \\(\\Psi_n\\) of the target parameter, defining update \\(\\overline{Q}_n^{\\star}\\) of the initial estimate \\(\\overline{Q}_{n, \\epsilon_n}\\): \\[\\begin{equation*}\\label{eqn:tmle} \\Psi_n = \\Psi(P_n^{\\star}) = \\frac{1}{n} \\sum_{i = 1}^n \\overline{Q}_n^{\\star}(d(A_i, W_i), W_i). \\end{equation*}\\] 7.5 Interpreting the Causal Effect of a Stochastic Intervention Figure 7.1: Animation of how a counterfactual outcome changes as the natural treatment distribution is subjected to a simple stochastic intervention 7.6 Evaluating the Causal Effect of a Stochastic Intervention To start, let us load the packages we will use and set a seed for simulation: library(here) library(tidyverse) library(data.table) library(sl3) library(tmle3) library(tmle3shift) set.seed(429153) We need to estimate two components of the likelihood in order to construct a TML estimator. The first of these components is the outcome regression, \\(\\hat{Q}_n\\), which is a simple regression of the form \\(\\mathbb{E}[Y \\mid A,W]\\). An estimate for such a quantity may be constructed using the Super Learner algorithm. We construct the components of an sl3-style Super Learner for a regression below, using a small variety of parametric and nonparametric regression techniques: # learners used for conditional expectation regression lrn_mean &lt;- Lrnr_mean$new() lrn_fglm &lt;- Lrnr_glm_fast$new() lrn_xgb &lt;- Lrnr_xgboost$new(nrounds = 200) sl_lrn &lt;- Lrnr_sl$new( learners = list(lrn_mean, lrn_fglm, lrn_xgb), metalearner = Lrnr_nnls$new() ) The second of these is an estimate of the treatment mechanism, \\(\\hat{g}_n\\), i.e., the propensity score. In the case of a continuous intervention node \\(A\\), such a quantity takes the form \\(p(A \\mid W)\\), which is a conditional density. Generally speaking, conditional density estimation is a challenging problem that has received much attention in the literature. To estimate the treatment mechanism, we must make use of learning algorithms specifically suited to conditional density estimation; a list of such learners may be extracted from sl3 by using sl3_list_learners(): sl3_list_learners(&quot;density&quot;) [1] &quot;Lrnr_condensier&quot; &quot;Lrnr_density_discretize&quot; [3] &quot;Lrnr_density_hse&quot; &quot;Lrnr_density_semiparametric&quot; [5] &quot;Lrnr_haldensify&quot; &quot;Lrnr_rfcde&quot; [7] &quot;Lrnr_solnp_density&quot; To proceed, we’ll select two of the above learners, Lrnr_haldensify for using the highly adaptive lasso for conditional density estimation, based on an algorithm given by Díaz and van der Laan (2011) and implemented in Hejazi, Benkeser, and van der Laan (2019), and Lrnr_rfcde, an approach for using random forests for conditional density estimation (Pospisil and Lee 2018). A Super Learner may be constructed by pooling estimates from each of these modified conditional density regression techniques. # learners used for conditional density regression (i.e., propensity score) lrn_haldensify &lt;- Lrnr_haldensify$new( n_bins = 5, grid_type = &quot;equal_mass&quot;, lambda_seq = exp(seq(-1, -13, length = 500)) ) lrn_rfcde &lt;- Lrnr_rfcde$new( n_trees = 1000, node_size = 5, n_basis = 31, output_type = &quot;observed&quot; ) sl_lrn_dens &lt;- Lrnr_sl$new( learners = list(lrn_haldensify, lrn_rfcde), metalearner = Lrnr_solnp_density$new() ) Finally, we construct a learner_list object for use in constructing a TML estimator of our target parameter of interest: learner_list &lt;- list(Y = sl_lrn, A = sl_lrn_dens) The learner_list object above specifies the role that each of the ensemble learners we have generated is to play in computing initial estimators to be used in building a TMLE for the parameter of interest here. In particular, it makes explicit the fact that our Q_learner is used in fitting the outcome regression while our g_learner is used in estimating the treatment mechanism. 7.6.1 Example with Simulated Data # simulate simple data for tmle-shift sketch n_obs &lt;- 500 # number of observations tx_mult &lt;- 2 # multiplier for the effect of W = 1 on the treatment ## baseline covariates -- simple, binary W &lt;- replicate(2, rbinom(n_obs, 1, 0.5)) ## create treatment based on baseline W A &lt;- rnorm(n_obs, mean = tx_mult * W, sd = 1) ## create outcome as a linear function of A, W + white noise Y &lt;- rbinom(n_obs, 1, prob = plogis(A + W)) # organize data and nodes for tmle3 data &lt;- data.table(W, A, Y) setnames(data, c(&quot;W1&quot;, &quot;W2&quot;, &quot;A&quot;, &quot;Y&quot;)) node_list &lt;- list(W = c(&quot;W1&quot;, &quot;W2&quot;), A = &quot;A&quot;, Y = &quot;Y&quot;) head(data) W1 W2 A Y 1: 1 1 2.4031607 1 2: 1 0 4.4973744 1 3: 1 0 2.0330871 1 4: 0 0 -0.8089023 0 5: 1 0 1.8432067 1 6: 1 1 1.3555863 1 The above composes our observed data structure \\(O = (W, A, Y)\\). To formally express this fact using the tlverse grammar introduced by the tmle3 package, we create a single data object and specify the functional relationships between the nodes in the directed acyclic graph (DAG) via nonparametric structural equation models (NPSEMs), reflected in the node list that we set up: We now have an observed data structure (data) and a specification of the role that each variable in the data set plays as the nodes in a DAG. To start, we will initialize a specification for the TMLE of our parameter of interest (called a tmle3_Spec in the tlverse nomenclature) simply by calling tmle_shift. We specify the argument shift_val = 0.5 when initializing the tmle3_Spec object to communicate that we’re interested in a shift of \\(0.5\\) on the scale of the treatment \\(A\\) – that is, we specify \\(\\delta = 0.5\\) (note that this is an arbitrarily chosen value for this example). # initialize a tmle specification tmle_spec &lt;- tmle_shift( shift_val = 0.5, shift_fxn = shift_additive_bounded, shift_fxn_inv = shift_additive_bounded_inv ) As seen above, the tmle_shift specification object (like all tmle3_Spec objects) does not store the data for our specific analysis of interest. Later, we’ll see that passing a data object directly to the tmle3 wrapper function, alongside the instantiated tmle_spec, will serve to construct a tmle3_Task object internally (see the tmle3 documentation for details). 7.6.2 Targeted Estimation of Stochastic Interventions Effects tmle_fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) Iter: 1 fn: 696.6708 Pars: 0.87922 0.12078 Iter: 2 fn: 696.6708 Pars: 0.87922 0.12078 solnp--&gt; Completed in 2 iterations tmle_fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=NULL}] 0.7692472 0.7708134 0.01889031 0.733789 0.8078377 psi_transformed lower_transformed upper_transformed 1: 0.7708134 0.733789 0.8078377 The print method of the resultant tmle_fit object conveniently displays the results from computing our TML estimator. 7.6.3 Statistical Inference for Targeted Maximum Likelihood Estimates Recall that the asymptotic distribution of TML estimators has been studied thoroughly: \\[\\psi_n - \\psi_0 = (P_n - P_0) \\cdot D(\\bar{Q}_n^*, g_n) + R(\\hat{P}^*, P_0),\\] which, provided the following two conditions: If \\(D(\\bar{Q}_n^*, g_n)\\) converges to \\(D(P_0)\\) in \\(L_2(P_0)\\) norm, and the size of the class of functions considered for estimation of \\(\\bar{Q}_n^*\\) and \\(g_n\\) is bounded (technically, \\(\\exists \\mathcal{F}\\) st \\(D(\\bar{Q}_n^*, g_n) \\in \\mathcal{F}\\) whp, where \\(\\mathcal{F}\\) is a Donsker class), readily admits the conclusion that \\(\\psi_n - \\psi_0 = (P_n - P_0) \\cdot D(P_0) + R(\\hat{P}^*, P_0)\\). Under the additional condition that the remainder term \\(R(\\hat{P}^*, P_0)\\) decays as \\(o_P \\left( \\frac{1}{\\sqrt{n}} \\right),\\) we have that \\[\\psi_n - \\psi_0 = (P_n - P_0) \\cdot D(P_0) + o_P \\left( \\frac{1}{\\sqrt{n}} \\right),\\] which, by a central limit theorem, establishes a Gaussian limiting distribution for the estimator: \\[\\sqrt{n}(\\psi_n - \\psi) \\to N(0, V(D(P_0))),\\] where \\(V(D(P_0))\\) is the variance of the efficient influence curve (canonical gradient) when \\(\\psi\\) admits an asymptotically linear representation. The above implies that \\(\\psi_n\\) is a \\(\\sqrt{n}\\)-consistent estimator of \\(\\psi\\), that it is asymptotically normal (as given above), and that it is locally efficient. This allows us to build Wald-type confidence intervals in a straightforward manner: \\[\\psi_n \\pm z_{\\alpha} \\cdot \\frac{\\sigma_n}{\\sqrt{n}},\\] where \\(\\sigma_n^2\\) is an estimator of \\(V(D(P_0))\\). The estimator \\(\\sigma_n^2\\) may be obtained using the bootstrap or computed directly via the following \\[\\sigma_n^2 = \\frac{1}{n} \\sum_{i = 1}^{n} D^2(\\bar{Q}_n^*, g_n)(O_i)\\] Having now re-examined these facts, let’s simply examine the results of computing our TML estimator: 7.7 Extensions: Variable Importance Analysis with Stochastic Interventions 7.7.1 Defining a grid of counterfactual interventions In order to specify a grid of shifts \\(\\delta\\) to be used in defining a set of stochastic intervention policies in an a priori manner, let us consider an arbitrary scalar \\(\\delta\\) that defines a counterfactual outcome \\(\\psi_n = Q_n(d(A, W), W)\\), where, for simplicity, let \\(d(A, W) = A + \\delta\\). A simplified expression of the auxiliary covariate for the TMLE of \\(\\psi\\) is \\(H_n = \\frac{g^{\\star}(a \\mid w)}{g(a \\mid w)}\\), where \\(g^{\\star}(a \\mid w)\\) defines the treatment mechanism with the stochastic intervention implemented. Then, to ascertain whether a given choice of the shift \\(\\delta\\) is admissable (in the sense of avoiding violations of the positivity assumption), let there be a bound \\(C(\\delta) = \\frac{g^{\\star}(a \\mid w)}{g(a \\mid w)} &lt; M\\), where \\(g^{\\star}(a \\mid w)\\) is a function of \\(\\delta\\) in part, and \\(M\\) is a potentially user-specified upper bound of \\(C(\\delta)\\). Then, \\(C(\\delta)\\) is a measure of the influence of a given observation, thereby providing a way to limit the maximum influence of a given observation (by way of the bound \\(M\\) placed on \\(C(\\delta)\\)) through a choice of the shift \\(\\delta\\). We formalize and extend the procedure to determine an acceptable set of values for the shift \\(\\delta\\) in the sequel. Specifically, let there be a shift \\(d(A, W) = A + \\delta(A, W)\\), where the shift \\(\\delta(A, W)\\) is defined as \\[\\begin{equation} \\delta(a, w) = \\begin{cases} \\delta, &amp; \\delta_{\\text{min}}(a,w) \\leq \\delta \\leq \\delta_{\\text{max}}(a,w) \\\\ \\delta_{\\text{max}}(a,w), &amp; \\delta \\geq \\delta_{\\text{max}}(a,w) \\\\ \\delta_{\\text{min}}(a,w), &amp; \\delta \\leq \\delta_{\\text{min}}(a,w) \\\\ \\end{cases}, \\end{equation}\\] where \\[\\delta_{\\text{max}}(a, w) = \\text{argmax}_{\\left\\{\\delta \\geq 0, \\frac{g(a - \\delta \\mid w)}{g(a \\mid w)} \\leq M \\right\\}} \\frac{g(a - \\delta \\mid w)}{g(a \\mid w)}\\] and \\[\\delta_{\\text{min}}(a, w) = \\text{argmin}_{\\left\\{\\delta \\leq 0, \\frac{g(a - \\delta \\mid w)}{g(a \\mid w)} \\leq M \\right\\}} \\frac{g(a - \\delta \\mid w)}{g(a \\mid w)}.\\] The above provides a strategy for implementing a shift at the level of a given observation \\((a_i, w_i)\\), thereby allowing for all observations to be shifted to an appropriate value – whether \\(\\delta_{\\text{min}}\\), \\(\\delta\\), or \\(\\delta_{\\text{max}}\\). For the purpose of using such a shift in practice, the present software provides the functions shift_additive_bounded and shift_additive_bounded_inv, which define a variation of this shift: \\[\\begin{equation} \\delta(a, w) = \\begin{cases} \\delta, &amp; C(\\delta) \\leq M \\\\ 0, \\text{otherwise} \\\\ \\end{cases}, \\end{equation}\\] which corresponds to an intervention in which the natural value of treatment of a given observational unit is shifted by a value \\(\\delta\\) in the case that the ratio of the intervened density \\(g^{\\star}(a \\mid w)\\) to the natural density \\(g(a \\mid w)\\) (that is, \\(C(\\delta)\\)) does not exceed a bound \\(M\\). In the case that the ratio \\(C(\\delta)\\) exceeds the bound \\(M\\), the stochastic intervention policy does not apply to the given unit and they remain at their natural value of treatment \\(a\\). 7.7.2 Initializing vimshift through its tmle3_Spec To start, we will initialize a specification for the TMLE of our parameter of interest (called a tmle3_Spec in the tlverse nomenclature) simply by calling tmle_shift. We specify the argument shift_grid = seq(-1, 1, by = 1) when initializing the tmle3_Spec object to communicate that we’re interested in assessing the mean counterfactual outcome over a grid of shifts -1, 0, 1 on the scale of the treatment \\(A\\) (note that the numerical choice of shift is an arbitrarily chosen set of values for this example). # what&#39;s the grid of shifts we wish to consider? delta_grid &lt;- seq(-1, 1, 1) # initialize a tmle specification tmle_spec &lt;- tmle_vimshift_delta( shift_grid = delta_grid, max_shifted_ratio = 2 ) As seen above, the tmle_vimshift specification object (like all tmle3_Spec objects) does not store the data for our specific analysis of interest. Later, we’ll see that passing a data object directly to the tmle3 wrapper function, alongside the instantiated tmle_spec, will serve to construct a tmle3_Task object internally (see the tmle3 documentation for details). 7.7.3 Targeted Estimation of Stochastic Interventions Effects One may walk through the step-by-step procedure for fitting the TML estimator of the mean counterfactual outcome under each shift in the grid, using the machinery exposed by the tmle3 R package. One may invoke the tmle3 wrapper function (a user-facing convenience utility) to fit the series of TML estimators (one for each parameter defined by the grid delta) in a single function call: tmle_fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) Iter: 1 fn: 687.6516 Pars: 0.92215 0.07785 Iter: 2 fn: 687.6516 Pars: 0.92215 0.07785 solnp--&gt; Completed in 2 iterations tmle_fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower 1: TSM E[Y_{A=NULL}] 0.61618517 0.6118479 0.021213317 0.57027052 2: TSM E[Y_{A=NULL}] 0.71555149 0.7160000 0.020186704 0.67643479 3: TSM E[Y_{A=NULL}] 0.81227287 0.8154171 0.016147066 0.78376945 4: MSM_linear MSM(intercept) 0.71466984 0.7144217 0.018515525 0.67813190 5: MSM_linear MSM(slope) 0.09804385 0.1017846 0.005707619 0.09059791 upper psi_transformed lower_transformed upper_transformed 1: 0.6534252 0.6118479 0.57027052 0.6534252 2: 0.7555652 0.7160000 0.67643479 0.7555652 3: 0.8470648 0.8154171 0.78376945 0.8470648 4: 0.7507114 0.7144217 0.67813190 0.7507114 5: 0.1129714 0.1017846 0.09059791 0.1129714 Remark: The print method of the resultant tmle_fit object conveniently displays the results from computing our TML estimator. 7.7.4 Inference with Marginal Structural Models Since we consider estimating the mean counterfactual outcome \\(\\psi_n\\) under several values of the intervention \\(\\delta\\), taken from the aforementioned \\(\\delta\\)-grid, one approach for obtaining inference on a single summary measure of these estimated quantities involves leveraging working marginal structural models (MSMs). Summarizing the estimates \\(\\psi_n\\) through a working MSM allows for inference on the trend imposed by a \\(\\delta\\)-grid to be evaluated via a simple hypothesis test on a parameter of this working MSM. Letting \\(\\psi_{\\delta}(P_0)\\) be the mean outcome under a shift \\(\\delta\\) of the treatment, we have \\(\\vec{\\psi}_{\\delta} = (\\psi_{\\delta}: \\delta)\\) with corresponding estimators \\(\\vec{\\psi}_{n, \\delta} = (\\psi_{n, \\delta}: \\delta)\\). Further, let \\(\\beta(\\vec{\\psi}_{\\delta}) = \\phi((\\psi_{\\delta}: \\delta))\\). For a given MSM \\(m_{\\beta}(\\delta)\\), we have that \\[\\beta_0 = \\text{argmin}_{\\beta} \\sum_{\\delta}(\\psi_{\\delta}(P_0) - m_{\\beta}(\\delta))^2 h(\\delta),\\] which is the solution to \\[u(\\beta, (\\psi_{\\delta}: \\delta)) = \\sum_{\\delta}h(\\delta) \\left(\\psi_{\\delta}(P_0) - m_{\\beta}(\\delta) \\right) \\frac{d}{d\\beta} m_{\\beta}(\\delta) = 0.\\] This then leads to the following expansion \\[\\beta(\\vec{\\psi}_n) - \\beta(\\vec{\\psi}_0) \\approx -\\frac{d}{d\\beta} u(\\beta_0, \\vec{\\psi}_0)^{-1} \\frac{d}{d\\psi} u(\\beta_0, \\psi_0)(\\vec{\\psi}_n - \\vec{\\psi}_0),\\] where we have \\[\\frac{d}{d\\beta} u(\\beta, \\psi) = -\\sum_{\\delta} h(\\delta) \\frac{d}{d\\beta} m_{\\beta}(\\delta)^t \\frac{d}{d\\beta} m_{\\beta}(\\delta) -\\sum_{\\delta} h(\\delta) m_{\\beta}(\\delta) \\frac{d^2}{d\\beta^2} m_{\\beta}(\\delta),\\] which, in the case of an MSM that is a linear model (since \\(\\frac{d^2}{d\\beta^2} m_{\\beta}(\\delta) = 0\\)), reduces simply to \\[\\frac{d}{d\\beta} u(\\beta, \\psi) = -\\sum_{\\delta} h(\\delta) \\frac{d}{d\\beta} m_{\\beta}(\\delta)^t \\frac{d}{d\\beta} m_{\\beta}(\\delta),\\] and \\[\\frac{d}{d\\psi}u(\\beta, \\psi)(\\psi_n - \\psi_0) = \\sum_{\\delta} h(\\delta) \\frac{d}{d\\beta} m_{\\beta}(\\delta) (\\psi_n - \\psi_0)(\\delta),\\] which we may write in terms of the efficient influence function (EIF) of \\(\\psi\\) by using the first order approximation \\((\\psi_n - \\psi_0)(\\delta) = \\frac{1}{n}\\sum_{i = 1}^n \\text{EIF}_{\\psi_{\\delta}}(O_i)\\), where \\(\\text{EIF}_{\\psi_{\\delta}}\\) is the efficient influence function (EIF) of \\(\\vec{\\psi}\\). Now, say, \\(\\vec{\\psi} = (\\psi(\\delta): \\delta)\\) is d-dimensional, then we may write the efficient influence function of the MSM parameter \\(\\beta\\) as follows \\[\\text{EIF}_{\\beta}(O) = \\left(\\sum_{\\delta} h(\\delta) \\frac{d}{d\\beta} m_{\\beta}(\\delta) \\frac{d}{d\\beta} m_{\\beta}(\\delta)^t \\right)^{-1} \\cdot \\sum_{\\delta} h(\\delta) \\frac{d}{d\\beta} m_{\\beta}(\\delta) \\text{EIF}_{\\psi_{\\delta}}(O),\\] where the first term is of dimension \\(d \\times d\\) and the second term is of dimension \\(d \\times 1\\). In the above, we assume a linear working MSM; however, an analogous procedure may be applied for working MSMs based on GLMs. Inference for a parameter of an MSM may be obtained by straightforward application of the delta method (discussed previously) – that is, we may write the efficient influence function of the MSM parameter \\(\\beta\\) in terms of the EIFs of each of the corresponding point estimates. Based on this, inference from a working MSM is rather straightforward. To wit, the limiting distribution for \\(m_{\\beta}(\\delta)\\) may be expressed \\[\\sqrt{n}(\\beta_n - \\beta_0) \\to N(0, \\Sigma),\\] where \\(\\Sigma\\) is the empirical covariance matrix of \\(\\text{EIF}_{\\beta}(O)\\). tmle_fit$summary[4:5, ] type param init_est tmle_est se lower 1: MSM_linear MSM(intercept) 0.71466984 0.7144217 0.018515525 0.67813190 2: MSM_linear MSM(slope) 0.09804385 0.1017846 0.005707619 0.09059791 upper psi_transformed lower_transformed upper_transformed 1: 0.7507114 0.7144217 0.67813190 0.7507114 2: 0.1129714 0.1017846 0.09059791 0.1129714 7.7.4.1 Directly Targeting the MSM Parameter \\(\\beta\\) Note that in the above, a working MSM is fit to the individual TML estimates of the mean counterfactual outcome under a given value of the shift \\(\\delta\\) in the supplied grid. The parameter of interest \\(\\beta\\) of the MSM is asymptotically linear (and, in fact, a TML estimator) as a consequence of its construction from individual TML estimators. In smaller samples, it may be prudent to perform a TML estimation procedure that targets the parameter \\(\\beta\\) directly, as opposed to constructing it from several independently targeted TML estimates. An approach for constructing such an estimator is proposed in the sequel. Suppose a simple working MSM \\(\\mathbb{E}Y_{g^0_{\\delta}} = \\beta_0 + \\beta_1 \\delta\\), then a TML estimator targeting \\(\\beta_0\\) and \\(\\beta_1\\) may be constructed as \\[\\overline{Q}_{n, \\epsilon}(A,W) = \\overline{Q}_n(A,W) + \\epsilon (H_1(g), H_2(g),\\] for all \\(\\delta\\), where \\(H_1(g)\\) is the auxiliary covariate for \\(\\beta_0\\) and \\(H_2(g)\\) is the auxiliary covariate for \\(\\beta_1\\). To construct a targeted maximum likelihood estimator that directly targets the parameters of the working marginal structural model, we may use the tmle_vimshift_msm Spec (instead of the tmle_vimshift_delta Spec that appears above): # initialize a tmle specification tmle_msm_spec &lt;- tmle_vimshift_msm( shift_grid = delta_grid, max_shifted_ratio = 2 ) # fit the TML estimator and examine the results tmle_msm_fit &lt;- tmle3(tmle_msm_spec, data, node_list, learner_list) Iter: 1 fn: 685.6965 Pars: 0.93659 0.06341 Iter: 2 fn: 685.6965 Pars: 0.93658 0.06342 solnp--&gt; Completed in 2 iterations tmle_msm_fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower 1: MSM_linear MSM(intercept) 0.71481373 0.71408377 0.018697479 0.6774374 2: MSM_linear MSM(slope) 0.09892178 0.09898425 0.005920031 0.0873812 upper psi_transformed lower_transformed upper_transformed 1: 0.7507302 0.71408377 0.6774374 0.7507302 2: 0.1105873 0.09898425 0.0873812 0.1105873 7.7.5 Example with the WASH Benefits Data To complete our walk through, let’s turn to using stochastic interventions to investigate the data from the WASH Benefits trial. To start, let’s load the data, convert all columns to be of class numeric, and take a quick look at it washb_data &lt;- fread(&quot;https://raw.githubusercontent.com/tlverse/tlverse-data/master/wash-benefits/washb_data.csv&quot;, stringsAsFactors = TRUE) washb_data &lt;- washb_data[!is.na(momage), lapply(.SD, as.numeric)] head(washb_data, 3) whz tr fracode month aged sex momage momedu momheight hfiacat Nlt18 Ncomp 1: 0.00 1 4 9 268 2 30 2 146.40 1 3 11 2: -1.16 1 4 9 286 2 25 2 148.75 3 2 4 3: -1.05 1 20 9 264 2 25 2 152.15 1 1 10 watmin elec floor walls roof asset_wardrobe asset_table asset_chair 1: 0 1 0 1 1 0 1 1 2: 0 1 0 1 1 0 1 0 3: 0 0 0 1 1 0 0 1 asset_khat asset_chouki asset_tv asset_refrig asset_bike asset_moto 1: 1 0 1 0 0 0 2: 1 1 0 0 0 0 3: 0 1 0 0 0 0 asset_sewmach asset_mobile 1: 0 1 2: 0 1 3: 0 1 Next, we specify our NPSEM via the node_list object. For our example analysis, we’ll consider the outcome to be the weight-for-height Z-score (as in previous chapters), the intervention of interest to be the mother’s age at time of child’s birth, and take all other covariates to be potential confounders. node_list &lt;- list( W = names(washb_data)[!(names(washb_data) %in% c(&quot;whz&quot;, &quot;momage&quot;))], A = &quot;momage&quot;, Y = &quot;whz&quot; ) Were we to consider the counterfactual weight-for-height Z-score under shifts in the age of the mother at child’s birth, how would we interpret estimates of our parameter? To simplify our interpretation, consider a shift of just a year in the mother’s age (i.e., \\(\\delta = 1\\)); in this setting, a stochastic intervention would correspond to a policy advocating that potential mothers defer having a child for a single calendar year, possibly implemented through an encouragement design deployed in a clinical setting. For this example, we’ll use the variable importance strategy of considering a grid of stochastic interventions to evaluate the weight-for-height Z-score under a shift in the mother’s age down by two years (\\(\\delta = -2\\)) or up by two years (\\(\\delta = 2\\)). To do this, we simply initialize a Spec tmle_vimshift_delta just as we did in a previous example: # initialize a tmle specification for the variable importance parameter washb_vim_spec &lt;- tmle_vimshift_delta( shift_grid = c(-2, 2), max_shifted_ratio = 2 ) Prior to running our analysis, we’ll modify the learner_list object we had created such that the density estimation procedure we rely on will be only the random forest conditional density estimation procedure of Pospisil and Lee (2018), as the nonparametric conditional density approach based on the highly adaptive lasso (Díaz and van der Laan 2011; Benkeser and van der Laan 2016; Coyle and Hejazi 2018; Hejazi, Benkeser, and van der Laan 2019) is currently unable to accommodate large datasets. # learners used for conditional density regression (i.e., propensity score) lrn_rfcde &lt;- Lrnr_rfcde$new( n_trees = 250, node_size = 5, n_basis = 20, output_type = &quot;observed&quot; ) # we need to turn on cross-validation for the RFCDE learner lrn_cv_rfcde &lt;- Lrnr_cv$new( learner = lrn_rfcde, full_fit = TRUE ) # modify learner list, using existing SL for Q fit learner_list &lt;- list(Y = sl_lrn, A = lrn_cv_rfcde) Having made the above preparations, we’re now ready to estimate the counterfactual mean of the weight-for-height Z-score under a small grid of shifts in the mother’s age at child’s birth. Just as before, we do this through a simple call to our tmle3 wrapper function: washb_tmle_fit &lt;- tmle3(washb_vim_spec, washb_data, node_list, learner_list) washb_tmle_fit 7.8 Exercises 7.8.1 The Ideas in Action Set the sl3 library of algorithms for the Super Learner to a simple, interpretable library and use this new library to estimate the counterfactual mean of mother’s age at child’s birth (momage) under a shift \\(\\delta = 0\\). What does this counterfactual mean equate to in terms of the observed data? Using a grid of values of the shift parameter \\(\\delta\\) (e.g., \\(\\{-1, 0, +1\\}\\)), repeat the analysis on the variable chosen in the preceding question, summarizing the trend for this sequence of shifts using a marginal structural model. Repeat the preceding analysis, using the same grid of shifts, but instead directly targeting the parameters of the marginal structural model. Interpret the results – that is, what does the slope of the marginal structural model tell us about the trend across the chosen sequence of shifts? 7.8.2 Review of Key Concepts Describe two (equivalent) ways in which the causal effects of stochastic interventions may be interpreted. How does the marginal structural model we used to summarize the trend along the sequence of shifts previously help to contextualize the estimated effect for a single shift? That is, how does access to estimates across several shifts and the marginal structural model parameters allow us to more richly interpret our findings? What advantages, if any, are there to targeting directly the parameters of a marginal structural model? References "],
["r6.html", "Chapter 8 A Primer on the R6 Class System 8.1 Classes, Fields, and Methods 8.2 Object Oriented Programming: Python and R", " Chapter 8 A Primer on the R6 Class System A central goal of the Targeted Learning statistical paradigm is to estimate scientifically relevant parameters in realistic (usually nonparametric) models. The tlverse is designed using basic OOP principles and the R6 OOP framework. While we’ve tried to make it easy to use the tlverse packages without worrying much about OOP, it is helpful to have some intuition about how the tlverse is structured. Here, we briefly outline some key concepts from OOP. Readers familiar with OOP basics are invited to skip this section. 8.1 Classes, Fields, and Methods The key concept of OOP is that of an object, a collection of data and functions that corresponds to some conceptual unit. Objects have two main types of elements: fields, which can be thought of as nouns, are information about an object, and methods, which can be thought of as verbs, are actions an object can perform. Objects are members of classes, which define what those specific fields and methods are. Classes can inherit elements from other classes (sometimes called base classes) – accordingly, classes that are similar, but not exactly the same, can share some parts of their definitions. Many different implementations of OOP exist, with variations in how these concepts are implemented and used. R has several different implementations, including S3, S4, reference classes, and R6. The tlverse uses the R6 implementation. In R6, methods and fields of a class object are accessed using the $ operator. For a more thorough introduction to R’s various OOP systems, see http://adv-r.had.co.nz/OO-essentials.html, from Hadley Wickham’s Advanced R (Wickham 2014). 8.2 Object Oriented Programming: Python and R OO concepts (classes with inherentence) were baked into Python from the first published version (version 0.9 in 1991). In contrast, R gets its OO “approach” from its predecessor, S, first released in 1976. For the first 15 years, S had no support for classes, then, suddenly, S got two OO frameworks bolted on in rapid succession: informal classes with S3 in 1991, and formal classes with S4 in 1998. This process continues, with new OO frameworks being periodically released, to try to improve the lackluster OO support in R, with reference classes (R5, 2010) and R6 (2014). Of these, R6 behaves most like Python classes (and also most like OOP focused languages like C++ and Java), including having method definitions be part of class definitions, and allowing objects to be modified by reference. References "],
["references.html", "References", " References "]
]
