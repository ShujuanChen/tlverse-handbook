<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Stochastic Treatment Regimes | The Hitchhiker’s Guide to the tlverse</title>
  <meta name="description" content="An open-source and fully-reproducible electronic handbook for applying the targeted learning methodology in practice using the tlverse software ecosystem." />
  <meta name="generator" content="bookdown 0.17.2 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Stochastic Treatment Regimes | The Hitchhiker’s Guide to the tlverse" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://tlverse.org/tlverse-handbook/" />
  
  <meta property="og:description" content="An open-source and fully-reproducible electronic handbook for applying the targeted learning methodology in practice using the tlverse software ecosystem." />
  <meta name="github-repo" content="tlverse/tlverse-handbook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Stochastic Treatment Regimes | The Hitchhiker’s Guide to the tlverse" />
  
  <meta name="twitter:description" content="An open-source and fully-reproducible electronic handbook for applying the targeted learning methodology in practice using the tlverse software ecosystem." />
  

<meta name="author" content="Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips, Alan Hubbard, Mark van der Laan" />


<meta name="date" content="2020-02-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="img/logos/favicons/favicon.png" type="image/x-icon" />
<link rel="prev" href="optimal-individualized-treatment-regimes.html"/>
<link rel="next" href="r6.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="libs/vis-4.20.1/vis.css" rel="stylesheet" />
<script src="libs/vis-4.20.1/vis.min.js"></script>
<script src="libs/visNetwork-binding-2.0.9/visNetwork.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-89938436-1', 'auto');
  ga('send', 'pageview');
</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">The Hitchhiker's Guide to the tlverse</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-this-book"><i class="fa fa-check"></i>About this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#outline"><i class="fa fa-check"></i>Outline</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#what-this-book-is-not"><i class="fa fa-check"></i>What this book is not</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-authors"><i class="fa fa-check"></i>About the authors</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#jeremy-coyle"><i class="fa fa-check"></i>Jeremy Coyle</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#nima-hejazi"><i class="fa fa-check"></i>Nima Hejazi</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#ivana-malenica"><i class="fa fa-check"></i>Ivana Malenica</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#rachael-phillips"><i class="fa fa-check"></i>Rachael Phillips</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#alan-hubbard"><i class="fa fa-check"></i>Alan Hubbard</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#mark-van-der-laan"><i class="fa fa-check"></i>Mark van der Laan</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#learn"><i class="fa fa-check"></i><b>0.1</b> Recommended Learning Resources</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#setup-instructions"><i class="fa fa-check"></i><b>0.2</b> Setup instructions</a><ul>
<li class="chapter" data-level="0.2.1" data-path="index.html"><a href="index.html#r-and-rstudio"><i class="fa fa-check"></i><b>0.2.1</b> R and RStudio</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="motivation.html"><a href="motivation.html"><i class="fa fa-check"></i>Motivation</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> The Roadmap for Targeted Learning</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#learning-objectives"><i class="fa fa-check"></i><b>1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#introduction"><i class="fa fa-check"></i><b>1.2</b> Introduction</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#the-roadmap"><i class="fa fa-check"></i><b>1.3</b> The Roadmap</a><ul>
<li><a href="intro.html#data-as-a-random-variable-with-a-probability-distribution-o-sim-p_0">(1) Data as a random variable with a probability distribution, <span class="math inline">\(O \sim P_0\)</span></a></li>
<li><a href="intro.html#the-statistical-model-mathcalm-such-that-p_0-in-mathcalm">(2) The statistical model <span class="math inline">\(\mathcal{M}\)</span> such that <span class="math inline">\(P_0 \in \mathcal{M}\)</span></a></li>
<li><a href="intro.html#the-statistical-target-parameter-psi-and-estimand-psip_0">(3) The statistical target parameter <span class="math inline">\(\Psi\)</span> and estimand <span class="math inline">\(\Psi(P_0)\)</span></a></li>
<li><a href="intro.html#the-estimator-hatpsi-and-estimate-hatpsip_n">(4) The estimator <span class="math inline">\(\hat{\Psi}\)</span> and estimate <span class="math inline">\(\hat{\Psi}(P_n)\)</span></a></li>
<li><a href="intro.html#a-measure-of-uncertainty-for-the-estimate-hatpsip_n">(5) A measure of uncertainty for the estimate <span class="math inline">\(\hat{\Psi}(P_n)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#summary-of-the-roadmap"><i class="fa fa-check"></i><b>1.4</b> Summary of the Roadmap</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#causal"><i class="fa fa-check"></i><b>1.5</b> Causal Target Parameters</a><ul>
<li class="chapter" data-level="1.5.1" data-path="intro.html"><a href="intro.html#the-causal-model"><i class="fa fa-check"></i><b>1.5.1</b> The Causal Model</a></li>
<li class="chapter" data-level="1.5.2" data-path="intro.html"><a href="intro.html#identifiability"><i class="fa fa-check"></i><b>1.5.2</b> Identifiability</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="tlverse.html"><a href="tlverse.html"><i class="fa fa-check"></i><b>2</b> Welcome to the <code>tlverse</code></a><ul>
<li class="chapter" data-level="2.1" data-path="tlverse.html"><a href="tlverse.html#learning-objectives-1"><i class="fa fa-check"></i><b>2.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="2.2" data-path="tlverse.html"><a href="tlverse.html#what-is-the-tlverse"><i class="fa fa-check"></i><b>2.2</b> What is the <code>tlverse</code>?</a></li>
<li class="chapter" data-level="2.3" data-path="tlverse.html"><a href="tlverse.html#tlverse-components"><i class="fa fa-check"></i><b>2.3</b> <code>tlverse</code> components</a></li>
<li class="chapter" data-level="2.4" data-path="tlverse.html"><a href="tlverse.html#installation"><i class="fa fa-check"></i><b>2.4</b> Installation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>3</b> Datasets</a><ul>
<li class="chapter" data-level="3.1" data-path="data.html"><a href="data.html#wash"><i class="fa fa-check"></i><b>3.1</b> WASH Benefits Example Dataset</a></li>
<li class="chapter" data-level="3.2" data-path="data.html"><a href="data.html#ist"><i class="fa fa-check"></i><b>3.2</b> International Stroke Trial Example Dataset</a></li>
<li class="chapter" data-level="3.3" data-path="data.html"><a href="data.html#vet"><i class="fa fa-check"></i><b>3.3</b> Veterans’ Administration Lung Cancer Trial Dataset</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="sl3.html"><a href="sl3.html"><i class="fa fa-check"></i><b>4</b> Super (Machine) Learning</a><ul>
<li class="chapter" data-level="4.1" data-path="sl3.html"><a href="sl3.html#learning-objectives-2"><i class="fa fa-check"></i><b>4.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="4.2" data-path="sl3.html"><a href="sl3.html#motivation-1"><i class="fa fa-check"></i><b>4.2</b> Motivation</a></li>
<li class="chapter" data-level="4.3" data-path="sl3.html"><a href="sl3.html#introduction-1"><i class="fa fa-check"></i><b>4.3</b> Introduction</a><ul>
<li class="chapter" data-level="4.3.1" data-path="sl3.html"><a href="sl3.html#background"><i class="fa fa-check"></i><b>4.3.1</b> Background</a></li>
<li class="chapter" data-level="4.3.2" data-path="sl3.html"><a href="sl3.html#super-learner-for-prediction"><i class="fa fa-check"></i><b>4.3.2</b> Super Learner for Prediction</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="sl3.html"><a href="sl3.html#sl3-microwave-dinner-implementation"><i class="fa fa-check"></i><b>4.4</b> <code>sl3</code> “Microwave Dinner” Implementation</a><ul>
<li class="chapter" data-level="4.4.1" data-path="sl3.html"><a href="sl3.html#wash-benefits-study-example"><i class="fa fa-check"></i><b>4.4.1</b> WASH Benefits Study Example</a></li>
<li class="chapter" data-level="" data-path="sl3.html"><a href="sl3.html#load-the-necessary-libraries-and-data"><i class="fa fa-check"></i>0. Load the necessary libraries and data</a></li>
<li class="chapter" data-level="" data-path="sl3.html"><a href="sl3.html#define-the-machine-learning-task"><i class="fa fa-check"></i>1. Define the machine learning task</a></li>
<li class="chapter" data-level="" data-path="sl3.html"><a href="sl3.html#make-a-super-learner"><i class="fa fa-check"></i>2. Make a Super Learner</a></li>
<li class="chapter" data-level="" data-path="sl3.html"><a href="sl3.html#train-the-super-learner-on-the-machine-learning-task"><i class="fa fa-check"></i>3. Train the Super Learner on the machine learning task</a></li>
<li class="chapter" data-level="" data-path="sl3.html"><a href="sl3.html#obtain-predicted-values"><i class="fa fa-check"></i>4. Obtain predicted values</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="sl3.html"><a href="sl3.html#cross-validated-super-learner"><i class="fa fa-check"></i><b>4.5</b> Cross-validated Super Learner</a></li>
<li class="chapter" data-level="4.6" data-path="sl3.html"><a href="sl3.html#variable-importance-measures-with-sl3"><i class="fa fa-check"></i><b>4.6</b> Variable Importance Measures with <code>sl3</code></a></li>
<li class="chapter" data-level="4.7" data-path="sl3.html"><a href="sl3.html#exercises"><i class="fa fa-check"></i><b>4.7</b> Exercises</a><ul>
<li class="chapter" data-level="4.7.1" data-path="sl3.html"><a href="sl3.html#sl3ex1"><i class="fa fa-check"></i><b>4.7.1</b> Predicting Myocardial Infarction with <code>sl3</code></a></li>
<li class="chapter" data-level="4.7.2" data-path="sl3.html"><a href="sl3.html#sl3ex2"><i class="fa fa-check"></i><b>4.7.2</b> Predicting Recurrent Ischemic Stroke in an RCT with <code>sl3</code></a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="sl3.html"><a href="sl3.html#concluding-remarks"><i class="fa fa-check"></i><b>4.8</b> Concluding Remarks</a></li>
<li class="chapter" data-level="4.9" data-path="sl3.html"><a href="sl3.html#appendix"><i class="fa fa-check"></i><b>4.9</b> Appendix</a><ul>
<li class="chapter" data-level="4.9.1" data-path="sl3.html"><a href="sl3.html#exercise-1-solution"><i class="fa fa-check"></i><b>4.9.1</b> Exercise 1 Solution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="tmle3.html"><a href="tmle3.html"><i class="fa fa-check"></i><b>5</b> The TMLE Framework</a><ul>
<li class="chapter" data-level="5.1" data-path="tmle3.html"><a href="tmle3.html#learning-objectives-3"><i class="fa fa-check"></i><b>5.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="5.2" data-path="tmle3.html"><a href="tmle3.html#introduction-2"><i class="fa fa-check"></i><b>5.2</b> Introduction</a><ul>
<li class="chapter" data-level="5.2.1" data-path="tmle3.html"><a href="tmle3.html#substitution-estimators"><i class="fa fa-check"></i><b>5.2.1</b> Substitution Estimators</a></li>
<li class="chapter" data-level="5.2.2" data-path="tmle3.html"><a href="tmle3.html#tmle"><i class="fa fa-check"></i><b>5.2.2</b> TMLE</a></li>
<li class="chapter" data-level="5.2.3" data-path="tmle3.html"><a href="tmle3.html#inference"><i class="fa fa-check"></i><b>5.2.3</b> Inference</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="tmle3.html"><a href="tmle3.html#easy-bake-example-tmle3-for-ate"><i class="fa fa-check"></i><b>5.3</b> Easy-Bake Example: <code>tmle3</code> for ATE</a><ul>
<li class="chapter" data-level="5.3.1" data-path="tmle3.html"><a href="tmle3.html#load-the-data"><i class="fa fa-check"></i><b>5.3.1</b> Load the Data</a></li>
<li class="chapter" data-level="5.3.2" data-path="tmle3.html"><a href="tmle3.html#define-the-variable-roles"><i class="fa fa-check"></i><b>5.3.2</b> Define the variable roles</a></li>
<li class="chapter" data-level="5.3.3" data-path="tmle3.html"><a href="tmle3.html#handle-missingness"><i class="fa fa-check"></i><b>5.3.3</b> Handle Missingness</a></li>
<li class="chapter" data-level="5.3.4" data-path="tmle3.html"><a href="tmle3.html#create-a-spec-object"><i class="fa fa-check"></i><b>5.3.4</b> Create a “Spec” Object</a></li>
<li class="chapter" data-level="5.3.5" data-path="tmle3.html"><a href="tmle3.html#define-the-learners"><i class="fa fa-check"></i><b>5.3.5</b> Define the learners</a></li>
<li class="chapter" data-level="5.3.6" data-path="tmle3.html"><a href="tmle3.html#fit-the-tmle"><i class="fa fa-check"></i><b>5.3.6</b> Fit the TMLE</a></li>
<li class="chapter" data-level="5.3.7" data-path="tmle3.html"><a href="tmle3.html#evaluate-the-estimates"><i class="fa fa-check"></i><b>5.3.7</b> Evaluate the Estimates</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="tmle3.html"><a href="tmle3.html#tmle3-components"><i class="fa fa-check"></i><b>5.4</b> <code>tmle3</code> Components</a><ul>
<li class="chapter" data-level="5.4.1" data-path="tmle3.html"><a href="tmle3.html#tmle3_task"><i class="fa fa-check"></i><b>5.4.1</b> <code>tmle3_task</code></a></li>
<li class="chapter" data-level="5.4.2" data-path="tmle3.html"><a href="tmle3.html#initial-likelihood"><i class="fa fa-check"></i><b>5.4.2</b> Initial Likelihood</a></li>
<li class="chapter" data-level="5.4.3" data-path="tmle3.html"><a href="tmle3.html#targeted-likelihood-updater"><i class="fa fa-check"></i><b>5.4.3</b> Targeted Likelihood (updater)</a></li>
<li class="chapter" data-level="5.4.4" data-path="tmle3.html"><a href="tmle3.html#parameter-mapping"><i class="fa fa-check"></i><b>5.4.4</b> Parameter Mapping</a></li>
<li class="chapter" data-level="5.4.5" data-path="tmle3.html"><a href="tmle3.html#putting-it-all-together"><i class="fa fa-check"></i><b>5.4.5</b> Putting it all together</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="tmle3.html"><a href="tmle3.html#fitting-tmle3-with-multiple-parameters"><i class="fa fa-check"></i><b>5.5</b> Fitting <code>tmle3</code> with multiple parameters</a><ul>
<li class="chapter" data-level="5.5.1" data-path="tmle3.html"><a href="tmle3.html#delta-method"><i class="fa fa-check"></i><b>5.5.1</b> Delta Method</a></li>
<li class="chapter" data-level="5.5.2" data-path="tmle3.html"><a href="tmle3.html#fit"><i class="fa fa-check"></i><b>5.5.2</b> Fit</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="tmle3.html"><a href="tmle3.html#exercises-1"><i class="fa fa-check"></i><b>5.6</b> Exercises</a><ul>
<li class="chapter" data-level="5.6.1" data-path="sl3.html"><a href="sl3.html#sl3ex2"><i class="fa fa-check"></i><b>5.6.1</b> Estimation of the ATE with <code>tmle3</code></a></li>
<li class="chapter" data-level="5.6.2" data-path="sl3.html"><a href="sl3.html#sl3ex2"><i class="fa fa-check"></i><b>5.6.2</b> Estimation of Strata-Specific ATEs with <code>tmle3</code></a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="tmle3.html"><a href="tmle3.html#summary"><i class="fa fa-check"></i><b>5.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html"><i class="fa fa-check"></i><b>6</b> Optimal Individualized Treatment Regimes</a></li>
<li class="chapter" data-level="7" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html"><i class="fa fa-check"></i><b>7</b> Stochastic Treatment Regimes</a><ul>
<li class="chapter" data-level="7.0.1" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#statistical-inference-for-targeted-maximum-likelihood-estimates"><i class="fa fa-check"></i><b>7.0.1</b> Statistical Inference for Targeted Maximum Likelihood Estimates</a></li>
<li class="chapter" data-level="7.1" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#extensions-variable-importance-analysis-with-stochastic-interventions"><i class="fa fa-check"></i><b>7.1</b> Extensions: Variable Importance Analysis with Stochastic Interventions</a><ul>
<li class="chapter" data-level="7.1.1" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#defining-a-grid-of-counterfactual-interventions"><i class="fa fa-check"></i><b>7.1.1</b> Defining a grid of counterfactual interventions</a></li>
<li class="chapter" data-level="7.1.2" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#initializing-vimshift-through-its-tmle3_spec"><i class="fa fa-check"></i><b>7.1.2</b> Initializing <code>vimshift</code> through its <code>tmle3_Spec</code></a></li>
<li class="chapter" data-level="7.1.3" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#targeted-estimation-of-stochastic-interventions-effects"><i class="fa fa-check"></i><b>7.1.3</b> Targeted Estimation of Stochastic Interventions Effects</a></li>
<li class="chapter" data-level="7.1.4" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#inference-with-marginal-structural-models"><i class="fa fa-check"></i><b>7.1.4</b> Inference with Marginal Structural Models</a></li>
<li class="chapter" data-level="7.1.5" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#example-with-the-wash-benefits-data"><i class="fa fa-check"></i><b>7.1.5</b> Example with the WASH Benefits Data</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#exercises-2"><i class="fa fa-check"></i><b>7.2</b> Exercises</a><ul>
<li class="chapter" data-level="7.2.1" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#the-ideas-in-action"><i class="fa fa-check"></i><b>7.2.1</b> The Ideas in Action</a></li>
<li class="chapter" data-level="7.2.2" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#review-of-key-concepts"><i class="fa fa-check"></i><b>7.2.2</b> Review of Key Concepts</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="r6.html"><a href="r6.html"><i class="fa fa-check"></i><b>8</b> A Primer on the <code>R6</code> Class System</a><ul>
<li class="chapter" data-level="8.1" data-path="r6.html"><a href="r6.html#classes-fields-and-methods"><i class="fa fa-check"></i><b>8.1</b> Classes, Fields, and Methods</a></li>
<li class="chapter" data-level="8.2" data-path="r6.html"><a href="r6.html#object-oriented-programming-python-and-r"><i class="fa fa-check"></i><b>8.2</b> Object Oriented Programming: <code>Python</code> and <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Hitchhiker’s Guide to the <code>tlverse</code></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="stochastic-treatment-regimes" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Stochastic Treatment Regimes</h1>
<!--
_Nima Hejazi_

Based on the [`tmle3shift` `R` package](https://github.com/tlverse/tmle3shift)
by _Nima Hejazi, Jeremy Coyle, and Mark van der Laan_.

Updated: 2020-02-13

## Learning Objectives

1. Differentiate stochastic treatment regimes from static, dynamic, and optimal
   treatment regimes.
2. Describe how estimating causal effects of stochastic interventions informs a
   real-world data analysis.
3. Contrast a population level stochastic intervention policy from a modified
   treatment policy.
4. Estimate causal effects under stochastic treatment regimes with the
   `tmle3shift` `R` package.
6. Specify a grid of counterfactual shift interventions to be used for defining
   a set of stochastic intervention policies.
7. Interpret a set of effect estimates from a grid of counterfactual shift
   interventions.
5. Construct marginal structural models to measure variable importance in terms
   of stochastic interventions, using a grid of shift interventions.
8. Implement a shift intervention at the individual level, to facilitate
   shifting each individual to a value that's supported by the data.
9. Define novel shift intervention functions to extend the `tmle3shift` `R`
   package.

## Introduction to Stochastic Interventions

Stochastic treatment regimes present a relatively simple, yet extremely flexible
manner by which _realistic_ causal effects (and contrasts thereof) may be
defined. Importantly, stochastic treatment regimes may be applied to nearly
any manner of treatment variable -- continuous, ordinal, categorical, binary --
allowing for a rich set of causal effects to be defined through this formalism.
In this chapter, we examine a simple example of stochastic treatment regimes in
the context of a continuous treatment variable of interest, defining an
intuitive causal effect through which to examine stochastic interventions more
generally. In later sections, we introduce numerous extensions based on this
broad class of interventions -- from stochastic interventions on binary
treatment variables to stochastic mediation effects and data-adaptive inference
for stochastic intervention effects. As a first step to using stochastic
treatment regimes in practice, we present the [`tmle3shift` R
package](https://github.com/tlverse/tmle3shift), which features an
implementation of a recently developed algorithm for computing targeted minimum
loss-based estimates of a causal effect based on a stochastic treatment regime
that shifts the natural value of the treatment based on a shifting function
$d(A,W)$. For a comprehensive technical presentation of some of the material in
this chapter, the interested reader is invited to consult @diaz2018stochastic.
Additional background on the field of Targeted Learning, as well as prior work
on stochastic treatment regimes, is available in @vdl2011targeted,
@vdl2018targeted, and @diaz2012population.

While stochastic treatment regimes are arguably the most general of the
classes of interventions through which causal effects may be defined, such
interventions are conceptually simple.

## Data Structure and Notation

Consider $n$ observed units $O_1, \ldots, O_n$, where each random variable $O =
(W, A, Y)$ corresponds to a single observational unit. Let $W$ denote baseline
covariates (e.g., age, sex, education level), $A$ an intervention variable of
interest (e.g., nutritional supplements), and $Y$ an outcome of interest (e.g.,
disease status). Though it need not be the case, let $A$ be continuous-valued,
i.e. $A \in \mathbb{R}$. Let $O_i \sim \mathcal{P} \in \mathcal{M}$, where
$\mathcal{M}$ is the nonparametric statistical model defined as the set of
continuous densities on $O$ with respect to some dominating measure. To
formalize the definition of stochastic interventions and their corresponding
causal effects, we introduce a nonparametric structural equation model (NPSEM),
based on @pearl2009causality, to define how the system changes under posited
interventions:
\begin{align*}\label{eqn:npsem}
  W &= f_W(U_W) \\ A &= f_A(W, U_A) \\ Y &= f_Y(A, W, U_Y),
\end{align*}
where the set of structural equations provide a mechanistic model by which the
observed data $O$ is assumed to have been generated. There are several standard
assumptions embedded in the NPSEM -- specifically, a temporal ordering that
supposes that $Y$ occurs after $A$, which occurs after $W$; each variable
(i.e., $\{W, A, Y\}$) is assumed to have been generated from its corresponding
deterministic function (i.e., $\{f_W, f_A, f_Y\}$) of the observed variables
that precede it temporally, as well as an exogenous variable, denoted by $U$;
lastly, each exogenous variable is assumed to contain all unobserved causes of
the corresponding observed variable.

The likelihood of the data $O$ admits a factorization, wherein, for $p_0^O$,
the density of $O$ with respect to the product measure, the density evaluated
on a particular observation $o$ may be a written
\begin{equation*}\label{eqn:likelihood_factorization}
  p_0^O(x) = q^O_{0,Y}(y \mid A = a, W = w) q^O_{0,A}(a \mid W = w)
  q^O_{0,W}(w),
\end{equation*}
where $q_{0, Y}$ is the conditional density of $Y$ given $(A, W)$ with respect
to some dominating measure, $q_{0, A}$ is the conditional density of $A$ given
$W$ with respect to dominating measure $\mu$, and $q_{0, W}$ is the density of
$W$ with respect to dominating measure $\nu$. Further, for ease of notation,
let $Q(A, W) = \mathbb{E}[Y \mid A, W]$, $g(A \mid W) = \mathbb{P}(A \mid W)$,
and $q_W$ the marginal distribution of $W$. These components of the likelihood
will be essential in developing an understanding of the manner in which
stochastic treatment regimes pertrub a system and how a corresponding causal
effect may be evaluated. Importantly, the NPSEM parameterizes $p_0^O$ in terms
of the distribution of random variables $(O, U)$ modeled by the system of
equations. In turn, this implies a model for the distribution of counterfactual
random variables generated by interventions on the data-generating process.

## Defining the Causal Effect of a Stochastic Intervention

As causal effects are defined in terms of hypothetical interventions on the
NPSEM (\ref{eqn:npsem}), we may consider stochastic interventions in two
equivalent ways: (1) where the equation $f_A$, giving rise to $A$, is replaced
by a probabilistic mechanism $g_{\delta}(A \mid W)$ that differs from the
original $g(A \mid W)$, or (2) where the observed value $A$ is replaced by a
new value $A_{d(A,W)}$ based on applying a user-defined function $d(A,W)$ to
$A$. In the former case, the _stochastically modified_ value of the treatment
$A_{\delta}$ is drawn from a user-specified distribution $g_\delta(A \mid W)$,
which may depend on the original distribution $g(A \mid W)$ and is indexed by
a user-specified parameter $\delta$. In this case, the stochastically modified
value of the treatment $A_{\delta} \sim g_{\delta}(\cdot \mid W)$.
Alternatively, in the latter case, the stochastic treatment regime may be
viewed as an intervention in which $A$ is set equal to a value based on a
hypothetical regime $d(A, W)$, where regime $d$ depends on the treatment level
$A$ that would be assigned in the absence of the regime as well as the
covariates $W$. In either case, one may view the stochastic intervention as
generating a counterfactual random variable $Y_{d(A,W)} := f_Y(d(A,W), W, U_Y)
\equiv Y_{g_{\delta}} := f_Y(A_{\delta}, W, U_Y)$, where the counterfactual
outcome $Y_{d(A,W)} \sim \mathcal{P}_0^{\delta}$.

Stochastic interventions of this second variety may be referred to as depending
on the _natural value of treatment_ or as _modified treatment policies_.
@haneuse2013estimation and @young2014identification provide a discussion of the
critical differences and similarities in the identification and interpretation
of these two classes of stochastic intervention. In the sequel, we will
restrict our attention to a simple stochastic treatment regime that has been
characterized as a _modified treatment policy_ (MTP). Letting $A$ denote a
continuous-valued treatment, such as the taking of nutritional supplements
(e.g., number of vitamin pills) and assume that the distribution of $A$
conditional on $W = w$ has support in the interval $(l(w), u(w))$. That is, the
minimum observed number of pills taken $A$ for an individual with covariates
$W = w$ is $l(w)$; similarly, the maximum is $u(w)$. Then, a simple stochastic
intervention, based on a shift $\delta$, may be defined
\begin{equation}\label{eqn:shift}
  d(a, w) =
  \begin{cases}
    a - \delta & \text{if } a > l(w) + \delta \\
    a & \text{if } a \leq l(w) + \delta,
  \end{cases}
\end{equation}
where $0 \leq \delta \leq u(w)$ is an arbitrary pre-specified value that
defines the degree to which the observed value $A$ is to be shifted, where
possible. Such a stochastic treatment regime may be interpreted as the result
of a clinic policy that encourages individuals to consume $\delta$ more vitamin
pills than they would normally, i.e., based on their baseline characteristics.
The interpretation of this stochastic intervention may be made more interesting
by allowing the modification $\delta$ that it engenders to be a function of the
baseline covariates $W$, thereby allowing for the number of vitamin pills taken
to be a function of covariates such as age, sex, comorbidities, etc. This class
of stochastic interventions was first introduced by @diaz2012population and has
been further discussed in @haneuse2013estimation, @diaz2018stochastic, and
@hejazi2019+generally. Note that this intervention may be written in a manner
consistent with the first class of stochastic treatment regimes discussed as
well -- that is, as per @diaz2012population, $\mathbb{P}_{\delta}(g_0)(A = a
\mid W) = g_0(a - \delta(W) \mid W)$.

The goal of any causal analysis motivated by such a stochastic intervention is
to estimate a parameter defined as the counterfactual mean of the outcome with
respect to the stochastically modified intervention distribution. In
particular, the target causal estimand of our analysis is $\psi_{0, \delta} :=
\mathbb{E}_{P_0^{\delta}}\{Y_{d(A,W)}\}$, the mean of the counterfactual
outcome variable $Y_{d(A, W)}$. In prior work, @diaz2012population showed that
the causal quantity of interest $\mathbb{E}_0 \{Y_{d(A, W)}\}$ is identified by
a functional of the distribution of $O$:
\begin{align*}\label{eqn:identification2012}
  \psi_{0,d} = \int_{\mathcal{W}} \int_{\mathcal{A}} & \mathbb{E}_{P_0}
   \{Y \mid A = d(a, w), W = w\} \cdot \\ &q_{0, A}^O(a \mid W = w) \cdot
   q_{0, W}^O(w) d\mu(a)d\nu(w).
\end{align*}
If the identification conditions may be assumed to hold, then the statistical
parameter in \ref{eqn:identification2012} matches exactly the counterfactual
outcome $\psi_{0, \delta}$ under such an intervention, allowing for the causal
effect to be learned from the observed data $O$. @diaz2012population provide a
derivation based on the efficient influence function (EIF) in the nonparametric
model $\mathcal{M}$ and develop several estimators of this quantity, including
substitution, inverse probability weighted (IPW), augmented inverse probability
weighted (AIPW), and targeted maximum likelihood (TML) estimators, allowing for
semiparametric-efficient estimation and inference on the quantity of interest.
As per @diaz2018stochastic, the statistical target parameter may also be
denoted $\Psi(P_0) = \mathbb{E}_{P_0}{\overline{Q}(d(A, W), W)}$, where
$\overline{Q}(d(A, W), W)$ is the counterfactual outcome value of a given
individual under the stochastic intervention distribution.

Although the focus of this work is neither the establishment of identification
results nor the development of theoretical details, we review the necessary
identification details for the counterfactual mean under a stochastic
intervention here, in the interest of completeness. Paraphrasing from
@diaz2012population and @diaz2018stochastic, four standard assumptions are
necessary in order to establish identifiability of the causal parameter from
the observed data via the statistical functional -- these are

1. _Consistency_: $Y^{d(a_i, w_i)}_i = Y_i$ in the event $A_i = d(a_i, w_i)$,
   for $i = 1, \ldots, n$
2. _Stable unit value treatment assumption (SUTVA)_: $Y^{d(a_i, w_i)}_i$ does
   not depend on $d(a_j, w_j)$ for $i = 1, \ldots, n$ and $j \neq i$, or lack
   of interference [@rubin1978bayesian; @rubin1980randomization].
3. _Strong ignorability_: $A_i \indep Y^{d(a_i, w_i)}_i \mid W_i$, for $i = 1,
   \ldots, n$.
4. Positivity (or overlap)_: $a_i \in \mathcal{A} \implies d(a_i, w_i) \in
   \mathcal{A}$ for all $w \in \mathcal{W}$, where $\mathcal{A}$ denotes the
   support of $A \mid W = w_i \quad \forall i = 1, \ldots n$.

With the identification assumptions satisfied, @diaz2012population and
@diaz2018stochastic provide an efficient influence function with  respect to
the nonparametric model $\mathcal{M}$ as
\begin{equation*}\label{eqn:eif}
  D(P_0)(x) = H(a, w)({y - \overline{Q}(a, w)}) +
  \overline{Q}(d(a, w), w) - \Psi(P_0),
\end{equation*}
where the auxiliary covariate $H(a,w)$ may be expressed
\begin{equation*}\label{eqn:aux_covar_full}
  H(a,w) = \mathbb{I}(a + \delta < u(w)) \frac{g_0(a - \delta \mid w)}
  {g_0(a \mid w)} + \mathbb{I}(a + \delta \geq u(w)),
\end{equation*}
which may be reduced to
\begin{equation*}\label{eqn:aux_covar_simple}
  H(a,w) = \frac{g_0(a - \delta \mid w)}{g_0(a \mid w)} + 1
\end{equation*}
in the case that the treatment is within the limits that arise from conditioning
on $W$, i.e., for $A_i \in (u(w) - \delta, u(w))$.

The efficient influence function allows the construction of a
semiparametric-efficient estimators may be constructed. In the sequel, we focus
on a targeted maximum likelihood (TML) estimator, for which @diaz2018stochastic
give a recipe:

1. Construct initial estimators $g_n$ of $g_0(A, W)$ and $Q_n$ of
   $\overline{Q}_0(A, W)$, perhaps using data-adaptive regression techniques.
2. For each observation $i$, compute an estimate $H_n(a_i, w_i)$ of the
   auxiliary covariate $H(a_i,w_i)$.
3. Estimate the parameter $\epsilon$ in the logistic regression model
   $$ \text{logit}\overline{Q}_{\epsilon, n}(a, w) =
   \text{logit}\overline{Q}_n(a, w) + \epsilon H_n(a, w),$$
   or an alternative regression model incorporating weights.
4. Compute TML estimator $\Psi_n$ of the target parameter, defining update
   $\overline{Q}_n^{\star}$ of the initial estimate
   $\overline{Q}_{n, \epsilon_n}$:
   \begin{equation*}\label{eqn:tmle}
     \Psi_n = \Psi(P_n^{\star}) = \frac{1}{n} \sum_{i = 1}^n
     \overline{Q}_n^{\star}(d(A_i, W_i), W_i).
   \end{equation*}

## Interpreting the Causal Effect of a Stochastic Intervention

<div class="figure" style="text-align: center">
<img src="img/gif/shift_animation.gif" alt="Animation of how a counterfactual outcome changes as the natural treatment distribution is subjected to a simple stochastic intervention" width="60%" />
<p class="caption">(\#fig:unnamed-chunk-3)Animation of how a counterfactual outcome changes as the natural treatment distribution is subjected to a simple stochastic intervention</p>
</div>

## Evaluating the Causal Effect of a Stochastic Intervention

To start, let us load the packages we will use and set a seed for simulation:


```r
library(here)
library(tidyverse)
library(data.table)
library(sl3)
library(tmle3)
library(tmle3shift)
set.seed(429153)
```

We need to estimate two components of the likelihood in order to construct a
TML estimator. The first of these components is the outcome regression,
$\hat{Q}_n$, which is a simple regression of the form $\mathbb{E}[Y \mid A,W]$.
An estimate for such a quantity may be constructed using the Super Learner
algorithm. We construct the components of an `sl3`-style Super Learner for a
regression below, using a small variety of parametric and nonparametric
regression techniques:


```r
# learners used for conditional expectation regression
lrn_mean <- Lrnr_mean$new()
lrn_fglm <- Lrnr_glm_fast$new()
lrn_xgb <- Lrnr_xgboost$new(nrounds = 200)
sl_lrn <- Lrnr_sl$new(
  learners = list(lrn_mean, lrn_fglm, lrn_xgb),
  metalearner = Lrnr_nnls$new()
)
```

The second of these is an estimate of the treatment mechanism, $\hat{g}_n$,
i.e., the _propensity score_. In the case of a continuous intervention node
$A$, such a quantity takes the form $p(A \mid W)$, which is a conditional
density. Generally speaking, conditional density estimation is a challenging
problem that has received much attention in the literature. To estimate the
treatment mechanism, we must make use of learning algorithms specifically suited
to conditional density estimation; a list of such learners may be extracted from
`sl3` by using `sl3_list_learners()`:


```r
sl3_list_learners("density")
```

```
[1] "Lrnr_condensier"             "Lrnr_density_discretize"    
[3] "Lrnr_density_hse"            "Lrnr_density_semiparametric"
[5] "Lrnr_haldensify"             "Lrnr_rfcde"                 
[7] "Lrnr_solnp_density"         
```

To proceed, we'll select two of the above learners, `Lrnr_haldensify` for using
the highly adaptive lasso for conditional density estimation, based on an
algorithm given by @diaz2011super and implemented in @hejazi2019haldensify, and
`Lrnr_rfcde`, an approach for using random forests for conditional density
estimation [@pospisil2018rfcde]. A Super Learner may be constructed by pooling
estimates from each of these modified conditional density regression techniques.


```r
# learners used for conditional density regression (i.e., propensity score)
lrn_haldensify <- Lrnr_haldensify$new(
  n_bins = 5, grid_type = "equal_mass",
  lambda_seq = exp(seq(-1, -13, length = 500))
)
lrn_rfcde <- Lrnr_rfcde$new(
  n_trees = 1000, node_size = 5,
  n_basis = 31, output_type = "observed"
)
sl_lrn_dens <- Lrnr_sl$new(
  learners = list(lrn_haldensify, lrn_rfcde),
  metalearner = Lrnr_solnp_density$new()
)
```

Finally, we construct a `learner_list` object for use in constructing a TML
estimator of our target parameter of interest:


```r
learner_list <- list(Y = sl_lrn, A = sl_lrn_dens)
```

The `learner_list` object above specifies the role that each of the ensemble
learners we have generated is to play in computing initial estimators to be
used in building a TMLE for the parameter of interest here. In particular, it
makes explicit the fact that our `Q_learner` is used in fitting the outcome
regression while our `g_learner` is used in estimating the treatment mechanism.

### Example with Simulated Data


```r
# simulate simple data for tmle-shift sketch
n_obs <- 500 # number of observations
tx_mult <- 2 # multiplier for the effect of W = 1 on the treatment

## baseline covariates -- simple, binary
W <- replicate(2, rbinom(n_obs, 1, 0.5))

## create treatment based on baseline W
A <- rnorm(n_obs, mean = tx_mult * W, sd = 1)

## create outcome as a linear function of A, W + white noise
Y <- rbinom(n_obs, 1, prob = plogis(A + W))

# organize data and nodes for tmle3
data <- data.table(W, A, Y)
setnames(data, c("W1", "W2", "A", "Y"))
node_list <- list(W = c("W1", "W2"), A = "A", Y = "Y")
head(data)
```

```
   W1 W2          A Y
1:  1  1  2.4031607 1
2:  1  0  4.4973744 1
3:  1  0  2.0330871 1
4:  0  0 -0.8089023 0
5:  1  0  1.8432067 1
6:  1  1  1.3555863 1
```

The above composes our observed data structure $O = (W, A, Y)$. To formally
express this fact using the `tlverse` grammar introduced by the `tmle3` package,
we create a single data object and specify the functional relationships between
the nodes in the _directed acyclic graph_ (DAG) via _nonparametric structural
equation models_ (NPSEMs), reflected in the node list that we set up:

We now have an observed data structure (`data`) and a specification of the role
that each variable in the data set plays as the nodes in a DAG.

To start, we will initialize a specification for the TMLE of our parameter of
interest (called a `tmle3_Spec` in the `tlverse` nomenclature) simply by calling
`tmle_shift`. We specify the argument `shift_val = 0.5` when initializing the
`tmle3_Spec` object to communicate that we're interested in a shift of $0.5$ on
the scale of the treatment $A$ -- that is, we specify $\delta = 0.5$ (note that
this is an arbitrarily chosen value for this example).


```r
# initialize a tmle specification
tmle_spec <- tmle_shift(
  shift_val = 0.5,
  shift_fxn = shift_additive_bounded,
  shift_fxn_inv = shift_additive_bounded_inv
)
```

As seen above, the `tmle_shift` specification object (like all `tmle3_Spec`
objects) does _not_ store the data for our specific analysis of interest. Later,
we'll see that passing a data object directly to the `tmle3` wrapper function,
alongside the instantiated `tmle_spec`, will serve to construct a `tmle3_Task`
object internally (see the `tmle3` documentation for details).

### Targeted Estimation of Stochastic Interventions Effects


```r
tmle_fit <- tmle3(tmle_spec, data, node_list, learner_list)
```

```

Iter: 1 fn: 696.9722     Pars:  0.87723 0.12277
Iter: 2 fn: 696.9722     Pars:  0.87723 0.12277
solnp-->
<p>Completed in 2 iterations
```</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb78-1" data-line-number="1">tmle_fit</a></code></pre></div>
<pre><code>A tmle3_Fit that took 1 step(s)
   type         param  init_est  tmle_est         se     lower     upper
1:  TSM E[Y_{A=NULL}] 0.7692472 0.7703716 0.01885915 0.7334084 0.8073349
   psi_transformed lower_transformed upper_transformed
1:       0.7703716         0.7334084         0.8073349</code></pre>
<p>The <code>print</code> method of the resultant <code>tmle_fit</code> object conveniently displays the
results from computing our TML estimator.</p>
<div id="statistical-inference-for-targeted-maximum-likelihood-estimates" class="section level3">
<h3><span class="header-section-number">7.0.1</span> Statistical Inference for Targeted Maximum Likelihood Estimates</h3>
<p>Recall that the asymptotic distribution of TML estimators has been studied
thoroughly:
<span class="math display">\[\psi_n - \psi_0 = (P_n - P_0) \cdot D(\bar{Q}_n^*, g_n) + R(\hat{P}^*, P_0),\]</span>
which, provided the following two conditions:</p>
<ol style="list-style-type: decimal">
<li>If <span class="math inline">\(D(\bar{Q}_n^*, g_n)\)</span> converges to <span class="math inline">\(D(P_0)\)</span> in <span class="math inline">\(L_2(P_0)\)</span> norm, and</li>
<li>the size of the class of functions considered for estimation of <span class="math inline">\(\bar{Q}_n^*\)</span>
and <span class="math inline">\(g_n\)</span> is bounded (technically, <span class="math inline">\(\exists \mathcal{F}\)</span> st
<span class="math inline">\(D(\bar{Q}_n^*, g_n) \in \mathcal{F}\)</span> <em><strong>whp</strong></em>, where <span class="math inline">\(\mathcal{F}\)</span> is a
Donsker class),
readily admits the conclusion that
<span class="math inline">\(\psi_n - \psi_0 = (P_n - P_0) \cdot D(P_0) + R(\hat{P}^*, P_0)\)</span>.</li>
</ol>
<p>Under the additional condition that the remainder term <span class="math inline">\(R(\hat{P}^*, P_0)\)</span>
decays as <span class="math inline">\(o_P \left( \frac{1}{\sqrt{n}} \right),\)</span> we have that
<span class="math display">\[\psi_n - \psi_0 = (P_n - P_0) \cdot D(P_0) + o_P \left( \frac{1}{\sqrt{n}}
 \right),\]</span>
which, by a central limit theorem, establishes a Gaussian limiting distribution
for the estimator:</p>
<p><span class="math display">\[\sqrt{n}(\psi_n - \psi) \to N(0, V(D(P_0))),\]</span>
where <span class="math inline">\(V(D(P_0))\)</span> is the variance of the efficient influence curve (canonical
gradient) when <span class="math inline">\(\psi\)</span> admits an asymptotically linear representation.</p>
<p>The above implies that <span class="math inline">\(\psi_n\)</span> is a <span class="math inline">\(\sqrt{n}\)</span>-consistent estimator of <span class="math inline">\(\psi\)</span>,
that it is asymptotically normal (as given above), and that it is locally
efficient. This allows us to build Wald-type confidence intervals in a
straightforward manner:</p>
<p><span class="math display">\[\psi_n \pm z_{\alpha} \cdot \frac{\sigma_n}{\sqrt{n}},\]</span>
where <span class="math inline">\(\sigma_n^2\)</span> is an estimator of <span class="math inline">\(V(D(P_0))\)</span>. The estimator <span class="math inline">\(\sigma_n^2\)</span>
may be obtained using the bootstrap or computed directly via the following</p>
<p><span class="math display">\[\sigma_n^2 = \frac{1}{n} \sum_{i = 1}^{n} D^2(\bar{Q}_n^*, g_n)(O_i)\]</span></p>
<p>Having now re-examined these facts, let’s simply examine the results of
computing our TML estimator:</p>
</div>
<div id="extensions-variable-importance-analysis-with-stochastic-interventions" class="section level2">
<h2><span class="header-section-number">7.1</span> Extensions: Variable Importance Analysis with Stochastic Interventions</h2>
<div id="defining-a-grid-of-counterfactual-interventions" class="section level3">
<h3><span class="header-section-number">7.1.1</span> Defining a grid of counterfactual interventions</h3>
<p>In order to specify a <em>grid</em> of shifts <span class="math inline">\(\delta\)</span> to be used in defining a set of
stochastic intervention policies in an <em>a priori</em> manner, let us consider an
arbitrary scalar <span class="math inline">\(\delta\)</span> that defines a counterfactual outcome <span class="math inline">\(\psi_n = Q_n(d(A, W), W)\)</span>, where, for simplicity, let <span class="math inline">\(d(A, W) = A + \delta\)</span>. A
simplified expression of the auxiliary covariate for the TMLE of <span class="math inline">\(\psi\)</span> is
<span class="math inline">\(H_n = \frac{g^{\star}(a \mid w)}{g(a \mid w)}\)</span>, where <span class="math inline">\(g^{\star}(a \mid w)\)</span>
defines the treatment mechanism with the stochastic intervention implemented.
Then, to ascertain whether a given choice of the shift <span class="math inline">\(\delta\)</span> is admissable
(in the sense of avoiding violations of the positivity assumption), let there
be a bound <span class="math inline">\(C(\delta) = \frac{g^{\star}(a \mid w)}{g(a \mid w)} &lt; M\)</span>, where
<span class="math inline">\(g^{\star}(a \mid w)\)</span> is a function of <span class="math inline">\(\delta\)</span> in part, and <span class="math inline">\(M\)</span> is a potentially
user-specified upper bound of <span class="math inline">\(C(\delta)\)</span>. Then, <span class="math inline">\(C(\delta)\)</span> is a measure of
the influence of a given observation, thereby providing a way to limit the
maximum influence of a given observation (by way of the bound <span class="math inline">\(M\)</span> placed on
<span class="math inline">\(C(\delta)\)</span>) through a choice of the shift <span class="math inline">\(\delta\)</span>.</p>
<p>We formalize and extend the procedure to determine an acceptable set of values
for the shift <span class="math inline">\(\delta\)</span> in the sequel. Specifically, let there be a shift <span class="math inline">\(d(A, W) = A + \delta(A, W)\)</span>, where the shift <span class="math inline">\(\delta(A, W)\)</span> is defined as
<span class="math display">\[\begin{equation}
  \delta(a, w) =
    \begin{cases}
      \delta, &amp; \delta_{\text{min}}(a,w) \leq \delta \leq
        \delta_{\text{max}}(a,w) \\
      \delta_{\text{max}}(a,w), &amp; \delta \geq \delta_{\text{max}}(a,w) \\
      \delta_{\text{min}}(a,w), &amp; \delta \leq \delta_{\text{min}}(a,w) \\
    \end{cases},
\end{equation}\]</span>
where <span class="math display">\[\delta_{\text{max}}(a, w) = \text{argmax}_{\left\{\delta \geq 0,
\frac{g(a - \delta \mid w)}{g(a \mid w)} \leq M \right\}} \frac{g(a - \delta
\mid w)}{g(a \mid w)}\]</span> and
<span class="math display">\[\delta_{\text{min}}(a, w) = \text{argmin}_{\left\{\delta \leq 0,
\frac{g(a - \delta \mid w)}{g(a \mid w)} \leq M \right\}} \frac{g(a - \delta
\mid w)}{g(a \mid w)}.\]</span></p>
<p>The above provides a strategy for implementing a shift at the level of a given
observation <span class="math inline">\((a_i, w_i)\)</span>, thereby allowing for all observations to be shifted
to an appropriate value – whether <span class="math inline">\(\delta_{\text{min}}\)</span>, <span class="math inline">\(\delta\)</span>, or
<span class="math inline">\(\delta_{\text{max}}\)</span>.</p>
<p>For the purpose of using such a shift in practice, the present software
provides the functions <code>shift_additive_bounded</code> and
<code>shift_additive_bounded_inv</code>, which define a variation of this shift:
<span class="math display">\[\begin{equation}
  \delta(a, w) =
    \begin{cases}
      \delta, &amp; C(\delta) \leq M \\
      0, \text{otherwise} \\
    \end{cases},
\end{equation}\]</span>
which corresponds to an intervention in which the natural value of treatment
of a given observational unit is shifted by a value <span class="math inline">\(\delta\)</span> in the case that
the ratio of the intervened density <span class="math inline">\(g^{\star}(a \mid w)\)</span> to the natural
density <span class="math inline">\(g(a \mid w)\)</span> (that is, <span class="math inline">\(C(\delta)\)</span>) does not exceed a bound <span class="math inline">\(M\)</span>. In
the case that the ratio <span class="math inline">\(C(\delta)\)</span> exceeds the bound <span class="math inline">\(M\)</span>, the stochastic
intervention policy does not apply to the given unit and they remain at their
natural value of treatment <span class="math inline">\(a\)</span>.</p>
</div>
<div id="initializing-vimshift-through-its-tmle3_spec" class="section level3">
<h3><span class="header-section-number">7.1.2</span> Initializing <code>vimshift</code> through its <code>tmle3_Spec</code></h3>
<p>To start, we will initialize a specification for the TMLE of our parameter of
interest (called a <code>tmle3_Spec</code> in the <code>tlverse</code> nomenclature) simply by calling
<code>tmle_shift</code>. We specify the argument <code>shift_grid = seq(-1, 1, by = 1)</code>
when initializing the <code>tmle3_Spec</code> object to communicate that we’re interested
in assessing the mean counterfactual outcome over a grid of shifts -1, 0, 1 on the scale of the treatment <span class="math inline">\(A\)</span> (note that the numerical
choice of shift is an arbitrarily chosen set of values for this example).</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb80-1" data-line-number="1"><span class="co"># what&#39;s the grid of shifts we wish to consider?</span></a>
<a class="sourceLine" id="cb80-2" data-line-number="2">delta_grid &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb80-3" data-line-number="3"></a>
<a class="sourceLine" id="cb80-4" data-line-number="4"><span class="co"># initialize a tmle specification</span></a>
<a class="sourceLine" id="cb80-5" data-line-number="5">tmle_spec &lt;-<span class="st"> </span><span class="kw">tmle_vimshift_delta</span>(</a>
<a class="sourceLine" id="cb80-6" data-line-number="6">  <span class="dt">shift_grid =</span> delta_grid,</a>
<a class="sourceLine" id="cb80-7" data-line-number="7">  <span class="dt">max_shifted_ratio =</span> <span class="dv">2</span></a>
<a class="sourceLine" id="cb80-8" data-line-number="8">)</a></code></pre></div>
<p>As seen above, the <code>tmle_vimshift</code> specification object (like all <code>tmle3_Spec</code>
objects) does <em>not</em> store the data for our specific analysis of interest. Later,
we’ll see that passing a data object directly to the <code>tmle3</code> wrapper function,
alongside the instantiated <code>tmle_spec</code>, will serve to construct a <code>tmle3_Task</code>
object internally (see the <code>tmle3</code> documentation for details).</p>
</div>
<div id="targeted-estimation-of-stochastic-interventions-effects" class="section level3">
<h3><span class="header-section-number">7.1.3</span> Targeted Estimation of Stochastic Interventions Effects</h3>
<p>One may walk through the step-by-step procedure for fitting the TML estimator
of the mean counterfactual outcome under each shift in the grid, using the
machinery exposed by the <a href="https://tmle3.tlverse.org/"><code>tmle3</code> R package</a>.</p>
<p>One may invoke the <code>tmle3</code> wrapper function (a user-facing convenience utility)
to fit the series of TML estimators (one for each parameter defined by the grid
delta) in a single function call:</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb81-1" data-line-number="1">tmle_fit &lt;-<span class="st"> </span><span class="kw">tmle3</span>(tmle_spec, data, node_list, learner_list)</a></code></pre></div>
<pre><code>
Iter: 1 fn: 690.4589     Pars:  0.90912 0.09088
Iter: 2 fn: 690.4589     Pars:  0.90913 0.09087
solnp--&gt; Completed in 2 iterations</code></pre>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb83-1" data-line-number="1">tmle_fit</a></code></pre></div>
<pre><code>A tmle3_Fit that took 1 step(s)
         type          param   init_est   tmle_est          se      lower
1:        TSM  E[Y_{A=NULL}] 0.61487012 0.61806561 0.021219449 0.57647625
2:        TSM  E[Y_{A=NULL}] 0.71452651 0.71600000 0.020186704 0.67643479
3:        TSM  E[Y_{A=NULL}] 0.81129695 0.80796904 0.016410478 0.77580509
4: MSM_linear MSM(intercept) 0.71356453 0.71401155 0.018598080 0.67755998
5: MSM_linear     MSM(slope) 0.09821342 0.09495172 0.005688819 0.08380184
       upper psi_transformed lower_transformed upper_transformed
1: 0.6596550      0.61806561        0.57647625         0.6596550
2: 0.7555652      0.71600000        0.67643479         0.7555652
3: 0.8401330      0.80796904        0.77580509         0.8401330
4: 0.7504631      0.71401155        0.67755998         0.7504631
5: 0.1061016      0.09495172        0.08380184         0.1061016</code></pre>
<p><em>Remark</em>: The <code>print</code> method of the resultant <code>tmle_fit</code> object conveniently
displays the results from computing our TML estimator.</p>
</div>
<div id="inference-with-marginal-structural-models" class="section level3">
<h3><span class="header-section-number">7.1.4</span> Inference with Marginal Structural Models</h3>
<p>Since we consider estimating the mean counterfactual outcome <span class="math inline">\(\psi_n\)</span> under
several values of the intervention <span class="math inline">\(\delta\)</span>, taken from the aforementioned
<span class="math inline">\(\delta\)</span>-grid, one approach for obtaining inference on a single summary measure
of these estimated quantities involves leveraging working marginal structural
models (MSMs). Summarizing the estimates <span class="math inline">\(\psi_n\)</span> through a working MSM allows
for inference on the <em>trend</em> imposed by a <span class="math inline">\(\delta\)</span>-grid to be evaluated via a
simple hypothesis test on a parameter of this working MSM. Letting
<span class="math inline">\(\psi_{\delta}(P_0)\)</span> be the mean outcome under a shift <span class="math inline">\(\delta\)</span> of the
treatment, we have <span class="math inline">\(\vec{\psi}_{\delta} = (\psi_{\delta}: \delta)\)</span> with
corresponding estimators <span class="math inline">\(\vec{\psi}_{n, \delta} = (\psi_{n, \delta}: \delta)\)</span>.
Further, let <span class="math inline">\(\beta(\vec{\psi}_{\delta}) = \phi((\psi_{\delta}: \delta))\)</span>.</p>
<p>For a given MSM <span class="math inline">\(m_{\beta}(\delta)\)</span>, we have that
<span class="math display">\[\beta_0 = \text{argmin}_{\beta} \sum_{\delta}(\psi_{\delta}(P_0) -
m_{\beta}(\delta))^2 h(\delta),\]</span>
which is the solution to
<span class="math display">\[u(\beta, (\psi_{\delta}: \delta)) = \sum_{\delta}h(\delta)
\left(\psi_{\delta}(P_0) - m_{\beta}(\delta) \right) \frac{d}{d\beta}
m_{\beta}(\delta) = 0.\]</span>
This then leads to the following expansion
<span class="math display">\[\beta(\vec{\psi}_n) - \beta(\vec{\psi}_0) \approx -\frac{d}{d\beta} u(\beta_0,
\vec{\psi}_0)^{-1} \frac{d}{d\psi} u(\beta_0, \psi_0)(\vec{\psi}_n -
\vec{\psi}_0),\]</span>
where we have
<span class="math display">\[\frac{d}{d\beta} u(\beta, \psi) = -\sum_{\delta} h(\delta) \frac{d}{d\beta}
m_{\beta}(\delta)^t \frac{d}{d\beta} m_{\beta}(\delta)
-\sum_{\delta} h(\delta) m_{\beta}(\delta) \frac{d^2}{d\beta^2}
m_{\beta}(\delta),\]</span>
which, in the case of an MSM that is a linear model (since
<span class="math inline">\(\frac{d^2}{d\beta^2} m_{\beta}(\delta) = 0\)</span>), reduces simply to
<span class="math display">\[\frac{d}{d\beta} u(\beta, \psi) = -\sum_{\delta} h(\delta) \frac{d}{d\beta}
m_{\beta}(\delta)^t \frac{d}{d\beta} m_{\beta}(\delta),\]</span>
and
<span class="math display">\[\frac{d}{d\psi}u(\beta, \psi)(\psi_n - \psi_0) = \sum_{\delta} h(\delta)
\frac{d}{d\beta} m_{\beta}(\delta) (\psi_n - \psi_0)(\delta),\]</span>
which we may write in terms of the efficient influence function (EIF) of <span class="math inline">\(\psi\)</span>
by using the first order approximation <span class="math inline">\((\psi_n - \psi_0)(\delta) = \frac{1}{n}\sum_{i = 1}^n \text{EIF}_{\psi_{\delta}}(O_i)\)</span>,
where <span class="math inline">\(\text{EIF}_{\psi_{\delta}}\)</span> is the efficient influence function (EIF) of
<span class="math inline">\(\vec{\psi}\)</span>.</p>
<p>Now, say, <span class="math inline">\(\vec{\psi} = (\psi(\delta): \delta)\)</span> is d-dimensional, then we may
write the efficient influence function of the MSM parameter <span class="math inline">\(\beta\)</span> as follows
<span class="math display">\[\text{EIF}_{\beta}(O) = \left(\sum_{\delta} h(\delta) \frac{d}{d\beta}
m_{\beta}(\delta) \frac{d}{d\beta} m_{\beta}(\delta)^t \right)^{-1} \cdot
\sum_{\delta} h(\delta) \frac{d}{d\beta} m_{\beta}(\delta)
\text{EIF}_{\psi_{\delta}}(O),\]</span> where the first term is of dimension
<span class="math inline">\(d \times d\)</span> and the second term is of dimension <span class="math inline">\(d \times 1\)</span>. In the above, we
assume a linear working MSM; however, an analogous procedure may be applied for
working MSMs based on GLMs.</p>
<p>Inference for a parameter of an MSM may be obtained by straightforward
application of the delta method (discussed previously) – that is, we may
write the efficient influence function of the MSM parameter <span class="math inline">\(\beta\)</span> in terms of
the EIFs of each of the corresponding point estimates. Based on this, inference
from a working MSM is rather straightforward. To wit, the limiting distribution
for <span class="math inline">\(m_{\beta}(\delta)\)</span> may be expressed <span class="math display">\[\sqrt{n}(\beta_n - \beta_0) \to N(0,
\Sigma),\]</span> where <span class="math inline">\(\Sigma\)</span> is the empirical covariance matrix of
<span class="math inline">\(\text{EIF}_{\beta}(O)\)</span>.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb85-1" data-line-number="1">tmle_fit<span class="op">$</span>summary[<span class="dv">4</span><span class="op">:</span><span class="dv">5</span>, ]</a></code></pre></div>
<pre><code>         type          param   init_est   tmle_est          se      lower
1: MSM_linear MSM(intercept) 0.71356453 0.71401155 0.018598080 0.67755998
2: MSM_linear     MSM(slope) 0.09821342 0.09495172 0.005688819 0.08380184
       upper psi_transformed lower_transformed upper_transformed
1: 0.7504631      0.71401155        0.67755998         0.7504631
2: 0.1061016      0.09495172        0.08380184         0.1061016</code></pre>
<div id="directly-targeting-the-msm-parameter-beta" class="section level4">
<h4><span class="header-section-number">7.1.4.1</span> Directly Targeting the MSM Parameter <span class="math inline">\(\beta\)</span></h4>
<p>Note that in the above, a working MSM is fit to the individual TML estimates of
the mean counterfactual outcome under a given value of the shift <span class="math inline">\(\delta\)</span> in the
supplied grid. The parameter of interest <span class="math inline">\(\beta\)</span> of the MSM is asymptotically
linear (and, in fact, a TML estimator) as a consequence of its construction from
individual TML estimators. In smaller samples, it may be prudent to perform a
TML estimation procedure that targets the parameter <span class="math inline">\(\beta\)</span> directly, as opposed
to constructing it from several independently targeted TML estimates. An
approach for constructing such an estimator is proposed in the sequel.</p>
<p>Suppose a simple working MSM <span class="math inline">\(\mathbb{E}Y_{g^0_{\delta}} = \beta_0 + \beta_1 \delta\)</span>, then a TML estimator targeting <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> may be
constructed as
<span class="math display">\[\overline{Q}_{n, \epsilon}(A,W) = \overline{Q}_n(A,W) + \epsilon (H_1(g),
H_2(g),\]</span> for all <span class="math inline">\(\delta\)</span>, where <span class="math inline">\(H_1(g)\)</span> is the auxiliary covariate for
<span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(H_2(g)\)</span> is the auxiliary covariate for <span class="math inline">\(\beta_1\)</span>.</p>
<p>To construct a targeted maximum likelihood estimator that directly targets the
parameters of the working marginal structural model, we may use the
<code>tmle_vimshift_msm</code> Spec (instead of the <code>tmle_vimshift_delta</code> Spec that
appears above):</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb87-1" data-line-number="1"><span class="co"># initialize a tmle specification</span></a>
<a class="sourceLine" id="cb87-2" data-line-number="2">tmle_msm_spec &lt;-<span class="st"> </span><span class="kw">tmle_vimshift_msm</span>(</a>
<a class="sourceLine" id="cb87-3" data-line-number="3">  <span class="dt">shift_grid =</span> delta_grid,</a>
<a class="sourceLine" id="cb87-4" data-line-number="4">  <span class="dt">max_shifted_ratio =</span> <span class="dv">2</span></a>
<a class="sourceLine" id="cb87-5" data-line-number="5">)</a>
<a class="sourceLine" id="cb87-6" data-line-number="6"></a>
<a class="sourceLine" id="cb87-7" data-line-number="7"><span class="co"># fit the TML estimator and examine the results</span></a>
<a class="sourceLine" id="cb87-8" data-line-number="8">tmle_msm_fit &lt;-<span class="st"> </span><span class="kw">tmle3</span>(tmle_msm_spec, data, node_list, learner_list)</a></code></pre></div>
<pre><code>
Iter: 1 fn: 690.9489     Pars:  0.90265 0.09735
Iter: 2 fn: 690.9489     Pars:  0.90265 0.09735
solnp--&gt; Completed in 2 iterations</code></pre>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb89-1" data-line-number="1">tmle_msm_fit</a></code></pre></div>
<pre><code>A tmle3_Fit that took 100 step(s)
         type          param   init_est   tmle_est          se      lower
1: MSM_linear MSM(intercept) 0.71408680 0.71404145 0.018738208 0.67731524
2: MSM_linear     MSM(slope) 0.09866036 0.09877643 0.005717429 0.08757048
       upper psi_transformed lower_transformed upper_transformed
1: 0.7507677      0.71404145        0.67731524         0.7507677
2: 0.1099824      0.09877643        0.08757048         0.1099824</code></pre>
</div>
</div>
<div id="example-with-the-wash-benefits-data" class="section level3">
<h3><span class="header-section-number">7.1.5</span> Example with the WASH Benefits Data</h3>
<p>To complete our walk through, let’s turn to using stochastic interventions to
investigate the data from the WASH Benefits trial. To start, let’s load the
data, convert all columns to be of class <code>numeric</code>, and take a quick look at it</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb91-1" data-line-number="1">washb_data &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="st">&quot;https://raw.githubusercontent.com/tlverse/tlverse-data/master/wash-benefits/washb_data.csv&quot;</span>,</a>
<a class="sourceLine" id="cb91-2" data-line-number="2">                    <span class="dt">stringsAsFactors =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb91-3" data-line-number="3">washb_data &lt;-<span class="st"> </span>washb_data[<span class="op">!</span><span class="kw">is.na</span>(momage), <span class="kw">lapply</span>(.SD, as.numeric)]</a>
<a class="sourceLine" id="cb91-4" data-line-number="4"><span class="kw">head</span>(washb_data, <span class="dv">3</span>)</a></code></pre></div>
<pre><code>     whz tr fracode month aged sex momage momedu momheight hfiacat Nlt18 Ncomp
1:  0.00  1       4     9  268   2     30      2    146.40       1     3    11
2: -1.16  1       4     9  286   2     25      2    148.75       3     2     4
3: -1.05  1      20     9  264   2     25      2    152.15       1     1    10
   watmin elec floor walls roof asset_wardrobe asset_table asset_chair
1:      0    1     0     1    1              0           1           1
2:      0    1     0     1    1              0           1           0
3:      0    0     0     1    1              0           0           1
   asset_khat asset_chouki asset_tv asset_refrig asset_bike asset_moto
1:          1            0        1            0          0          0
2:          1            1        0            0          0          0
3:          0            1        0            0          0          0
   asset_sewmach asset_mobile
1:             0            1
2:             0            1
3:             0            1</code></pre>
<p>Next, we specify our NPSEM via the <code>node_list</code> object. For our example analysis,
we’ll consider the outcome to be the weight-for-height Z-score (as in previous
chapters), the intervention of interest to be the mother’s age at time of
child’s birth, and take all other covariates to be potential confounders.</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb93-1" data-line-number="1">node_list &lt;-<span class="st"> </span><span class="kw">list</span>(</a>
<a class="sourceLine" id="cb93-2" data-line-number="2">  <span class="dt">W =</span> <span class="kw">names</span>(washb_data)[<span class="op">!</span>(<span class="kw">names</span>(washb_data) <span class="op">%in%</span></a>
<a class="sourceLine" id="cb93-3" data-line-number="3"><span class="st">    </span><span class="kw">c</span>(<span class="st">&quot;whz&quot;</span>, <span class="st">&quot;momage&quot;</span>))],</a>
<a class="sourceLine" id="cb93-4" data-line-number="4">  <span class="dt">A =</span> <span class="st">&quot;momage&quot;</span>, <span class="dt">Y =</span> <span class="st">&quot;whz&quot;</span></a>
<a class="sourceLine" id="cb93-5" data-line-number="5">)</a></code></pre></div>
<p>Were we to consider the counterfactual weight-for-height Z-score under shifts in
the age of the mother at child’s birth, how would we interpret estimates of our
parameter? To simplify our interpretation, consider a shift of just a year in
the mother’s age (i.e., <span class="math inline">\(\delta = 1\)</span>); in this setting, a stochastic
intervention would correspond to a policy advocating that potential mothers
defer having a child for a single calendar year, possibly implemented through an
encouragement design deployed in a clinical setting.</p>
<p>For this example, we’ll use the variable importance strategy of considering a
grid of stochastic interventions to evaluate the weight-for-height Z-score under
a shift in the mother’s age down by two years (<span class="math inline">\(\delta = -2\)</span>) or up by two years
(<span class="math inline">\(\delta = 2\)</span>). To do this, we simply initialize a <code>Spec</code> <code>tmle_vimshift_delta</code>
just as we did in a previous example:</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb94-1" data-line-number="1"><span class="co"># initialize a tmle specification for the variable importance parameter</span></a>
<a class="sourceLine" id="cb94-2" data-line-number="2">washb_vim_spec &lt;-<span class="st"> </span><span class="kw">tmle_vimshift_delta</span>(</a>
<a class="sourceLine" id="cb94-3" data-line-number="3">  <span class="dt">shift_grid =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>),</a>
<a class="sourceLine" id="cb94-4" data-line-number="4">  <span class="dt">max_shifted_ratio =</span> <span class="dv">2</span></a>
<a class="sourceLine" id="cb94-5" data-line-number="5">)</a></code></pre></div>
<p>Prior to running our analysis, we’ll modify the <code>learner_list</code> object we had
created such that the density estimation procedure we rely on will be only the
random forest conditional density estimation procedure of <span class="citation">Pospisil and Lee (<a href="#ref-pospisil2018rfcde">2018</a>)</span>, as
the nonparametric conditional density approach based on the highly adaptive
lasso <span class="citation">(Díaz and van der Laan <a href="#ref-diaz2011super">2011</a>; Benkeser and van der Laan <a href="#ref-benkeser2016hal">2016</a>; Coyle and Hejazi <a href="#ref-coyle2018hal9001">2018</a>; Hejazi, Benkeser, and van der Laan <a href="#ref-hejazi2019haldensify">2019</a>)</span> is currently unable to accommodate large datasets.</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb95-1" data-line-number="1"><span class="co"># learners used for conditional density regression (i.e., propensity score)</span></a>
<a class="sourceLine" id="cb95-2" data-line-number="2">lrn_rfcde &lt;-<span class="st"> </span>Lrnr_rfcde<span class="op">$</span><span class="kw">new</span>(</a>
<a class="sourceLine" id="cb95-3" data-line-number="3">  <span class="dt">n_trees =</span> <span class="dv">250</span>, <span class="dt">node_size =</span> <span class="dv">5</span>,</a>
<a class="sourceLine" id="cb95-4" data-line-number="4">  <span class="dt">n_basis =</span> <span class="dv">20</span>, <span class="dt">output_type =</span> <span class="st">&quot;observed&quot;</span></a>
<a class="sourceLine" id="cb95-5" data-line-number="5">)</a>
<a class="sourceLine" id="cb95-6" data-line-number="6"></a>
<a class="sourceLine" id="cb95-7" data-line-number="7"><span class="co"># we need to turn on cross-validation for the RFCDE learner</span></a>
<a class="sourceLine" id="cb95-8" data-line-number="8">lrn_cv_rfcde &lt;-<span class="st"> </span>Lrnr_cv<span class="op">$</span><span class="kw">new</span>(</a>
<a class="sourceLine" id="cb95-9" data-line-number="9">  <span class="dt">learner =</span> lrn_rfcde,</a>
<a class="sourceLine" id="cb95-10" data-line-number="10">  <span class="dt">full_fit =</span> <span class="ot">TRUE</span></a>
<a class="sourceLine" id="cb95-11" data-line-number="11">)</a>
<a class="sourceLine" id="cb95-12" data-line-number="12"></a>
<a class="sourceLine" id="cb95-13" data-line-number="13"><span class="co"># modify learner list, using existing SL for Q fit</span></a>
<a class="sourceLine" id="cb95-14" data-line-number="14">learner_list &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">Y =</span> sl_lrn, <span class="dt">A =</span> lrn_cv_rfcde)</a></code></pre></div>
<p>Having made the above preparations, we’re now ready to estimate the
counterfactual mean of the weight-for-height Z-score under a small grid of
shifts in the mother’s age at child’s birth. Just as before, we do this through
a simple call to our <code>tmle3</code> wrapper function:</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb96-1" data-line-number="1">washb_tmle_fit &lt;-<span class="st"> </span><span class="kw">tmle3</span>(washb_vim_spec, washb_data, node_list, learner_list)</a>
<a class="sourceLine" id="cb96-2" data-line-number="2">washb_tmle_fit</a></code></pre></div>
<hr />
</div>
</div>
<div id="exercises-2" class="section level2">
<h2><span class="header-section-number">7.2</span> Exercises</h2>
<div id="the-ideas-in-action" class="section level3">
<h3><span class="header-section-number">7.2.1</span> The Ideas in Action</h3>
<ol style="list-style-type: decimal">
<li><p>Set the <code>sl3</code> library of algorithms for the Super Learner to a simple,
interpretable library and use this new library to estimate the counterfactual
mean of mother’s age at child’s birth (<code>momage</code>) under a shift <span class="math inline">\(\delta = 0\)</span>.
What does this counterfactual mean equate to in terms of the observed data?</p></li>
<li><p>Using a grid of values of the shift parameter <span class="math inline">\(\delta\)</span> (e.g., <span class="math inline">\(\{-1, 0, +1\}\)</span>), repeat the analysis on the variable chosen in the preceding question,
summarizing the trend for this sequence of shifts using a marginal structural
model.</p></li>
<li><p>Repeat the preceding analysis, using the same grid of shifts, but instead
directly targeting the parameters of the marginal structural model. Interpret
the results – that is, what does the slope of the marginal structural model
tell us about the trend across the chosen sequence of shifts?</p></li>
</ol>
</div>
<div id="review-of-key-concepts" class="section level3">
<h3><span class="header-section-number">7.2.2</span> Review of Key Concepts</h3>
<ol style="list-style-type: decimal">
<li><p>Describe two (equivalent) ways in which the causal effects of stochastic
interventions may be interpreted.</p></li>
<li><p>How does the marginal structural model we used to summarize the trend along
the sequence of shifts previously help to contextualize the estimated effect
for a single shift? That is, how does access to estimates across several
shifts and the marginal structural model parameters allow us to more richly
interpret our findings?</p></li>
<li><p>What advantages, if any, are there to targeting directly the parameters of a
marginal structural model?</p></li>
</ol>
<!--
- @haneuse2013estimation characterization of stochastic interventions as
  \textit{modified treatment policies} (MTPs).
- Assumption of \textit{piecewise smooth invertibility} allows for the
  intervention distribution of any MTP to be recovered:
  \begin{equation*}
    g_{0, \delta}(a \mid w) = \sum_{j = 1}^{J(w)} I_{\delta, j} \{h_j(a, w),
    w\} g_0\{h_j(a, w) \mid w\} h^{\prime}_j(a,w)
  \end{equation*}
- Such intervention policies account for the natural value of the
  intervention $A$ directly yet are interpretable as the imposition of an
  altered intervention mechanism.
- Piecewise smooth invertibility: This assumption ensures that we can
  use the change of variable formula when computing integrals over $A$ and
  it is useful to study the estimators that we propose in this paper.

- __Asymptotic linearity:__
  \begin{equation*}
    \Psi(P_n^{\star}) - \Psi(P_0) = \frac{1}{n} \sum_{i = 1}^{n} D(P_0)(X_i) +
    o_P\left(\frac{1}{\sqrt{n}}\right)
  \end{equation*}
- Gaussian limiting distribution:
  \begin{equation*}
    \sqrt{n}(\Psi(P_n^{\star}) - \Psi(P_0)) \to N(0, Var(D(P_0)(O)))
  \end{equation*}
- Statistical inference:
  \begin{equation*}
    \text{Wald-type CI}: \Psi(P_n^{\star}) \pm z_{\alpha} \cdot
    \frac{\sigma_n}{\sqrt{n}},
  \end{equation*}
  where $\sigma_n^2$ is computed directly via
  $\sigma_n^2 = \frac{1}{n} \sum_{i = 1}^{n} D^2(\cdot)(O_i)$.

Under the additional condition that the remainder term $R(\hat{P}^*, P_0)$
decays as $o_P \left( \frac{1}{\sqrt{n}} \right),$ we have that
$\Psi_n - \Psi_0 = (P_n - P_0) \cdot D(P_0) + o_P
\left( \frac{1}{\sqrt{n}} \right),$ which, by a central limit theorem,
establishes a Gaussian limiting distribution for the estimator, with variance
$V(D(P_0))$, the variance of the efficient influence function
when $\Psi$ admits an asymptotically linear representation.

The above implies that $\Psi_n$ is a $\sqrt{n}$-consistent estimator of $\Psi$,
that it is asymptotically normal (as given above), and that it is locally
efficient. This allows us to build Wald-type confidence intervals, where
$\sigma_n^2$ is an estimator of $V(D(P_0))$. The estimator $\sigma_n^2$
may be obtained using the bootstrap or computed directly via
$\sigma_n^2 = \frac{1}{n} \sum_{i = 1}^{n} D^2(\bar{Q}_n^*, g_n)(O_i)$

We obtain semiparametric-efficient estimation and robust inference in the
nonparametric model $\M$ by solving the efficient influence function.

1. If $D(\bar{Q}_n^*, g_n)$ converges to $D(P_0)$ in $L_2(P_0)$ norm.
2. The size of the class of functions $\bar{Q}_n^*$ and $g_n$ is bounded
   (technically, $\exists \mathcal{F}$ st
   $D(\bar{Q}_n^*, g_n) \in \mathcal{F}$ whp, where $\mathcal{F}$ is a
   Donsker class)
-->

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-benkeser2016hal">
<p>Benkeser, David, and Mark J van der Laan. 2016. “The Highly Adaptive Lasso Estimator.” In <em>2016 IEEE International Conference on Data Science and Advanced Analytics (DSAA)</em>. IEEE. <a href="https://doi.org/10.1109/dsaa.2016.93" class="uri">https://doi.org/10.1109/dsaa.2016.93</a>.</p>
</div>
<div id="ref-coyle2018hal9001">
<p>Coyle, Jeremy R, and Nima S Hejazi. 2018. “hal9001: The Scalable Highly Adaptive LASSO.” <a href="https://github.com/tlverse/hal9001" class="uri">https://github.com/tlverse/hal9001</a>.</p>
</div>
<div id="ref-diaz2011super">
<p>Díaz, Iván, and Mark J van der Laan. 2011. “Super Learner Based Conditional Density Estimation with Application to Marginal Structural Models.” <em>The International Journal of Biostatistics</em> 7 (1). De Gruyter: 1–20.</p>
</div>
<div id="ref-hejazi2019haldensify">
<p>Hejazi, Nima S, David C Benkeser, and Mark J van der Laan. 2019. <em>Haldensify: Nonparametric Conditional Density Estimation with the Highly Adaptive Lasso in R</em>. <a href="https://github.com/nhejazi/haldensify" class="uri">https://github.com/nhejazi/haldensify</a>.</p>
</div>
<div id="ref-pospisil2018rfcde">
<p>Pospisil, Taylor, and Ann B Lee. 2018. “RFCDE: Random Forests for Conditional Density Estimation.” <em>arXiv Preprint arXiv:1804.05753</em>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="optimal-individualized-treatment-regimes.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="r6.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/tlverse/tlverse-handbook/edit/master/08-tmle3shift.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
