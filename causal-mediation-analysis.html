<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 7 Causal Mediation Analysis | Targeted Learning in R</title>
<meta name="author" content="Mark van der Laan, Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips, Alan Hubbard">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.4/tabs.js"></script><script src="libs/bs3compat-0.2.4/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
</head>
<body>
<span class="math inline">
  \(\DeclareMathOperator{\expit}{expit}\)
  \(\DeclareMathOperator{\logit}{logit}\)
  \(\DeclareMathOperator*{\argmin}{\arg\!\min}\)
  \(\newcommand{\indep}{\perp\!\!\!\perp}\)
  \(\newcommand{\coloneqq}{\mathrel{=}}\)
  \(\newcommand{\R}{\mathbb{R}}\)
  \(\newcommand{\E}{\mathbb{E}}\)
  \(\newcommand{\M}{\mathcal{M}}\)
  \(\renewcommand{\P}{\mathbb{P}}\)
  \(\newcommand{\I}{\mathbb{I}}\)
  \(\newcommand{\1}{\mathbbm{1}}\)
  </span>
    <script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS --><div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="Causal Data Science with the tlverse Software Ecosystem">Targeted Learning in R</a>:
        <small class="text-muted">Causal Data Science with the tlverse Software Ecosystem</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">About this book</a></li>
<li><a class="" href="robust.html"><span class="header-section-number">1</span> Robust Statistics and Reproducible Science</a></li>
<li><a class="" href="intro.html"><span class="header-section-number">2</span> The Roadmap for Targeted Learning</a></li>
<li><a class="" href="tlverse.html"><span class="header-section-number">3</span> Welcome to the tlverse</a></li>
<li><a class="" href="data.html"><span class="header-section-number">4</span> Meet the Data</a></li>
<li><a class="" href="origami.html"><span class="header-section-number">5</span> Cross-validation</a></li>
<li><a class="" href="tmle3.html"><span class="header-section-number">6</span> The TMLE Framework</a></li>
<li><a class="active" href="causal-mediation-analysis.html"><span class="header-section-number">7</span> Causal Mediation Analysis</a></li>
<li><a class="" href="r6.html"><span class="header-section-number">8</span> A Primer on the R6 Class System</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/tlverse/tlverse-handbook">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="causal-mediation-analysis" class="section level1">
<h1>
<span class="header-section-number">7</span> Causal Mediation Analysis<a class="anchor" aria-label="anchor" href="#causal-mediation-analysis"><i class="fas fa-link"></i></a>
</h1>
<p><em>Nima Hejazi</em></p>
<p>Based on the <a href="https://github.com/tlverse/tmle3mediate"><code>tmle3mediate</code> <code>R</code>
package</a> by <em>Nima Hejazi, James
Duncan, and David McCoy</em>.</p>
<p>Updated: 2021-04-19</p>
<!--
## Learning Objectives

1. TODO
2. TODO
3. TODO
4. TODO
5. TODO
6. TODO
7. TODO
-->
<div id="introduction-to-causal-mediation-analysis" class="section level2">
<h2>
<span class="header-section-number">7.1</span> Introduction to Causal Mediation Analysis<a class="anchor" aria-label="anchor" href="#introduction-to-causal-mediation-analysis"><i class="fas fa-link"></i></a>
</h2>
<p>A treatment often affects an outcome indirectly, through a particular pathway,
by its effect on <em>intermediate variables</em> (mediators). Causal mediation analysis
concerns the construction and evaluation of these <em>indirect effects</em> and their
complementary <em>direct effects</em>. Generally, the indirect effect (IE) of a
treatment on an outcome is the portion of the total effect that is found to work
<em>through</em> mediator variables, while the direct effect often encompasses all
other components of the total effect, including both the effect of the treatment
on the outcome <em>and</em> the effect through all paths not explicitly involving the
mediators). Identifying and quantifying the mechanisms underlying causal effects
is an increasingly desirable endeavor in public health, medicine, and the social
sciences, as such mechanistic knowledge improves understanding of both <em>why</em> and
<em>how</em> treatments may be effective.</p>
<p>While the study of mediation analysis may be traced back quite far, the field
only came into its modern form with the identification and careful study of the
natural direct and indirect effects [<span class="citation">Robins and Greenland (<a href="references.html#ref-robins1992identifiability">1992</a>)</span>;
pearl2001direct]. The natural direct effect (NDE) and the natural indirect
effect (NIE) are based on a decomposition of the average treatment effect (ATE)
in the presence of mediators <span class="citation">(VanderWeele <a href="references.html#ref-vanderweele2015explanation">2015</a>)</span>; requisite
theory for the construction of efficient estimators of these quantities only
receiving attention relatively recently <span class="citation">(Tchetgen Tchetgen and Shpitser <a href="references.html#ref-tchetgen2012semiparametric">2012</a>)</span>.</p>
</div>
<div id="data-structure-and-notation" class="section level2">
<h2>
<span class="header-section-number">7.2</span> Data Structure and Notation<a class="anchor" aria-label="anchor" href="#data-structure-and-notation"><i class="fas fa-link"></i></a>
</h2>
<p>Consider <span class="math inline">\(n\)</span> observed units <span class="math inline">\(O_1, \ldots, O_n\)</span>, where each observed data random
variable takes the form <span class="math inline">\(O = (W, A, Z, Y)\)</span>, for a vector of observed covariates
<span class="math inline">\(W\)</span>, a binary or continuous treatment <span class="math inline">\(A\)</span>, possibly multivariate mediators <span class="math inline">\(Z\)</span>,
and a binary or continuous outcome <span class="math inline">\(Y\)</span>. To avoid undue assumptions, we assume
only that <span class="math inline">\(O \sim \mathcal{P} \in \M\)</span> where <span class="math inline">\(\M\)</span> is the nonparametric
statistical model defined as all continuous densities on <span class="math inline">\(O\)</span> with respect to an
arbitrary dominating measure.</p>
<p>We formalize the definition of our counterfactual variables using the following
non-parametric structural equation model (NPSEM):
<span class="math display" id="eq:npsem-mediate">\[\begin{align}
  W &amp;= f_W(U_W) \\
  A &amp;= f_A(W, U_A) \\
  Z &amp;= f_Z(W, A, U_M) \\
  Y &amp;= f_Y(W, A, Z, U_Y).
  \tag{7.1}
\end{align}\]</span>
This set of equations
represents a mechanistic model generating the observed data <span class="math inline">\(O\)</span>; furthermore,
the NPSEM encodes several fundamental assumptions. Firstly, there is an implicit
temporal ordering: <span class="math inline">\(W\)</span> occurs first, depending only on exogenous factors <span class="math inline">\(U_W\)</span>;
<span class="math inline">\(A\)</span> happens next, based on both <span class="math inline">\(W\)</span> and exogenous factors <span class="math inline">\(U_A\)</span>; then come the
mediators <span class="math inline">\(Z\)</span>, which depend on <span class="math inline">\(A\)</span>, <span class="math inline">\(W\)</span>, and another set of exogenous factors
<span class="math inline">\(U_Z\)</span>; and finally appears the outcome <span class="math inline">\(Y\)</span>. We assume neither access to the set
of exogenous factors <span class="math inline">\(\{U_W, U_A, U_Z, U_Y\}\)</span> nor knowledge of the forms of the
deterministic generating functions <span class="math inline">\(\{f_W, f_A, f_Z, f_Y\}\)</span>. The NPSEM
corresponds to the following DAG:</p>
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.dagitty.net">dagitty</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/malcolmbarrett/ggdag">ggdag</a></span><span class="op">)</span>

<span class="co"># make DAG by specifying dependence structure</span>
<span class="va">dag</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/dagitty/man/dagitty.html">dagitty</a></span><span class="op">(</span>
  <span class="st">"dag {
    W -&gt; A
    W -&gt; Z
    W -&gt; Y
    A -&gt; Z
    A -&gt; Y
    Z -&gt; Y
    W -&gt; A -&gt; Y
    W -&gt; A -&gt; Z -&gt; Y
  }"</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/pkg/dagitty/man/VariableStatus.html">exposures</a></span><span class="op">(</span><span class="va">dag</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"A"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/pkg/dagitty/man/VariableStatus.html">outcomes</a></span><span class="op">(</span><span class="va">dag</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Y"</span><span class="op">)</span>
<span class="va">tidy_dag</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/ggdag/man/tidy_dagitty.html">tidy_dagitty</a></span><span class="op">(</span><span class="va">dag</span><span class="op">)</span>

<span class="co"># visualize DAG</span>
<span class="fu"><a href="https://rdrr.io/pkg/ggdag/man/ggdag.html">ggdag</a></span><span class="op">(</span><span class="va">tidy_dag</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://rdrr.io/pkg/ggdag/man/theme_dag_blank.html">theme_dag</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="10-tmle3mediate_files/figure-html/mediation-DAG-1.png" width="80%" style="display: block; margin: auto;"></div>
<p>The likelihood of the data <span class="math inline">\(O\)</span> admits a factorization, wherein, for <span class="math inline">\(p_0^O\)</span>,
the density of <span class="math inline">\(O\)</span> with respect to the product measure, the density evaluated
on a particular observation <span class="math inline">\(o\)</span> may be a written
<span class="math display" id="eq:likelihood-factorization-mediate">\[\begin{equation}
  p_0^O(x) = q^O_{0,Y}(y \mid Z = z A = a, W = w)
    q^O_{0,Z}(z \mid A = a, W = w)
    q^O_{0,A}(a \mid W = w)
    q^O_{0,W}(w),
  \tag{7.2}
\end{equation}\]</span>
where <span class="math inline">\(q_{0, Y}\)</span> is the conditional density of <span class="math inline">\(Y\)</span> given <span class="math inline">\((Z, A, W)\)</span>, <span class="math inline">\(q_{0, Z}\)</span>
is the conditional density of <span class="math inline">\(Z\)</span> given <span class="math inline">\((A, W)\)</span>, <span class="math inline">\(q_{0, A}\)</span> is the conditional
density of <span class="math inline">\(A\)</span> given <span class="math inline">\(W\)</span>, and <span class="math inline">\(q_{0, W}\)</span> is the density of <span class="math inline">\(W\)</span>. Further, for
ease of notation, we let <span class="math inline">\(\bar{Q}_Y(Z, A, W) = \E[Y \mid Z, A, W]\)</span>,
<span class="math inline">\(\bar{Q}_Z(A, W) = \P[Z \mid A, W]\)</span> (later re-parametrized to <span class="math inline">\(e(A \mid Z, W) = \P(A \mid Z, W)\)</span>), <span class="math inline">\(g(A \mid W) = \P(A \mid W)\)</span>, and <span class="math inline">\(q_W\)</span> the marginal
distribution of <span class="math inline">\(W\)</span>.</p>
<p>Finally, note that we have explicitly excluded potential confounders of the
mediator-outcome relationship affected by exposure (i.e., variables affected by
<span class="math inline">\(A\)</span> and affecting both <span class="math inline">\(Z\)</span> and <span class="math inline">\(Y\)</span>). Mediation analysis in the presence of such
variables is exceptionally challenging <span class="citation">(Avin, Shpitser, and Pearl <a href="references.html#ref-avin2005identifiability">2005</a>)</span>; thus, most
efforts to develop definitions of causal direct and indirect effects explicitly
disallowed such a form of confounding. While we will not discuss the matter
here, the interested reader may consult recent advances in the vast literature
on causal mediation analysis, among them <span class="citation">Díaz et al. (<a href="references.html#ref-diaz2020nonparametric">2020</a>)</span> and
<span class="citation">Hejazi et al. (<a href="references.html#ref-hejazi2021nonparametric">2021</a>)</span>.</p>
</div>
<div id="decomposing-the-average-treatment-effect" class="section level2">
<h2>
<span class="header-section-number">7.3</span> Decomposing the Average Treatment Effect<a class="anchor" aria-label="anchor" href="#decomposing-the-average-treatment-effect"><i class="fas fa-link"></i></a>
</h2>
<p>The natural direct and indirect effects arise from a decomposition of the ATE:
<span class="math display">\[\begin{equation*}
  \E[Y(1) - Y(0)] =
    \underbrace{\E[Y(1, Z(0)) - Y(0, Z(0))]}_{NDE} +
    \underbrace{\E[Y(1, Z(1)) - Y(1, Z(0))]}_{NIE}.
\end{equation*}\]</span>
In particular, the natural indirect effect (NIE) measures the effect of the
treatment <span class="math inline">\(A \in \{0, 1\}\)</span> on the outcome <span class="math inline">\(Y\)</span> through the mediators <span class="math inline">\(Z\)</span>, while
the natural direct effect (NDE) measures the effect of the treatment on the
outcome <em>through all other paths</em>. Identification of the natural direct and
indirect effects requires the following non-testable causal assumptions:</p>
<ol style="list-style-type: decimal">
<li>
<em>Exchangeability</em>: <span class="math inline">\(Y(a, z) \indep (A, Z) \mid W\)</span>, which further implies
<span class="math inline">\(\E\{Y(a, z) \mid A=a, W=w, Z=z\} = \E\{Y(a, z) \mid W=w\}\)</span>. This is a
special case of the randomization assumption, extended to observational
studies with mediators.</li>
<li>
<em>Treatment positivity</em>: For any <span class="math inline">\(a \in \mathcal{A}\)</span> and <span class="math inline">\(w \in \mathcal{W}\)</span>, <span class="math inline">\(\xi &lt; g(a \mid w) &lt; 1 - \xi\)</span>, for <span class="math inline">\(\xi &gt; 0\)</span>. This mirrors the
assumption required for static intervention, discussed previously.</li>
<li>
<em>Mediator positivity</em>: For any $z , $<span class="math inline">\(a \in \mathcal{A}\)</span>, and
<span class="math inline">\(w \in \mathcal{W}\)</span>, <span class="math inline">\(\epsilon &lt; g(a \mid w)\)</span>, for <span class="math inline">\(\epsilon &gt; 0\)</span>. This only
requires that the conditional density of the mediators be bounded away from
zero for all <span class="math inline">\((z, a, w)\)</span> in the joint support of <span class="math inline">\(\mathcal{Z} \times \mathcal{A} \times \mathcal{W}\)</span>.</li>
<li>
<em>Cross-world counterfactual independence</em>: For all <span class="math inline">\(a \neq a'\)</span>, both
contained in <span class="math inline">\(\mathcal{A}\)</span> and <span class="math inline">\(z \in \mathcal{Z}\)</span>, <span class="math inline">\(Y(a', z)\)</span> is independent
of <span class="math inline">\(Z(a)\)</span>, given <span class="math inline">\(W\)</span>. That is, the counterfactual outcome under the treatment
contrast <span class="math inline">\(a' \in \mathcal{A}\)</span> and the counterfactual mediator <span class="math inline">\(Z(a) in \mathcal{Z}\)</span> (under a different contrast <span class="math inline">\(a \in \mathcal{A}\)</span>) are
independent. Note that the counterfactual outcome and mediator are defined
under differing contrasts, hence the “cross-world” designation.</li>
</ol>
<p>We note that many attempts have been made to weaken the last assumption, that of
cross-world counterfactual independence, including work by
<span class="citation">Petersen, Sinisi, and Laan (<a href="references.html#ref-petersen2006estimation">2006</a>)</span> and <span class="citation">Imai, Keele, and Yamamoto (<a href="references.html#ref-imai2010identification">2010</a>)</span>; however, importantly,
<span class="citation">Robins and Richardson (<a href="references.html#ref-robins2010alternative">2010</a>)</span> established that this assumption cannot be satisfied in
randomized experiments. Thus, the natural direct and indirect effects are not
identifiable in randomized experiments, calling into question their utility.
Despite this significant limitation, we will turn to considering estimation of
the statistical functionals corresponding to these effects in observational
studies.</p>
</div>
<div id="the-natural-direct-effect" class="section level2">
<h2>
<span class="header-section-number">7.4</span> The Natural Direct Effect<a class="anchor" aria-label="anchor" href="#the-natural-direct-effect"><i class="fas fa-link"></i></a>
</h2>
<p>The NDE is defined as
<span class="math display">\[\begin{equation*}
  \Psi_{NDE} = \E[Y(1, Z(0)) - Y(0, Z(0))]
  \overset{\text{rand.}}{=} \sum_w \sum_z
  [\underbrace{\E(Y \mid A = 1, z, w)}_{\bar{Q}_Y(A = 1, z, w)} -
  \underbrace{\E(Y \mid A = 0, z, w)}_{\bar{Q}_Y(A = 0, z, w)}] \times
  \underbrace{p(z \mid A = 0, w)}_{Q_Z(0, w))} \underbrace{p(w)}_{q_W},
\end{equation*}\]</span>
where the likelihood factors <span class="math inline">\(p(z \mid A = 0, w)\)</span> and <span class="math inline">\(p(w)\)</span> (among other
conditional densities) arise from a factorization of the joint likelihood:
<span class="math display">\[\begin{equation*}
  p(w, a, z, y) = \underbrace{p(y \mid w, a, z)}_{Q_Y(A, W, Z)}
  \underbrace{p(z \mid w, a)}_{Q_Z(Z \mid A, W)}
  \underbrace{p(a \mid w)}_{g(A \mid W)}
  \underbrace{p(w)}_{Q_W}.
\end{equation*}\]</span></p>
<p>The process of estimating the NDE begins by constructing <span class="math inline">\(\bar{Q}_{Y, n}\)</span>, an
estimate of the outcome mechanism <span class="math inline">\(\bar{Q}_Y(Z, A, W) = \E \{Y \mid Z, A, W\}\)</span> (i.e., the conditional mean of <span class="math inline">\(Y\)</span>, given <span class="math inline">\(Z\)</span>, <span class="math inline">\(A\)</span>, and <span class="math inline">\(W\)</span>). With an
estimate of this conditional expectation in hand, predictions of the
counterfactual quantities <span class="math inline">\(\bar{Q}_Y(Z, 1, W)\)</span> (setting <span class="math inline">\(A = 1\)</span>) and, likewise,
<span class="math inline">\(\bar{Q}_Y(Z, 0, W)\)</span> (setting <span class="math inline">\(A = 0\)</span>) can readily be obtained. We denote the
difference of these counterfactual quantities <span class="math inline">\(\bar{Q}_{\text{diff}}\)</span>, i.e.,
<span class="math inline">\(\bar{Q}_{\text{diff}} = \bar{Q}_Y(Z, 1, W) - \bar{Q}_Y(Z, 0, W)\)</span>.
<span class="math inline">\(\bar{Q}_{\text{diff}}\)</span> represents the difference in the conditional mean of
<span class="math inline">\(Y\)</span> attributable to changes in <span class="math inline">\(A\)</span> while keeping <span class="math inline">\(Z\)</span> and <span class="math inline">\(W\)</span> at their <em>natural</em>
(that is, observed) values.</p>
<p>The estimation procedure treats <span class="math inline">\(\bar{Q}_{\text{diff}}\)</span> itself as a nuisance
parameter, regressing its estimate <span class="math inline">\(\bar{Q}_{\text{diff}, n}\)</span> on <span class="math inline">\(W\)</span>, among
control observations only (i.e., those for whom <span class="math inline">\(A = 0\)</span> is observed); the goal
of this step is to remove part of the marginal impact of <span class="math inline">\(Z\)</span> on
<span class="math inline">\(\bar{Q}_{\text{diff}}\)</span>, since <span class="math inline">\(W\)</span> is a parent of <span class="math inline">\(Z\)</span>. Regressing this
difference on <span class="math inline">\(W\)</span> among the controls recovers the expected
<span class="math inline">\(\bar{Q}_{\text{diff}}\)</span>, had all individuals been set to the control condition
<span class="math inline">\(A = 0\)</span>. Any residual additive effect of <span class="math inline">\(Z\)</span> on <span class="math inline">\(\bar{Q}_{\text{diff}}\)</span> is
removed during the TML estimation step using the auxiliary (or “clever”)
covariate, which accounts for the mediators <span class="math inline">\(Z\)</span>. This auxiliary covariate takes
the form
<span class="math display">\[\begin{equation*}
  C_Y(Q_Z, g)(O) = \Bigg\{\frac{\mathbb{I}(A = 1)}{g(1 \mid W)}
  \frac{Q_Z(Z \mid 0, W)}{Q_Z(Z \mid 1, W)} -
  \frac{\mathbb{I}(A = 0)}{g(0 \mid W)} \Bigg\}.
\end{equation*}\]</span>
Breaking this down, <span class="math inline">\(\frac{\mathbb{I}(A = 1)}{g(1 \mid W)}\)</span> is the inverse
propensity score weight for <span class="math inline">\(A = 1\)</span> and, likewise, <span class="math inline">\(\frac{\mathbb{I}(A = 0)} {g(0 \mid W)}\)</span> is the inverse propensity score weight for <span class="math inline">\(A = 0\)</span>. The middle
term is the ratio of the conditional densities of the mediator under the control
(<span class="math inline">\(A = 0\)</span>) and treatment (<span class="math inline">\(A = 1\)</span>) conditions.</p>
<p>This subtle appearance of a ratio of conditional densities is concerning –
unfortunately, tools to estimate such quantities are sparse in the statistics
literature, and the problem is still more complicated (and computationally
taxing) when <span class="math inline">\(Z\)</span> is high-dimensional. As only the ratio of these conditional
densities is required, a convenient re-parametrization may be achieved, that is,
<span class="math display">\[\begin{equation*}
  \frac{p(A = 0 \mid Z, W) g(0 \mid W)}{p(A = 1 \mid Z, W) g(1 \mid W)}.
\end{equation*}\]</span>
Going forward, we will denote this re-parameterized conditional probability
<span class="math inline">\(e(A \mid Z, W) := p(A \mid Z, W)\)</span>. Similar re-parameterizations have been used
in <span class="citation">Zheng and van der Laan (<a href="references.html#ref-zheng2012targeted">2012</a>)</span> and <span class="citation">Tchetgen Tchetgen (<a href="references.html#ref-tchetgen2013inverse">2013</a>)</span>. This is particularly useful
since this reformulation reduces the problem to one concerning only the
estimation of conditional means, opening the door to the use of a wide range of
machine learning algorithms (e.g., most of those in
<a href="https://github.com/tlverse/sl3"><code>sl3</code></a>).</p>
<p>Underneath the hood, the counterfactual outcome difference
<span class="math inline">\(\bar{Q}_{\text{diff}}\)</span> and <span class="math inline">\(e(A \mid Z, W)\)</span>, the conditional probability of <span class="math inline">\(A\)</span>
given <span class="math inline">\(Z\)</span> and <span class="math inline">\(W\)</span>, are used in constructing the auxiliary covariate for TML
estimation. These nuisance parameters play an important role in the
bias-correcting update step of the TMLE procedure.</p>
</div>
<div id="the-natural-indirect-effect" class="section level2">
<h2>
<span class="header-section-number">7.5</span> The Natural Indirect Effect<a class="anchor" aria-label="anchor" href="#the-natural-indirect-effect"><i class="fas fa-link"></i></a>
</h2>
<p>Derivation and estimation of the NIE is analogous to that of the NDE. The NIE
is the effect of <span class="math inline">\(A\)</span> on <span class="math inline">\(Y\)</span> <em>only through the mediator(s) <span class="math inline">\(Z\)</span></em>. This quantity
– known as the natural indirect effect <span class="math inline">\(\E(Y(Z(1), 1) - \E(Y(Z(0), 1)\)</span> –
corresponds to the difference of the conditional expectation of <span class="math inline">\(Y\)</span> given <span class="math inline">\(A = 1\)</span> and <span class="math inline">\(Z(1)\)</span> (the values the mediator would take under <span class="math inline">\(A = 1\)</span>) and the
conditional expectation of <span class="math inline">\(Y\)</span> given <span class="math inline">\(A = 1\)</span> and <span class="math inline">\(Z(0)\)</span> (the values the mediator
would take under <span class="math inline">\(A = 0\)</span>).</p>
<p>As with the NDE, the re-parameterization trick can be used to estimate <span class="math inline">\(\E(A \mid Z, W)\)</span>, avoiding estimation of a possibly multivariate conditional density.
However, in this case, the mediated mean outcome difference, denoted
<span class="math inline">\(\Psi_Z(Q)\)</span>, is instead estimated as follows
<span class="math display">\[\begin{equation*}
  \Psi_{NIE}(Q) = \E_{QZ}(\Psi_{NIE, Z}(Q)(1, W) - \Psi_{NIE, Z}(Q)(0, W))
\end{equation*}\]</span></p>
<p>Here, <span class="math inline">\(\bar{Q}_Y(Z, 1, W)\)</span> (the predicted values for <span class="math inline">\(Y\)</span> given <span class="math inline">\(Z\)</span> and <span class="math inline">\(W\)</span> when
<span class="math inline">\(A = 1\)</span>) is regressed on <span class="math inline">\(W\)</span>, among the treated units (for whom <span class="math inline">\(A = 1\)</span> is
observed) to obtain the conditional mean <span class="math inline">\(\Psi_{NIE, Z}(Q)(1, W)\)</span>. Performing
the same procedure, but now regressing <span class="math inline">\(\bar{Q}_Y(Z, 1, W)\)</span> on <span class="math inline">\(W\)</span> among the
control units (for whom <span class="math inline">\(A = 0\)</span> is observed) yields <span class="math inline">\(\Psi_{NIE,Z}(Q)(0, W)\)</span>. The
difference of these two estimates is the NIE and can be thought of as the
additive marginal effect of treatment on the conditional expectation of <span class="math inline">\(Y\)</span>
given <span class="math inline">\(W\)</span>, <span class="math inline">\(A = 1\)</span>, <span class="math inline">\(Z\)</span> through its effects on <span class="math inline">\(Z\)</span>. So, in the case of the NIE,
our estimate <span class="math inline">\(\psi_n\)</span> is slightly different, but the same quantity <span class="math inline">\(e(A \mid Z, W)\)</span> comes into play as the auxiliary covariate.</p>
</div>
<div id="the-population-intervention-indirect-effects" class="section level2">
<h2>
<span class="header-section-number">7.6</span> The Population Intervention (In)Direct Effects<a class="anchor" aria-label="anchor" href="#the-population-intervention-indirect-effects"><i class="fas fa-link"></i></a>
</h2>
<p>At times, the natural direct and indirect effects may prove too limiting, as
these effect definitions are based on <em>static interventions</em> (i.e., setting
<span class="math inline">\(A = 0\)</span> or <span class="math inline">\(A = 1\)</span>), which may be unrealistic for real-world interventions. In
such cases, one may turn instead to the population intervention direct effect
(PIDE) and the population intervention indirect effect (PIIE), which are based
on decomposing the effect of the population intervention effect (PIE) of
flexible stochastic interventions <span class="citation">(<span class="citeproc-not-found" data-reference-id="diaz2020causal"><strong>???</strong></span>)</span>.</p>
<p>A particular type of stochastic intervention well-suited to working with binary
treatments is the <em>incremental propensity score intervention</em> (IPSI), first
proposed by <span class="citation">Kennedy et al. (<a href="references.html#ref-kennedy2017nonparametric">2017</a>)</span>. Such interventions do not
deterministically set the treatment level of an observed unit to a fixed
quantity (i.e., setting <span class="math inline">\(A = 1\)</span>), but instead <em>alter the odds of receiving the
treatment</em> by a fixed amount (<span class="math inline">\(0 \leq \delta \leq \infty\)</span>) for each individual.
In particular, this intervention takes the form
<span class="math display">\[\begin{equation*}
  g_{\delta}(1 \mid w) = \frac{\delta g(1 \mid w)}{\delta g(1 \mid w) + 1
  - g(1\mid w)},
\end{equation*}\]</span>
where the scalar <span class="math inline">\(0 &lt; \delta &lt; \infty\)</span> specifies a <em>change in the odds of
receiving treatment</em>. As described by <span class="citation">(<span class="citeproc-not-found" data-reference-id="diaz2020causal"><strong>???</strong></span>)</span>, this stochastic
intervention is a special case of exponential tilting, a framework that unifies
post-intervention treatment values that are draws from an altered distribution.</p>
<p>Unlike the natural direct and indirect effects, the conditions required for
identifiability of the population intervention direct and indirect effects are
more lax. Most importantly, these differences involve a (1) treatment positivity
assumption that only requires that the counterfactual treatment be in the
observed support of the treatment <span class="math inline">\(\mathcal{A}\)</span>, and (2) no requirement of the
independence any cross-world counterfactuals.</p>
</div>
<div id="decomposing-the-population-intervention-effect" class="section level2">
<h2>
<span class="header-section-number">7.7</span> Decomposing the Population Intervention Effect<a class="anchor" aria-label="anchor" href="#decomposing-the-population-intervention-effect"><i class="fas fa-link"></i></a>
</h2>
<p>We may decompose the population intervention effect (PIE) in terms of the
<em>population intervention direct effect</em> (PIDE) and the <em>population
intervention indirect effect</em> (PIIE):
<span class="math display">\[\begin{equation*}
  \mathbb{E}\{Y(A_\delta)\} - \mathbb{E}Y =
    \overbrace{\mathbb{E}\{Y(A_\delta, Z(A_\delta))
      - Y(A_\delta, Z)\}}^{\text{PIIE}} +
    \overbrace{\mathbb{E}\{Y(A_\delta, Z) - Y(A, Z)\}}^{\text{PIDE}}.
\end{equation*}\]</span></p>
<p>This decomposition of the PIE as the sum of the population intervention direct
and indirect effects has an interpretation analogous to the corresponding
standard decomposition of the average treatment effect. In the sequel, we will
compute each of the components of the direct and indirect effects above using
appropriate estimators as follows</p>
<ul>
<li>For <span class="math inline">\(\mathbb{E}\{Y(A, Z)\}\)</span>, the sample mean <span class="math inline">\(\frac{1}{n}\sum_{i=1}^n Y_i\)</span> is
consistent;</li>
<li>for <span class="math inline">\(\mathbb{E}\{Y(A_{\delta}, Z)\}\)</span>, a TML estimator for the effect of a
joint intervention altering the treatment mechanism but not the mediation
mechanism, based on the proposal in <span class="citation">(<span class="citeproc-not-found" data-reference-id="diaz2020causal"><strong>???</strong></span>)</span>; and,</li>
<li>for <span class="math inline">\(\mathbb{E}\{Y(A_{\delta}, Z_{A_{\delta}})\}\)</span>, an efficient estimator for
the effect of a joint intervention altering both the treatment and mediation
mechanisms, as proposed in <span class="citation">Kennedy et al. (<a href="references.html#ref-kennedy2017nonparametric">2017</a>)</span> and implemented in the
<a href="https://github.com/ehkennedy/npcausal"><code>npcausal</code> R package</a>.</li>
</ul>
</div>
<div id="estimating-the-effect-decomposition-term" class="section level2">
<h2>
<span class="header-section-number">7.8</span> Estimating the Effect Decomposition Term<a class="anchor" aria-label="anchor" href="#estimating-the-effect-decomposition-term"><i class="fas fa-link"></i></a>
</h2>
<p>As described by <span class="citation">(<span class="citeproc-not-found" data-reference-id="diaz2020causal"><strong>???</strong></span>)</span>, the statistical functional identifying the
decomposition term that appears in both the PIDE and PIIE
<span class="math inline">\(\mathbb{E}\{Y(A_{\delta}, Z)\}\)</span>, which corresponds to altering the treatment
mechanism while keeping the mediation mechanism fixed, is
<span class="math display">\[\begin{equation*}
  \theta_0(\delta) = \int m_0(a, z, w) g_{0,\delta}(a \mid w) p_0(z, w)
    d\nu(a, z, w),
\end{equation*}\]</span>
for which a TML estimator is available. The corresponding <em>efficient influence
function</em> (EIF) with respect to the nonparametric model <span class="math inline">\(\mathcal{M}\)</span> is
<span class="math inline">\(D_{\eta,\delta}(o) = D^Y_{\eta,\delta}(o) + D^A_{\eta,\delta}(o) + D^{Z,W}_{\eta,\delta}(o) - \theta(\delta)\)</span>.</p>
<p>The TML estimator may be computed basd on the EIF estimating equation and may
incorporate cross-validation <span class="citation">(<span class="citeproc-not-found" data-reference-id="zheng2011cross"><strong>???</strong></span>; <span class="citeproc-not-found" data-reference-id="chernozhukov2018double"><strong>???</strong></span>)</span> to
circumvent possibly restrictive entropy conditions (e.g., Donsker class). The
resultant estimator is
<span class="math display">\[\begin{equation*}
  \hat{\theta}(\delta) = \frac{1}{n} \sum_{i = 1}^n D_{\hat{\eta}_{j(i)},
  \delta}(O_i) = \frac{1}{n} \sum_{i = 1}^n \left\{ D^Y_{\hat{\eta}_{j(i)},
  \delta}(O_i) + D^A_{\hat{\eta}_{j(i)}, \delta}(O_i) +
  D^{Z,W}_{\hat{\eta}_{j(i)}, \delta}(O_i) \right\},
\end{equation*}\]</span>
which is implemented in <code>tmle3mediate</code> (a one-step estimator is also avaialble,
in the <a href="https://github.com/nhejazi/medshift"><code>medshift</code> R package</a>). We
demonstrate the use of <code>tmle3mediate</code> to obtain <span class="math inline">\(\mathbb{E}\{Y(A_{\delta}, Z)\}\)</span>
via its TML estimator.</p>
</div>
<div id="evaluating-the-direct-and-indirect-effects" class="section level2">
<h2>
<span class="header-section-number">7.9</span> Evaluating the Direct and Indirect Effects<a class="anchor" aria-label="anchor" href="#evaluating-the-direct-and-indirect-effects"><i class="fas fa-link"></i></a>
</h2>
<p>We now turn to estimating the natural direct and indirect effects, as well as
the population intervention direct effect, using the WASH Benefits data,
introduced in earlier chapters. Let’s first load the data:</p>
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://r-datatable.com">data.table</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tlverse.org/sl3">sl3</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tlverse.org/tmle3">tmle3</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tlverse.org/tmle3mediate">tmle3mediate</a></span><span class="op">)</span>

<span class="co"># download data</span>
<span class="va">washb_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/fread.html">fread</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span>
    <span class="st">"https://raw.githubusercontent.com/tlverse/tlverse-data/master/"</span>,
    <span class="st">"wash-benefits/washb_data.csv"</span>
  <span class="op">)</span>,
  stringsAsFactors <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span>

<span class="co"># make intervention node binary</span>
<span class="va">washb_data</span><span class="op">[</span>, <span class="va">tr</span> <span class="op">:=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">tr</span> <span class="op">!=</span> <span class="st">"Control"</span><span class="op">)</span><span class="op">]</span></code></pre></div>
<p>We’ll next define the baseline covariates <span class="math inline">\(W\)</span>, treatment <span class="math inline">\(A\)</span>, mediators <span class="math inline">\(Z\)</span>,
and outcome <span class="math inline">\(Y\)</span> nodes of the NPSEM via a “Node List” object:</p>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">node_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
  W <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>
    <span class="st">"momage"</span>, <span class="st">"momedu"</span>, <span class="st">"momheight"</span>, <span class="st">"hfiacat"</span>, <span class="st">"Nlt18"</span>, <span class="st">"Ncomp"</span>, <span class="st">"watmin"</span>,
    <span class="st">"elec"</span>, <span class="st">"floor"</span>, <span class="st">"walls"</span>, <span class="st">"roof"</span>
  <span class="op">)</span>,
  A <span class="op">=</span> <span class="st">"tr"</span>,
  Z <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"sex"</span>, <span class="st">"month"</span>, <span class="st">"aged"</span><span class="op">)</span>,
  Y <span class="op">=</span> <span class="st">"whz"</span>
<span class="op">)</span></code></pre></div>
<p>Here the <code>node_list</code> encodes the parents of each node – for example, <span class="math inline">\(Z\)</span> (the
mediators) have parents <span class="math inline">\(A\)</span> (the treatment) and <span class="math inline">\(W\)</span> (the baseline confounders),
and <span class="math inline">\(Y\)</span> (the outcome) has parents <span class="math inline">\(Z\)</span>, <span class="math inline">\(A\)</span>, and <span class="math inline">\(W\)</span>. We’ll also handle any
missingness in the data by invoking <code>process_missing</code>:</p>
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">processed</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/tmle3/reference/process_missing.html">process_missing</a></span><span class="op">(</span><span class="va">washb_data</span>, <span class="va">node_list</span><span class="op">)</span>
<span class="va">washb_data</span> <span class="op">&lt;-</span> <span class="va">processed</span><span class="op">$</span><span class="va">data</span>
<span class="va">node_list</span> <span class="op">&lt;-</span> <span class="va">processed</span><span class="op">$</span><span class="va">node_list</span></code></pre></div>
<p>We’ll now construct an ensemble learner using a handful of popular machine
learning algorithms:</p>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># SL learners used for continuous data (the nuisance parameter M)</span>
<span class="va">enet_contin_learner</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glmnet.html">Lrnr_glmnet</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>
  alpha <span class="op">=</span> <span class="fl">0.5</span>, family <span class="op">=</span> <span class="st">"gaussian"</span>, nfolds <span class="op">=</span> <span class="fl">5</span>
<span class="op">)</span>
<span class="va">lasso_contin_learner</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glmnet.html">Lrnr_glmnet</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>
  alpha <span class="op">=</span> <span class="fl">1</span>, family <span class="op">=</span> <span class="st">"gaussian"</span>, nfolds <span class="op">=</span> <span class="fl">5</span>
<span class="op">)</span>
<span class="va">fglm_contin_learner</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glm_fast.html">Lrnr_glm_fast</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">gaussian</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span>
<span class="va">mean_learner</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_mean.html">Lrnr_mean</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span>
<span class="va">contin_learner_lib</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Stack.html">Stack</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>
  <span class="va">enet_contin_learner</span>, <span class="va">lasso_contin_learner</span>, <span class="va">fglm_contin_learner</span>, <span class="va">mean_learner</span>
<span class="op">)</span>
<span class="va">sl_contin_learner</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_sl.html">Lrnr_sl</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>learners <span class="op">=</span> <span class="va">contin_learner_lib</span><span class="op">)</span>

<span class="co"># SL learners used for binary data (nuisance parameters G and E in this case)</span>
<span class="va">enet_binary_learner</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glmnet.html">Lrnr_glmnet</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>
  alpha <span class="op">=</span> <span class="fl">0.5</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, nfolds <span class="op">=</span> <span class="fl">5</span>
<span class="op">)</span>
<span class="va">lasso_binary_learner</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glmnet.html">Lrnr_glmnet</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>
  alpha <span class="op">=</span> <span class="fl">1</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, nfolds <span class="op">=</span> <span class="fl">5</span>
<span class="op">)</span>
<span class="va">fglm_binary_learner</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glm_fast.html">Lrnr_glm_fast</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span>
<span class="va">binary_learner_lib</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Stack.html">Stack</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>
  <span class="va">enet_binary_learner</span>, <span class="va">lasso_binary_learner</span>, <span class="va">fglm_binary_learner</span>, <span class="va">mean_learner</span>
<span class="op">)</span>
<span class="va">sl_binary_learner</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_sl.html">Lrnr_sl</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>learners <span class="op">=</span> <span class="va">binary_learner_lib</span><span class="op">)</span>

<span class="co"># create list for treatment and outcome mechanism regressions</span>
<span class="va">learner_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
  Y <span class="op">=</span> <span class="va">sl_contin_learner</span>,
  A <span class="op">=</span> <span class="va">sl_binary_learner</span>
<span class="op">)</span></code></pre></div>
</div>
<div id="estimating-the-natural-indirect-effect" class="section level2">
<h2>
<span class="header-section-number">7.10</span> Estimating the Natural Indirect Effect<a class="anchor" aria-label="anchor" href="#estimating-the-natural-indirect-effect"><i class="fas fa-link"></i></a>
</h2>
<p>We demonstrate calculation of the NIE below, starting by instantiating a “Spec”
object that encodes exactly which learners to use for the nuisance parameters
<span class="math inline">\(e(A \mid Z, W)\)</span> and <span class="math inline">\(\Psi_Z\)</span>. We then pass our Spec object to the <code>tmle3</code>
function, alongside the data, the node list (created above), and a learner list
indicating which machine learning algorithms to use for estimating the nuisance
parameters based on <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span>.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb55-1" data-line-number="1">tmle_spec_NIE &lt;-<span class="st"> </span><span class="kw">tmle_NIE</span>(</a>
<a class="sourceLine" id="cb55-2" data-line-number="2">  <span class="dt">e_learners =</span> Lrnr_cv<span class="op">$</span><span class="kw">new</span>(lasso_binary_learner, <span class="dt">full_fit =</span> <span class="ot">TRUE</span>),</a>
<a class="sourceLine" id="cb55-3" data-line-number="3">  <span class="dt">psi_Z_learners =</span> Lrnr_cv<span class="op">$</span><span class="kw">new</span>(lasso_contin_learner, <span class="dt">full_fit =</span> <span class="ot">TRUE</span>),</a>
<a class="sourceLine" id="cb55-4" data-line-number="4">  <span class="dt">max_iter =</span> <span class="dv">1</span></a>
<a class="sourceLine" id="cb55-5" data-line-number="5">)</a>
<a class="sourceLine" id="cb55-6" data-line-number="6">washb_NIE &lt;-<span class="st"> </span><span class="kw">tmle3</span>(</a>
<a class="sourceLine" id="cb55-7" data-line-number="7">  tmle_spec_NIE, washb_data, node_list, learner_list</a>
<a class="sourceLine" id="cb55-8" data-line-number="8">)</a>
<a class="sourceLine" id="cb55-9" data-line-number="9">washb_NIE</a>
<a class="sourceLine" id="cb55-10" data-line-number="10">A tmle3_Fit that took <span class="dv">1</span> <span class="kw">step</span>(s)</a>
<a class="sourceLine" id="cb55-11" data-line-number="11">   type                  param  init_est  tmle_est       se     lower    upper</a>
<a class="sourceLine" id="cb55-12" data-line-number="12"><span class="dv">1</span><span class="op">:</span><span class="st">  </span>NIE NIE[Y_{A=<span class="dv">1</span>} <span class="op">-</span><span class="st"> </span>Y_{A=<span class="dv">0</span>}] <span class="fl">0.0030972</span> <span class="fl">0.0029694</span> <span class="fl">0.015535</span> <span class="fl">-0.027479</span> <span class="fl">0.033418</span></a>
<a class="sourceLine" id="cb55-13" data-line-number="13">   psi_transformed lower_transformed upper_transformed</a>
<a class="sourceLine" id="cb55-14" data-line-number="14"><span class="dv">1</span><span class="op">:</span><span class="st">       </span><span class="fl">0.0029694</span>         <span class="fl">-0.027479</span>          <span class="fl">0.033418</span></a></code></pre></div>
<p>Based on the output, we conclude that the indirect effect of the treatment
through the mediators (sex, month, aged) is
0.00297.</p>
</div>
<div id="estimating-the-natural-direct-effect" class="section level2">
<h2>
<span class="header-section-number">7.11</span> Estimating the Natural Direct Effect<a class="anchor" aria-label="anchor" href="#estimating-the-natural-direct-effect"><i class="fas fa-link"></i></a>
</h2>
<p>An analogous procedure applies for estimation of the NDE, only replacing the
Spec object for the NIE with <code>tmle_spec_NDE</code> to define learners for the NDE
nuisance parameters:</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb56-1" data-line-number="1">tmle_spec_NDE &lt;-<span class="st"> </span><span class="kw">tmle_NDE</span>(</a>
<a class="sourceLine" id="cb56-2" data-line-number="2">  <span class="dt">e_learners =</span> Lrnr_cv<span class="op">$</span><span class="kw">new</span>(lasso_binary_learner, <span class="dt">full_fit =</span> <span class="ot">TRUE</span>),</a>
<a class="sourceLine" id="cb56-3" data-line-number="3">  <span class="dt">psi_Z_learners =</span> Lrnr_cv<span class="op">$</span><span class="kw">new</span>(lasso_contin_learner, <span class="dt">full_fit =</span> <span class="ot">TRUE</span>),</a>
<a class="sourceLine" id="cb56-4" data-line-number="4">  <span class="dt">max_iter =</span> <span class="dv">1</span></a>
<a class="sourceLine" id="cb56-5" data-line-number="5">)</a>
<a class="sourceLine" id="cb56-6" data-line-number="6">washb_NDE &lt;-<span class="st"> </span><span class="kw">tmle3</span>(</a>
<a class="sourceLine" id="cb56-7" data-line-number="7">  tmle_spec_NDE, washb_data, node_list, learner_list</a>
<a class="sourceLine" id="cb56-8" data-line-number="8">)</a>
<a class="sourceLine" id="cb56-9" data-line-number="9">washb_NDE</a>
<a class="sourceLine" id="cb56-10" data-line-number="10">A tmle3_Fit that took <span class="dv">1</span> <span class="kw">step</span>(s)</a>
<a class="sourceLine" id="cb56-11" data-line-number="11">   type                  param init_est tmle_est      se    lower  upper</a>
<a class="sourceLine" id="cb56-12" data-line-number="12"><span class="dv">1</span><span class="op">:</span><span class="st">  </span>NDE NDE[Y_{A=<span class="dv">1</span>} <span class="op">-</span><span class="st"> </span>Y_{A=<span class="dv">0</span>}] <span class="fl">0.028931</span> <span class="fl">0.028931</span> <span class="fl">0.31693</span> <span class="fl">-0.59223</span> <span class="fl">0.6501</span></a>
<a class="sourceLine" id="cb56-13" data-line-number="13">   psi_transformed lower_transformed upper_transformed</a>
<a class="sourceLine" id="cb56-14" data-line-number="14"><span class="dv">1</span><span class="op">:</span><span class="st">        </span><span class="fl">0.028931</span>          <span class="fl">-0.59223</span>            <span class="fl">0.6501</span></a></code></pre></div>
<p>From this, we can draw the conclusion that the direct effect of the treatment
(through all paths not involving the mediators (sex, month, aged)) is
0.02893. Note that, together, the estimates of
the natural direct and indirect effects approximately recover the <em>average
treatment effect</em>, that is, based on these estimates of the NDE and NIE, the
ATE is roughly
0.0319.</p>
</div>
<div id="estimating-the-population-intervention-direct-effect" class="section level2">
<h2>
<span class="header-section-number">7.12</span> Estimating the Population Intervention Direct Effect<a class="anchor" aria-label="anchor" href="#estimating-the-population-intervention-direct-effect"><i class="fas fa-link"></i></a>
</h2>
<p>As previously noted, the assumptions underlying the natural direct and indirect
effects may be challenging to justify; moreover, the effect definitions
themselves depend on the application of a static intervention to the treatment,
sharply limiting their flexibility. When considering binary treatments,
incremental propensity score shifts provide an alternative class of flexible,
stochastic interventions. We’ll now consider estimating the PIDE with an IPSI
that modulates the odds of receiving treatment by <span class="math inline">\(\delta = 3\)</span>. Such an
intervention may be interpreted (hypothetically) as the effect of a design that
encourages study participants to opt in to receiving the treatment, thus
increasing their relative odds of receiving said treatment. To exemplify our
approach, we postulate a motivational intervention that <em>triples the odds</em>
(i.e., <span class="math inline">\(\delta = 3\)</span>) of receiving the treatment for each individual:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb57-1" data-line-number="1"><span class="co"># set the IPSI multiplicative shift</span></a>
<a class="sourceLine" id="cb57-2" data-line-number="2">delta_ipsi &lt;-<span class="st"> </span><span class="dv">3</span></a>
<a class="sourceLine" id="cb57-3" data-line-number="3"></a>
<a class="sourceLine" id="cb57-4" data-line-number="4"><span class="co"># instantiate tmle3 spec for stochastic mediation</span></a>
<a class="sourceLine" id="cb57-5" data-line-number="5">tmle_spec_pie_decomp &lt;-<span class="st"> </span><span class="kw">tmle_medshift</span>(</a>
<a class="sourceLine" id="cb57-6" data-line-number="6">  <span class="dt">delta =</span> delta_ipsi,</a>
<a class="sourceLine" id="cb57-7" data-line-number="7">  <span class="dt">e_learners =</span> Lrnr_cv<span class="op">$</span><span class="kw">new</span>(lasso_binary_learner, <span class="dt">full_fit =</span> <span class="ot">TRUE</span>),</a>
<a class="sourceLine" id="cb57-8" data-line-number="8">  <span class="dt">phi_learners =</span> Lrnr_cv<span class="op">$</span><span class="kw">new</span>(lasso_contin_learner, <span class="dt">full_fit =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb57-9" data-line-number="9">)</a>
<a class="sourceLine" id="cb57-10" data-line-number="10"></a>
<a class="sourceLine" id="cb57-11" data-line-number="11"><span class="co"># compute the TML estimate</span></a>
<a class="sourceLine" id="cb57-12" data-line-number="12">washb_pie_decomp &lt;-<span class="st"> </span><span class="kw">tmle3</span>(</a>
<a class="sourceLine" id="cb57-13" data-line-number="13">  tmle_spec_pie_decomp, washb_data, node_list, learner_list</a>
<a class="sourceLine" id="cb57-14" data-line-number="14">)</a>
<a class="sourceLine" id="cb57-15" data-line-number="15">washb_pie_decomp</a>
<a class="sourceLine" id="cb57-16" data-line-number="16">A tmle3_Fit that took <span class="dv">510</span> <span class="kw">step</span>(s)</a>
<a class="sourceLine" id="cb57-17" data-line-number="17">   type         param init_est tmle_est       se   lower    upper</a>
<a class="sourceLine" id="cb57-18" data-line-number="18"><span class="dv">1</span><span class="op">:</span><span class="st"> </span>PIDE E[Y_{A=<span class="ot">NULL</span>}] <span class="fl">-0.58163</span> <span class="fl">-0.58385</span> <span class="fl">0.016302</span> <span class="fl">-0.6158</span> <span class="fl">-0.55189</span></a>
<a class="sourceLine" id="cb57-19" data-line-number="19">   psi_transformed lower_transformed upper_transformed</a>
<a class="sourceLine" id="cb57-20" data-line-number="20"><span class="dv">1</span><span class="op">:</span><span class="st">        </span><span class="fl">-0.58385</span>           <span class="fl">-0.6158</span>          <span class="fl">-0.55189</span></a></code></pre></div>
<p>Recall that, based on the decomposition outlined previously, the PIDE may be
denoted <span class="math inline">\(\beta_{\text{PIDE}}(\delta) = \theta_0(\delta) - \mathbb{E}Y\)</span>. Thus, an
estimator of the PIDE, <span class="math inline">\(\hat{\beta}_{\text{PIDE}}(\delta)\)</span> may be expressed as a
composition of estimators of its constituent parameters:
<span class="math display">\[\begin{equation*}
  \hat{\beta}_{\text{PIDE}}({\delta}) = \hat{\theta}(\delta) -
  \frac{1}{n} \sum_{i = 1}^n Y_i.
\end{equation*}\]</span></p>
<p>Based on the above, we may construct an estimator of the PIDE using the already
estimated decomposition term and the empirical (marginal) mean of the outcome.
Thus, our estimate of the PIDE is approximately
0.00223.
Note that this is a straightforward application of the delta method and could
equivalently be performed using the functionality exposed in the <a href="https://github.com/tlverse/tmle3"><code>tmle3</code>
package</a>.</p>
<!--

```r
tmle_task <- tmle_spec_pie_decomp$make_tmle_task(
  weight_behavior_complete, node_list
)
initial_likelihood <- tmle_spec_pie_decomp$make_initial_likelihood(
  tmle_task, learner_list
)
```
-->
<!--
## Exercises

### Review of Key Concepts

1. Additivity of the natural (in)direct effects and the ATE.

2. Working with continuous mediators.

3. TODO

### The Ideas in Action

1. TODO

2. TODO

3. TODO
-->
<!--
## Appendix

### Exercise solutions
-->

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="tmle3.html"><span class="header-section-number">6</span> The TMLE Framework</a></div>
<div class="next"><a href="r6.html"><span class="header-section-number">8</span> A Primer on the R6 Class System</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#causal-mediation-analysis"><span class="header-section-number">7</span> Causal Mediation Analysis</a></li>
<li><a class="nav-link" href="#introduction-to-causal-mediation-analysis"><span class="header-section-number">7.1</span> Introduction to Causal Mediation Analysis</a></li>
<li><a class="nav-link" href="#data-structure-and-notation"><span class="header-section-number">7.2</span> Data Structure and Notation</a></li>
<li><a class="nav-link" href="#decomposing-the-average-treatment-effect"><span class="header-section-number">7.3</span> Decomposing the Average Treatment Effect</a></li>
<li><a class="nav-link" href="#the-natural-direct-effect"><span class="header-section-number">7.4</span> The Natural Direct Effect</a></li>
<li><a class="nav-link" href="#the-natural-indirect-effect"><span class="header-section-number">7.5</span> The Natural Indirect Effect</a></li>
<li><a class="nav-link" href="#the-population-intervention-indirect-effects"><span class="header-section-number">7.6</span> The Population Intervention (In)Direct Effects</a></li>
<li><a class="nav-link" href="#decomposing-the-population-intervention-effect"><span class="header-section-number">7.7</span> Decomposing the Population Intervention Effect</a></li>
<li><a class="nav-link" href="#estimating-the-effect-decomposition-term"><span class="header-section-number">7.8</span> Estimating the Effect Decomposition Term</a></li>
<li><a class="nav-link" href="#evaluating-the-direct-and-indirect-effects"><span class="header-section-number">7.9</span> Evaluating the Direct and Indirect Effects</a></li>
<li><a class="nav-link" href="#estimating-the-natural-indirect-effect"><span class="header-section-number">7.10</span> Estimating the Natural Indirect Effect</a></li>
<li><a class="nav-link" href="#estimating-the-natural-direct-effect"><span class="header-section-number">7.11</span> Estimating the Natural Direct Effect</a></li>
<li><a class="nav-link" href="#estimating-the-population-intervention-direct-effect"><span class="header-section-number">7.12</span> Estimating the Population Intervention Direct Effect</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/tlverse/tlverse-handbook/blob/master/10-tmle3mediate.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/tlverse/tlverse-handbook/edit/master/10-tmle3mediate.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Targeted Learning in R</strong>: Causal Data Science with the tlverse Software Ecosystem" was written by Mark van der Laan, Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips, Alan Hubbard. It was last built on April 19, 2021.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
