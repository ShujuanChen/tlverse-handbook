\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames*,x11names*}{xcolor}
%
\documentclass[12pt, krantz2,]{krantz}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\usepackage{xcolor}
\usepackage{hyperref}
\hypersetup{
            pdftitle={Targeted Learning in R},
            pdfauthor={Mark van der Laan, Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips, Alan Hubbard},
            colorlinks=true,
            linkcolor=Maroon,
            citecolor=Blue,
            urlcolor=Blue,
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{listings}
\newcommand{\passthrough}[1]{#1}
\usepackage{longtable,booktabs}
% Fix footnotes in tables (requires footnote package)
\IfFileExists{footnote.sty}{\usepackage{footnote}\makesavenoteenv{longtable}}{}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{booktabs}
\usepackage[inline]{enumitem}
\usepackage{float}
\usepackage{graphicx}
\usepackage[round]{natbib}
\usepackage{geometry}
\usepackage{tikz}
\usepackage[english]{babel}
\usepackage{longtable}
\usepackage{color}
\usepackage{mathtools,bm,amssymb,amsmath,amsthm}
\usepackage{multirow}
\usepackage[titletoc,title]{appendix}
\usepackage{authblk}
\usepackage{setspace}
\usepackage{dsfont}
\PassOptionsToPackage{utf8x}{inputenc}
\usepackage[OT1]{fontenc}
\usepackage[bf,singlelinecheck=off]{caption}
\usepackage{refcount}
\usepackage{framed,color}
\definecolor{shadecolor}{RGB}{248,248,248}
\urlstyle{tt}

\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.8}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\floatpagefraction}{0.75}

\usepackage{makeidx}
\makeindex

\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\newtheorem*{remark}{Remark}
\newtheorem{theorem}{Theorem}
\AtEndDocument{\refstepcounter{theorem}\label{finalthm}}
{
  \theoremstyle{definition}
  \newtheorem{assumption}{}
}
{
  \theoremstyle{definition}
  \newtheorem{assumptioniden}{}
}
{
  \theoremstyle{definition}
  \newtheorem{example}{Example}[section]
}
\DeclareMathOperator{\opt}{opt}
\DeclareMathOperator{\dr}{IF}
\newcommand{\hopt}{\hat h_{\opt}}
\newcommand{\supp}{\mathop{\mathrm{supp}}}
\renewcommand\theassumptioniden{{A}\arabic{assumptioniden}}
\renewcommand\theassumption{{C}\arabic{assumption}}
\renewcommand\theexample{\arabic{example}}

\newtheorem{lemma}{Lemma}
\newtheorem{coro}{Corollary}
\newtheorem{definition}{Definition}
\DeclareMathOperator{\bern}{Bern}
\DeclareMathOperator{\var}{Var}
\DeclareMathOperator{\Rem}{Rem}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\1}{\mathbbm{1}}
\DeclareMathOperator{\expit}{expit}
\DeclareMathOperator{\logit}{logit}
\newcommand{\indep}{\mbox{$\perp\!\!\!\perp$}}
\DeclareMathOperator*{\argmin}{\arg\!\min}
\DeclarePairedDelimiterX{\norm}[1]{\lVert}{\rVert}{#1}
\usepackage{color}
\lstset{
  breaklines=true,
  language=R,
  showspaces=false, 
  showstringspaces=false,
  basicstyle=\footnotesize\ttfamily,
  keywordstyle=\bfseries\color{green!40!black},
  commentstyle=\itshape\color{purple!40!black},
  identifierstyle=\color{blue},
  stringstyle=\color{orange}
}

% setting bookdown frontmatter option
\frontmatter
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Targeted Learning in R}
\providecommand{\subtitle}[1]{}
\subtitle{Causal Data Science with the tlverse Software Ecosystem}
\author{Mark van der Laan, Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips, Alan Hubbard}
\date{April 28, 2021}

\begin{document}
\maketitle

% you may need to leave a few empty pages before the dedication page

%\cleardoublepage\newpage\thispagestyle{empty}\null
%\cleardoublepage\newpage\thispagestyle{empty}\null
%\cleardoublepage\newpage
\thispagestyle{empty}

\begin{center}
%\includegraphics{images/dedication.pdf}
\end{center}

\setlength{\abovedisplayskip}{-5pt}
\setlength{\abovedisplayshortskip}{-5pt}

% setting bookdown mainmatter (e.g., arabic numerals for page numbering)
\mainmatter

{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\hypertarget{about-this-book}{%
\chapter*{About this book}\label{about-this-book}}


\emph{Targeted Learning in \passthrough{\lstinline!R!}: Causal Data Science with the \passthrough{\lstinline!tlverse!} Software
Ecosystem} is an open source, reproducible electronic handbook for applying the
Targeted Learning methodology in practice using the \href{https://github.com/tlverse}{\passthrough{\lstinline!tlverse!} software
ecosystem}. This work is currently in an early draft
phase and is available to facilitate input from the community. To view or
contribute to the available content, consider visiting the \href{https://github.com/tlverse/tlverse-handbook}{GitHub
repository}.

\hypertarget{outline}{%
\section{Outline}\label{outline}}

The contents of this handbook are meant to serve as a reference guide for
applied research as well as materials that can be taught in a series of short
courses focused on the applications of Targeted Learning. Each section
introduces a set of distinct causal questions, motivated by a case study,
alongside statistical methodology and software for assessing the causal claim of
interest. The (evolving) set of materials includes

\begin{itemize}
\tightlist
\item
  Motivation: \href{https://senseaboutscienceusa.org/super-learning-and-the-revolution-in-knowledge/}{Why we need a statistical
  revolution}
\item
  The Roadmap and introductory case study: the WASH Beneifits data
\item
  Introduction to the \href{https://tlverse.org}{\passthrough{\lstinline!tlverse!} software
  ecosystem}
\item
  Cross-validation with the \href{https://github.com/tlverse/origami}{\passthrough{\lstinline!origami!}}
  package
\item
  Ensemble machine learning with the
  \href{https://github.com/tlverse/sl3}{\passthrough{\lstinline!sl3!}} package
\item
  Targeted learning for causal inference with the
  \href{https://github.com/tlverse/tmle3}{\passthrough{\lstinline!tmle3!}} package
\item
  Optimal treatments regimes and the
  \href{https://github.com/tlverse/tmle3mopttx}{\passthrough{\lstinline!tmle3mopttx!}} package
\item
  Stochastic treatment regimes and the
  \href{https://github.com/tlverse/tmle3shift}{\passthrough{\lstinline!tmle3shift!}} package
\item
  Causal mediation analysis with the
  \href{https://github.com/tlverse/tmle3mediate}{\passthrough{\lstinline!tmle3mediate!}} package
\item
  \emph{Coda}: \href{https://senseaboutscienceusa.org/super-learning-and-the-revolution-in-knowledge/}{Why we need a statistical
  revolution}
\end{itemize}

\hypertarget{what-this-book-is-not}{%
\section*{What this book is not}\label{what-this-book-is-not}}


The focus of this work is \textbf{not} on providing in-depth technical descriptions
of current statistical methodology or recent advancements. Instead, the goal is
to convey key details of state-of-the-art techniques in an manner that is both
clear and complete, without burdening the reader with extraneous information.
We hope that the presentations herein will serve as references for researchers
-- methodologists and domain specialists alike -- that empower them to deploy
the central tools of Targeted Learning in an efficient manner. For technical
details and in-depth descriptions of both classical theory and recent advances
in the field of Targeted Learning, the interested reader is invited to consult
\citet{vdl2011targeted} and/or \citet{vdl2018targeted} as appropriate. The primary literature
in statistical causal inference, machine learning, and non/semiparametric theory
include many of the most recent advances in Targeted Learning and related areas.

\hypertarget{about-the-authors}{%
\section*{About the authors}\label{about-the-authors}}


\hypertarget{mark-van-der-laan}{%
\subsection*{Mark van der Laan}\label{mark-van-der-laan}}


Mark van der Laan, PhD, is Professor of Biostatistics and Statistics at UC
Berkeley. His research interests include statistical methods in computational
biology, survival analysis, censored data, adaptive designs, targeted maximum
likelihood estimation, causal inference, data-adaptive loss-based learning, and
multiple testing. His research group developed loss-based super learning in
semiparametric models, based on cross-validation, as a generic optimal tool for
the estimation of infinite-dimensional parameters, such as nonparametric density
estimation and prediction with both censored and uncensored data. Building on
this work, his research group developed targeted maximum likelihood estimation
for a target parameter of the data-generating distribution in arbitrary
semiparametric and nonparametric models, as a generic optimal methodology for
statistical and causal inference. Most recently, Mark's group has focused in
part on the development of a centralized, principled set of software tools for
targeted learning, the \passthrough{\lstinline!tlverse!}.

\hypertarget{jeremy-coyle}{%
\subsection*{Jeremy Coyle}\label{jeremy-coyle}}


Jeremy Coyle, PhD, is a consulting data scientist and statistical programmer,
currently leading the software development effort that has produced the
\passthrough{\lstinline!tlverse!} ecosystem of R packages and related software tools. Jeremy earned his
PhD in Biostatistics from UC Berkeley in 2016, primarily under the supervision
of Alan Hubbard.

\hypertarget{nima-hejazi}{%
\subsection*{Nima Hejazi}\label{nima-hejazi}}


Nima Hejazi is a PhD candidate in biostatistics, working under the collaborative
direction of Mark van der Laan and Alan Hubbard. Nima is affiliated with UC
Berkeley's Center for Computational Biology and NIH Biomedical Big Data training
program, as well as with the Fred Hutchinson Cancer Research Center. Previously,
he earned an MA in Biostatistics and a BA (with majors in Molecular and Cell
Biology, Psychology, and Public Health), both at UC Berkeley. His research
interests fall at the intersection of causal inference and machine learning,
drawing on ideas from non/semi-parametric estimation in large, flexible
statistical models to develop efficient and robust statistical procedures for
evaluating complex target estimands in observational and randomized studies.
Particular areas of current emphasis include mediation/path analysis,
outcome-dependent sampling designs, targeted loss-based estimation, and vaccine
efficacy trials. Nima is also passionate about statistical computing and open
source software development for applied statistics.

\hypertarget{ivana-malenica}{%
\subsection*{Ivana Malenica}\label{ivana-malenica}}


Ivana Malenica is a PhD student in biostatistics advised by Mark van der Laan.
Ivana is currently a fellow at the Berkeley Institute for Data Science, after
serving as a NIH Biomedical Big Data and Freeport-McMoRan Genomic Engine fellow.
She earned her Master's in Biostatistics and Bachelor's in Mathematics, and
spent some time at the Translational Genomics Research Institute. Very broadly,
her research interests span non/semi-parametric theory, probability theory,
machine learning, causal inference and high-dimensional statistics. Most of her
current work involves complex dependent settings (dependence through time and
network) and adaptive sequential designs.

\hypertarget{rachael-phillips}{%
\subsection*{Rachael Phillips}\label{rachael-phillips}}


Rachael Phillips is a PhD student in biostatistics, advised by Alan Hubbard and
Mark van der Laan. She has an MA in Biostatistics, BS in Biology, and BA in
Mathematics. A student of targeted learning and causal inference; her research
integrates personalized medicine, human-computer interaction, experimental
design, and regulatory policy.

\hypertarget{alan-hubbard}{%
\subsection*{Alan Hubbard}\label{alan-hubbard}}


Alan Hubbard is Professor of Biostatistics, former head of the Division of
Biostatistics at UC Berkeley, and head of data analytics core at UC Berkeley's
SuperFund research program. His current research interests include causal
inference, variable importance analysis, statistical machine learning,
estimation of and inference for data-adaptive statistical target parameters, and
targeted minimum loss-based estimation. Research in his group is generally
motivated by applications to problems in computational biology, epidemiology,
and precision medicine.

\hypertarget{learn}{%
\section{Learning resources}\label{learn}}

To effectively utilize this handbook, the reader need not be a fully trained
statistician to begin understanding and applying these methods. However, it is
highly recommended for the reader to have an understanding of basic statistical
concepts such as confounding, probability distributions, confidence intervals,
hypothesis tests, and regression. Advanced knowledge of mathematical statistics
may be useful but is not necessary. Familiarity with the \passthrough{\lstinline!R!} programming
language will be essential. We also recommend an understanding of introductory
causal inference.

For learning the \passthrough{\lstinline!R!} programming language we recommend the following (free)
introductory resources:

\begin{itemize}
\tightlist
\item
  \href{http://swcarpentry.github.io/r-novice-inflammation/}{Software Carpentry's \emph{Programming with
  \passthrough{\lstinline!R!}}}
\item
  \href{http://swcarpentry.github.io/r-novice-gapminder/}{Software Carpentry's \emph{\passthrough{\lstinline!R!} for Reproducible Scientific
  Analysis}}
\item
  \href{https://r4ds.had.co.nz}{Garret Grolemund and Hadley Wickham's \emph{\passthrough{\lstinline!R!} for Data
  Science}}
\end{itemize}

For a general introduction to causal inference, we recommend

\begin{itemize}
\tightlist
\item
  \href{https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/}{Miguel A. Hernán and James M. Robins' \emph{Causal Inference: What If},
  2021}
\item
  \href{https://www.coursera.org/learn/crash-course-in-causality}{Jason A. Roy's \emph{A Crash Course in Causality: Inferring Causal Effects from
  Observational Data} on
  Coursera}
\end{itemize}

\hypertarget{setup}{%
\section{Setup instructions}\label{setup}}

\hypertarget{r-and-rstudio}{%
\subsection{R and RStudio}\label{r-and-rstudio}}

\textbf{R} and \textbf{RStudio} are separate downloads and installations. R is the
underlying statistical computing environment. RStudio is a graphical integrated
development environment (IDE) that makes using R much easier and more
interactive. You need to install R before you install RStudio.

\hypertarget{windows}{%
\subsubsection{Windows}\label{windows}}

\hypertarget{if-you-already-have-r-and-rstudio-installed}{%
\paragraph{If you already have R and RStudio installed}\label{if-you-already-have-r-and-rstudio-installed}}

\begin{itemize}
\tightlist
\item
  Open RStudio, and click on ``Help'' \textgreater{} ``Check for updates''. If a new version is
  available, quit RStudio, and download the latest version for RStudio.
\item
  To check which version of R you are using, start RStudio and the first thing
  that appears in the console indicates the version of R you are
  running. Alternatively, you can type \passthrough{\lstinline!sessionInfo()!}, which will also display
  which version of R you are running. Go on the \href{https://cran.r-project.org/bin/windows/base/}{CRAN
  website} and check whether a
  more recent version is available. If so, please download and install it. You
  can \href{https://cran.r-project.org/bin/windows/base/rw-FAQ.html\#How-do-I-UNinstall-R_003f}{check here}
  for more information on how to remove old versions from your system if you
  wish to do so.
\end{itemize}

\hypertarget{if-you-dont-have-r-and-rstudio-installed}{%
\paragraph{If you don't have R and RStudio installed}\label{if-you-dont-have-r-and-rstudio-installed}}

\begin{itemize}
\tightlist
\item
  Download R from
  the \href{http://cran.r-project.org/bin/windows/base/release.htm}{CRAN website}.
\item
  Run the \passthrough{\lstinline!.exe!} file that was just downloaded
\item
  Go to the \href{https://www.rstudio.com/products/rstudio/download/\#download}{RStudio download page}
\item
  Under \emph{Installers} select \textbf{RStudio x.yy.zzz - Windows
  XP/Vista/7/8} (where x, y, and z represent version numbers)
\item
  Double click the file to install it
\item
  Once it's installed, open RStudio to make sure it works and you don't get any
  error messages.
\end{itemize}

\hypertarget{macos-mac-os-x}{%
\subsubsection{macOS / Mac OS X}\label{macos-mac-os-x}}

\hypertarget{if-you-already-have-r-and-rstudio-installed-1}{%
\paragraph{If you already have R and RStudio installed}\label{if-you-already-have-r-and-rstudio-installed-1}}

\begin{itemize}
\tightlist
\item
  Open RStudio, and click on ``Help'' \textgreater{} ``Check for updates''. If a new version is
  available, quit RStudio, and download the latest version for RStudio.
\item
  To check the version of R you are using, start RStudio and the first thing
  that appears on the terminal indicates the version of R you are running.
  Alternatively, you can type \passthrough{\lstinline!sessionInfo()!}, which will also display which
  version of R you are running. Go on the \href{https://cran.r-project.org/bin/macosx/}{CRAN
  website} and check whether a more
  recent version is available. If so, please download and install it.
\end{itemize}

\hypertarget{if-you-dont-have-r-and-rstudio-installed-1}{%
\paragraph{If you don't have R and RStudio installed}\label{if-you-dont-have-r-and-rstudio-installed-1}}

\begin{itemize}
\tightlist
\item
  Download R from
  the \href{http://cran.r-project.org/bin/macosx}{CRAN website}.
\item
  Select the \passthrough{\lstinline!.pkg!} file for the latest R version
\item
  Double click on the downloaded file to install R
\item
  It is also a good idea to install \href{https://www.xquartz.org/}{XQuartz} (needed
  by some packages)
\item
  Go to the \href{https://www.rstudio.com/products/rstudio/download/\#download}{RStudio download
  page}
\item
  Under \emph{Installers} select \textbf{RStudio x.yy.zzz - Mac OS X 10.6+ (64-bit)}
  (where x, y, and z represent version numbers)
\item
  Double click the file to install RStudio
\item
  Once it's installed, open RStudio to make sure it works and you don't get any
  error messages.
\end{itemize}

\hypertarget{linux}{%
\subsubsection{Linux}\label{linux}}

\begin{itemize}
\tightlist
\item
  Follow the instructions for your distribution
  from \href{https://cloud.r-project.org/bin/linux}{CRAN}, they provide information
  to get the most recent version of R for common distributions. For most
  distributions, you could use your package manager (e.g., for Debian/Ubuntu run
  \passthrough{\lstinline!sudo apt-get install r-base!}, and for Fedora \passthrough{\lstinline!sudo yum install R!}), but we
  don't recommend this approach as the versions provided by this are
  usually out of date. In any case, make sure you have at least R 3.3.1.
\item
  Go to the \href{https://www.rstudio.com/products/rstudio/download/\#download}{RStudio download
  page}
\item
  Under \emph{Installers} select the version that matches your distribution, and
  install it with your preferred method (e.g., with Debian/Ubuntu \passthrough{\lstinline!sudo dpkg -i rstudio-x.yy.zzz-amd64.deb!} at the terminal).
\item
  Once it's installed, open RStudio to make sure it works and you don't get any
  error messages.
\end{itemize}

These setup instructions are adapted from those written for \href{http://www.datacarpentry.org/R-ecology-lesson/}{Data Carpentry: R
for Data Analysis and Visualization of Ecological
Data}.

\hypertarget{robust}{%
\chapter{Robust Statistics and Reproducible Science}\label{robust}}

\begin{shortbox}
\Boxhead{Test}
test shortbox
\end{shortbox}

\begin{VT1}
\VH{Test}
test VT1
\end{VT1}

\begin{quote}
``One enemy of robust science is our humanity --- our appetite for
being right, and our tendency to find patterns in noise, to see supporting
evidence for what we already believe is true, and to ignore the facts that do
not fit.''

--- \citet{naturenews_2015}
\end{quote}

Scientific research is at a unique point in history. The need to improve rigor
and reproducibility in our field is greater than ever; corroboration moves
science forward, yet there is a growing alarm about results that cannot be
reproduced and that report false discoveries \citep{baker2016there}. Consequences of
not meeting this need will result in further decline in the rate of scientific
progression, the reputation of the sciences, and the public's trust in its
findings \citep{munafo2017manifesto, naturenews2_2015}.

\begin{quote}
``The key question we want to answer when seeing the results of any scientific
study is whether we can trust the data analysis.''

--- \citet{peng2015reproducibility}
\end{quote}

Unfortunately, at its current state the culture of data analysis and statistics
actually enables human bias through improper model selection. All hypothesis
tests and estimators are derived from statistical models, so to obtain valid
estimates and inference it is critical that the statistical model contains the
process that generated the data. Perhaps treatment was randomized or only
depended on a small number of baseline covariates; this knowledge should and
can be incorporated in the model. Alternatively, maybe the data is
observational, and there is no knowledge about the data-generating process (DGP).
If this is the case, then the statistical model should contain \emph{all} data
distributions. In practice; however, models are not selected based on knowledge
of the DGP, instead models are often selected based on (1) the p-values they
yield, (2) their convenience of implementation, and/or (3) an analysts loyalty
to a particular model. This practice of ``cargo-cult statistics --- the
ritualistic miming of statistics rather than conscientious practice,''
\citep{stark2018cargo} is characterized by arbitrary modeling choices, even though
these choices often result in different answers to the same research question.
That is, ``increasingly often, {[}statistics{]} is used instead to aid and
abet weak science, a role it can perform well when used mechanically or
ritually,'' as opposed to its original purpose of safeguarding against weak
science \citep{stark2018cargo}. This presents a fundamental drive behind the epidemic
of false findings that scientific research is suffering from \citep{vdl2014entering}.

\begin{quote}
``We suggest that the weak statistical understanding is probably due to
inadequate''statistics lite" education. This approach does not build up
appropriate mathematical fundamentals and does not provide scientifically
rigorous introduction into statistics. Hence, students' knowledge may remain
imprecise, patchy, and prone to serious misunderstandings. What this approach
achieves, however, is providing students with false confidence of being able
to use inferential tools whereas they usually only interpret the p-value
provided by black box statistical software. While this educational problem
remains unaddressed, poor statistical practices will prevail regardless of
what procedures and measures may be favored and/or banned by editorials."

--- \citet{szucs2017null}
\end{quote}

Our team at The University of California, Berkeley, is uniquely positioned to
provide such an education. Spearheaded by Professor Mark van der Laan, and
spreading rapidly by many of his students and colleagues who have greatly
enriched the field, the aptly named ``Targeted Learning'' methodology targets the
scientific question at hand and is counter to the current culture of
``convenience statistics'' which opens the door to biased estimation, misleading
results, and false discoveries. Targeted Learning restores the fundamentals that
formalized the field of statistics, such as the that facts that a statistical
model represents real knowledge about the experiment that generated the data,
and a target parameter represents what we are seeking to learn from the data as
a feature of the distribution that generated it \citep{vdl2014entering}. In this way,
Targeted Learning defines a truth and establishes a principled standard for
estimation, thereby inhibiting these all-too-human biases (e.g., hindsight bias,
confirmation bias, and outcome bias) from infiltrating analysis.

\begin{quote}
``The key for effective classical {[}statistical{]} inference is to have
well-defined questions and an analysis plan that tests those questions.''

--- \citet{nosek2018preregistration}
\end{quote}

The objective for this handbook is to provide training to students, researchers,
industry professionals, faculty in science, public health, statistics, and other
fields to empower them with the necessary knowledge and skills to utilize the
sound methodology of Targeted Learning --- a technique that provides tailored
pre-specified machines for answering queries, so that each data analysis is
completely reproducible, and estimators are efficient, minimally biased, and
provide formal statistical inference.

Just as the conscientious use of modern statistical methodology is necessary to
ensure that scientific practice thrives, it remains critical to acknowledge the
role that robust software plays in allowing practitioners direct access to
published results. We recall that ``an article\ldots{}in a scientific publication is
not the scholarship itself, it is merely advertising of the scholarship. The
actual scholarship is the complete software development environment and the
complete set of instructions which generated the figures,'' thus making the
availability and adoption of robust statistical software key to enhancing the
transparency that is an inherent aspect of science \citep{buckheit1995wavelab}.

For a statistical methodology to be readily accessible in practice, it is
crucial that it is accompanied by robust user-friendly software
\citep{pullenayegum2016knowledge, stromberg2004write}. The \passthrough{\lstinline!tlverse!} software
ecosystem was developed to fulfill this need for the Targeted Learning
methodology. Not only does this software facilitate computationally reproducible
and efficient analyses, it is also a tool for Targeted Learning education since
its workflow mirrors that of the methodology. In particular, the \passthrough{\lstinline!tlverse!}
paradigm does not focus on implementing a specific estimator or a small set of
related estimators. Instead, the focus is on exposing the statistical framework
of Targeted Learning itself --- all \passthrough{\lstinline!R!} packages in the \passthrough{\lstinline!tlverse!} ecosystem
directly model the key objects defined in the mathematical and theoretical
framework of Targeted Learning. What's more, the \passthrough{\lstinline!tlverse!} \passthrough{\lstinline!R!} packages share a
core set of design principles centered on extensibility, allowing for them to be
used in conjunction with each other and built upon one other in a cohesive
fashion. For an introduction to Targeted Learning, we recommend the \href{https://arxiv.org/abs/2006.07333}{recent
review paper} from \citet{coyle2021targeted}.

In this handbook, the reader will embark on a journey through the \passthrough{\lstinline!tlverse!}
ecosystem. Guided by \passthrough{\lstinline!R!} programming exercises, case studies, and
intuitive explanation readers will build a toolbox for applying the Targeted
Learning statistical methodology, which will translate to real-world causal
inference analyses. Some preliminaries are required prior to this learning
endeavor -- we have made available a list of \protect\hyperlink{learn}{recommended learning
resources}.

\hypertarget{intro}{%
\chapter{The Roadmap for Targeted Learning}\label{intro}}

\hypertarget{learning-objectives}{%
\section*{Learning Objectives}\label{learning-objectives}}


By the end of this chapter you will be able to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Translate scientific questions to statistical questions.
\item
  Define a statistical model based on the knowledge of the experiment that
  generated the data.
\item
  Identify a causal parameter as a function of the observed data distribution.
\item
  Explain the following causal and statistical assumptions and their
  implications: i.i.d., consistency, interference, positivity, SUTVA.
\end{enumerate}

\hypertarget{introduction}{%
\section*{Introduction}\label{introduction}}


The roadmap of statistical learning is concerned with the translation from
real-world data applications to a mathematical and statistical formulation of
the relevant estimation problem. This involves data as a random variable having
a probability distribution, scientific knowledge represented by a statistical
model, a statistical target parameter representing an answer to the question of
interest, and the notion of an estimator and sampling distribution of the
estimator.

\hypertarget{roadmap}{%
\section{The Roadmap}\label{roadmap}}

Following the roadmap is a process of five stages.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Data as a random variable with a probability distribution, \(O \sim P_0\).
\item
  The statistical model \(\M\) such that \(P_0 \in \M\).
\item
  The statistical target parameter \(\Psi\) and estimand \(\Psi(P_0)\).
\item
  The estimator \(\hat{\Psi}\) and estimate \(\hat{\Psi}(P_n)\).
\item
  A measure of uncertainty for the estimate \(\hat{\Psi}(P_n)\).
\end{enumerate}

\hypertarget{data-a-random-variable-with-a-probability-distribution-o-sim-p_0}{%
\subsection*{\texorpdfstring{(1) Data: A random variable with a probability distribution, \(O \sim P_0\)}{(1) Data: A random variable with a probability distribution, O \textbackslash{}sim P\_0}}\label{data-a-random-variable-with-a-probability-distribution-o-sim-p_0}}


The data set we're confronted with is the result of an experiment and we can
view the data as a random variable, \(O\), because if we repeat the experiment
we would have a different realization of this experiment. In particular, if we
repeat the experiment many times we could learn the probability distribution,
\(P_0\), of our data. So, the observed data \(O\) with probability distribution
\(P_0\) are \(n\) independent identically distributed (i.i.d.) observations of the
random variable \(O; O_1, \ldots, O_n\). Note that while not all data are i.i.d.,
there are ways to handle non-i.i.d. data, such as establishing conditional
independence, stratifying data to create sets of identically distributed data,
etc. It is crucial that researchers be absolutely clear about what they actually
know about the data-generating distribution for a given problem of interest.
Unfortunately, communication between statisticians and researchers is often
fraught with misinterpretation. The roadmap provides a mechanism by which to
ensure clear communication between research and statistician -- it truly helps
with this communication!

\hypertarget{the-empirical-probability-measure-p_n}{%
\subsubsection*{\texorpdfstring{The empirical probability measure, \(P_n\)}{The empirical probability measure, P\_n}}\label{the-empirical-probability-measure-p_n}}


Once we have \(n\) of such i.i.d. observations we have an empirical probability
measure, \(P_n\). The empirical probability measure is an approximation of the
true probability measure \(P_0\), allowing us to learn from our data. For
example, we can define the empirical probability measure of a set, \(A\), to be
the proportion of observations which end up in \(A\). That is,
\begin{equation*}
  P_n(A) = \frac{1}{n}\sum_{i=1}^{n} \I(O_i \in A)
\end{equation*}

In order to start learning something, we need to ask \emph{``What do we know about the
probability distribution of the data?''} This brings us to Step 2.

\hypertarget{the-statistical-model-m-such-that-p_0-in-m}{%
\subsection*{\texorpdfstring{(2) The statistical model \(\M\) such that \(P_0 \in \M\)}{(2) The statistical model \textbackslash{}M such that P\_0 \textbackslash{}in \textbackslash{}M}}\label{the-statistical-model-m-such-that-p_0-in-m}}


The statistical model \(\M\) is defined by the question we asked at the end of
Step 1. It is defined as the set of possible probability distributions for our
observed data. Often \(\M\) is very large (possibly infinite-dimensional), to
reflect the fact that statistical knowledge is limited. In the case that \(\M\) is
infinite-dimensional, we deem this a nonparametric statistical model.

Alternatively, if the probability distribution of the data at hand is described
by a finite number of parameters, then the statistical model is parametric. In
this case, we subscribe to the belief that the random variable \(O\) being
observed has, for example, a normal distribution with mean \(\mu\) and variance
\(\sigma^2\). Formally, a parametric model may be defined
\begin{equation*}
  \M = \{P_{\theta} : \theta \in \R^d \}
\end{equation*}

Sadly, the assumption that the data-generating distribution has a specific,
parametric form is all too common, especially since this is a leap of faith or
an assumption made of convenience. This practice of oversimplification in the
current culture of data analysis typically derails any attempt at trying to
answer the scientific question at hand; alas, such statements as the
ever-popular quip of Box that ``All models are wrong but some are useful''
encourage the data analyst to make arbitrary choices even when such a practice
often forces starkly different answers to the same estimation problem. The
Targeted Learning paradigm does not suffer from this bias since it defines the
statistical model through a representation of the true data-generating
distribution corresponding to the observed data.

Now, on to Step 3: \emph{``What are we trying to learn from the data?''}

\hypertarget{the-statistical-target-parameter-psi-and-estimand-psip_0}{%
\subsection*{\texorpdfstring{(3) The statistical target parameter \(\Psi\) and estimand \(\Psi(P_0)\)}{(3) The statistical target parameter \textbackslash{}Psi and estimand \textbackslash{}Psi(P\_0)}}\label{the-statistical-target-parameter-psi-and-estimand-psip_0}}


The statistical target parameter, \(\Psi\), is defined as a mapping from the
statistical model, \(\M\), to the parameter space (i.e., a real number) \(\R\). That
is, \(\Psi: \M \rightarrow \R\). The estimand may be seen as a representation of
the quantity that we wish to learn from the data, the answer to a well-specified
(often causal) question of interest. In contrast to purely statistical
estimands, causal estimands require \emph{identification from the observed data},
based on causal models that include several untestable assumptions, described in
more detail in the section on \protect\hyperlink{causal}{causal target parameters}.

For a simple example, consider a data set which contains observations of a
survival time on every subject, for which our question of interest is ``What's
the probability that someone lives longer than five years?'' We have,
\begin{equation*}
  \Psi(P_0) = \P(O > 5)
\end{equation*}

This answer to this question is the \textbf{estimand, \(\Psi(P_0)\)}, which is the
quantity we're trying to learn from the data. Once we have defined \(O\), \(\M\) and
\(\Psi(P_0)\) we have formally defined the statistical estimation problem.

\hypertarget{the-estimator-hatpsi-and-estimate-hatpsip_n}{%
\subsection*{\texorpdfstring{(4) The estimator \(\hat{\Psi}\) and estimate \(\hat{\Psi}(P_n)\)}{(4) The estimator \textbackslash{}hat\{\textbackslash{}Psi\} and estimate \textbackslash{}hat\{\textbackslash{}Psi\}(P\_n)}}\label{the-estimator-hatpsi-and-estimate-hatpsip_n}}


To obtain a good approximation of the estimand, we need an estimator, an \emph{a
priori}-specified algorithm defined as a mapping from the set of possible
empirical distributions, \(P_n\), which live in a non-parametric statistical
model, \(\M_{NP}\) (\(P_n \in \M_{NP}\)), to the parameter space of the parameter of
interest. That is, \(\hat{\Psi} : \M_{NP} \rightarrow \R^d\). The estimator is a
function that takes as input the observed data, a realization of \(P_n\), and
gives as output a value in the parameter space, which is the \textbf{estimate,
\(\hat{\Psi}(P_n)\)}.

Where the estimator may be seen as an operator that maps the observed data and
corresponding empirical distribution to a value in the parameter space, the
numerical output that produced such a function is the estimate. Thus, it is an
element of the parameter space based on the empirical probability distribution
of the observed data. If we plug in a realization of \(P_n\) (based on a sample
size \(n\) of the random variable \(O\)), we get back an estimate \(\hat{\Psi}(P_n)\)
of the true parameter value \(\Psi(P_0)\).

In order to quantify the uncertainty in our estimate of the target parameter
(i.e., to construct statistical inference), an understanding of the sampling
distribution of our estimator will be necessary. This brings us to Step 5.

\hypertarget{a-measure-of-uncertainty-for-the-estimate-hatpsip_n}{%
\subsection*{\texorpdfstring{(5) A measure of uncertainty for the estimate \(\hat{\Psi}(P_n)\)}{(5) A measure of uncertainty for the estimate \textbackslash{}hat\{\textbackslash{}Psi\}(P\_n)}}\label{a-measure-of-uncertainty-for-the-estimate-hatpsip_n}}


Since the estimator \(\hat{\Psi}\) is a function of the empirical distribution
\(P_n\), the estimator itself is a random variable with a sampling distribution.
So, if we repeat the experiment of drawing \(n\) observations we would every time
end up with a different realization of our estimate and our estimator has a
sampling distribution. The sampling distribution of some estimators can be
theoretically validated to be approximately normally distributed by a Central
Limit Theorem (CLT).

A \textbf{Central Limit Theorem} (CLTs) is a statement regarding the convergence of
the \textbf{sampling distribution of an estimator} to a normal distribution. In
general, we will construct estimators whose limit sampling distributions may be
shown to be approximately normal distributed as sample size increases. For large
enough \(n\) we have,
\begin{equation*}
  \hat{\Psi}(P_n) \sim N \left(\Psi(P_0), \frac{\sigma^2}{n}\right),
\end{equation*}
permitting statistical inference. Now, we can proceed to quantify the
uncertainty of our chosen estimator by construction of hypothesis tests and
confidence intervals. For example, we may construct a confidence interval at
level \((1 - \alpha)\) for our estimand, \(\Psi(P_0)\):
\begin{equation*}
  \hat{\Psi}(P_n) \pm z_{1 - \frac{\alpha}{2}}
    \left(\frac{\sigma}{\sqrt{n}}\right),
\end{equation*}
where \(z_{1 - \frac{\alpha}{2}}\) is the \((1 - \frac{\alpha}{2})^\text{th}\)
quantile of the standard normal distribution. Often, we will be interested in
constructing 95\% confidence intervals, corresponding to mass \(\alpha = 0.05\) in
either tail of the limit distribution; thus, we will typically take
\(z_{1 - \frac{\alpha}{2}} \approx 1.96\).

\emph{Note:} we will typically have to estimate the standard error,
\(\frac{\sigma}{\sqrt{n}}\).

A 95\% confidence interval means that if we were to take 100 different samples
of size \(n\) and compute a 95\% confidence interval for each sample, then
approximately 95 of the 100 confidence intervals would contain the estimand,
\(\Psi(P_0)\). More practically, this means that there is a 95\% probability
that the confidence interval procedure generates intervals containing the
true estimand value (or 95\% confidence of ``covering'' the true value). That is,
any single estimated confidence interval either will contain the true estimand
or will not (also called ``coverage'').

\hypertarget{roadmap-summary}{%
\section{Summary of the Roadmap}\label{roadmap-summary}}

Data, \(O\), is viewed as a random variable that has a probability distribution.
We often have \(n\) units of independent identically distributed units with
probability distribution \(P_0\), such that \(O_1, \ldots, O_n \sim P_0\). We have
statistical knowledge about the experiment that generated this data. In other
words, we make a statement that the true data distribution \(P_0\) falls in a
certain set called a statistical model, \(\M\). Often these sets are very large
because statistical knowledge is very limited - hence, these statistical models
are often infinite dimensional models. Our statistical query is, ``What are we
trying to learn from the data?'' denoted by the statistical target parameter,
\(\Psi\), which maps the \(P_0\) into the estimand, \(\Psi(P_0)\). At this point the
statistical estimation problem is formally defined and now we will need
statistical theory to guide us in the construction of estimators. There's a lot
of statistical theory we will review in this course that, in particular, relies
on the Central Limit Theorem, allowing us to come up with estimators that are
approximately normally distributed and also allowing us to come with statistical
inference (i.e., confidence intervals and hypothesis tests).

\hypertarget{causal}{%
\section{Causal Target Parameters}\label{causal}}

In many cases, we are interested in problems that ask questions regarding the
effect of an intervention on a future outcome of interest. These questions can
be represented as causal estimands.

\hypertarget{the-causal-model}{%
\subsection*{The Causal Model}\label{the-causal-model}}


After formalizing the data and the statistical model, we can define a causal
model to express causal parameters of interest. Directed acyclic graphs (DAGs)
are one useful tool to express what we know about the causal relations among
variables. Ignoring exogenous \(U\) terms (explained below), we assume the
following ordering of the variables in the observed data \(O\). We do this below
using \passthrough{\lstinline!DAGitty!} \citep{textor2011dagitty}:

\begin{lstlisting}[language=R]
library(dagitty)
library(ggdag)

# make DAG by specifying dependence structure
dag <- dagitty(
  "dag {
    W -> A
    W -> Y
    A -> Y
    W -> A -> Y
  }"
)
exposures(dag) <- c("A")
outcomes(dag) <- c("Y")
tidy_dag <- tidy_dagitty(dag)

# visualize DAG
ggdag(tidy_dag) +
  theme_dag()
\end{lstlisting}

\begin{center}\includegraphics[width=0.8\linewidth]{02-roadmap_files/figure-latex/simple-DAG-1} \end{center}

While directed acyclic graphs (DAGs) like above provide a convenient means by
which to visualize causal relations between variables, the same causal relations
among variables can be represented via a set of structural equations, which
define the non-parametric structural equation model (NPSEM):
\begin{align*}
  W &= f_W(U_W) \\
  A &= f_A(W, U_A) \\
  Y &= f_Y(W, A, U_Y),
\end{align*}
where \(U_W\), \(U_A\), and \(U_Y\) represent the unmeasured exogenous background
characteristics that influence the value of each variable. In the NPSEM, \(f_W\),
\(f_A\) and \(f_Y\) denote that each variable (for \(W\), \(A\) and \(Y\), respectively)
is a function of its parents and unmeasured background characteristics, but note
that there is no imposition of any particular functional constraints(e.g.,
linear, logit-linear, only one interaction, etc.). For this reason, they are
called non-parametric structural equation models (NPSEMs). The DAG and set of
nonparametric structural equations represent exactly the same information and so
may be used interchangeably.

The first hypothetical experiment we will consider is assigning exposure to the
whole population and observing the outcome, and then assigning no exposure to
the whole population and observing the outcome. On the nonparametric structural
equations, this corresponds to a comparison of the outcome distribution in the
population under two interventions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(A\) is set to \(1\) for all individuals, and
\item
  \(A\) is set to \(0\) for all individuals.
\end{enumerate}

These interventions imply two new nonparametric structural equation models. For
the case \(A = 1\), we have
\begin{align*}
  W &= f_W(U_W) \\
  A &= 1 \\
  Y(1) &= f_Y(W, 1, U_Y),
\end{align*}
and for the case \(A=0\),
\begin{align*}
  W &= f_W(U_W) \\
  A &= 0 \\
  Y(0) &= f_Y(W, 0, U_Y).
\end{align*}

In these equations, \(A\) is no longer a function of \(W\) because we have
intervened on the system, setting \(A\) deterministically to either of the values
\(1\) or \(0\). The new symbols \(Y(1)\) and \(Y(0)\) indicate the outcome variable in
our population if it were generated by the respective NPSEMs above; these are
often called \emph{counterfactuals} (since they run contrary-to-fact). The difference
between the means of the outcome under these two interventions defines a
parameter that is often called the ``average treatment effect'' (ATE), denoted
\begin{equation}
  ATE = \E_X(Y(1) - Y(0)),
  \label{eq:ate}
\end{equation}
where \(\E_X\) is the mean under the theoretical (unobserved) full data \(X = (W, Y(1), Y(0))\).

Note, we can define much more complicated interventions on NPSEM's, such as
interventions based upon rules (themselves based upon covariates), stochastic
rules, etc. and each results in a different targeted parameter and entails
different identifiability assumptions discussed below.

\hypertarget{identifiability}{%
\subsection*{Identifiability}\label{identifiability}}


Because we can never observe both \(Y(0)\) (the counterfactual outcome when \(A=0\))
and \(Y(1)\) (similarly, the counterfactual outcome when \(A=1\)), we cannot
estimate the quantity in Equation \eqref{eq:ate} directly. Instead, we have to
make assumptions under which this quantity may be estimated from the observed
data \(O \sim P_0\) under the data-generating distribution \(P_0\). Fortunately,
given the causal model specified in the NPSEM above, we can, with a handful of
untestable assumptions, estimate the ATE, even from observational data. These
assumptions may be summarized as follows.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The causal graph implies \(Y(a) \perp A\) for all \(a \in \mathcal{A}\), which
  is the \emph{randomization} assumption. In the case of observational data, the
  analogous assumption is \emph{strong ignorability} or \emph{no unmeasured confounding}
  \(Y(a) \perp A \mid W\) for all \(a \in \mathcal{A}\);
\item
  Although not represented in the causal graph, also required is the assumption
  of no interference between units, that is, the outcome for unit \(i\) \(Y_i\) is
  not affected by exposure for unit \(j\) \(A_j\) unless \(i=j\);
\item
  \emph{Consistency} of the treatment mechanism is also required, i.e., the outcome
  for unit \(i\) is \(Y_i(a)\) whenever \(A_i = a\), an assumption also known as ``no
  other versions of treatment'';
\item
  It is also necessary that all observed units, across strata defined by \(W\),
  have a bounded (non-deterministic) probability of receiving treatment --
  that is, \(0 < \P(A = a \mid W) < 1\) for all \(a\) and \(W\)). This assumption
  is referred to as \emph{positivity} or \emph{overlap}.
\end{enumerate}

\emph{Remark}: Together, (2) and (3), the assumptions of no interference and
consistency, respectively, are jointly referred to as the \emph{stable unit
treatment value assumption} (SUTVA).

Given these assumptions, the ATE may be re-written as a function of \(P_0\),
specifically
\begin{equation}
  ATE = \E_0(Y(1) - Y(0)) = \E_0
    \left(\E_0[Y \mid A = 1, W] - \E_0[Y \mid A = 0, W]\right).
  \label{eq:estimand}
\end{equation}
In words, the ATE is the difference in the predicted outcome values for each
subject, under the contrast of treatment conditions (\(A = 0\) versus \(A = 1\)),
in the population, averaged over all observations. Thus, a parameter of a
theoretical ``full'' data distribution can be represented as an estimand of the
observed data distribution. Significantly, there is nothing about the
representation in Equation \eqref{eq:estimand} that requires parameteric
assumptions; thus, the regressions on the right hand side may be estimated
freely with machine learning. With different parameters, there will be
potentially different identifiability assumptions and the resulting estimands
can be functions of different components of \(P_0\). We discuss several more
complex estimands in later sections of this handbook.

\hypertarget{tlverse}{%
\chapter{\texorpdfstring{Welcome to the \texttt{tlverse}}{Welcome to the tlverse}}\label{tlverse}}

\hypertarget{learning-objectives-1}{%
\section*{Learning Objectives}\label{learning-objectives-1}}


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Understand the \passthrough{\lstinline!tlverse!} ecosystem conceptually
\item
  Identify the core components of the \passthrough{\lstinline!tlverse!}
\item
  Install \passthrough{\lstinline!tlverse!} \passthrough{\lstinline!R!} packages
\item
  Understand the Targeted Learning roadmap
\item
  Learn about the WASH Benefits example data
\end{enumerate}

\hypertarget{what-is-the-tlverse}{%
\section*{\texorpdfstring{What is the \texttt{tlverse}?}{What is the tlverse?}}\label{what-is-the-tlverse}}


The \passthrough{\lstinline!tlverse!} is a new framework for doing Targeted Learning in R, inspired by
the \href{https://tidyverse.org}{\passthrough{\lstinline!tidyverse!} ecosystem} of R packages.

By analogy to the \href{https://tidyverse.org/}{\passthrough{\lstinline!tidyverse!}}:

\begin{quote}
The \passthrough{\lstinline!tidyverse!} is an opinionated collection of R packages designed for data
science. All packages share an underlying design philosophy, grammar, and data
structures.
\end{quote}

So, the \href{https://tlverse.org}{\passthrough{\lstinline!tlverse!}} is

\begin{itemize}
\tightlist
\item
  an opinionated collection of R packages for Targeted Learning
\item
  sharing an underlying philosophy, grammar, and set of data structures
\end{itemize}

\hypertarget{anatomy-of-the-tlverse}{%
\section*{\texorpdfstring{Anatomy of the \texttt{tlverse}}{Anatomy of the tlverse}}\label{anatomy-of-the-tlverse}}


These are the main packages that represent the \textbf{core} of the \passthrough{\lstinline!tlverse!}:

\begin{itemize}
\tightlist
\item
  \href{https://github.com/tlverse/sl3}{\passthrough{\lstinline!sl3!}}: Modern Super Learning with Pipelines

  \begin{itemize}
  \tightlist
  \item
    \emph{What?} A modern object-oriented re-implementation of the Super Learner
    algorithm, employing recently developed paradigms for \passthrough{\lstinline!R!} programming.
  \item
    \emph{Why?} A design that leverages modern tools for fast computation, is
    forward-looking, and can form one of the cornerstones of the \passthrough{\lstinline!tlverse!}.
  \end{itemize}
\item
  \href{https://github.com/tlverse/tmle3}{\passthrough{\lstinline!tmle3!}}: An Engine for Targeted Learning

  \begin{itemize}
  \tightlist
  \item
    \emph{What?} A generalized framework that simplifies Targeted Learning by
    identifying and implementing a series of common statistical estimation
    procedures.
  \item
    \emph{Why?} A common interface and engine that accommodates current algorithmic
    approaches to Targeted Learning and is still flexible enough to remain the
    engine even as new techniques are developed.
  \end{itemize}
\end{itemize}

In addition to the engines that drive development in the \passthrough{\lstinline!tlverse!}, there are
some supporting packages -- in particular, we have two\ldots{}

\begin{itemize}
\tightlist
\item
  \href{https://github.com/tlverse/origami}{\passthrough{\lstinline!origami!}}: A Generalized Framework for
  Cross-Validation

  \begin{itemize}
  \tightlist
  \item
    \emph{What?} A generalized framework for flexible cross-validation
  \item
    \emph{Why?} Cross-validation is a key part of ensuring error estimates are honest
    and preventing overfitting. It is an essential part of the both the Super
    Learner algorithm and Targeted Learning.
  \end{itemize}
\item
  \href{https://github.com/tlverse/delayed}{\passthrough{\lstinline!delayed!}}: Parallelization Framework for
  Dependent Tasks

  \begin{itemize}
  \tightlist
  \item
    \emph{What?} A framework for delayed computations (futures) based on task
    dependencies.
  \item
    \emph{Why?} Efficient allocation of compute resources is essential when deploying
    large-scale, computationally intensive algorithms.
  \end{itemize}
\end{itemize}

A key principle of the \passthrough{\lstinline!tlverse!} is extensibility. That is, we want to support
new Targeted Learning estimators as they are developed. The model for this is
new estimators are implemented in additional packages using the core packages
above. There are currently two featured examples of this:

\begin{itemize}
\tightlist
\item
  \href{https://github.com/tlverse/tmle3mopttx}{\passthrough{\lstinline!tmle3mopttx!}}: Optimal Treatments
  in \passthrough{\lstinline!tlverse!}

  \begin{itemize}
  \tightlist
  \item
    \emph{What?} Learn an optimal rule and estimate the mean outcome under the rule
  \item
    \emph{Why?} Optimal Treatment is a powerful tool in precision healthcare and
    other settings where a one-size-fits-all treatment approach is not
    appropriate.
  \end{itemize}
\item
  \href{https://github.com/tlverse/tmle3shift}{\passthrough{\lstinline!tmle3shift!}}: Shift Interventions in
  \passthrough{\lstinline!tlverse!}

  \begin{itemize}
  \tightlist
  \item
    \emph{What?} Shift interventions for continuous treatments
  \item
    \emph{Why?} Not all treatment variables are discrete. Being able to estimate the
    effects of continuous treatment represents a powerful extension of the
    Targeted Learning approach.
  \end{itemize}
\end{itemize}

\hypertarget{installtlverse}{%
\section{Installation}\label{installtlverse}}

The \passthrough{\lstinline!tlverse!} ecosystem of packages are currently hosted at
\url{https://github.com/tlverse}, not yet on \href{https://CRAN.R-project.org/}{CRAN}. You
can use the \href{https://usethis.r-lib.org/}{\passthrough{\lstinline!usethis!} package} to install them:

\begin{lstlisting}[language=R]
install.packages("devtools")
devtools::install_github("tlverse/tlverse")
\end{lstlisting}

The \passthrough{\lstinline!tlverse!} depends on a large number of other packages that are also hosted
on GitHub. Because of this, you may see the following error:

\begin{lstlisting}
Error: HTTP error 403.
  API rate limit exceeded for 71.204.135.82. (But here's the good news:
  Authenticated requests get a higher rate limit. Check out the documentation
  for more details.)

  Rate limit remaining: 0/60
  Rate limit reset at: 2019-03-04 19:39:05 UTC

  To increase your GitHub API rate limit
  - Use `usethis::browse_github_pat()` to create a Personal Access Token.
  - Use `usethis::edit_r_environ()` and add the token as `GITHUB_PAT`.
\end{lstlisting}

This just means that R tried to install too many packages from GitHub in too
short of a window. To fix this, you need to tell R how to use GitHub as your
user (you'll need a GitHub user account). Follow these two steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Type \passthrough{\lstinline!usethis::browse\_github\_pat()!} in your R console, which will direct
  you to GitHub's page to create a New Personal Access Token (PAT).
\item
  Create a PAT simply by clicking ``Generate token'' at the bottom of the page.
\item
  Copy your PAT, a long string of lowercase letters and numbers.
\item
  Type \passthrough{\lstinline!usethis::edit\_r\_environ()!} in your R console, which will open your
  \passthrough{\lstinline!.Renviron!} file in the source window of RStudio.

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    If your \passthrough{\lstinline!.Renviron!} file does not pop-up after calling
    \passthrough{\lstinline!usethis::edit\_r\_environ()!}; then try inputting
    \passthrough{\lstinline!Sys.setenv(GITHUB\_PAT = "yourPAT")!}, replacing your PAT with inside the
    quotes. If this does not error, then skip to step 8.
  \end{enumerate}
\item
  In your \passthrough{\lstinline!.Renviron!} file, type \passthrough{\lstinline!GITHUB\_PAT=!} and then paste your PAT after
  the equals symbol with no space.
\item
  In your \passthrough{\lstinline!.Renviron!} file, press the enter key to ensure that your \passthrough{\lstinline!.Renviron!}
  ends with a new line.
\item
  Save your \passthrough{\lstinline!.Renviron!} file. The example below shows how this syntax should
  look.
\end{enumerate}

\begin{lstlisting}[language=R]
GITHUB_PAT <- yourPAT
\end{lstlisting}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Restart R. You can restart R via the drop-down menu on RStudio's ``Session''
  tab, which is located at the top of the RStudio interface. You have to
  restart R for the changes to take effect!
\end{enumerate}

After following these steps, you should be able to successfully install the
package which threw the error above.

\hypertarget{data}{%
\chapter{Meet the Data}\label{data}}

\hypertarget{wash}{%
\section{WASH Benefits Example Dataset}\label{wash}}

The data come from a study of the effect of water quality, sanitation, hand
washing, and nutritional interventions on child development in rural Bangladesh
(WASH Benefits Bangladesh): a cluster randomized controlled trial
\citep{luby2018effect}. The study enrolled pregnant women in their first or second
trimester from the rural villages of Gazipur, Kishoreganj, Mymensingh, and
Tangail districts of central Bangladesh, with an average of eight women per
cluster. Groups of eight geographically adjacent clusters were block randomized,
using a random number generator, into six intervention groups (all of which
received weekly visits from a community health promoter for the first 6 months
and every 2 weeks for the next 18 months) and a double-sized control group (no
intervention or health promoter visit). The six intervention groups were:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  chlorinated drinking water;
\item
  improved sanitation;
\item
  hand-washing with soap;
\item
  combined water, sanitation, and hand washing;
\item
  improved nutrition through counseling and provision of lipid-based nutrient
  supplements; and
\item
  combined water, sanitation, handwashing, and nutrition.
\end{enumerate}

In the handbook, we concentrate on child growth (size for age) as the outcome of
interest. For reference, this trial was registered with ClinicalTrials.gov as
NCT01590095.

\begin{lstlisting}[language=R]
library(readr)
# read in data via readr::read_csv
dat <- read_csv(
  paste0(
    "https://raw.githubusercontent.com/tlverse/tlverse-data/master/",
    "wash-benefits/washb_data.csv"
  )
)
\end{lstlisting}

For the purposes of this handbook, we start by treating the data as independent
and identically distributed (i.i.d.) random draws from a very large target
population. We could, with available options, account for the clustering of the
data (within sampled geographic units), but, for simplification, we avoid these
details in the handbook, although modifications of our methodology for biased
samples, repeated measures, and related complications, are available.

We have 28 variables measured, of which a single variable is set to
be the outcome of interest. This outcome, \(Y\), is the weight-for-height Z-score
(\passthrough{\lstinline!whz!} in \passthrough{\lstinline!dat!}); the treatment of interest, \(A\), is the randomized treatment
group (\passthrough{\lstinline!tr!} in \passthrough{\lstinline!dat!}); and the adjustment set, \(W\), consists simply of
\emph{everything else}. This results in our observed data structure being \(n\) i.i.d.
copies of \(O_i = (W_i, A_i, Y_i)\), for \(i = 1, \ldots, n\).

Using the \href{https://CRAN.R-project.org/package=skimr}{\passthrough{\lstinline!skimr!} package}, we can
quickly summarize the variables measured in the WASH Benefits data set:

\begin{tabular}{l|l|r|r|r|r|r|r|r|r|r|r|r|r|r|r}
\hline
skim\_type & skim\_variable & n\_missing & complete\_rate & character.min & character.max & character.empty & character.n\_unique & character.whitespace & numeric.mean & numeric.sd & numeric.p0 & numeric.p25 & numeric.p50 & numeric.p75 & numeric.p100\\
\hline
character & tr & 0 & 1.00000 & 3 & 15 & 0 & 7 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & fracode & 0 & 1.00000 & 2 & 6 & 0 & 20 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & sex & 0 & 1.00000 & 4 & 6 & 0 & 2 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & momedu & 0 & 1.00000 & 12 & 15 & 0 & 3 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & hfiacat & 0 & 1.00000 & 11 & 24 & 0 & 4 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
numeric & whz & 0 & 1.00000 & NA & NA & NA & NA & NA & -0.58608 & 1.03212 & -4.67 & -1.28 & -0.6 & 0.08 & 4.97\\
\hline
numeric & month & 0 & 1.00000 & NA & NA & NA & NA & NA & 6.45474 & 3.33214 & 1.00 & 4.00 & 6.0 & 9.00 & 12.00\\
\hline
numeric & aged & 0 & 1.00000 & NA & NA & NA & NA & NA & 266.31502 & 52.17465 & 42.00 & 230.00 & 266.0 & 303.00 & 460.00\\
\hline
numeric & momage & 18 & 0.99617 & NA & NA & NA & NA & NA & 23.90592 & 5.24055 & 14.00 & 20.00 & 23.0 & 27.00 & 60.00\\
\hline
numeric & momheight & 31 & 0.99340 & NA & NA & NA & NA & NA & 150.50407 & 5.22667 & 120.65 & 147.05 & 150.6 & 154.06 & 168.00\\
\hline
numeric & Nlt18 & 0 & 1.00000 & NA & NA & NA & NA & NA & 1.60469 & 1.24726 & 0.00 & 1.00 & 1.0 & 2.00 & 10.00\\
\hline
numeric & Ncomp & 0 & 1.00000 & NA & NA & NA & NA & NA & 11.04324 & 6.35044 & 2.00 & 6.00 & 10.0 & 14.00 & 52.00\\
\hline
numeric & watmin & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.94867 & 9.48125 & 0.00 & 0.00 & 0.0 & 1.00 & 600.00\\
\hline
numeric & elec & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.59510 & 0.49092 & 0.00 & 0.00 & 1.0 & 1.00 & 1.00\\
\hline
numeric & floor & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.10671 & 0.30878 & 0.00 & 0.00 & 0.0 & 0.00 & 1.00\\
\hline
numeric & walls & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.71502 & 0.45145 & 0.00 & 0.00 & 1.0 & 1.00 & 1.00\\
\hline
numeric & roof & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.98530 & 0.12035 & 0.00 & 1.00 & 1.0 & 1.00 & 1.00\\
\hline
numeric & asset\_wardrobe & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.16720 & 0.37319 & 0.00 & 0.00 & 0.0 & 0.00 & 1.00\\
\hline
numeric & asset\_table & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.73440 & 0.44170 & 0.00 & 0.00 & 1.0 & 1.00 & 1.00\\
\hline
numeric & asset\_chair & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.73440 & 0.44170 & 0.00 & 0.00 & 1.0 & 1.00 & 1.00\\
\hline
numeric & asset\_khat & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.61321 & 0.48707 & 0.00 & 0.00 & 1.0 & 1.00 & 1.00\\
\hline
numeric & asset\_chouki & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.78126 & 0.41344 & 0.00 & 1.00 & 1.0 & 1.00 & 1.00\\
\hline
numeric & asset\_tv & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.30394 & 0.46001 & 0.00 & 0.00 & 0.0 & 1.00 & 1.00\\
\hline
numeric & asset\_refrig & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.07945 & 0.27046 & 0.00 & 0.00 & 0.0 & 0.00 & 1.00\\
\hline
numeric & asset\_bike & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.31906 & 0.46616 & 0.00 & 0.00 & 0.0 & 1.00 & 1.00\\
\hline
numeric & asset\_moto & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.06603 & 0.24836 & 0.00 & 0.00 & 0.0 & 0.00 & 1.00\\
\hline
numeric & asset\_sewmach & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.06475 & 0.24611 & 0.00 & 0.00 & 0.0 & 0.00 & 1.00\\
\hline
numeric & asset\_mobile & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.85857 & 0.34850 & 0.00 & 1.00 & 1.0 & 1.00 & 1.00\\
\hline
\end{tabular}

A convenient summary of the relevant variables is given just above, complete
with a small visualization describing the marginal characteristics of each
covariate. Note that the \emph{asset} variables reflect socio-economic status of the
study participants. Notice also the uniform distribution of the treatment groups
(with twice as many controls); this is, of course, by design.

\hypertarget{ist}{%
\section{International Stroke Trial Example Dataset}\label{ist}}

The International Stroke Trial database contains individual patient data from
the International Stroke Trial (IST), a multi-national randomized trial
conducted between 1991 and 1996 (pilot phase between 1991 and 1993) that aimed
to assess whether early administration of aspirin, heparin, both aspirin and
heparin, or neither influenced the clinical course of acute ischaemic stroke
\citep{sandercock1997international}. The IST dataset includes data on 19,435 patients
with acute stroke, with 99\% complete follow-up. De-identified data are
available for download at \url{https://datashare.is.ed.ac.uk/handle/10283/128}. This
study is described in more detail in \citet{sandercock2011international}. The example
data for this handbook considers a sample of 5,000 patients and the binary
outcome of recurrent ischemic stroke within 14 days after randomization. Also
in this example data, we ensure that we have subjects with a missing outcome.

\begin{lstlisting}[language=R]
# read in data
ist <- read_csv(
  paste0(
    "https://raw.githubusercontent.com/tlverse/tlverse-handbook/master/",
    "data/ist_sample.csv"
  )
)
\end{lstlisting}

We have 26 variables measured, and the outcome of interest, \(Y\),
indicates recurrent ischemic stroke within 14 days after randomization (\passthrough{\lstinline!DRSISC!}
in \passthrough{\lstinline!ist!}); the treatment of interest, \(A\), is the randomized aspirin vs.~no
aspirin treatment allocation (\passthrough{\lstinline!RXASP!} in \passthrough{\lstinline!ist!}); and the adjustment set, \(W\),
consists of all other variables measured at baseline. In this data, the outcome
is occasionally missing, but there is no need to create a variable indicating
this missingness (such as \(\Delta\)) for analyses in the \passthrough{\lstinline!tlverse!}, since it is
automatically detected when \passthrough{\lstinline!NA!} are present in the outcome. This observed data
structure can be denoted as \(n\) i.i.d. copies of \(O_i = (W_i, A_i, \Delta_i, \Delta Y_i)\), for \(i = 1, \ldots, n\), where \(\Delta\) denotes the binary
indicator that the outcome is observed.

Like before, we can summarize the variables measured in the IST sample data set
with \passthrough{\lstinline!skimr!}:

\begin{tabular}{l|l|r|r|r|r|r|r|r|r|r|r|r|r|r|r}
\hline
skim\_type & skim\_variable & n\_missing & complete\_rate & character.min & character.max & character.empty & character.n\_unique & character.whitespace & numeric.mean & numeric.sd & numeric.p0 & numeric.p25 & numeric.p50 & numeric.p75 & numeric.p100\\
\hline
character & RCONSC & 0 & 1.000 & 1 & 1 & 0 & 3 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & SEX & 0 & 1.000 & 1 & 1 & 0 & 2 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & RSLEEP & 0 & 1.000 & 1 & 1 & 0 & 2 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & RATRIAL & 0 & 1.000 & 1 & 1 & 0 & 3 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & RCT & 0 & 1.000 & 1 & 1 & 0 & 2 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & RVISINF & 0 & 1.000 & 1 & 1 & 0 & 2 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & RHEP24 & 0 & 1.000 & 1 & 1 & 0 & 3 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & RASP3 & 0 & 1.000 & 1 & 1 & 0 & 3 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & RDEF1 & 0 & 1.000 & 1 & 1 & 0 & 3 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & RDEF2 & 0 & 1.000 & 1 & 1 & 0 & 3 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & RDEF3 & 0 & 1.000 & 1 & 1 & 0 & 3 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & RDEF4 & 0 & 1.000 & 1 & 1 & 0 & 3 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & RDEF5 & 0 & 1.000 & 1 & 1 & 0 & 3 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & RDEF6 & 0 & 1.000 & 1 & 1 & 0 & 3 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & RDEF7 & 0 & 1.000 & 1 & 1 & 0 & 3 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & RDEF8 & 0 & 1.000 & 1 & 1 & 0 & 3 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & STYPE & 0 & 1.000 & 3 & 4 & 0 & 5 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & RXHEP & 0 & 1.000 & 1 & 1 & 0 & 4 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & REGION & 0 & 1.000 & 10 & 26 & 0 & 7 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
numeric & RDELAY & 0 & 1.000 & NA & NA & NA & NA & NA & 20.14400 & 12.43485 & 1 & 9 & 19 & 29 & 48\\
\hline
numeric & AGE & 0 & 1.000 & NA & NA & NA & NA & NA & 71.93460 & 11.65016 & 16 & 65 & 74 & 81 & 99\\
\hline
numeric & RSBP & 0 & 1.000 & NA & NA & NA & NA & NA & 160.61560 & 27.84196 & 71 & 140 & 160 & 180 & 290\\
\hline
numeric & MISSING\_RATRIAL\_RASP3 & 0 & 1.000 & NA & NA & NA & NA & NA & 0.05000 & 0.21797 & 0 & 0 & 0 & 0 & 1\\
\hline
numeric & MISSING\_RHEP24 & 0 & 1.000 & NA & NA & NA & NA & NA & 0.01840 & 0.13441 & 0 & 0 & 0 & 0 & 1\\
\hline
numeric & RXASP & 0 & 1.000 & NA & NA & NA & NA & NA & 0.49780 & 0.50005 & 0 & 0 & 0 & 1 & 1\\
\hline
numeric & DRSISC & 10 & 0.998 & NA & NA & NA & NA & NA & 0.02365 & 0.15196 & 0 & 0 & 0 & 0 & 1\\
\hline
\end{tabular}

\hypertarget{NHEFS}{%
\section{NHANES I Epidemiologic Follow-up Study (NHEFS)}\label{NHEFS}}

This data is from the National Health and Nutrition Examination Survey (NHANES)
Data I Epidemiologic Follow-up Study. More coming soon.

\begin{lstlisting}[language=R]
# read in data
nhefs_data <- read_csv(
  paste0(
    "https://raw.githubusercontent.com/tlverse/tlverse-handbook/master/",
    "data/NHEFS.csv"
  )
)
\end{lstlisting}

A snapshot of the data set is shown below:

\begin{tabular}{l|l|r|r|r|r|r|r|r|r|r}
\hline
skim\_type & skim\_variable & n\_missing & complete\_rate & numeric.mean & numeric.sd & numeric.p0 & numeric.p25 & numeric.p50 & numeric.p75 & numeric.p100\\
\hline
numeric & seqn & 0 & 1.00000 & 16552.36464 & 7498.91820 & 233.00000 & 10607.00000 & 20333.00000 & 2.2719e+04 & 2.5061e+04\\
\hline
numeric & qsmk & 0 & 1.00000 & 0.26274 & 0.44026 & 0.00000 & 0.00000 & 0.00000 & 1.0000e+00 & 1.0000e+00\\
\hline
numeric & death & 0 & 1.00000 & 0.19521 & 0.39649 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & yrdth & 1311 & 0.19521 & 87.56918 & 2.65941 & 83.00000 & 85.00000 & 88.00000 & 9.0000e+01 & 9.2000e+01\\
\hline
numeric & modth & 1307 & 0.19767 & 6.25776 & 3.61530 & 1.00000 & 3.00000 & 6.00000 & 1.0000e+01 & 1.2000e+01\\
\hline
numeric & dadth & 1307 & 0.19767 & 15.87267 & 8.90549 & 1.00000 & 8.00000 & 15.50000 & 2.4000e+01 & 3.1000e+01\\
\hline
numeric & sbp & 77 & 0.95273 & 128.70941 & 19.05156 & 87.00000 & 116.00000 & 126.00000 & 1.4000e+02 & 2.2900e+02\\
\hline
numeric & dbp & 81 & 0.95028 & 77.74483 & 10.63486 & 47.00000 & 70.00000 & 77.00000 & 8.5000e+01 & 1.3000e+02\\
\hline
numeric & sex & 0 & 1.00000 & 0.50952 & 0.50006 & 0.00000 & 0.00000 & 1.00000 & 1.0000e+00 & 1.0000e+00\\
\hline
numeric & age & 0 & 1.00000 & 43.91529 & 12.17043 & 25.00000 & 33.00000 & 44.00000 & 5.3000e+01 & 7.4000e+01\\
\hline
numeric & race & 0 & 1.00000 & 0.13198 & 0.33858 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & income & 62 & 0.96194 & 17.94767 & 2.66328 & 11.00000 & 17.00000 & 19.00000 & 2.0000e+01 & 2.2000e+01\\
\hline
numeric & marital & 0 & 1.00000 & 2.50338 & 1.08237 & 2.00000 & 2.00000 & 2.00000 & 2.0000e+00 & 8.0000e+00\\
\hline
numeric & school & 0 & 1.00000 & 11.13505 & 3.08960 & 0.00000 & 10.00000 & 12.00000 & 1.2000e+01 & 1.7000e+01\\
\hline
numeric & education & 0 & 1.00000 & 2.70350 & 1.19010 & 1.00000 & 2.00000 & 3.00000 & 3.0000e+00 & 5.0000e+00\\
\hline
numeric & ht & 0 & 1.00000 & 168.74096 & 9.05313 & 142.87500 & 161.78125 & 168.28125 & 1.7538e+02 & 1.9809e+02\\
\hline
numeric & wt71 & 0 & 1.00000 & 71.05213 & 15.72959 & 36.17000 & 59.65000 & 69.40000 & 7.9950e+01 & 1.6919e+02\\
\hline
numeric & wt82 & 63 & 0.96133 & 73.46922 & 16.15805 & 35.38020 & 61.68856 & 72.12119 & 8.3461e+01 & 1.3653e+02\\
\hline
numeric & wt82\_71 & 63 & 0.96133 & 2.63830 & 7.87991 & -41.28047 & -1.47840 & 2.60381 & 6.6896e+00 & 4.8538e+01\\
\hline
numeric & birthplace & 92 & 0.94352 & 31.59532 & 14.50050 & 1.00000 & 22.00000 & 34.00000 & 4.2000e+01 & 5.6000e+01\\
\hline
numeric & smokeintensity & 0 & 1.00000 & 20.55126 & 11.80375 & 1.00000 & 10.00000 & 20.00000 & 3.0000e+01 & 8.0000e+01\\
\hline
numeric & smkintensity82\_71 & 0 & 1.00000 & -4.73788 & 13.74136 & -80.00000 & -10.00000 & -1.00000 & 1.0000e+00 & 5.0000e+01\\
\hline
numeric & smokeyrs & 0 & 1.00000 & 24.87109 & 12.19807 & 1.00000 & 15.00000 & 24.00000 & 3.3000e+01 & 6.4000e+01\\
\hline
numeric & asthma & 0 & 1.00000 & 0.04850 & 0.21488 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & bronch & 0 & 1.00000 & 0.08533 & 0.27946 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & tb & 0 & 1.00000 & 0.01412 & 0.11802 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & hf & 0 & 1.00000 & 0.00491 & 0.06993 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & hbp & 0 & 1.00000 & 1.05095 & 0.95821 & 0.00000 & 0.00000 & 1.00000 & 2.0000e+00 & 2.0000e+00\\
\hline
numeric & pepticulcer & 0 & 1.00000 & 0.10374 & 0.30502 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & colitis & 0 & 1.00000 & 0.03376 & 0.18067 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & hepatitis & 0 & 1.00000 & 0.01719 & 0.13001 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & chroniccough & 0 & 1.00000 & 0.05402 & 0.22613 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & hayfever & 0 & 1.00000 & 0.08963 & 0.28573 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & diabetes & 0 & 1.00000 & 0.97974 & 0.99579 & 0.00000 & 0.00000 & 0.00000 & 2.0000e+00 & 2.0000e+00\\
\hline
numeric & polio & 0 & 1.00000 & 0.01412 & 0.11802 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & tumor & 0 & 1.00000 & 0.02333 & 0.15099 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & nervousbreak & 0 & 1.00000 & 0.02885 & 0.16744 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & alcoholpy & 0 & 1.00000 & 0.87600 & 0.33887 & 0.00000 & 1.00000 & 1.00000 & 1.0000e+00 & 2.0000e+00\\
\hline
numeric & alcoholfreq & 0 & 1.00000 & 1.92020 & 1.30714 & 0.00000 & 1.00000 & 2.00000 & 3.0000e+00 & 5.0000e+00\\
\hline
numeric & alcoholtype & 0 & 1.00000 & 2.47575 & 1.20816 & 1.00000 & 1.00000 & 3.00000 & 4.0000e+00 & 4.0000e+00\\
\hline
numeric & alcoholhowmuch & 417 & 0.74401 & 3.28713 & 2.98470 & 1.00000 & 2.00000 & 2.00000 & 4.0000e+00 & 4.8000e+01\\
\hline
numeric & pica & 0 & 1.00000 & 0.97545 & 0.99785 & 0.00000 & 0.00000 & 0.00000 & 2.0000e+00 & 2.0000e+00\\
\hline
numeric & headache & 0 & 1.00000 & 0.62983 & 0.48300 & 0.00000 & 0.00000 & 1.00000 & 1.0000e+00 & 1.0000e+00\\
\hline
numeric & otherpain & 0 & 1.00000 & 0.24616 & 0.43091 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & weakheart & 0 & 1.00000 & 0.02210 & 0.14705 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & allergies & 0 & 1.00000 & 0.06200 & 0.24123 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & nerves & 0 & 1.00000 & 0.14426 & 0.35146 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & lackpep & 0 & 1.00000 & 0.05095 & 0.21997 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & hbpmed & 0 & 1.00000 & 1.00552 & 0.98295 & 0.00000 & 0.00000 & 1.00000 & 2.0000e+00 & 2.0000e+00\\
\hline
numeric & boweltrouble & 0 & 1.00000 & 1.03499 & 0.96722 & 0.00000 & 0.00000 & 1.00000 & 2.0000e+00 & 2.0000e+00\\
\hline
numeric & wtloss & 0 & 1.00000 & 0.02578 & 0.15854 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & infection & 0 & 1.00000 & 0.14794 & 0.35515 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & active & 0 & 1.00000 & 0.65193 & 0.65274 & 0.00000 & 0.00000 & 1.00000 & 1.0000e+00 & 2.0000e+00\\
\hline
numeric & exercise & 0 & 1.00000 & 1.19521 & 0.73935 & 0.00000 & 1.00000 & 1.00000 & 2.0000e+00 & 2.0000e+00\\
\hline
numeric & birthcontrol & 0 & 1.00000 & 1.08471 & 0.94775 & 0.00000 & 0.00000 & 1.00000 & 2.0000e+00 & 2.0000e+00\\
\hline
numeric & pregnancies & 903 & 0.44567 & 3.69146 & 2.20560 & 1.00000 & 2.00000 & 3.00000 & 5.0000e+00 & 1.5000e+01\\
\hline
numeric & cholesterol & 16 & 0.99018 & 219.97396 & 45.44420 & 78.00000 & 189.00000 & 216.00000 & 2.4500e+02 & 4.1600e+02\\
\hline
numeric & hightax82 & 92 & 0.94352 & 0.16591 & 0.37212 & 0.00000 & 0.00000 & 0.00000 & 0.0000e+00 & 1.0000e+00\\
\hline
numeric & price71 & 92 & 0.94352 & 2.13875 & 0.22902 & 1.50659 & 2.03662 & 2.16797 & 2.2417e+00 & 2.6929e+00\\
\hline
numeric & price82 & 92 & 0.94352 & 1.80610 & 0.13064 & 1.45190 & 1.73999 & 1.81494 & 1.8677e+00 & 2.1030e+00\\
\hline
numeric & tax71 & 92 & 0.94352 & 1.05858 & 0.21623 & 0.52490 & 0.94495 & 1.04980 & 1.1548e+00 & 1.5225e+00\\
\hline
numeric & tax82 & 92 & 0.94352 & 0.50598 & 0.11189 & 0.21997 & 0.43994 & 0.50598 & 5.7190e-01 & 7.4792e-01\\
\hline
numeric & price71\_82 & 92 & 0.94352 & 0.33274 & 0.15504 & -0.20270 & 0.20099 & 0.33600 & 4.4379e-01 & 6.1206e-01\\
\hline
numeric & tax71\_82 & 92 & 0.94352 & 0.55261 & 0.15032 & 0.03600 & 0.46100 & 0.54395 & 6.2195e-01 & 8.8440e-01\\
\hline
\end{tabular}

\hypertarget{origami}{%
\chapter{Cross-validation}\label{origami}}

\emph{Ivana Malenica}

Based on the \href{https://github.com/tlverse/origami}{\passthrough{\lstinline!origami!} \passthrough{\lstinline!R!} package}
by \emph{Jeremy Coyle, Nima Hejazi, Ivana Malenica and Rachael Phillips}.

Updated: 2021-04-28

\hypertarget{learning-objectives-2}{%
\section{Learning Objectives}\label{learning-objectives-2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Differentiate between training, validation and test sets.
\item
  Understand the concept of a loss function, risk and cross-validation.
\item
  Select a loss function that is appropriate for the functional parameter to be
  estimated.
\item
  Understand and contrast different cross-validation schemes for i.i.d. data.
\item
  Understand and contrast different cross-validation schemes for time dependent
  data.
\item
  Setup the proper fold structure, build custom fold-based function, and
  cross-validate the proposed function using the \passthrough{\lstinline!origami!} \passthrough{\lstinline!R!} package.
\item
  Setup the proper cross-validation structure for the use by the Super Learner
  using the the \passthrough{\lstinline!origami!} \passthrough{\lstinline!R!} package.
\end{enumerate}

\hypertarget{introduction-1}{%
\section{Introduction}\label{introduction-1}}

In this chapter, we start elaborating on the estimation step outlined in the
\protect\hyperlink{intro}{introductory chapter}, which discussed the \protect\hyperlink{roadmap}{\emph{Roadmap for Targeted
Learning}}. In order to generate an initial estimate of our target
parameter -- which is the focus of the following \protect\hyperlink{sl3}{chapter on Super
Learning}, we first need to translate, and incorporate, our knowledge
about the data generating process into the estimation procedure, and decide how
to evaluate our estimation performance.

The performance, or error, of any algorithm used in the estimation procedure
directly relates to its generalizability on the independent data. The proper
assessment of the performance of proposed algorithms is extremely important; it
guides the choice of the final learning method, and it gives us a quantitative
assessment of how good the chosen algorithm is doing. In order to assess the
performance of an algorithm, we introduce the concept of a \textbf{loss} function,
which helps us define the \textbf{risk}, also referred to as the \textbf{expected
prediction error}. Our goal, as further specified in the next chapter, will be
to estimate the true risk of the proposed statistical learning method. Our
goal(s) consist of:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Estimating the performance of different algorithms in order to choose the
  best one.
\item
  Having chosen a winner, try to estimate the true risk of the proposed
  statistical learning method.
\end{enumerate}

In the following, we propose a method to do so using the observed data and
\textbf{cross-validation} procedure using the \passthrough{\lstinline!origami!} package \citep{coyle2018origami}.

\hypertarget{background}{%
\section{Background}\label{background}}

Ideally, in a data-rich scenario, we would split our dataset into three parts:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  training set,
\item
  validation set,
\item
  test set.
\end{enumerate}

The training set is used to fit algorithm(s) of interest; we evaluate the
performance of the fit(s) on a validation set, which can be used to estimate
prediction error (e.g., for tuning and model selection). The final error of the
chosen algorithm(s) is obtained by using the test set, which is kept separately,
and doesn't see the data before the final evaluation. One might wonder, with
training data readily available, why not use the training error to evaluate the
proposed algorithm's performance? Unfortunately, the training error is not a
good estimate of the true risk; it consistently decreases with model complexity,
resulting in a possible overfit to the training data and low generalizability.

Since data are often scarce, separating it into training, validation and test
set is usually not possible. In the absence of a large data set and a designated
test set, we must resort to methods that estimate the true risk by efficient
sample re-use. Re-sampling methods, in great generality, involve repeatedly
sampling from the training set and fitting proposed algorithms on the new
samples. While often computationally intensive, re-sampling methods are
particularly useful for model selection and estimation of the true risk. In
addition, they might provide more insight on variability and robustness of the
algorithm fit then fitting an algorithm only once on all the training data.

\hypertarget{introducing-cross-validation}{%
\subsection{Introducing: cross-validation}\label{introducing-cross-validation}}

In this chapter, we focus on \textbf{cross-validation} -- an essential tool for
evaluating how any given algorithm extends from a sample to the target
population from which the sample is derived. It has seen widespread application
in all facets of statistics, perhaps most notably statistical machine learning.
The cross-validation procedure can be used for model selection, as well as for
estimation of the true risk associated with any statistical learning method in
order to evaluate its performance. It particular, cross-validation directly
estimates the true risk when the estimate is applied to an independent sample
from the joint distribution of the predictors and outcome. When used for model
selection, cross-validation has powerful optimality properties. The asymptotic
optimality results state that the cross-validated selector performs (in terms of
risk) asymptotically as well as an optimal oracle selector based on the true,
unknown data generating distribution. For further details on the theoretical
results, we suggest \citet{vdl2004asymptotic}, \citet{dudoit2005asymptotics} and
\citet{vaart2006oracle}.

In great generality, cross-validation works by partitioning a sample into
complementary subsets, applying a particular algorithm(s) on a subset (the
training set), and evaluating the method of choice on the complementary subset
(the validation/test set). This procedure is repeated across multiple partitions
of the data. A variety of different partitioning schemes exist, depending on the
problem of interest, data size, prevalence of the outcome, and dependence
structure. The \passthrough{\lstinline!origami!} package provides a suite of tools that generalize the
application of cross-validation to arbitrary data analytic procedures. In the
the following, we describe different types of cross-validation schemes readily
available in \passthrough{\lstinline!origami!}, introduce the general structure of the \passthrough{\lstinline!origami!}
package, and show their use in applied settings.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{estimation-roadmap-how-does-it-all-fit-together}{%
\section{Estimation Roadmap: how does it all fit together?}\label{estimation-roadmap-how-does-it-all-fit-together}}

Similarly to how we defined the \protect\hyperlink{roadmap}{\emph{Roadmap for Targeted Learning}}, we
can define the \textbf{Estimation Roadmap} to guide the estimation process. In
particular, we have developed a unified loss-based cross-validation methodology
for estimator construction, selection, and performance assessment in a series of
articles (e.g., see \citet{vdl2004asymptotic}, \citet{dudoit2005asymptotics},
\citet{vaart2006oracle}, and \citet{vdl2007super}) that follow three main steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{The loss funtion}:
  Define the target parameter as the minimizer of the expected loss (risk) for a
  full data loss function chosen to represent the desired performance measure.
  Map the full data loss function into an observed data loss function, having the
  same expected value and leading to an efficient estimator of risk.
\item
  \textbf{The algorithms}:
  Construct a finite collection of candidate estimators for the parameter of
  interest.
\item
  \textbf{The cross-validation scheme}:
  Apply appropriate cross-validation to select an optimal estimator among the
  candidates, and assess the overall performance of the resulting estimator.
\end{enumerate}

Step 1 of the Estimation Roadmap allows us to unify a broad range of problems
that are traditionally treated separately in the statistical literature,
including density estimation, prediction of polychotomous and continuous
outcomes. For example, if we are interested in estimating the full joint
conditional density, we could use the negative log-likelihood loss. If instead
we are interested in the conditional mean with continuous outcome, one could use
the squared error loss; had the outcome been binary, one could resort to the
indicator (0-1) loss. The unified loss-based framework also reconciles censored
and full data estimation methods, as full data estimators are recovered as
special cases of censored data estimators.

\hypertarget{example-cross-validation-and-prediction}{%
\section{Example: cross-validation and prediction}\label{example-cross-validation-and-prediction}}

Now that we introduced the Estimation Roadmap, we can define our objective with
more mathematical notation, using prediction as an example. Let the observed
data be defined as \(X = (W,Y)\), where a unit specific data can be written as
\(X_i = (W_i,Y_i)\), for \(i = 1, \ldots, n\). For each of the \(n\) samples, we
denote \(Y_i\) as the outcome of interest (polychotomous or continuous), and \(W_i\)
as a \(p\)-dimensional set of covariates. Let \(\psi_0(W)\) denote the target
parameter of interest we want to estimate; for this example, we are interested
in estimating the conditional expectation of the outcome given the covariates,
\(\psi_0(W) = E(Y \mid W)\). Following the Estimation Roadmap, we chose the
appropriate loss function, \(L\), such that \(\psi_0(W) = \text{argmin}_{\psi} E[L(X,\psi(W))]\). But how do we know how each \(\psi\) is doing? In order to pick
the optimal estimator among the candidates, and assess the overall performance
of the resulting estimator, use cross-validation -- dividing the available data
into the training set and validation set. Observations in the training set are
used to fit (or train) the estimator, while the validation set is used to assess
the risk of (or validate) it.

To derive a general representation for cross-validation, we define a \textbf{split
vector}, \(B_n = (B_n(i): i = 1, \ldots, n) \in \{0,1\}^n\). Note that split
vector is independent of the empirical distribution, \(P_n\). A realization of
\(B_n\) defines a random split of the data into a training and validation set such
that if
\[B_n(i) = 0, \ \ \text{i sample is in the training set}\]
\[B_n(i) = 1, \ \ \text{i sample is in the validation set.}\]
We can further define \(P_{n,B_n}^0\) and \(P_{n,B_n}^1\) as the empirical
distributions of the training and validation sets, respectively. Then \(n_0 = \sum_i 1-B_n(i)\) and \(n_1 = \sum_i B_n(i)\) denote the number of samples in each
set. The particular distribution of the split vector \(B_n\) defines the type of
cross-validation scheme, tailored to the problem and data set in hand.

\hypertarget{cross-validation-schemes-in-origami}{%
\section{\texorpdfstring{Cross-validation schemes in \texttt{origami}}{Cross-validation schemes in origami}}\label{cross-validation-schemes-in-origami}}

As we specified earlier, the particular distribution of the split vector \(B_n\)
defines the type of cross-validation method. In the following, we describe
different types of cross-validation schemes available in \passthrough{\lstinline!origami!} package, and
show their use in the sequel.

\hypertarget{wash-benefits-study-example}{%
\subsection*{WASH Benefits Study Example}\label{wash-benefits-study-example}}


In order to illustrate different cross-validation schemes, we will be using the
WASH data. Detailed information on the WASH Benefits Example Dataset can be
found in \protect\hypertarget{data}{}{Chapter 3}. In particular, we are interested in predicting
weight-for-height z-score \passthrough{\lstinline!whz!} using the available covariate data. For this
illustration, we will start by treating the data as independent and identically
distributed (i.i.d.) random draws. To see what each cross-validation scheme is
doing, we will subset the data to only \(n=30\). Note that each row represents an
i.i.d. sample, indexed by the row number.

\begin{lstlisting}[language=R]
library(data.table)
library(origami)
library(knitr)
library(kableExtra)

# load data set and take a peek
washb_data <- fread(
  paste0(
    "https://raw.githubusercontent.com/tlverse/tlverse-data/master/",
    "wash-benefits/washb_data.csv"
  ),
  stringsAsFactors = TRUE
)
\end{lstlisting}

\begin{tabular}{r|l|l|r|r|l|r|l|r|l|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r}
\hline
whz & tr & fracode & month & aged & sex & momage & momedu & momheight & hfiacat & Nlt18 & Ncomp & watmin & elec & floor & walls & roof & asset\_wardrobe & asset\_table & asset\_chair & asset\_khat & asset\_chouki & asset\_tv & asset\_refrig & asset\_bike & asset\_moto & asset\_sewmach & asset\_mobile\\
\hline
0.00 & Control & N05265 & 9 & 268 & male & 30 & Primary (1-5y) & 146.40 & Food Secure & 3 & 11 & 0 & 1 & 0 & 1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 1\\
\hline
-1.16 & Control & N05265 & 9 & 286 & male & 25 & Primary (1-5y) & 148.75 & Moderately Food Insecure & 2 & 4 & 0 & 1 & 0 & 1 & 1 & 0 & 1 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
-1.05 & Control & N08002 & 9 & 264 & male & 25 & Primary (1-5y) & 152.15 & Food Secure & 1 & 10 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
-1.26 & Control & N08002 & 9 & 252 & female & 28 & Primary (1-5y) & 140.25 & Food Secure & 3 & 5 & 0 & 1 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 1\\
\hline
-0.59 & Control & N06531 & 9 & 336 & female & 19 & Secondary (>5y) & 150.95 & Food Secure & 2 & 7 & 0 & 1 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
-0.51 & Control & N06531 & 9 & 304 & male & 20 & Secondary (>5y) & 154.20 & Severely Food Insecure & 0 & 3 & 1 & 1 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
\end{tabular}

Above is a look at the first 30 of the data.

\hypertarget{cross-validation-for-i.i.d.-data}{%
\subsection{Cross-validation for i.i.d. data}\label{cross-validation-for-i.i.d.-data}}

\hypertarget{re-substitution}{%
\subsubsection{Re-substitution}\label{re-substitution}}

The re-substitution method is the simplest strategy for estimating the risk
associated with fitting a proposed algorithm on a set of observations. Here, all
observed data is used for both training and validation set.

We illustrate the usage of the re-substitution method with \passthrough{\lstinline!origami!} package
below; we will use the function \passthrough{\lstinline!folds\_resubstitution(n)!}. In order to setup
\passthrough{\lstinline!folds\_resubstitution(n)!}, we just need the total number of samples we want to
allocate to training and validation sets; remember that each row of data is a
unique i.i.d. sample. Notice the structure of the \passthrough{\lstinline!origami!} output:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  v: the cross-validation fold
\item
  training\_set: the indexes of the samples in the training set
\item
  validation\_set: the indexes of the samples in the training set.
\end{enumerate}

This structure of the \passthrough{\lstinline!origami!} output (fold(s)) will persist for each of the
cross-validation schemes we present in this chapter. Below, we show the fold
generated by the re-substitution method:

\begin{lstlisting}[language=R]
folds_resubstitution(nrow(washb_data))
[[1]]
$v
[1] 1

$training_set
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
[26] 26 27 28 29 30

$validation_set
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
[26] 26 27 28 29 30

attr(,"class")
[1] "fold"
\end{lstlisting}

\hypertarget{holdout-method}{%
\subsubsection{Holdout method}\label{holdout-method}}

The holdout method, or the validation set approach, consists of randomly
dividing the available data into the training set and validation set (holdout
set). The model is then fitted on the training set, and further evaluated on
the observations in the validation set. Typically, the data is split into
\(60/40\), \(70/30\) or \(80/20\) splits.

The holdout method is intuitive, conceptually easy, and computationally not too
demanding. However, if we repeat the process of randomly splitting the data into
the training and validation set, we might get a different validation loss (e.g.,
MSE). In particular, the loss over the validation sets might be highly
variable, depending on which samples were included in the training/validation
split. For classification problems, there is a possibility of an uneven
distribution of different classes in the training and validation set unless data
is stratified. Finally, note that we are not using all of the data to train and
evaluate the performance of the proposed algorithm, which might result in bias.

\hypertarget{leave-one-out}{%
\subsubsection{Leave-one-out}\label{leave-one-out}}

The leave-one-out cross-validation scheme is closely related to the holdout
method. In particular, it also involves splitting the data into the training and
validation set; however, instead of partitioning the observed data into sets of
similar size, a single observation is used as a validation set. With that,
majority of the units are employed for training (fitting) the proposed
algorithm. Since only one unit (for example \(x_1 = (w_1, y_1)\)) is not used in
the fitting process, leave-one-out cross-validation results in a possibly less
biased estimate of the true risk; typically, leave-one-out approach will not
overestimate the risk as much as the holdout method. On the other hand, since
the estimate of risk is based on a single sample, it is typically a highly
variable estimate.

We can repeat the process of spiting the data into training and validation set
until all samples are part of the validation set at some point. For example,
next iteration of the cross-validation might have \(x_2 = (w_2,y_2)\) as the
validation set and all the rest of \(n-1\) samples as the training set. Repeating
this approach \(n\) times results in, for example, \(n\) squared errors \(MSE_1, MSE_2, \ldots, MSE_n\). The estimate of the true risk is the average over the
\(n\) squared errors. While the leave-one-out cross-validation results in a less
biased (albeit, more variable) estimate of risk than the holdout method, it
could be expensive to implement if \(n\) is large.

We illustrate the usage of the leave-one-out cross-validation with \passthrough{\lstinline!origami!}
package below; we will use the function \passthrough{\lstinline!folds\_loo(n)!}. In order to setup
\passthrough{\lstinline!folds\_loo(n)!}, similarly to the re-substitution method, we just need the total
number of samples we want to cross-validate. We show the first two folds
generated by the leave-one-out cross-validation below.

\begin{lstlisting}[language=R]
folds <- folds_loo(nrow(washb_data))
folds[[1]]
$v
[1] 1

$training_set
 [1]  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26
[26] 27 28 29 30

$validation_set
[1] 1

attr(,"class")
[1] "fold"
folds[[2]]
$v
[1] 2

$training_set
 [1]  1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26
[26] 27 28 29 30

$validation_set
[1] 2

attr(,"class")
[1] "fold"
\end{lstlisting}

\hypertarget{v-fold}{%
\subsubsection{V-fold}\label{v-fold}}

An alternative to leave-one-out is V-fold cross-validation. This
cross-validation scheme randomly divides the data into \(v\) sets (folds) of equal
size; for each fold, the number of samples in the validation set are the same.
For V-fold cross-validation, one of the folds is treated as a validation set,
whereas the proposed algorithm is fit on the remaining \(v-1\) folds in the
training set. The loss, for example MSE, is computed on the samples in the
validation set. With the proposed algorithm trained and its performance
evaluated on the first fold, we repeat this process \(v\) times; each time, a
different group of samples is treated as a validation set. Note that with V-fold
cross-validation we effectively use all of the data to train and evaluate the
proposed algorithm without overfitting to the training data. In the end, the
V-fold cross-validation results in \(v\) estimates of validation error. The final
V-fold CV estimate is computed as an average over all the validation losses.

For a dataset with \(n\) samples, V-fold cross-validation with \(v=n\) is just
leave-one-out; similarly, if we set \(n=1\), we can get the holdout method's
estimate of algorithm's performance. Despite the obvious computational
advantages, V-fold cross-validation often gives more accurate estimates of the
true risk. The reason for this comes from the bias-variance trade-off that comes
from employing both methods; while leave-one-out might be less biased, it has
higher variance. This difference becomes more obvious as \(v<<n\) (but not too
small, as then we increase bias). With V-fold cross-validation, we end up
averaging output from \(v\) fits that are typically less correlated than the
outputs from leave-one-out fits. Since the mean of many highly correlated
quantities has higher variance, leave-one-out estimate of the risk will also
have higher variance than the estimate based on V-fold cross-validation.

Let's see V-fold cross-validation with \passthrough{\lstinline!origami!} in action! In the next chapter
we will study the Super Learner, an actual algorithm that we fit and evaluate
its performance, that uses V-fold as default cross-validation scheme. In order
to set up V-fold CV, we need to call function \passthrough{\lstinline!folds\_vfold(n, V)!}. Arguments
for \passthrough{\lstinline!folds\_vfold(n, V)!} require the total number of samples to be
cross-validated, and the number of folds we want to get.

At \(V=2\), we get 2 folds with \(n/2\) number of samples in both training and
validation set.

\begin{lstlisting}[language=R]
folds <- folds_vfold(nrow(washb_data), V = 2)
folds[[1]]
$v
[1] 1

$training_set
 [1]  2  3  4  6  7  8 11 12 14 15 19 22 23 24 28

$validation_set
 [1]  1  5  9 10 13 16 17 18 20 21 25 26 27 29 30

attr(,"class")
[1] "fold"
folds[[2]]
$v
[1] 2

$training_set
 [1]  1  5  9 10 13 16 17 18 20 21 25 26 27 29 30

$validation_set
 [1]  2  3  4  6  7  8 11 12 14 15 19 22 23 24 28

attr(,"class")
[1] "fold"
\end{lstlisting}

\hypertarget{monte-carlo}{%
\subsubsection{Monte Carlo}\label{monte-carlo}}

With Monte Carlo cross-validation, we randomly select some fraction of the data
(without replacement) to form the training set; we assign the rest of the
samples to the validation set. With that, the data is repeatedly and randomly
divided into two sets, a training set of \(n_0 = n \cdot (1-p)\) observations and
a validation set of \(n_1 = n \cdot p\) observations. This process is then
repeated multiple times, generating (at random) new training and validation
partitions each time.

Since the partitions are independent across folds, the same sample can appear in
the validation set multiple times -- note that this is a stark difference
between Monte Carlo and V-fold cross-validation. With Monte Carlo
cross-validation, one is able to explore many more available partitions than
with V-fold cross-validation -- resulting in a possibly less variable estimate
of the risk, at a cost of an increase in bias.

We illustrate the usage of the Monte Carlo cross-validation with \passthrough{\lstinline!origami!}
package below using the function \passthrough{\lstinline!folds\_montecarlo(n, V, pvalidation)!}. In order
to setup \passthrough{\lstinline!folds\_montecarlo(n, V, pvalidation)!}, we need:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the total number of samples we want to cross-validate;
\item
  the number of folds;
\item
  the proportion of observations to be placed in the validation set.
\end{enumerate}

At \(V=2\) and \(pvalidation=0.2\), we obtain 2 folds with approximately \(6\) samples
in validation set per fold.

\begin{lstlisting}[language=R]
folds <- folds_montecarlo(nrow(washb_data), V = 2, pvalidation = 0.2)
folds[[1]]
$v
[1] 1

$training_set
 [1] 19 27 16 29 23 12  1  3 18 11  5  7  8  6  9 22 10 25 20 28 15  2 24 26

$validation_set
[1]  4 13 14 17 21 30

attr(,"class")
[1] "fold"
folds[[2]]
$v
[1] 2

$training_set
 [1] 19 15 28 25 29 11 20 17 14  4  9 12 30  8 27 18 16 10 13  6 24  3 26  1

$validation_set
[1]  2  5  7 21 22 23

attr(,"class")
[1] "fold"
\end{lstlisting}

\hypertarget{bootstrap}{%
\subsubsection{Bootstrap}\label{bootstrap}}

The bootstrap cross-validation also consists of randomly selecting samples, with
replacement, for the training set. The rest of the samples not picked for the
training set are allocated to the validation set. This process is then repeated
multiple times, generating (at random) new training and validation partitions
each time. In contract to the Monte Carlo cross-validation, the total number of
samples in a training and validation size across folds is not constant. We also
sample with replacement, hence the same samples can be in multiple training
sets. The proportion of observations in the validation sets is a random
variable, with expectation \(\sim 0.368\).

We illustrate the usage of the bootstrap cross-validation with \passthrough{\lstinline!origami!} package
below using the function \passthrough{\lstinline!folds\_bootstrap(n, V)!}. In order to setup
\passthrough{\lstinline!folds\_bootstrap(n, V)!}, we need:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the total number of samples we want to cross-validate;
\item
  the number of folds.
\end{enumerate}

At \(V=2\), we obtain \(2\) folds with different number of samples in the validation
set across folds.

\begin{lstlisting}[language=R]
folds <- folds_bootstrap(nrow(washb_data), V = 2)
folds[[1]]
$v
[1] 1

$training_set
 [1]  2  5 30  1 29 16 10 11  8 25 28  2 11  2 16 28 15 28  1 27  9 19 20 30 18
[26] 11 13  2 18 12

$validation_set
 [1]  3  4  6  7 14 17 21 22 23 24 26

attr(,"class")
[1] "fold"
folds[[2]]
$v
[1] 2

$training_set
 [1] 12 16 10 29 22 15 27  9 27 16 12 28 10 28 26  1 14  6 23 14 21 16  5 20  8
[26] 23 25  8 27  5

$validation_set
 [1]  2  3  4  7 11 13 17 18 19 24 30

attr(,"class")
[1] "fold"
\end{lstlisting}

\hypertarget{cross-validation-for-dependent-data}{%
\subsection{Cross-validation for dependent data}\label{cross-validation-for-dependent-data}}

The \passthrough{\lstinline!origami!} package also supports numerous cross-validation schemes for
time-series data, for both single and multiple time-series with arbitrary time
and network dependence.

\hypertarget{airpassenger-example}{%
\subsection*{AirPassenger Example}\label{airpassenger-example}}


In order to illustrate different cross-validation schemes for time-series, we
will be using the AirPassenger data; this is a widely used, freely available
dataset. The AirPassenger dataset in \passthrough{\lstinline!R!} provides monthly totals of
international airline passengers from 1949 to 1960. This dataset is already of a
time series class therefore no further class or date manipulation is required.

\textbf{Goal:} we want to forecast the number of airline passengers at time \(h\)
horizon using the historical data from 1949 to 1960.

\begin{lstlisting}[language=R]
library(ggfortify)

data(AirPassengers)
AP <- AirPassengers

autoplot(AP) +
  labs(
    x = "Date",
    y = "Passenger numbers (1000's)",
    title = "Air Passengers from 1949 to 1961"
  )

t <- length(AP)
\end{lstlisting}

\begin{center}\includegraphics[width=0.8\linewidth]{05-origami_files/figure-latex/plot_airpass-1} \end{center}

\hypertarget{rolling-origin}{%
\subsubsection{Rolling origin}\label{rolling-origin}}

Rolling origin cross-validation scheme lends itself to ``online'' algorithms,
where large streams of data have to be fit continually, and the final fit is
constantly updated with more data acquired. In general, the rolling origin
scheme defines an initial training set, and with each iteration the size of the
training set grows by \(m\) observations until we reach time \(t\) for a particular
fold. The time points included in the training set are always behind the
validation set time points; in addition, there might be a gap between training
and validation times of size \(h\).

To further illustrate rolling origin cross-validation, we show below an example
with 3 folds. Here, the first window size is 15 time points, on which we first
train the proposed algorithm. We then evaluate its performance on 10 time
points, with a gap of size 5 between the training and validation time points.
For the following fold, we train the algorithm on a longer stream of data, 25
time points, including the original 15 we started with. We then evaluate its
performance on 10 time points in the future.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{img/image/rolling_origin} 

}

\caption{Rolling origin CV}\label{fig:unnamed-chunk-1}
\end{figure}

We illustrate the usage of the rolling origin cross-validation with \passthrough{\lstinline!origami!}
package below using the function \passthrough{\lstinline!folds\_rolling\_origin(n, first\_window, validation\_size, gap, batch)!}. In order to setup \passthrough{\lstinline!folds\_rolling\_origin(n, first\_window, validation\_size, gap, batch)!}, we need:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the total number of time points we want to cross-validate
\item
  the size of the first training set
\item
  the size of the validation set
\item
  the gap between training and validation set
\item
  the size of the update on the training set per each iteration of CV
\end{enumerate}

Our time-series has \(t=144\) time points. Setting the \passthrough{\lstinline!first\_window!} to \(50\),
\passthrough{\lstinline!validation\_size!} to 10, \passthrough{\lstinline!gap!} to 5 and \passthrough{\lstinline!batch!} to 20, we get 4 time-series
folds; we show the first two below.

\begin{lstlisting}[language=R]
folds <- folds_rolling_origin(
  t,
  first_window = 50, validation_size = 10, gap = 5, batch = 20
)
folds[[1]]
$v
[1] 1

$training_set
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
[26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50

$validation_set
 [1] 56 57 58 59 60 61 62 63 64 65

attr(,"class")
[1] "fold"
folds[[2]]
$v
[1] 2

$training_set
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
[26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
[51] 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70

$validation_set
 [1] 76 77 78 79 80 81 82 83 84 85

attr(,"class")
[1] "fold"
\end{lstlisting}

\hypertarget{rolling-window}{%
\subsubsection{Rolling window}\label{rolling-window}}

Instead of adding more time points to the training set per each iteration, the
rolling window cross-validation scheme ``rolls'' the training sample forward by
\(m\) time units. The rolling window scheme might be considered in parametric
settings when one wishes to guard against moment or parameter drift that is
difficult to model explicitly; it is also more efficient for computationally
demanding settings such as streaming data, in which large amounts of training
data cannot be stored. In contrast to rolling origin CV, the training sample for
each iteration of the rolling window scheme is always the same.

To illustrate the rolling window cross-validation with 3 time-series folds
below. The first window size is 15 time points, on which we first train the
proposed algorithm. As in the previous illustration, we evaluate its performance
on 10 time points, with a gap of size 5 between the training and validation time
points. However, for the next fold, we train the algorithm on time points
further away from the origin (here, 10 time points). Note that the size of the
training set in the new fold is the same as in the first fold (15 time points).
This setup keeps the training sets comparable over time (and fold) as compared
to the rolling origin CV. We then evaluate the performance of the proposed
algorithm on 10 time points in the future.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{img/image/rolling_window} 

}

\caption{Rolling window CV}\label{fig:unnamed-chunk-2}
\end{figure}

We illustrate the usage of the rolling window cross-validation with \passthrough{\lstinline!origami!}
package below using the function \passthrough{\lstinline!folds\_rolling\_window(n, window\_size, validation\_size, gap, batch)!}. In order to setup \passthrough{\lstinline!folds\_rolling\_window(n, window\_size, validation\_size, gap, batch)!}, we need:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the total number of time points we want to cross-validate
\item
  the size of the training sets
\item
  the size of the validation set
\item
  the gap between training and validation set
\item
  the size of the update on the training set per each iteration of CV
\end{enumerate}

Setting the \passthrough{\lstinline!window\_size!} to \(50\), \passthrough{\lstinline!validation\_size!} to 10, \passthrough{\lstinline!gap!} to 5 and
\passthrough{\lstinline!batch!} to 20, we also get 4 time-series folds; we show the first two below.

\begin{lstlisting}[language=R]
folds <- folds_rolling_window(
  t,
  window_size = 50, validation_size = 10, gap = 5, batch = 20
)
folds[[1]]
$v
[1] 1

$training_set
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
[26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50

$validation_set
 [1] 56 57 58 59 60 61 62 63 64 65

attr(,"class")
[1] "fold"
folds[[2]]
$v
[1] 2

$training_set
 [1] 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45
[26] 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70

$validation_set
 [1] 76 77 78 79 80 81 82 83 84 85

attr(,"class")
[1] "fold"
\end{lstlisting}

\hypertarget{rolling-origin-with-v-fold}{%
\subsubsection{Rolling origin with V-fold}\label{rolling-origin-with-v-fold}}

A variant of rolling origin scheme which accounts for sample dependence is the
rolling-origin-\(V\)-fold cross-validation. In contrast to the canonical rolling
origin CV, samples in the training and validation set are not the same, as the
variant encompasses \(V\)-fold CV in addition to the time-series setup. The
predictions are evaluated on the future times of time-series units not seen
during the training step, allowing for dependence in both samples and time. One
can use the rolling-origin-\(v\)-fold cross-validation with \passthrough{\lstinline!origami!} package
using the function \passthrough{\lstinline!folds\_vfold\_rolling\_origin\_pooled(n, t, id, time, V, first\_window, validation\_size, gap, batch)!}. In the figure below, we show \(V=2\)
\(V\)-folds, and 2 time-series CV folds.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{img/image/rolling_origin_v_fold} 

}

\caption{Rolling origin V-fold CV}\label{fig:unnamed-chunk-3}
\end{figure}

\hypertarget{rolling-window-with-v-fold}{%
\subsubsection{Rolling window with v-fold}\label{rolling-window-with-v-fold}}

Analogous to the previous section, we can extend rolling window CV to support
multiple time-series with arbitrary sample dependence. One can use the
rolling-window-\(V\)-fold cross-validation with \passthrough{\lstinline!origami!} package using the
function \passthrough{\lstinline!folds\_vfold\_rolling\_window\_pooled(n, t, id, time, V, window\_size, validation\_size, gap, batch)!}. In the figure below, we show \(V=2\) \(V\)-folds, and
2 time-series CV folds.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{img/image/rolling_window_v_fold} 

}

\caption{Rolling window V-fold CV}\label{fig:unnamed-chunk-4}
\end{figure}

\hypertarget{general-workflow-of-origami}{%
\section{\texorpdfstring{General workflow of \texttt{origami}}{General workflow of origami}}\label{general-workflow-of-origami}}

Before we dive into more details, let's take a moment to review some of the
basic functionality in \passthrough{\lstinline!origami!} R package. The main function in the \passthrough{\lstinline!origami!}
is \passthrough{\lstinline!cross\_validate!}. To start off, the user must define folds and a function
that operates on each fold. Once these are passed to \passthrough{\lstinline!cross\_validate!}, this
function will map the fold-specific function across the folds, combining the
results in a reasonable way. We will see this in action in later sections; for
now, we provide specific details on each each step of this process below.

\hypertarget{define-folds}{%
\subsection{(1) Define folds}\label{define-folds}}

The \passthrough{\lstinline!folds!} object passed to \passthrough{\lstinline!cross\_validate!} is a list of folds; such lists can
be generated using the \passthrough{\lstinline!make\_folds!} function. Each fold consists of a list with
a \passthrough{\lstinline!training!} index vector, a \passthrough{\lstinline!validation!} index vector, and a \passthrough{\lstinline!fold\_index!} (its
order in the list of folds). This function supports a variety of
cross-validation schemes we describe in the following section. The \passthrough{\lstinline!make\_folds!}
can balance across levels of a variable (\passthrough{\lstinline!strata\_ids!}), and it can also keep
all observations from the same independent unit together (\passthrough{\lstinline!cluster!}).

\hypertarget{define-fold-function}{%
\subsection{(2) Define fold function}\label{define-fold-function}}

The \passthrough{\lstinline!cv\_fun!} argument to \passthrough{\lstinline!cross\_validate!} is a function that will perform some
operation on each fold. The first argument to this function must be \passthrough{\lstinline!fold!},
which will receive an individual fold object to operate on. Additional arguments
can be passed to \passthrough{\lstinline!cv\_fun!} using the \passthrough{\lstinline!...!} argument to \passthrough{\lstinline!cross\_validate!}. Within
this function, the convenience functions \passthrough{\lstinline!training!}, \passthrough{\lstinline!validation!} and
\passthrough{\lstinline!fold\_index!} can return the various components of a fold object. If \passthrough{\lstinline!training!}
or \passthrough{\lstinline!validation!} is passed an object, it will index into it in a sensible way.
For instance, if it is a vector, it will index the vector directly. If it is a
\passthrough{\lstinline!data.frame!} or \passthrough{\lstinline!matrix!}, it will index rows. This allows the user to easily
partition data into training and validation sets. The fold function must return
a named list of results containing whatever fold-specific outputs are generated.

\hypertarget{apply-cross_validate}{%
\subsection{\texorpdfstring{(3) Apply \texttt{cross\_validate}}{(3) Apply cross\_validate}}\label{apply-cross_validate}}

After defining folds, \passthrough{\lstinline!cross\_validate!} can be used to map the \passthrough{\lstinline!cv\_fun!} across
the \passthrough{\lstinline!folds!} using \passthrough{\lstinline!future\_lapply!}. This means that it can be easily parallelized
by specifying a parallelization scheme (i.e., a \passthrough{\lstinline!plan!} from the \href{https://Cran.R-project.org/package=future}{future
parallelization framework for \passthrough{\lstinline!R!}}
\citep{bengtsson2020unifying}). The application of \passthrough{\lstinline!cross\_validate!} generates a list
of results. As described above, each call to \passthrough{\lstinline!cv\_fun!} itself returns a list of
results, with different elements for each type of result we care about. The main
loop generates a list of these individual lists of results (a sort of
``meta-list''). This ``meta-list'' is then inverted such that there is one element
per result type (this too is a list of the results for each fold). By default,
\passthrough{\lstinline!combine\_results!} is used to combine these results type lists in a sensible
manner. How results are combined is determined automatically by examining the
data types of the results from the first fold. This can be modified by
specifying a list of arguments to \passthrough{\lstinline!.combine\_control!}.

\hypertarget{cross-validation-in-action}{%
\section{Cross-validation in action}\label{cross-validation-in-action}}

Let's see \passthrough{\lstinline!origami!} in action! In the following chapter we will learn how to use
cross-validation with the Super Learner, and how we can utilize the power of
cross-validation to build optimal ensembles of algorithms, not just its use on a
single statistical learning method.

\hypertarget{cross-validation-with-linear-regression}{%
\subsection{Cross-validation with linear regression}\label{cross-validation-with-linear-regression}}

First, we will load the relevant \passthrough{\lstinline!R!} packages, set a seed, and load the full
WASH data once again. In order to illustrate cross-validation with \passthrough{\lstinline!origami!} and
linear regression, we will focus on predicting the weight-for-height Z-score
\passthrough{\lstinline!whz!} using all of the available covariate data. As stated previously, we will
assume the data is independent and identically distributed, ignoring the cluster
structure imposed by the clinical trial design. For the sake of illustration, we
will work with a subset of data, and remove all samples with missing data from
the dataset; we will learn in the next chapter how to deal with missingness.

\begin{lstlisting}[language=R]
library(stringr)
library(dplyr)
library(tidyr)

# load data set and take a peek
washb_data <- fread(
  paste0(
    "https://raw.githubusercontent.com/tlverse/tlverse-data/master/",
    "wash-benefits/washb_data.csv"
  ),
  stringsAsFactors = TRUE
)

# Remove missing data, then pick just the first 500 rows
washb_data <- washb_data %>%
  drop_na() %>%
  slice(1:500)

outcome <- "whz"
covars <- colnames(washb_data)[-which(names(washb_data) == outcome)]
\end{lstlisting}

Here's a look at the data:

\begin{tabular}{r|l|l|r|r|l|r|l|r|l|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r}
\hline
whz & tr & fracode & month & aged & sex & momage & momedu & momheight & hfiacat & Nlt18 & Ncomp & watmin & elec & floor & walls & roof & asset\_wardrobe & asset\_table & asset\_chair & asset\_khat & asset\_chouki & asset\_tv & asset\_refrig & asset\_bike & asset\_moto & asset\_sewmach & asset\_mobile\\
\hline
0.00 & Control & N05265 & 9 & 268 & male & 30 & Primary (1-5y) & 146.40 & Food Secure & 3 & 11 & 0 & 1 & 0 & 1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 1\\
\hline
-1.16 & Control & N05265 & 9 & 286 & male & 25 & Primary (1-5y) & 148.75 & Moderately Food Insecure & 2 & 4 & 0 & 1 & 0 & 1 & 1 & 0 & 1 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
-1.05 & Control & N08002 & 9 & 264 & male & 25 & Primary (1-5y) & 152.15 & Food Secure & 1 & 10 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
-1.26 & Control & N08002 & 9 & 252 & female & 28 & Primary (1-5y) & 140.25 & Food Secure & 3 & 5 & 0 & 1 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 1\\
\hline
-0.59 & Control & N06531 & 9 & 336 & female & 19 & Secondary (>5y) & 150.95 & Food Secure & 2 & 7 & 0 & 1 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
-0.51 & Control & N06531 & 9 & 304 & male & 20 & Secondary (>5y) & 154.20 & Severely Food Insecure & 0 & 3 & 1 & 1 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
\end{tabular}

We can see the covariates used in the prediction:

\begin{lstlisting}[language=R]
outcome
[1] "whz"
covars
 [1] "tr"             "fracode"        "month"          "aged"          
 [5] "sex"            "momage"         "momedu"         "momheight"     
 [9] "hfiacat"        "Nlt18"          "Ncomp"          "watmin"        
[13] "elec"           "floor"          "walls"          "roof"          
[17] "asset_wardrobe" "asset_table"    "asset_chair"    "asset_khat"    
[21] "asset_chouki"   "asset_tv"       "asset_refrig"   "asset_bike"    
[25] "asset_moto"     "asset_sewmach"  "asset_mobile"  
\end{lstlisting}

Next, we fit a linear model on the full data, with the goal of predicting the
weight-for-height Z-score \passthrough{\lstinline!whz!} using all of the available covariate data. Let's
try it out:

\begin{lstlisting}[language=R]
lm_mod <- lm(whz ~ ., data = washb_data)
summary(lm_mod)

Call:
lm(formula = whz ~ ., data = washb_data)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.8890 -0.6799 -0.0169  0.6595  3.1005 

Coefficients:
                                Estimate Std. Error t value Pr(>|t|)   
(Intercept)                     -1.89006    1.72022   -1.10   0.2725   
trHandwashing                   -0.25276    0.17032   -1.48   0.1385   
trNutrition                     -0.09695    0.15696   -0.62   0.5371   
trNutrition + WSH               -0.09587    0.16528   -0.58   0.5622   
trSanitation                    -0.27702    0.15846   -1.75   0.0811 . 
trWSH                           -0.02846    0.15967   -0.18   0.8586   
trWater                         -0.07148    0.15813   -0.45   0.6515   
fracodeN05160                    0.62355    0.30719    2.03   0.0430 * 
fracodeN05265                    0.38762    0.31011    1.25   0.2120   
fracodeN05359                    0.10187    0.31329    0.33   0.7452   
fracodeN06229                    0.30933    0.29766    1.04   0.2993   
fracodeN06453                    0.08066    0.30006    0.27   0.7882   
fracodeN06458                    0.43707    0.29970    1.46   0.1454   
fracodeN06473                    0.45406    0.30912    1.47   0.1426   
fracodeN06479                    0.60994    0.31463    1.94   0.0532 . 
fracodeN06489                    0.25923    0.31901    0.81   0.4169   
fracodeN06500                    0.07539    0.35794    0.21   0.8333   
fracodeN06502                    0.36748    0.30504    1.20   0.2290   
fracodeN06505                    0.20038    0.31560    0.63   0.5258   
fracodeN06516                    0.55455    0.29807    1.86   0.0635 . 
fracodeN06524                    0.49429    0.31423    1.57   0.1164   
fracodeN06528                    0.75966    0.31060    2.45   0.0148 * 
fracodeN06531                    0.36856    0.30155    1.22   0.2223   
fracodeN06862                    0.56932    0.29293    1.94   0.0526 . 
fracodeN08002                    0.36779    0.26846    1.37   0.1714   
month                            0.17161    0.10865    1.58   0.1149   
aged                            -0.00336    0.00112   -3.00   0.0029 **
sexmale                          0.12352    0.09203    1.34   0.1802   
momage                          -0.01379    0.00973   -1.42   0.1570   
momeduPrimary (1-5y)            -0.13214    0.15225   -0.87   0.3859   
momeduSecondary (>5y)            0.12632    0.16041    0.79   0.4314   
momheight                        0.00512    0.00919    0.56   0.5776   
hfiacatMildly Food Insecure      0.05804    0.19341    0.30   0.7643   
hfiacatModerately Food Insecure -0.01362    0.12887   -0.11   0.9159   
hfiacatSeverely Food Insecure   -0.13447    0.25418   -0.53   0.5970   
Nlt18                           -0.02557    0.04060   -0.63   0.5291   
Ncomp                            0.00179    0.00762    0.23   0.8145   
watmin                           0.01347    0.00861    1.57   0.1182   
elec                             0.08906    0.10700    0.83   0.4057   
floor                           -0.17763    0.17734   -1.00   0.3171   
walls                           -0.03001    0.21445   -0.14   0.8888   
roof                            -0.03716    0.49214   -0.08   0.9399   
asset_wardrobe                  -0.05754    0.13736   -0.42   0.6755   
asset_table                     -0.22079    0.12276   -1.80   0.0728 . 
asset_chair                      0.28012    0.13750    2.04   0.0422 * 
asset_khat                       0.02306    0.11766    0.20   0.8447   
asset_chouki                    -0.13943    0.14084   -0.99   0.3227   
asset_tv                         0.17723    0.12972    1.37   0.1726   
asset_refrig                     0.12613    0.23162    0.54   0.5863   
asset_bike                      -0.02568    0.10083   -0.25   0.7990   
asset_moto                      -0.32094    0.19944   -1.61   0.1083   
asset_sewmach                    0.05090    0.17795    0.29   0.7750   
asset_mobile                     0.01420    0.14972    0.09   0.9245   
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.984 on 447 degrees of freedom
Multiple R-squared:  0.129, Adjusted R-squared:  0.0277 
F-statistic: 1.27 on 52 and 447 DF,  p-value: 0.104
\end{lstlisting}

We can assess how well the model fits the data by comparing the predictions of
the linear model to the true outcomes observed in the data set. This is the well
known (and standard) mean squared error. We can extract that from the \passthrough{\lstinline!lm!} model
object like so:

\begin{lstlisting}[language=R]
(err <- mean(resid(lm_mod)^2))
[1] 0.86568
\end{lstlisting}

The mean squared error is 0.86568. There is an important problem that arises
when we assess the model in this way - that is, we have trained our linear
regression model on the full data set and assessed the error on the full data
set, using up all of our data. We, of course, are generally not interested in
how well the model explains variation in the observed data; rather, we are
interested in how the explanation provided by the model generalizes to a target
population from which the sample is presumably derived. Having used all of our
available data, we cannot honestly evaluate how well the model fits (and thus
explains) variation at the population level.

To resolve this issue, cross-validation allows for a particular procedure (e.g.,
linear regression) to be implemented over subsets of the data, evaluating how
well the procedure fits on a testing (``validation'') set, thereby providing an
honest evaluation of the error.

We can easily add cross-validation to our linear regression procedure using
\passthrough{\lstinline!origami!}. First, let us define a new function to perform linear regression on a
specific partition of the data (called a ``fold''):

\begin{lstlisting}[language=R]
cv_lm <- function(fold, data, reg_form) {
  # get name and index of outcome variable from regression formula
  out_var <- as.character(unlist(str_split(reg_form, " "))[1])
  out_var_ind <- as.numeric(which(colnames(data) == out_var))

  # split up data into training and validation sets
  train_data <- training(data)
  valid_data <- validation(data)

  # fit linear model on training set and predict on validation set
  mod <- lm(as.formula(reg_form), data = train_data)
  preds <- predict(mod, newdata = valid_data)
  valid_data <- as.data.frame(valid_data)

  # capture results to be returned as output
  out <- list(
    coef = data.frame(t(coef(mod))),
    SE = (preds - valid_data[, out_var_ind])^2
  )
  return(out)
}
\end{lstlisting}

Our \passthrough{\lstinline!cv\_lm!} function is rather simple: we merely split the available data into a
training and validation sets, using the eponymous functions provided in
\passthrough{\lstinline!origami!}, fit the linear model on the training set, and evaluate the model on
the testing set. This is a simple example of what \passthrough{\lstinline!origami!} considers to be
\passthrough{\lstinline!cv\_fun!} -- functions for using cross-validation to perform a particular routine
over an input data set. Having defined such a function, we can simply generate a
set of partitions using \passthrough{\lstinline!origami!}'s \passthrough{\lstinline!make\_folds!} function, and apply our \passthrough{\lstinline!cv\_lm!}
function over the resultant \passthrough{\lstinline!folds!} object. Below, we replicate the
re-substitution estimate of the error -- we did this ``by hand'' above -- using
the functions \passthrough{\lstinline!make\_folds!} and \passthrough{\lstinline!cv\_lm!}.

\begin{lstlisting}[language=R]
# re-substitution estimate
resub <- make_folds(washb_data, fold_fun = folds_resubstitution)[[1]]
resub_results <- cv_lm(fold = resub, data = washb_data, reg_form = "whz ~ .")
mean(resub_results$SE, na.rm = TRUE)
[1] 0.86568
\end{lstlisting}

This (nearly) matches the estimate of the error that we obtained above.

We can more honestly evaluate the error by V-fold cross-validation, which
partitions the data into \(v\) subsets, fitting the model on \(v - 1\) of the
subsets and evaluating on the subset that was held out for testing. This is
repeated such that each subset is used for testing. We can easily apply our
\passthrough{\lstinline!cv\_lm!} function using \passthrough{\lstinline!origami!}'s \passthrough{\lstinline!cross\_validate!} (n.b., by default this
performs 10-fold cross-validation):

\begin{lstlisting}[language=R]
# cross-validated estimate
folds <- make_folds(washb_data)
cvlm_results <- cross_validate(
  cv_fun = cv_lm, folds = folds, data = washb_data, reg_form = "whz ~ .",
  use_future = FALSE
)
mean(cvlm_results$SE, na.rm = TRUE)
[1] 1.35
\end{lstlisting}

Having performed 10-fold cross-validation, we quickly notice that our previous
estimate of the model error (by resubstitution) was a bit optimistic. The honest
estimate of the error is larger.

\hypertarget{cross-validation-with-random-forests}{%
\subsection{Cross-validation with random forests}\label{cross-validation-with-random-forests}}

To examine \passthrough{\lstinline!origami!} further, let us return to our example analysis using the
WASH data set. Here, we will write a new \passthrough{\lstinline!cv\_fun!} type object. As an example, we
will use Breiman's \passthrough{\lstinline!randomForest!} \citep{breiman2001random}:

\begin{lstlisting}[language=R]
# make sure to load the package!
library(randomForest)

cv_rf <- function(fold, data, reg_form) {
  # get name and index of outcome variable from regression formula
  out_var <- as.character(unlist(str_split(reg_form, " "))[1])
  out_var_ind <- as.numeric(which(colnames(data) == out_var))

  # define training and validation sets based on input object of class "folds"
  train_data <- training(data)
  valid_data <- validation(data)

  # fit Random Forest regression on training set and predict on holdout set
  mod <- randomForest(formula = as.formula(reg_form), data = train_data)
  preds <- predict(mod, newdata = valid_data)
  valid_data <- as.data.frame(valid_data)

  # define output object to be returned as list (for flexibility)
  out <- list(
    coef = data.frame(mod$coefs),
    SE = ((preds - valid_data[, out_var_ind])^2)
  )
  return(out)
}
\end{lstlisting}

Above, in writing our \passthrough{\lstinline!cv\_rf!} function to cross-validate \passthrough{\lstinline!randomForest!}, we used
our previous function \passthrough{\lstinline!cv\_lm!} as an example. For now, individual \passthrough{\lstinline!cv\_fun!} must
be written by hand; however, in future releases, a wrapper may be available to
support auto-generating \passthrough{\lstinline!cv\_fun!}s to be used with \passthrough{\lstinline!origami!}.

Below, we use \passthrough{\lstinline!cross\_validate!} to apply our new \passthrough{\lstinline!cv\_rf!} function over the \passthrough{\lstinline!folds!}
object generated by \passthrough{\lstinline!make\_folds!}.

\begin{lstlisting}[language=R]
# now, let's cross-validate...
folds <- make_folds(washb_data)
cvrf_results <- cross_validate(
  cv_fun = cv_rf, folds = folds, data = washb_data, reg_form = "whz ~ .",
  use_future = FALSE
)
mean(cvrf_results$SE)
[1] 1.0271
\end{lstlisting}

Using 10-fold cross-validation (the default), we obtain an honest estimate of
the prediction error of random forests. From this, we gather that the use of
\passthrough{\lstinline!origami!}'s \passthrough{\lstinline!cross\_validate!} procedure can be generalized to arbitrary estimation
techniques, given availability of an appropriate \passthrough{\lstinline!cv\_fun!} function.

\hypertarget{cross-validation-with-arima}{%
\subsection{Cross-validation with arima}\label{cross-validation-with-arima}}

Cross-validation can also be used for forecast model selection in a time series
setting. Here, the partitioning scheme mirrors the application of the
forecasting model: we'll train the data on past observations (either all
available or a recent subset), and then use the model fit to predict the next
few observations. We consider the \passthrough{\lstinline!AirPassengers!} dataset again, a monthly time
series of passenger air traffic in thousands of people.

\begin{lstlisting}[language=R]
data(AirPassengers)
print(AirPassengers)
     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
1949 112 118 132 129 121 135 148 148 136 119 104 118
1950 115 126 141 135 125 149 170 170 158 133 114 140
1951 145 150 178 163 172 178 199 199 184 162 146 166
1952 171 180 193 181 183 218 230 242 209 191 172 194
1953 196 196 236 235 229 243 264 272 237 211 180 201
1954 204 188 235 227 234 264 302 293 259 229 203 229
1955 242 233 267 269 270 315 364 347 312 274 237 278
1956 284 277 317 313 318 374 413 405 355 306 271 306
1957 315 301 356 348 355 422 465 467 404 347 305 336
1958 340 318 362 348 363 435 491 505 404 359 310 337
1959 360 342 406 396 420 472 548 559 463 407 362 405
1960 417 391 419 461 472 535 622 606 508 461 390 432
\end{lstlisting}

Suppose we want to pick between two forecasting models with different \passthrough{\lstinline!arima!}
configurations. We can do that by evaluating their forecasting performance.
First, we set up the appropriate cross-validation scheme for time-series.

\begin{lstlisting}[language=R]
folds <- make_folds(AirPassengers,
  fold_fun = folds_rolling_origin,
  first_window = 36, validation_size = 24, batch = 10
)

# How many folds where generated?
length(folds)
[1] 9

# Examine the first 2 folds.
folds[[1]]
$v
[1] 1

$training_set
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
[26] 26 27 28 29 30 31 32 33 34 35 36

$validation_set
 [1] 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60

attr(,"class")
[1] "fold"
folds[[2]]
$v
[1] 2

$training_set
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
[26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46

$validation_set
 [1] 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70

attr(,"class")
[1] "fold"
\end{lstlisting}

By default, \passthrough{\lstinline!folds\_rolling\_origin!} will increase the size of the training set by
one time point each fold. Had we followed the default option, we would have 85
folds to train! Luckily, we can pass the \passthrough{\lstinline!batch!} as option to
\passthrough{\lstinline!folds\_rolling\_origin!} that tells it to increase the size of the training set by
10 points each iteration. Since we want to forecast the immediate next point,
\passthrough{\lstinline!gap!} argument remains the default (0).

\begin{lstlisting}[language=R]
# make sure to load the package!
library(forecast)

# function to calculate cross-validated squared error
cv_forecasts <- function(fold, data) {
  # Get training and validation data
  train_data <- training(data)
  valid_data <- validation(data)
  valid_size <- length(valid_data)

  train_ts <- ts(log10(train_data), frequency = 12)

  # First arima model
  arima_fit <- arima(train_ts, c(0, 1, 1),
    seasonal = list(
      order = c(0, 1, 1),
      period = 12
    )
  )
  raw_arima_pred <- predict(arima_fit, n.ahead = valid_size)
  arima_pred <- 10^raw_arima_pred$pred
  arima_MSE <- mean((arima_pred - valid_data)^2)

  # Second arima model
  arima_fit2 <- arima(train_ts, c(5, 1, 1),
    seasonal = list(
      order = c(0, 1, 1),
      period = 12
    )
  )
  raw_arima_pred2 <- predict(arima_fit2, n.ahead = valid_size)
  arima_pred2 <- 10^raw_arima_pred2$pred
  arima_MSE2 <- mean((arima_pred2 - valid_data)^2)

  out <- list(mse = data.frame(
    fold = fold_index(),
    arima = arima_MSE, arima2 = arima_MSE2
  ))
  return(out)
}

mses <- cross_validate(
  cv_fun = cv_forecasts, folds = folds, data = AirPassengers,
  use_future = FALSE
)
mses$mse
  fold   arima  arima2
1    1   68.21  137.28
2    2  319.68  313.15
3    3  578.35  713.36
4    4  428.69  505.31
5    5  407.33  371.27
6    6  281.82  250.99
7    7  827.56  910.12
8    8 2099.59 2213.15
9    9  398.37  293.38
colMeans(mses$mse[, c("arima", "arima2")])
 arima arima2 
601.07 634.22 
\end{lstlisting}

The arima model with no AR component seems to be a better fit for this data.

\hypertarget{exercises}{%
\section{Exercises}\label{exercises}}

\hypertarget{review-of-key-concepts}{%
\subsection{Review of Key Concepts}\label{review-of-key-concepts}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Compare and contrast V-fold cross-validation with resubstitution
  cross-validation. What are some of the differences between the two methods?
  How are they similar? Describe a scenario when you would use one over the
  other.
\item
  What are the advantages and disadvantages of \(v\)-fold CV relative to:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    holdout CV?
  \item
    leave-one-out CV?
  \end{enumerate}
\item
  Why can't we use V-fold cross-validation for time-series data?
\item
  Would you use rolling window or origin for non-stationary time-series? Why?
\end{enumerate}

\hypertarget{the-ideas-in-action}{%
\subsection{The Ideas in Action}\label{the-ideas-in-action}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Let \(Y\) be a binary variable with \(P(Y=1 \mid W) = 0.01\). What kind of
  cross-validation scheme should be used for a rare outcome? How can we do this
  with the \passthrough{\lstinline!origami!} package?
\item
  Consider the WASH benefits dataset presented in this chapter. How can we
  include cluster information into cross-validation? How can we do this with
  the \passthrough{\lstinline!origami!} package?
\end{enumerate}

\hypertarget{advanced-topics}{%
\subsection{Advanced Topics}\label{advanced-topics}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Think about a dataset with arbitrary spatial dependence, where we know
  the extent of dependence, and groups formed by such dependence are clear
  with no spillover effects. What kind of cross-validation can we use?
\item
  Continuing on the last problem, what kind of procedure, and cross-validation
  method, can we use if the spatial dependence is not clearly defined as in the
  previous problem?
\item
  Consider a classification problem with a large number of predictors. A
  statistician proposes the following analysis:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    First screen the predictors, leaving only covariates with a strong
    correlation with the class labels.
  \item
    Fit some algorithm using only the subset of highly correlated covariates.
  \item
    Use cross-validation to estimate the tuning parameters and the performance
    of the proposed algorithm.
  \end{enumerate}

  Is this a correct application of cross-validation? Why?
\end{enumerate}

\hypertarget{sl3}{%
\chapter{Super (Machine) Learning}\label{sl3}}

\emph{Rachael Phillips}

Based on the \href{https://github.com/tlverse/sl3}{\passthrough{\lstinline!sl3!} \passthrough{\lstinline!R!} package} by \emph{Jeremy
Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips, and Oleg Sofrygin}.

Updated: 2021-04-28

\hypertarget{learning-objectives-3}{%
\section*{Learning Objectives}\label{learning-objectives-3}}


By the end of this chapter you will be able to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Select a loss function that is appropriate for the functional parameter to
  be estimated.
\item
  Assemble an ensemble of learners based on the properties that identify what
  features they support.
\item
  Customize learner tuning parameters to incorporate a diversity of different
  settings.
\item
  Select a subset of available covariates and pass only those variables to the
  modeling algorithm.
\item
  Fit an ensemble with nested cross-validation to obtain an estimate of the
  performance of the ensemble itself.
\item
  Obtain \passthrough{\lstinline!sl3!} variable importance metrics.
\item
  Interpret the discrete and continuous Super Learner fits.
\item
  Rationalize the need to remove bias from the Super Learner to make an
  optimal bias-variance tradeoff for the parameter of interest.
\end{enumerate}

\hypertarget{motivation}{%
\section*{Motivation}\label{motivation}}


\begin{itemize}
\tightlist
\item
  A common task in data analysis is prediction -- using the observed data to
  learn a function, which can be used to map new input variables into a
  predicted outcome.
\item
  For some data, algorithms that can model a complex function are necessary to
  adequately model the data. For other data, a main terms regression model might
  fit the data quite well.
\item
  The Super Learner (SL), an ensemble learner, solves this issue, by allowing a
  combination of algorithms from the simplest (intercept-only) to most complex
  (neural nets, random forests, SVM, etc).
\item
  It works by using cross-validation in a manner which guarantees that the
  resulting fit will be as good as possible, given the learners provided.
\end{itemize}

\hypertarget{introduction-2}{%
\section{Introduction}\label{introduction-2}}

In \protect\hyperlink{intro}{Chapter 1}, we introduced the \protect\hyperlink{roadmap}{\emph{Roadmap for Targeted
Learning}} as a general template to translate real-world data
applications into formal statistical estimation problems. The first steps of
this roadmap define the \emph{statistical estimation problem}, which establish

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Data as a random variable, or equivalently, a realization of a particular
  experiment/study. We assume the observations in the data are independent and
  identically distributed.
\item
  A statistical model as the set of possible probability distributions that
  could have given rise to the observed data.
\item
  A translation of the scientific question, which is often causal, into a
  target estimand.
\end{enumerate}

Note that if the estimand is causal, step 3 also requires establishing
identifiability of the estimand from the observed data, under possible
non-testable assumptions that may not necessarily be reasonable. Still, the
target quantity does have a valid statistical interpretation. See \protect\hyperlink{causal}{causal target
parameters} for more detail on causal models and identifiability.

Now that we have defined the statistical estimation problem, we are ready to
construct the TMLE; an asymptotically linear and efficient substitution
estimator of this estimand. The first step in this estimation procedure is an
initial estimate of the data-generating distribution, or the relevant part of
this distribution that is needed to evaluate the target parameter. For this
initial estimation, we use the Super Learner (SL) \citep{vdl2007super}.

The SL provides an important step in creating a robust estimator. It is a
loss-function-based tool that uses cross-validation to obtain the best
prediction of our target parameter, based on a weighted average of a library of
machine learning algorithms. The library of machine learning algorithms consists
of functions (``learners'' in the \passthrough{\lstinline!sl3!} nomenclature) that we think might be
consistent with the true data-generating distribution. By ``consistent with the
true data-generating distribution'', we mean that the algorithms selected should
not violate subject-matter knowledge about the experiment that generated the
data. Also, the library should contain a diversity of algorithms that range from
parametric regression models to multi-step algorithms involving screening
covariates, penalizations, optimizing tuning parameters, etc.

The ensembling of the collection of algorithms with weights (``metalearning'' in
the \passthrough{\lstinline!sl3!} nomenclature) has been shown to be adaptive and robust, even in small
samples \citep{polley2010super}. The SL is proven to be asymptotically as accurate as
the best possible prediction algorithm in the library \citep{vdl2003unified, vaart2006oracle}.

\hypertarget{step-by-step-overview}{%
\subsection{Step-by-step overview}\label{step-by-step-overview}}

Consider the scenario in which we have \(n\) independent and identically
distributed observations in the data, and our data structure is not a time
series. Also, let's say we have \(k\) number of candidate learners/algorithms.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create the validation data for all \(V=v\) folds. Break up the data evenly
  into \(V=v\) splits; such that no observation is contained more than one split,
  and the splits contain about the same number of observations (e.g., about
  \(n/V\) observations in each split).

  \begin{itemize}
  \tightlist
  \item
    If a rare binary outcome (or highly important binary predictor, such as
    a treatment) is present in the data, we should consider making the
    prevalence of this binary outcome in the splits similar to the
    prevalence that exists in the data. We can achieve this by specifying,
    for the \passthrough{\lstinline!strata\_ids!} argument in \passthrough{\lstinline!origami::make\_folds()!}, the vector of
    binary outcomes (or important binary covariate).
  \item
    If we have repeated measures or cluster-level dependence in the data,
    then all observations within a subject/cluster should be placed in the
    same split.
  \end{itemize}
\item
  For each fold \(v\):

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \item
    Separate (i) from (ii):
  \item
    The data that was selected for fold \(v\) in Step 1, which contains
    roughly \(n/V\) total observations. We will refer to this subset of the
    data as the ``validation'' data, and it's also commonly referred to as
    the ``test'' data. Let's call \(n_{\text{validation}}\) as the number of
    observations in then validation data,
  \end{enumerate}

  \begin{enumerate}
  \def\labelenumii{\roman{enumii}.}
  \setcounter{enumii}{1}
  \tightlist
  \item
    The data that was NOT selected for fold \(v\) in Step 1, which contains
    roughly \(n - n_{\text{validation}}\) total observations. We will refer
    to this subset of the data as the ``training'', and
    \(n_{\text{training}}\) as the number of observations in the training
    data.
  \end{enumerate}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \setcounter{enumii}{1}
  \tightlist
  \item
    Fit each of the \(k\) learners on the training data (ii).
  \item
    Using each of the \(k\) trained learners, predict the outcomes in the
    validation data (i). We can call these predictions
    ``cross-validated predictions''; since they were obtained from the
    validation sample's covariate information, which was never seen while
    fitting these models. We end up with a \(n_{validation} \times k\)
    matrix of cross-validated predictions.
  \end{enumerate}
\item
  Bind together the rows of all \(v\) \(n_{validation} \times k\) matrices of
  cross-validated predictions, to obtain an \(n \times k\) matrix of
  cross-validated predictions. This matrix \(n \times k\) matrix of
  cross-validated predictions is often referred to as the
  ``level-one'' or ``Z'' matrix.
\item
  Retain the observed outcome \(Y\) for all of the \(n\) observations, using
  them to measure the ``loss'' of each cross-validated prediction
  (e.g., (\(Y - \hat{Y}^2\)).
\item
  For each \(k\) column, take the (potentially weighted) mean across all of the
  \(n\) losses, which we call the ``cross-validated empirical risk''. The
  cross-validated empirical risk provides measure of performance, summarized
  across all \(n\), for each of the \(k\) learners. The weights that could be
  incorporated in the data, and used to calculate a weighted mean, serve to
  to up weight or down weight samples whose loss should be considered less or
  more important, respectively.
\item
  Establish the ensemble/combination of the \(k\) learners by fitting the
  so-called ``metalearner''. The ensemble is just a weighted combination of
  the learners, so the weights here are just a \(k\)-dimensional vector. The
  metalearner is a function that decides on the weights to be assigned to
  each of the \(k\) learners; taking as input the cross-validated empirical risk
  for all \(k\) learners (a), or taking as input a loss function and the Z
  matrix (b).

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    The discrete SL (or cross-validated selector) employs a simple
    metalearner that takes as input the cross-validated empirical risk for
    all \(k\) learners. This metalearner assigns weight of 1 to the single
    learner with smallest cross-validated risk, and a weight of 0 to all
    other learners.
  \item
    The ensemble SL (often referred to as the ``Super Learner'') employs
    metalearners that take as input the Z matrix, and the loss function of
    interest (unless the loss is implied by the metalearning function
    itself). These metalearners assign the weights such that the weighted
    combination of Z matrix predictions is optimized to minimize the
    cross-validated empirical risk. This often results in more than one
    learner having positive weight. Aggressive metalearning (e.g., assigning
    negative weight) can be problematic, leading to overfitting.
  \end{enumerate}
\item
  Fit the learners (or only the learners with non-zero weight from Step 5)
  on the entire sample of \(n\) observations, and use the weights that were
  obtained in Step 5 to get the SL fit. That's it! The SL fit is just all of
  \(k\) learner fits --- the weights don't come in to play until we obtain the
  predictions from the SL; where the SL predictions are the weighted
  combination of the \(k\) learner predictions, as determined by the
  metalearner. Notice that, we use this rigorous, optimal, and fair procedure
  to derive the weights from the \(n \times k\) Z matrix of cross-validated
  predictions; but once we've done that, we capitalize on the entire sample
  of observations, transitioning our focus to obtaining the best fit possible
  of our \(k\) learners.
\item
  SL predictions, variable importance, and/or a cross-validated SL can be
  obtained from an SL fit (like most other learners). The cross-validated SL
  provides an estimate of the performance of the SL on unseen data, and
  incorporates a outer layer of cross-validation in order to cross-validate
  this entire procedure.
\end{enumerate}

Below is a figure from {[}ADD REF{]} describing the same step-by-step procedure.
This figure considers \(k=16\) learners, and in the figure \(p=k\); and the squared
error loss function, thus mean squared error (MSE) is the risk.

\begin{center}\includegraphics[width=0.8\linewidth]{img/misc/SLKaiserNew} \end{center}

\hypertarget{theoretical-foundations-and-further-reading}{%
\subsection{Theoretical Foundations and Further Reading}\label{theoretical-foundations-and-further-reading}}

\begin{itemize}
\item
  Cross-validation is proven to be optimal for selection among estimators. This
  result was established through the oracle inequality for the cross-validation
  selector among a collection of candidate estimators \citep{vdl2003unified, vaart2006oracle}. The only condition is that loss function is uniformly
  bounded, which is guaranteed in \passthrough{\lstinline!sl3!}.
\item
  We use a \emph{loss function} \(L\) to assign a measure of performance to each
  learner \(\psi\) when applied to the data \(O\), and subsequently compare
  performance across the learners. More generally, \(L\) maps every \(\psi \in \R\)
  to \(L(\psi) : (O) \mapsto L(\psi)(O)\). We use the terms ``learner'',
  ``algorithm'', and ``estimator'' interchangeably.

  \begin{itemize}
  \tightlist
  \item
    It is important to recall that \(\psi\) is an estimator of \(\psi_0\), the
    unknown and true parameter value under \(P_0\).
  \item
    A valid loss function will have mean/expectation (risk) that is minimized
    at the true value of the parameter \(\psi_0\). Thus, minimizing the expected
    loss will bring an estimator \(\psi\) closer to the true \(\psi_0\).
  \item
    For example, say we observe a learning data set \(O_i=(Y_i,X_i)\), of
    \(i=1, \ldots, n\) independent and identically distributed observations,
    where \(Y_i\) is a continuous outcome of interest, \(X_i\) is a set of
    covariates. Also, let our objective be to estimate the function \(\psi_0: X \mapsto \psi_0(X) = E_0(Y \mid X)\), which is the conditional mean outcome
    given covariates. This function can be expressed as the minimizer of the
    expected squared error loss: \(\psi_0 = \text{argmin}_{\psi} E[L(O,\psi(X))]\), where \(L(O, \psi(X)) = (Y - \psi(X))^2\).
  \item
    We can estimate the loss by substituting the empirical distribution of
    the data \(P_n\) for the true and unknown distribution of the observed data
    \(P_0\).
  \item
    Also, we can use the cross-validated risk to empirically determine the
    relative performance of an estimator (i.e., a candidate learner), and
    perhaps how it's performance compares to other estimators.
  \item
    Once we have tested different estimators on actual data, and looked at
    the performance (e.g., MSE of predictions across all learners), we can
    see which algorithm (or weighted combination) has the lowest risk, and
    thus is closest to the true \(\psi_0\).
  \end{itemize}
\item
  The \emph{cross-validated empirical risk} of an algorithm is defined as the
  empirical mean over a validation sample of the loss of the algorithm fitted on
  the training sample, averaged across the splits of the data.

  \begin{itemize}
  \tightlist
  \item
    The \emph{discrete Super Learner}, or \emph{cross-validation selector}, is the
    algorithm in the library that minimizes the cross-validated empirical
    risk.
  \item
    The \emph{continuous/ensemble Super Learner}, often referred to as
    \emph{Super Learner} is a weighted average of the library of algorithm
    predictions, where the weights are chosen to minimize the cross-validated
    empirical risk of the library. This notion of weighted combinations was
    introduced in \citet{wolpert1992stacked} for neural networks and adapted for
    regressions in \citet{breiman1996stacked}. Restricting the weights to be positive
    and sum to one (i.e., a convex combination) has been shown to perform well
    in practice \citep{polley2010super, vdl2007super}.
  \end{itemize}
\end{itemize}

\hypertarget{sl3-microwave-dinner-implementation}{%
\section{\texorpdfstring{\texttt{sl3} ``Microwave Dinner'' Implementation}{sl3 ``Microwave Dinner'' Implementation}}\label{sl3-microwave-dinner-implementation}}

We begin by illustrating the core functionality of the SL algorithm as
implemented in \passthrough{\lstinline!sl3!}.

The \passthrough{\lstinline!sl3!} implementation consists of the following steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{-1}
\tightlist
\item
  Load the necessary libraries and data.
\item
  Define the machine learning task.
\item
  Make an SL by creating library of base learners and a metalearner.
\item
  Train the SL on the machine learning task.
\item
  Obtain predicted values.
\end{enumerate}

\hypertarget{wash-benefits-study-example-1}{%
\subsection*{WASH Benefits Study Example}\label{wash-benefits-study-example-1}}


Using the WASH Benefits Bangladesh data, we are interested in predicting
weight-for-height z-score \passthrough{\lstinline!whz!} using the available covariate data. More
information on this dataset, and all other data that we will work with in this
handbook, is contained in \protect\hypertarget{data}{}{Chapter 3}. Let's begin!

\hypertarget{preliminaries-load-the-necessary-libraries-and-data}{%
\subsection*{Preliminaries: Load the necessary libraries and data}\label{preliminaries-load-the-necessary-libraries-and-data}}


First, we will load the relevant \passthrough{\lstinline!R!} packages, set a seed, and load the data.

\begin{lstlisting}[language=R]
library(data.table)
library(dplyr)
library(readr)
library(ggplot2)
library(SuperLearner)
library(origami)
library(sl3)
library(knitr)
library(kableExtra)

# load data set and take a peek
washb_data <- fread(
  paste0(
    "https://raw.githubusercontent.com/tlverse/tlverse-data/master/",
    "wash-benefits/washb_data.csv"
  ),
  stringsAsFactors = TRUE
)
\end{lstlisting}

A quick look at the data:

\begin{tabular}{r|l|l|r|r|l|r|l|r|l|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r}
\hline
whz & tr & fracode & month & aged & sex & momage & momedu & momheight & hfiacat & Nlt18 & Ncomp & watmin & elec & floor & walls & roof & asset\_wardrobe & asset\_table & asset\_chair & asset\_khat & asset\_chouki & asset\_tv & asset\_refrig & asset\_bike & asset\_moto & asset\_sewmach & asset\_mobile\\
\hline
0.00 & Control & N05265 & 9 & 268 & male & 30 & Primary (1-5y) & 146.40 & Food Secure & 3 & 11 & 0 & 1 & 0 & 1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 1\\
\hline
-1.16 & Control & N05265 & 9 & 286 & male & 25 & Primary (1-5y) & 148.75 & Moderately Food Insecure & 2 & 4 & 0 & 1 & 0 & 1 & 1 & 0 & 1 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
-1.05 & Control & N08002 & 9 & 264 & male & 25 & Primary (1-5y) & 152.15 & Food Secure & 1 & 10 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
-1.26 & Control & N08002 & 9 & 252 & female & 28 & Primary (1-5y) & 140.25 & Food Secure & 3 & 5 & 0 & 1 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 1\\
\hline
-0.59 & Control & N06531 & 9 & 336 & female & 19 & Secondary (>5y) & 150.95 & Food Secure & 2 & 7 & 0 & 1 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
-0.51 & Control & N06531 & 9 & 304 & male & 20 & Secondary (>5y) & 154.20 & Severely Food Insecure & 0 & 3 & 1 & 1 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
\end{tabular}

\hypertarget{step-1-define-the-machine-learning-task}{%
\subsection{Step 1: Define the machine learning task}\label{step-1-define-the-machine-learning-task}}

To define the machine learning \textbf{``task''} (predict weight-for-height Z-score
\passthrough{\lstinline!whz!} using the available covariate data), we need to create an \passthrough{\lstinline!sl3\_Task!}
object.

The \passthrough{\lstinline!sl3\_Task!} keeps track of the roles the variables play in the machine
learning problem, the data, and any metadata (e.g., observational-level
weights, IDs, offset).

Also, if we had missing outcomes, we would need to set \passthrough{\lstinline!drop\_missing\_outcome = TRUE!} when we create the task. In the next analysis, with the \protect\hyperlink{ist}{IST stroke trial
data}, we do have a missing outcome. In the following chapter, we need to
estimate this ``missingness mechanism''; which is the conditional probability that
the outcome is observed, given the history (i.e., variables that were measured
before the missingness). Estimating the missingness mechanism requires learning
a prediction function that outputs the predicted probability that a unit is
missing, given their history.

\begin{lstlisting}[language=R]
# specify the outcome and covariates
outcome <- "whz"
covars <- colnames(washb_data)[-which(names(washb_data) == outcome)]

# create the sl3 task
washb_task <- make_sl3_Task(
  data = washb_data,
  covariates = covars,
  outcome = outcome
)
Warning in process_data(data, nodes, column_names = column_names, flag = flag, :
Missing covariate data detected: imputing covariates.
\end{lstlisting}

\emph{This warning is important.} The task just imputed missing covariates for us.
Specifically, for each covariate column with missing values, \passthrough{\lstinline!sl3!} uses the
median to impute missing continuous covariates, and the mode to impute binary
and categorical covariates.

Also, for each covariate column with missing values, \passthrough{\lstinline!sl3!} adds an additional
column indicating whether or not the value was imputed, which is particularly
handy when the missingness in the data might be informative.

Also, notice that we did not specify the number of folds, or the loss function
in the task. The default cross-validation scheme is V-fold, with \(V=10\) number
of folds.

Let's visualize our \passthrough{\lstinline!washb\_task!}:

\begin{lstlisting}[language=R]
washb_task
A sl3 Task with 4695 obs and these nodes:
$covariates
 [1] "tr"              "fracode"         "month"           "aged"           
 [5] "sex"             "momage"          "momedu"          "momheight"      
 [9] "hfiacat"         "Nlt18"           "Ncomp"           "watmin"         
[13] "elec"            "floor"           "walls"           "roof"           
[17] "asset_wardrobe"  "asset_table"     "asset_chair"     "asset_khat"     
[21] "asset_chouki"    "asset_tv"        "asset_refrig"    "asset_bike"     
[25] "asset_moto"      "asset_sewmach"   "asset_mobile"    "delta_momage"   
[29] "delta_momheight"

$outcome
[1] "whz"

$id
NULL

$weights
NULL

$offset
NULL

$time
NULL
\end{lstlisting}

We can't see when we print the task, but the default cross-validation fold
structure (\(V\)-fold cross-validation with \(V\)=10 folds) was created when we
defined the task.

\begin{lstlisting}[language=R]
length(washb_task$folds) # how many folds?
[1] 10

head(washb_task$folds[[1]]$training_set) # row indexes for fold 1 training
[1] 1 2 3 4 5 6
head(washb_task$folds[[1]]$validation_set) # row indexes for fold 1 validation
[1] 12 21 29 41 43 53

any(
  washb_task$folds[[1]]$training_set %in%
    washb_task$folds[[1]]$validation_set
)
[1] FALSE
\end{lstlisting}

\passthrough{\lstinline!R6!} Tip: If you type \passthrough{\lstinline!washb\_task$!} and then press the ``tab'' button (you will
need to press ``tab'' twice if you're not in RStudio), you can view all of the
active and public fields and methods that can be accessed from the \passthrough{\lstinline!washb\_task!}
object.

\hypertarget{step-2-make-a-super-learner}{%
\subsection{Step 2: Make a Super Learner}\label{step-2-make-a-super-learner}}

Now that we have defined our machine learning problem with the \passthrough{\lstinline!sl3\_Task!}, we
are ready to \textbf{``make''} the Super Learner (SL). This requires specification of

\begin{itemize}
\tightlist
\item
  A set of candidate machine learning algorithms, also commonly referred to as
  a ``library'' of ``learners''. The set should include a diversity of algorithms
  that are believed to be consistent with the true data-generating
  distribution.
\item
  A metalearner, to ensemble the base learners.
\end{itemize}

We might also incorporate

\begin{itemize}
\tightlist
\item
  Feature selection, to pass only a subset of the predictors to the algorithm.
\item
  Hyperparameter specification, to tune base learners.
\end{itemize}

Learners have properties that indicate what features they support. We may use
\passthrough{\lstinline!sl3\_list\_properties()!} to get a list of all properties supported by at least
one learner.

\begin{lstlisting}[language=R]
sl3_list_properties()
 [1] "binomial"      "categorical"   "continuous"    "cv"           
 [5] "density"       "h2o"           "ids"           "importance"   
 [9] "offset"        "preprocessing" "sampling"      "screener"     
[13] "timeseries"    "weights"       "wrapper"      
\end{lstlisting}

Since we have a continuous outcome, we may identify the learners that support
this outcome type with \passthrough{\lstinline!sl3\_list\_learners()!}.

\begin{lstlisting}[language=R]
sl3_list_learners("continuous")
 [1] "Lrnr_arima"                     "Lrnr_bartMachine"              
 [3] "Lrnr_bayesglm"                  "Lrnr_bilstm"                   
 [5] "Lrnr_bound"                     "Lrnr_caret"                    
 [7] "Lrnr_cv_selector"               "Lrnr_dbarts"                   
 [9] "Lrnr_earth"                     "Lrnr_expSmooth"                
[11] "Lrnr_gam"                       "Lrnr_gbm"                      
[13] "Lrnr_glm"                       "Lrnr_glm_fast"                 
[15] "Lrnr_glmnet"                    "Lrnr_grf"                      
[17] "Lrnr_gru_keras"                 "Lrnr_gts"                      
[19] "Lrnr_h2o_glm"                   "Lrnr_h2o_grid"                 
[21] "Lrnr_hal9001"                   "Lrnr_HarmonicReg"              
[23] "Lrnr_hts"                       "Lrnr_lightgbm"                 
[25] "Lrnr_lstm"                      "Lrnr_lstm_keras"               
[27] "Lrnr_mean"                      "Lrnr_multiple_ts"              
[29] "Lrnr_nnet"                      "Lrnr_nnls"                     
[31] "Lrnr_optim"                     "Lrnr_pkg_SuperLearner"         
[33] "Lrnr_pkg_SuperLearner_method"   "Lrnr_pkg_SuperLearner_screener"
[35] "Lrnr_polspline"                 "Lrnr_randomForest"             
[37] "Lrnr_ranger"                    "Lrnr_rpart"                    
[39] "Lrnr_rugarch"                   "Lrnr_screener_correlation"     
[41] "Lrnr_solnp"                     "Lrnr_stratified"               
[43] "Lrnr_svm"                       "Lrnr_tsDyn"                    
[45] "Lrnr_xgboost"                  
\end{lstlisting}

Now that we have an idea of some learners, we can construct them using the
\passthrough{\lstinline!make\_learner!} function or the \passthrough{\lstinline!new!} method.

\begin{lstlisting}[language=R]
# choose base learners
lrn_glm <- make_learner(Lrnr_glm)
lrn_mean <- Lrnr_mean$new()
\end{lstlisting}

We can customize learner hyperparameters to incorporate a diversity of
different settings. Documentation for the learners and their hyperparameters
can be found in the \href{https://tlverse.org/sl3/reference/index.html\#section-sl-learners}{\passthrough{\lstinline!sl3!} Learners
Reference}.

\begin{lstlisting}[language=R]
lrn_lasso <- make_learner(Lrnr_glmnet) # alpha default is 1
lrn_ridge <- Lrnr_glmnet$new(alpha = 0)
lrn_enet.5 <- make_learner(Lrnr_glmnet, alpha = 0.5)

lrn_polspline <- Lrnr_polspline$new()

lrn_ranger100 <- make_learner(Lrnr_ranger, num.trees = 100)

lrn_hal_faster <- Lrnr_hal9001$new(max_degree = 2, reduce_basis = 0.05)

xgb_fast <- Lrnr_xgboost$new() # default with nrounds = 20 is pretty fast
xgb_50 <- Lrnr_xgboost$new(nrounds = 50)
\end{lstlisting}

We can use \passthrough{\lstinline!Lrnr\_define\_interactions!} to define interaction terms among
covariates. The interactions should be supplied as list of character vectors,
where each vector specifies an interaction. For example, we specify
interactions below between (1) \passthrough{\lstinline!tr!} (whether or not the subject received the
WASH intervention) and \passthrough{\lstinline!elec!} (whether or not the subject had electricity); and
between (2) \passthrough{\lstinline!tr!} and \passthrough{\lstinline!hfiacat!} (the subject's level of food security).

\begin{lstlisting}[language=R]
interactions <- list(c("elec", "tr"), c("tr", "hfiacat"))
# main terms as well as the interactions above will be included
lrn_interaction <- make_learner(Lrnr_define_interactions, interactions)
\end{lstlisting}

What we just defined above is incomplete. In order to fit learners with these
interactions, we need to create a \passthrough{\lstinline!Pipeline!}. A \passthrough{\lstinline!Pipeline!} is a set of learners
to be fit sequentially, where the fit from one learner is used to define the
task for the next learner. We need to create a \passthrough{\lstinline!Pipeline!} with the interaction
defining learner and another learner that incorporate these terms when fitting
a model. Let's create a learner pipeline that will fit a linear model with the
combination of main terms and interactions terms, as specified in
\passthrough{\lstinline!lrn\_interaction\_main!}.

\begin{lstlisting}[language=R]
# we already instantiated a linear model learner above, no need to do it again
lrn_glm_interaction <- make_learner(Pipeline, lrn_interaction, lrn_glm)
lrn_glm_interaction
[1] "Lrnr_define_interactions_TRUE"
[1] "Lrnr_glm_TRUE"
\end{lstlisting}

We can also include learners from the \passthrough{\lstinline!SuperLearner!} \passthrough{\lstinline!R!} package.

\begin{lstlisting}[language=R]
lrn_bayesglm <- Lrnr_pkg_SuperLearner$new("SL.bayesglm")
\end{lstlisting}

Here is a fun trick to create customized learners over a grid of parameters.

\begin{lstlisting}[language=R]
# I like to crock pot my SLs
grid_params <- list(
  cost = c(0.01, 0.1, 1, 10, 100, 1000),
  gamma = c(0.001, 0.01, 0.1, 1),
  kernel = c("polynomial", "radial", "sigmoid"),
  degree = c(1, 2, 3)
)
grid <- expand.grid(grid_params, KEEP.OUT.ATTRS = FALSE)
svm_learners <- apply(grid, MARGIN = 1, function(tuning_params) {
  do.call(Lrnr_svm$new, as.list(tuning_params))
})
\end{lstlisting}

\begin{lstlisting}[language=R]
grid_params <- list(
  max_depth = c(2, 4, 6),
  eta = c(0.001, 0.1, 0.3),
  nrounds = 100
)
grid <- expand.grid(grid_params, KEEP.OUT.ATTRS = FALSE)
grid
  max_depth   eta nrounds
1         2 0.001     100
2         4 0.001     100
3         6 0.001     100
4         2 0.100     100
5         4 0.100     100
6         6 0.100     100
7         2 0.300     100
8         4 0.300     100
9         6 0.300     100

xgb_learners <- apply(grid, MARGIN = 1, function(tuning_params) {
  do.call(Lrnr_xgboost$new, as.list(tuning_params))
})
xgb_learners
[[1]]
[1] "Lrnr_xgboost_100_1_2_0.001"

[[2]]
[1] "Lrnr_xgboost_100_1_4_0.001"

[[3]]
[1] "Lrnr_xgboost_100_1_6_0.001"

[[4]]
[1] "Lrnr_xgboost_100_1_2_0.1"

[[5]]
[1] "Lrnr_xgboost_100_1_4_0.1"

[[6]]
[1] "Lrnr_xgboost_100_1_6_0.1"

[[7]]
[1] "Lrnr_xgboost_100_1_2_0.3"

[[8]]
[1] "Lrnr_xgboost_100_1_4_0.3"

[[9]]
[1] "Lrnr_xgboost_100_1_6_0.3"
\end{lstlisting}

Did you see \passthrough{\lstinline!Lrnr\_caret!} when we called \passthrough{\lstinline!sl3\_list\_learners(c("binomial"))!}?
All we need to specify to use this popular algorithm as a candidate in our
SL is the \passthrough{\lstinline!algorithm!} we want to tune, which is passed as \passthrough{\lstinline!method!} to
\passthrough{\lstinline!caret::train()!}. The default method for parameter selection criterion with is
set to ``CV'' instead of the \passthrough{\lstinline!caret::train()!} default \passthrough{\lstinline!boot!}. The summary metric
used to select the optimal model is \passthrough{\lstinline!RMSE!} for continuous outcomes and
\passthrough{\lstinline!Accuracy!} for categorical and binomial outcomes.

\begin{lstlisting}[language=R]
# Unlike xgboost, I have no idea how to tune a neural net or BART machine, so
# I let caret take the reins
lrnr_caret_nnet <- make_learner(Lrnr_caret, algorithm = "nnet")
lrnr_caret_bartMachine <- make_learner(Lrnr_caret,
  algorithm = "bartMachine",
  method = "boot", metric = "Accuracy",
  tuneLength = 10
)
\end{lstlisting}

In order to assemble the library of learners, we need to \textbf{``stack''} them
together.

A \passthrough{\lstinline!Stack!} is a special learner and it has the same interface as all other
learners. What makes a stack special is that it combines multiple learners by
training them simultaneously, so that their predictions can be either combined
or compared.

\begin{lstlisting}[language=R]
stack <- make_learner(
  Stack, lrn_glm, lrn_polspline, lrn_enet.5, lrn_ridge, lrn_lasso, xgb_50
)
stack
[1] "Lrnr_glm_TRUE"                                  
[2] "Lrnr_polspline_5"                               
[3] "Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE_FALSE"
[4] "Lrnr_glmnet_NULL_deviance_10_0_100_TRUE_FALSE"  
[5] "Lrnr_glmnet_NULL_deviance_10_1_100_TRUE_FALSE"  
[6] "Lrnr_xgboost_50_1"                              
\end{lstlisting}

We can also stack the learners by first creating a vector, and then
instantiating the stack. I prefer this method, since it easily allows us to
modify the names of the learners.

\begin{lstlisting}[language=R]
# named vector of learners first
learners <- c(lrn_glm, lrn_polspline, lrn_enet.5, lrn_ridge, lrn_lasso, xgb_50)
names(learners) <- c(
  "glm", "polspline", "enet.5", "ridge", "lasso", "xgboost50"
)
# next make the stack
stack <- make_learner(Stack, learners)
# now the names are pretty
stack
[1] "glm"       "polspline" "enet.5"    "ridge"     "lasso"     "xgboost50"
\end{lstlisting}

We're jumping ahead a bit, but let's check something out quickly. It's
straightforward, and just one more step, to set up this stack such that all of
the learners will train in a cross-validated manner.

\begin{lstlisting}[language=R]
cv_stack <- Lrnr_cv$new(stack)
cv_stack
[1] "Lrnr_cv"
[1] "glm"       "polspline" "enet.5"    "ridge"     "lasso"     "xgboost50"
\end{lstlisting}

\hypertarget{screening-algorithms-for-feature-selection}{%
\subsubsection{Screening Algorithms for Feature Selection}\label{screening-algorithms-for-feature-selection}}

We can optionally select a subset of available covariates and pass only those
variables to the modeling algorithm. The current set of learners that can be
used for prescreening covariates is included below.

\begin{itemize}
\tightlist
\item
  \passthrough{\lstinline!Lrnr\_screener\_importance!} selects \passthrough{\lstinline!num\_screen!} (default = 5) covariates
  based on the variable importance ranking provided by the \passthrough{\lstinline!learner!}. Any
  learner with an ``importance'' method can be used in \passthrough{\lstinline!Lrnr\_screener\_importance!};
  and this currently includes \passthrough{\lstinline!Lrnr\_ranger!}, \passthrough{\lstinline!Lrnr\_randomForest!}, and
  \passthrough{\lstinline!Lrnr\_xgboost!}.
\item
  \passthrough{\lstinline!Lrnr\_screener\_coefs!}, which provides screening of covariates based on the
  magnitude of their estimated coefficients in a (possibly regularized) GLM.
  The \passthrough{\lstinline!threshold!} (default = 1e-3) defines the minimum absolute size of the
  coefficients, and thus covariates, to be kept. Also, a \passthrough{\lstinline!max\_retain!} argument
  can be optionally provided to restrict the number of selected covariates to
  be no more than \passthrough{\lstinline!max\_retain!}.
\item
  \passthrough{\lstinline!Lrnr\_screener\_correlation!} provides covariate screening procedures by
  running a test of correlation (Pearson default), and then selecting the (1)
  top ranked variables (default), or (2) the variables with a pvalue lower than
  some pre-specified threshold.
\item
  \passthrough{\lstinline!Lrnr\_screener\_augment!} augments a set of screened covariates with additional
  covariates that should be included by default, even if the screener did not
  select them. An example of how to use this screener is included below.
\end{itemize}

Let's consider screening covariates based on their \passthrough{\lstinline!randomForest!} variable
importance ranking (ordered by mean decrease in accuracy). To select the top
5 most important covariates according to this ranking, we can combine
\passthrough{\lstinline!Lrnr\_screener\_importance!} with \passthrough{\lstinline!Lrnr\_ranger!} (limiting the number of trees by
setting \passthrough{\lstinline!ntree = 20!}).

Hang on! Before you think it -- I will confess: Bob Ross and I both know that 20
trees makes for a lonely forest, and I shouldn't consider it, but these are the
sacrifices I have to make for this chapter to build in time!

\begin{lstlisting}[language=R]
miniforest <- Lrnr_ranger$new(
  num.trees = 20, write.forest = FALSE,
  importance = "impurity_corrected"
)

# learner must already be instantiated, we did this when we created miniforest
screen_rf <- Lrnr_screener_importance$new(learner = miniforest, num_screen = 5)
screen_rf
[1] "Lrnr_screener_importance_5"

# which covariates are selected on the full data?
screen_rf$train(washb_task)
[1] "Lrnr_screener_importance_5"
$selected
[1] "aged"         "momheight"    "month"        "momedu"       "asset_refrig"
\end{lstlisting}

An example of how to format \passthrough{\lstinline!Lrnr\_screener\_augment!} is included below for
clarity.

\begin{lstlisting}[language=R]
keepme <- c("aged", "momage")
# screener must already be instantiated, we did this when we created screen_rf
screen_augment_rf <- Lrnr_screener_augment$new(
  screener = screen_rf, default_covariates = keepme
)
screen_augment_rf
[1] "Lrnr_screener_augment_c(\"aged\", \"momage\")"
\end{lstlisting}

Selecting covariates with non-zero lasso coefficients is quite common. Let's
construct \passthrough{\lstinline!Lrnr\_screener\_coefs!} screener that does just that, and test it out.

\begin{lstlisting}[language=R]
# we already instantiated a lasso learner above, no need to do it again
screen_lasso <- Lrnr_screener_coefs$new(learner = lrn_lasso, threshold = 0)
screen_lasso
[1] "Lrnr_screener_coefs_0_NULL_2"
\end{lstlisting}

To \textbf{``pipe''} only the selected covariates to the modeling algorithm, we need to
make a \passthrough{\lstinline!Pipeline!}, similar to the one we built for the regression model with
interaction terms.

\begin{lstlisting}[language=R]
screen_rf_pipe <- make_learner(Pipeline, screen_rf, stack)
screen_lasso_pipe <- make_learner(Pipeline, screen_lasso, stack)
\end{lstlisting}

Now, these learners with no internal screening will be preceded by a screening
step.

We also consider the original \passthrough{\lstinline!stack!}, to compare how the feature selection
methods perform in comparison to the methods without feature selection.

Analogous to what we have seen before, we have to stack the pipeline and
original \passthrough{\lstinline!stack!} together, so we may use them as base learners in our super
learner.

\begin{lstlisting}[language=R]
# pretty names again
learners2 <- c(learners, screen_rf_pipe, screen_lasso_pipe)
names(learners2) <- c(names(learners), "randomforest_screen", "lasso_screen")

fancy_stack <- make_learner(Stack, learners2)
fancy_stack
[1] "glm"                 "polspline"           "enet.5"             
[4] "ridge"               "lasso"               "xgboost50"          
[7] "randomforest_screen" "lasso_screen"       
\end{lstlisting}

We will use the \href{https://tlverse.org/sl3/reference/default_metalearner.html}{default
metalearner}, which
uses \href{https://tlverse.org/sl3/reference/Lrnr_solnp.html}{\passthrough{\lstinline!Lrnr\_solnp()!}} to
provide fitting procedures for a pairing of \href{https://tlverse.org/sl3/reference/loss_functions.html}{loss
function} and
\href{https://tlverse.org/sl3/reference/metalearners.html}{metalearner function}.
This default metalearner selects a loss and metalearner pairing based on the
outcome type. Note that any learner can be used as a metalearner.

Now that we have made a diverse stack of base learners, we are ready to make
the SL. The SL algorithm fits a metalearner on the validation set
predictions/losses across all folds.

\begin{lstlisting}[language=R]
sl <- make_learner(Lrnr_sl, learners = fancy_stack)
\end{lstlisting}

We can also use \passthrough{\lstinline!Lrnr\_cv!} to build a SL, cross-validate a stack of
learners to compare performance of the learners in the stack, or cross-validate
any single learner (see ``Cross-validation'' section of this \href{https://tlverse.org/sl3/articles/intro_sl3.html}{\passthrough{\lstinline!sl3!}
introductory tutorial}).

Furthermore, we can \href{https://tlverse.org/sl3/articles/custom_lrnrs.html}{Define New \passthrough{\lstinline!sl3!}
Learners} which can be used
in all the places you could otherwise use any other \passthrough{\lstinline!sl3!} learners, including
\passthrough{\lstinline!Pipelines!}, \passthrough{\lstinline!Stacks!}, and the SL.

Recall that the discrete SL, or cross-validated selector, is a metalearner that
assigns a weight of 1 to the learner with the lowest cross-validated empirical
risk, and weight of 0 to all other learners. This metalearner specification can
be invoked with \passthrough{\lstinline!Lrnr\_cv\_selector!}.

\begin{lstlisting}[language=R]
discrete_sl_metalrn <- Lrnr_cv_selector$new()
discrete_sl <- Lrnr_sl$new(
  learners = fancy_stack,
  metalearner = discrete_sl_metalrn
)
\end{lstlisting}

\hypertarget{step-3-train-the-super-learner-on-the-machine-learning-task}{%
\subsection{Step 3: Train the Super Learner on the machine learning task}\label{step-3-train-the-super-learner-on-the-machine-learning-task}}

The SL algorithm fits a metalearner on the validation-set predictions in a
cross-validated manner, thereby avoiding overfitting.

Now we are ready to \textbf{``train''} our SL on our \passthrough{\lstinline!sl3\_task!} object, \passthrough{\lstinline!washb\_task!}.

\begin{lstlisting}[language=R]
set.seed(4197)
sl_fit <- sl$train(washb_task)
\end{lstlisting}

\hypertarget{step-4-obtain-predicted-values}{%
\subsection{Step 4: Obtain predicted values}\label{step-4-obtain-predicted-values}}

Now that we have fit the SL, we are ready to calculate the predicted outcome
for each subject.

\begin{lstlisting}[language=R]
# we did it! now we have SL predictions
sl_preds <- sl_fit$predict()
head(sl_preds)
[1] -0.59571 -0.76121 -0.68938 -0.66515 -0.61549 -0.65685
\end{lstlisting}

We can also obtain a summary of the results.

\begin{lstlisting}[language=R]
sl_fit_summary <- sl_fit$print()
[1] "SuperLearner:"
List of 8
 $ glm                : chr "Lrnr_glm_TRUE"
 $ polspline          : chr "Lrnr_polspline_5"
 $ enet.5             : chr "Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE_FALSE"
 $ ridge              : chr "Lrnr_glmnet_NULL_deviance_10_0_100_TRUE_FALSE"
 $ lasso              : chr "Lrnr_glmnet_NULL_deviance_10_1_100_TRUE_FALSE"
 $ xgboost50          : chr "Lrnr_xgboost_50_1"
 $ randomforest_screen: chr "Pipeline(Lrnr_screener_importance_5->Stack)"
 $ lasso_screen       : chr "Pipeline(Lrnr_screener_coefs_0_NULL_2->Stack)"
[1] "Lrnr_solnp_TRUE_TRUE_FALSE_1e-05"
$pars
 [1] 0.055566 0.055551 0.055559 0.055564 0.055559 0.055585 0.055556 0.055574
 [9] 0.055555 0.055555 0.055555 0.055543 0.055554 0.055554 0.055554 0.055553
[17] 0.055554 0.055509

$convergence
[1] 0

$values
[1] 1.0105 1.0105

$lagrange
           [,1]
[1,] -0.0041139

$hessian
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]
 [1,]    1    0    0    0    0    0    0    0    0     0     0     0     0
 [2,]    0    1    0    0    0    0    0    0    0     0     0     0     0
 [3,]    0    0    1    0    0    0    0    0    0     0     0     0     0
 [4,]    0    0    0    1    0    0    0    0    0     0     0     0     0
 [5,]    0    0    0    0    1    0    0    0    0     0     0     0     0
 [6,]    0    0    0    0    0    1    0    0    0     0     0     0     0
 [7,]    0    0    0    0    0    0    1    0    0     0     0     0     0
 [8,]    0    0    0    0    0    0    0    1    0     0     0     0     0
 [9,]    0    0    0    0    0    0    0    0    1     0     0     0     0
[10,]    0    0    0    0    0    0    0    0    0     1     0     0     0
[11,]    0    0    0    0    0    0    0    0    0     0     1     0     0
[12,]    0    0    0    0    0    0    0    0    0     0     0     1     0
[13,]    0    0    0    0    0    0    0    0    0     0     0     0     1
[14,]    0    0    0    0    0    0    0    0    0     0     0     0     0
[15,]    0    0    0    0    0    0    0    0    0     0     0     0     0
[16,]    0    0    0    0    0    0    0    0    0     0     0     0     0
[17,]    0    0    0    0    0    0    0    0    0     0     0     0     0
[18,]    0    0    0    0    0    0    0    0    0     0     0     0     0
      [,14] [,15] [,16] [,17] [,18]
 [1,]     0     0     0     0     0
 [2,]     0     0     0     0     0
 [3,]     0     0     0     0     0
 [4,]     0     0     0     0     0
 [5,]     0     0     0     0     0
 [6,]     0     0     0     0     0
 [7,]     0     0     0     0     0
 [8,]     0     0     0     0     0
 [9,]     0     0     0     0     0
[10,]     0     0     0     0     0
[11,]     0     0     0     0     0
[12,]     0     0     0     0     0
[13,]     0     0     0     0     0
[14,]     1     0     0     0     0
[15,]     0     1     0     0     0
[16,]     0     0     1     0     0
[17,]     0     0     0     1     0
[18,]     0     0     0     0     1

$ineqx0
NULL

$nfuneval
[1] 23

$outer.iter
[1] 1

$elapsed
Time difference of 0.011935 secs

$vscale
 [1] 1.01048 0.00001 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000
[10] 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000
[19] 1.00000 1.00000

$coefficients
                          glm                     polspline 
                     0.055566                      0.055551 
                       enet.5                         ridge 
                     0.055559                      0.055564 
                        lasso                     xgboost50 
                     0.055559                      0.055585 
      randomforest_screen_glm randomforest_screen_polspline 
                     0.055556                      0.055574 
   randomforest_screen_enet.5     randomforest_screen_ridge 
                     0.055555                      0.055555 
    randomforest_screen_lasso randomforest_screen_xgboost50 
                     0.055555                      0.055543 
             lasso_screen_glm        lasso_screen_polspline 
                     0.055554                      0.055554 
          lasso_screen_enet.5            lasso_screen_ridge 
                     0.055554                      0.055553 
           lasso_screen_lasso        lasso_screen_xgboost50 
                     0.055554                      0.055509 

$training_offset
[1] FALSE

$name
[1] "solnp"

[1] "Cross-validated risk:"
                          learner coefficients   risk       se  fold_sd
 1:                           glm     0.055566 1.0202 0.023955 0.067500
 2:                     polspline     0.055551 1.0208 0.023577 0.067921
 3:                        enet.5     0.055559 1.0133 0.023618 0.066232
 4:                         ridge     0.055564 1.0155 0.023727 0.065653
 5:                         lasso     0.055559 1.0132 0.023607 0.066250
 6:                     xgboost50     0.055585 1.1136 0.025262 0.077580
 7:       randomforest_screen_glm     0.055556 1.0181 0.023617 0.064287
 8: randomforest_screen_polspline     0.055574 1.0122 0.023604 0.064125
 9:    randomforest_screen_enet.5     0.055555 1.0179 0.023619 0.064642
10:     randomforest_screen_ridge     0.055555 1.0182 0.023632 0.064600
11:     randomforest_screen_lasso     0.055555 1.0178 0.023612 0.064616
12: randomforest_screen_xgboost50     0.055543 1.1242 0.025511 0.065775
13:              lasso_screen_glm     0.055554 1.0161 0.023525 0.064938
14:        lasso_screen_polspline     0.055554 1.0177 0.023520 0.065566
15:           lasso_screen_enet.5     0.055554 1.0161 0.023527 0.064945
16:            lasso_screen_ridge     0.055553 1.0163 0.023536 0.064715
17:            lasso_screen_lasso     0.055554 1.0161 0.023527 0.064944
18:        lasso_screen_xgboost50     0.055509 1.1297 0.026028 0.088532
19:                  SuperLearner           NA 1.0105 0.023438 0.066924
    fold_min_risk fold_max_risk
 1:       0.89442        1.1200
 2:       0.89892        1.1255
 3:       0.88927        1.1102
 4:       0.88562        1.1093
 5:       0.88842        1.1090
 6:       0.96019        1.2337
 7:       0.90212        1.1105
 8:       0.90246        1.0919
 9:       0.89998        1.1092
10:       0.90104        1.1110
11:       0.90037        1.1091
12:       1.02694        1.2325
13:       0.90204        1.1114
14:       0.89742        1.1162
15:       0.90182        1.1112
16:       0.90120        1.1100
17:       0.90183        1.1112
18:       0.96251        1.2622
19:       0.88891        1.1094
\end{lstlisting}

From the table of the printed SL fit, we note that the SL had a mean risk of
1.0105 and that
this ensemble weighted the \passthrough{\lstinline!ranger!} and \passthrough{\lstinline!glmnet!} learners highest while not
weighting the \passthrough{\lstinline!mean!} learner highly.

We can also see that the \passthrough{\lstinline!glmnet!} learner had the lowest cross-validated mean
risk, thus making it the cross-validated selector (or the \emph{discrete} SL). The
mean risk of the SL is calculated using all of the data, and not a separate
hold-out, so the SL's mean risk that is reported here is an underestimation.

\hypertarget{cross-validated-super-learner}{%
\section{Cross-validated Super Learner}\label{cross-validated-super-learner}}

We can cross-validate the SL to see how well the SL performs on unseen data,
and obtain an estimate of the cross-validated risk of the SL.

This estimation procedure requires an ``outer/external'' layer of
cross-validation, also called nested cross-validation, which involves setting
aside a separate holdout sample that we don't use to fit the SL. This external
cross-validation procedure may also incorporate 10 folds, which is the default
in \passthrough{\lstinline!sl3!}. However, we will incorporate 2 outer/external folds of
cross-validation for computational efficiency.

We also need to specify a loss function to evaluate SL. Documentation for the
available loss functions can be found in the \href{https://tlverse.org/sl3/reference/loss_functions.html}{\passthrough{\lstinline!sl3!} Loss
Function Reference}.

\begin{lstlisting}[language=R]
washb_task_new <- make_sl3_Task(
  data = washb_data,
  covariates = covars,
  outcome = outcome,
  folds = origami::make_folds(washb_data, fold_fun = folds_vfold, V = 2)
)
CVsl <- CV_lrnr_sl(
  lrnr_sl = sl_fit, task = washb_task_new, loss_fun = loss_squared_error
)
\end{lstlisting}

Let's take a look at a table summarizing the performance:

\begin{lstlisting}[language=R]
if (knitr::is_latex_output()) {
  CVsl %>%
    kable(format = "latex")
} else if (knitr::is_html_output()) {
  CVsl %>%
    kable() %>%
    kable_styling(fixed_thead = TRUE) %>%
    scroll_box(width = "100%", height = "300px")
}
\end{lstlisting}

\begin{tabular}{l|r|r|r|r|r|r}
\hline
learner & coefficients & risk & se & fold\_sd & fold\_min\_risk & fold\_max\_risk\\
\hline
glm & 0.05556 & 1.0644 & 0.03068 & 0.02372 & 1.0476 & 1.0812\\
\hline
polspline & 0.05556 & 1.0349 & 0.02403 & 0.00855 & 1.0289 & 1.0410\\
\hline
enet.5 & 0.05557 & 1.0292 & 0.02429 & 0.00703 & 1.0243 & 1.0342\\
\hline
ridge & 0.05557 & 1.0351 & 0.02476 & 0.00141 & 1.0340 & 1.0360\\
\hline
lasso & 0.05557 & 1.0274 & 0.02409 & 0.00907 & 1.0210 & 1.0338\\
\hline
xgboost50 & 0.05555 & 1.1912 & 0.02743 & 0.01545 & 1.1803 & 1.2021\\
\hline
randomforest\_screen\_glm & 0.05555 & 1.0416 & 0.02449 & 0.02868 & 1.0213 & 1.0619\\
\hline
randomforest\_screen\_polspline & 0.05557 & 1.0345 & 0.02443 & 0.01277 & 1.0254 & 1.0435\\
\hline
randomforest\_screen\_enet.5 & 0.05555 & 1.0395 & 0.02443 & 0.02687 & 1.0205 & 1.0585\\
\hline
randomforest\_screen\_ridge & 0.05555 & 1.0406 & 0.02453 & 0.02991 & 1.0194 & 1.0617\\
\hline
randomforest\_screen\_lasso & 0.05555 & 1.0396 & 0.02443 & 0.02625 & 1.0211 & 1.0582\\
\hline
randomforest\_screen\_xgboost50 & 0.05549 & 1.2261 & 0.02865 & 0.05917 & 1.1843 & 1.2680\\
\hline
lasso\_screen\_glm & 0.05557 & 1.0289 & 0.02403 & 0.01470 & 1.0185 & 1.0393\\
\hline
lasso\_screen\_polspline & 0.05557 & 1.0320 & 0.02410 & 0.01204 & 1.0235 & 1.0406\\
\hline
lasso\_screen\_enet.5 & 0.05557 & 1.0288 & 0.02403 & 0.01473 & 1.0184 & 1.0393\\
\hline
lasso\_screen\_ridge & 0.05557 & 1.0286 & 0.02404 & 0.01514 & 1.0179 & 1.0393\\
\hline
lasso\_screen\_lasso & 0.05557 & 1.0288 & 0.02403 & 0.01473 & 1.0184 & 1.0393\\
\hline
lasso\_screen\_xgboost50 & 0.05552 & 1.1836 & 0.02652 & 0.01095 & 1.1759 & 1.1913\\
\hline
SuperLearner & NA & 1.0261 & 0.02396 & 0.00802 & 1.0205 & 1.0318\\
\hline
\end{tabular}

\hypertarget{variable-importance-measures-with-sl3}{%
\section{\texorpdfstring{Variable Importance Measures with \texttt{sl3}}{Variable Importance Measures with sl3}}\label{variable-importance-measures-with-sl3}}

Variable importance can be interesting and informative. It can also be
contradictory and confusing. Nevertheless, we like it, and so do our
collaborators, so we created a variable importance function in \passthrough{\lstinline!sl3!}! The \passthrough{\lstinline!sl3!}
\passthrough{\lstinline!importance!} function returns a table with variables listed in decreasing order
of importance (i.e., most important on the first row).

The measure of importance in \passthrough{\lstinline!sl3!} is based on a risk ratio, or risk
difference, between the learner fit with a removed, or permuted, covariate and
the learner fit with the true covariate, across all covariates. In this manner,
the larger the risk difference, the more important the variable is in the
prediction.

The intuition of this measure is that it calculates the risk (in terms of the
average loss in predictive accuracy) of losing one covariate, while keeping
everything else fixed, and compares it to the risk if the covariate was not
lost. If this risk ratio is one, or risk difference is zero, then losing that
covariate had no impact, and is thus not important by this measure. We do this
across all of the covariates. As stated above, we can remove the covariate and
refit the SL without it, or we just permute the covariate (faster, more risky)
and hope for the shuffling to distort any meaningful information that was
present in the covariate. This idea of permuting instead of removing saves a
lot of time, and is also incorporated in the \passthrough{\lstinline!randomForest!} variable importance
measures. However, the permutation approach is risky, so the importance
function default is to remove and refit.

Let's explore the \passthrough{\lstinline!sl3!} variable importance measurements for the \passthrough{\lstinline!washb!} data.

\begin{lstlisting}[language=R]
washb_varimp <- importance(sl_fit, loss = loss_squared_error, type = "permute")
\end{lstlisting}

\begin{lstlisting}[language=R]
if (knitr::is_latex_output()) {
  washb_varimp %>%
    kable(format = "latex")
} else if (knitr::is_html_output()) {
  washb_varimp %>%
    kable() %>%
    kable_styling(fixed_thead = TRUE) %>%
    scroll_box(width = "100%", height = "300px")
}
\end{lstlisting}

\begin{tabular}{l|r}
\hline
X & risk\_ratio\\
\hline
aged & 1.04255\\
\hline
momedu & 1.01531\\
\hline
asset\_refrig & 1.01000\\
\hline
month & 1.00378\\
\hline
asset\_chair & 1.00249\\
\hline
momheight & 1.00085\\
\hline
Ncomp & 1.00051\\
\hline
walls & 1.00050\\
\hline
floor & 1.00046\\
\hline
tr & 1.00040\\
\hline
asset\_mobile & 1.00035\\
\hline
asset\_khat & 1.00029\\
\hline
Nlt18 & 1.00023\\
\hline
asset\_chouki & 1.00014\\
\hline
asset\_sewmach & 1.00007\\
\hline
delta\_momheight & 1.00002\\
\hline
asset\_tv & 0.99996\\
\hline
asset\_moto & 0.99996\\
\hline
delta\_momage & 0.99995\\
\hline
roof & 0.99994\\
\hline
sex & 0.99989\\
\hline
asset\_bike & 0.99988\\
\hline
hfiacat & 0.99987\\
\hline
watmin & 0.99985\\
\hline
elec & 0.99975\\
\hline
asset\_table & 0.99969\\
\hline
momage & 0.99954\\
\hline
asset\_wardrobe & 0.99937\\
\hline
fracode & 0.99880\\
\hline
\end{tabular}

\begin{lstlisting}[language=R]
# plot variable importance
importance_plot(
  washb_varimp,
  main = "sl3 Variable Importance for WASH Benefits Example Data"
)
\end{lstlisting}

\begin{center}\includegraphics[width=0.8\linewidth]{06-sl3_files/figure-latex/varimp-plot-1} \end{center}

\hypertarget{sl3-exercises}{%
\section{Exercises}\label{sl3-exercises}}

\hypertarget{sl3ex1}{%
\subsection{\texorpdfstring{Predicting Myocardial Infarction with \texttt{sl3}}{Predicting Myocardial Infarction with sl3}}\label{sl3ex1}}

Follow the steps below to predict myocardial infarction (\passthrough{\lstinline!mi!}) using the
available covariate data. We thank Prof.~David Benkeser at Emory University for
making the this Cardiovascular Health Study (CHS) data accessible.

\begin{lstlisting}[language=R]
# load the data set
db_data <- url(
  paste0(
    "https://raw.githubusercontent.com/benkeser/sllecture/master/",
    "chspred.csv"
  )
)
chspred <- read_csv(file = db_data, col_names = TRUE)
\end{lstlisting}

Let's take a quick peek at the data:

\begin{tabular}{r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r}
\hline
waist & alcoh & hdl & beta & smoke & ace & ldl & bmi & aspirin & gend & age & estrgn & glu & ins & cysgfr & dm & fetuina & whr & hsed & race & logcystat & logtrig & logcrp & logcre & health & logkcal & sysbp & mi\\
\hline
110.164 & 0.0000 & 66.497 & 0 & 0 & 1 & 114.216 & 27.997 & 0 & 0 & 73.518 & 0 & 159.931 & 70.3343 & 75.008 & 1 & 0.17516 & 1.16898 & 1 & 1 & -0.34202 & 5.4063 & 2.01260 & -0.67385 & 0 & 4.3926 & 177.135 & 0\\
\hline
89.976 & 0.0000 & 50.065 & 0 & 0 & 0 & 103.777 & 20.893 & 0 & 0 & 61.772 & 0 & 153.389 & 33.9695 & 82.743 & 1 & 0.57165 & 0.90114 & 0 & 0 & -0.08465 & 4.8592 & 3.29328 & -0.55509 & 1 & 6.2071 & 136.374 & 0\\
\hline
106.194 & 8.4174 & 40.506 & 0 & 0 & 0 & 165.716 & 28.455 & 1 & 1 & 72.931 & 0 & 121.715 & -17.3017 & 74.699 & 0 & 0.35168 & 1.17971 & 0 & 1 & -0.44511 & 4.5088 & 0.30132 & -0.01152 & 0 & 6.7320 & 135.199 & 0\\
\hline
90.057 & 0.0000 & 36.175 & 0 & 0 & 0 & 45.203 & 23.961 & 0 & 0 & 79.119 & 0 & 53.969 & 11.7315 & 95.782 & 0 & 0.54391 & 1.13599 & 0 & 0 & -0.48072 & 5.1832 & 3.02426 & -0.57507 & 1 & 7.3972 & 139.018 & 0\\
\hline
78.614 & 2.9790 & 71.064 & 0 & 1 & 0 & 131.312 & 10.966 & 0 & 1 & 69.018 & 0 & 94.315 & 9.7112 & 72.711 & 0 & 0.49159 & 1.10276 & 1 & 0 & 0.31206 & 4.2190 & -0.70568 & 0.00534 & 1 & 8.2779 & 88.047 & 0\\
\hline
91.659 & 0.0000 & 59.496 & 0 & 0 & 0 & 171.187 & 29.132 & 0 & 1 & 81.835 & 0 & 212.907 & -28.2269 & 69.218 & 1 & 0.46215 & 0.95291 & 1 & 0 & -0.28716 & 5.1773 & 0.97046 & 0.21268 & 1 & 5.9942 & 69.594 & 0\\
\hline
\end{tabular}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create an \passthrough{\lstinline!sl3!} task, setting myocardial infarction \passthrough{\lstinline!mi!} as the outcome and
  using all available covariate data.
\item
  Make a library of seven relatively fast base learning algorithms (i.e., do
  not consider BART or HAL). Customize hyperparameters for one of your
  learners. Feel free to use learners from \passthrough{\lstinline!sl3!} or \passthrough{\lstinline!SuperLearner!}. You may
  use the same base learning library that is presented above.
\item
  Incorporate at least one pipeline with feature selection. Any screener and
  learner(s) can be used.
\item
  Fit the metalearning step with the default metalearner.
\item
  With the metalearner and base learners, make the Super Learner (SL) and
  train it on the task.
\item
  Print your SL fit by calling \passthrough{\lstinline!print()!} with \passthrough{\lstinline!$!}.
\item
  Cross-validate your SL fit to see how well it performs on unseen
  data. Specify a valid loss function to evaluate the SL.
\item
  Use the \passthrough{\lstinline!importance()!} function to identify the ``most important'' predictor of
  myocardial infarction, according to \passthrough{\lstinline!sl3!} importance metrics.
\end{enumerate}

\hypertarget{sl3ex2}{%
\subsection{\texorpdfstring{Predicting Recurrent Ischemic Stroke in an RCT with \texttt{sl3}}{Predicting Recurrent Ischemic Stroke in an RCT with sl3}}\label{sl3ex2}}

For this exercise, we will work with a random sample of 5,000 patients who
participated in the International Stroke Trial (IST). This data is described in
\href{https://tlverse.org/tlverse-handbook/data.html\#ist}{Chapter 3.2 of the \passthrough{\lstinline!tlverse!}
handbook}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Train a SL to predict recurrent stroke \passthrough{\lstinline!DRSISC!} with the available covariate
  data (the 25 other variables). Of course, you can consider feature selection
  in the machine learning algorithms. In this data, the outcome is
  occasionally missing, so be sure to specify \passthrough{\lstinline!drop\_missing\_outcome = TRUE!}
  when defining the task.
\item
  Use the SL-based predictions to calculate the area under the ROC curve
  (AUC).
\item
  Calculate the cross-validated AUC to evaluate the performance of the
  SL on unseen data.
\item
  Which covariates are the most predictive of 14-day recurrent stroke,
  according to \passthrough{\lstinline!sl3!} variable importance measures?
\end{enumerate}

\begin{lstlisting}[language=R]
ist_data <- paste0(
  "https://raw.githubusercontent.com/tlverse/",
  "tlverse-handbook/master/data/ist_sample.csv"
) %>% fread()

# number 3 help
ist_task_CVsl <- make_sl3_Task(
  data = ist_data,
  outcome = "DRSISC",
  covariates = colnames(ist_data)[-which(names(ist_data) == "DRSISC")],
  drop_missing_outcome = TRUE,
  folds = origami::make_folds(
    n = sum(!is.na(ist_data$DRSISC)),
    fold_fun = folds_vfold,
    V = 5
  )
)
\end{lstlisting}

\hypertarget{concluding-remarks}{%
\section{Concluding Remarks}\label{concluding-remarks}}

\begin{itemize}
\item
  Super Learner (SL) is a general approach that can be applied to a diversity of
  estimation and prediction problems which can be defined by a loss function.
\item
  It would be straightforward to plug in the estimator returned by SL into the
  target parameter mapping.

  \begin{itemize}
  \tightlist
  \item
    For example, suppose we are after the average treatment effect (ATE) of a
    binary treatment intervention:
    \(\Psi_0 = E_{0,W}[E_0(Y|A=1,W) - E_0(Y|A=0,W)]\).
  \item
    We could use the SL that was trained on the original data (let's call
    this \passthrough{\lstinline!sl\_fit!}) to predict the outcome for all subjects under each
    intervention. All we would need to do is take the average difference
    between the counterfactual outcomes under each intervention of interest.
  \item
    Considering \(\Psi_0\) above, we would first need two \(n\)-length vectors of
    predicted outcomes under each intervention. One vector would represent
    the predicted outcomes under an intervention that sets all subjects to
    receive \(A=1\), \(Y_i|A_i=1,W_i\) for all \(i=1,\ldots,n\). The other vector
    would represent the predicted outcomes under an intervention that sets
    all subjects to receive \(A=0\), \(Y_i|A_i=0,W_i\) for all \(i=1,\ldots,n\).
  \item
    After obtaining these vectors of counterfactual predicted outcomes, all
    we would need to do is average and then take the difference in order to
    ``plug-in'' the SL estimator into the target parameter mapping.
  \item
    In \passthrough{\lstinline!sl3!} and with our current ATE example, this could be achieved with
    \passthrough{\lstinline!mean(sl\_fit$predict(A1\_task)) - mean(sl\_fit$predict(A0\_task))!};
    where \passthrough{\lstinline!A1\_task$data!} would contain all 1's (or the level that pertains to
    receiving the treatment) for the treatment column in the data (keeping
    all else the same), and \passthrough{\lstinline!A0\_task$data!} would contain all 0's (or the
    level that pertains to not receiving the treatment) for the treatment
    column in the data.
  \end{itemize}
\item
  It's a worthwhile exercise to obtain the predicted counterfactual outcomes
  and create these counterfactual \passthrough{\lstinline!sl3!} tasks. It's too biased; however, to
  plug the SL fit into the target parameter mapping, (e.g., calling the result
  of \passthrough{\lstinline!mean(sl\_fit$predict(A1\_task)) - mean(sl\_fit$predict(A0\_task))!} the
  estimated ATE. We would end up with an estimator for the ATE that was
  optimized for estimation of the prediction function, and not the ATE!
\item
  At the end of the ``analysis day'', we want an estimator that is optimized for
  our target estimand of interest. We ultimately care about doing a good job
  estimating \(\psi_0\). The SL is an essential step to help us get there. In
  fact, we will use the counterfactual predicted outcomes that were explained
  at length above. However, SL is not the end of the estimation procedure.
  Specifically, the Super Learner would not be an asymptotically linear
  estimator of the target estimand; and it is not an efficient substitution
  estimator. This begs the question, why is it so important for an estimator to
  possess these properties?

  \begin{itemize}
  \item
    An asymptotically linear estimator converges to the estimand a
    \(\frac{1}{\sqrt{n}}\) rate, thereby permitting formal statistical inference
    (i.e., confidence intervals and \(p\)-values).
  \item
    Substitution, or plug-in, estimators of the estimand are desirable because
    they respect both the local and global constraints of the statistical model
    (e.g., bounds), and have they have better finite-sample properties.
  \item
    An efficient estimator is optimal in the sense that it has the lowest
    possible variance, and is thus the most precise. An estimator is efficient
    if and only if is asymptotically linear with influence curve equal to the
    canonical gradient.

    \begin{itemize}
    \tightlist
    \item
      The canonical gradient is a mathematical object that is specific to
      the target estimand, and it provides information on the level of
      difficulty of the estimation problem. Various canonical gradient are
      shown in the chapters that follow.
    \item
      Practitioner's do not need to know how to calculate a canonical
      gradient in order to understand efficiency and use Targeted Maximum
      Likelihood Estimation (TMLE). Metaphorically, you do not need to be
      Yoda in order to be a Jedi.
    \end{itemize}
  \end{itemize}
\item
  TMLE is a general strategy that succeeds in constructing efficient and
  asymptotically linear plug-in estimators.
\item
  SL is fantastic for pure prediction, and for obtaining an initial
  estimate in the first step of TMLE, but we need the second step of TMLE to
  have the desirable statistical properties mentioned above.
\item
  In the chapters that follow, we focus on the targeted maximum likelihood
  estimator and the targeted minimum loss-based estimator, both referred to as
  TMLE.
\end{itemize}

\hypertarget{appendix}{%
\section{Appendix}\label{appendix}}

\hypertarget{sl3ex1-sol}{%
\subsection{Exercise 1 Solution}\label{sl3ex1-sol}}

Here is a potential solution to the \protect\hyperlink{sl3ex1}{\passthrough{\lstinline!sl3!} Exercise 1 -- Predicting Myocardial
Infarction with \passthrough{\lstinline!sl3!}}.

\begin{lstlisting}[language=R]
db_data <- url(
  "https://raw.githubusercontent.com/benkeser/sllecture/master/chspred.csv"
)
chspred <- read_csv(file = db_data, col_names = TRUE)

# make task
chspred_task <- make_sl3_Task(
  data = chspred,
  covariates = head(colnames(chspred), -1),
  outcome = "mi"
)

# make learners
glm_learner <- Lrnr_glm$new()
lasso_learner <- Lrnr_glmnet$new(alpha = 1)
ridge_learner <- Lrnr_glmnet$new(alpha = 0)
enet_learner <- Lrnr_glmnet$new(alpha = 0.5)
# curated_glm_learner uses formula = "mi ~ smoke + beta + waist"
curated_glm_learner <- Lrnr_glm_fast$new(covariates = c("smoke, beta, waist"))
mean_learner <- Lrnr_mean$new() # That is one mean learner!
glm_fast_learner <- Lrnr_glm_fast$new()
ranger_learner <- Lrnr_ranger$new()
svm_learner <- Lrnr_svm$new()
xgb_learner <- Lrnr_xgboost$new()

# screening
screen_cor <- make_learner(Lrnr_screener_correlation)
glm_pipeline <- make_learner(Pipeline, screen_cor, glm_learner)

# stack learners together
stack <- make_learner(
  Stack,
  glm_pipeline, glm_learner,
  lasso_learner, ridge_learner, enet_learner,
  curated_glm_learner, mean_learner, glm_fast_learner,
  ranger_learner, svm_learner, xgb_learner
)

# make and train SL
sl <- Lrnr_sl$new(
  learners = stack
)
sl_fit <- sl$train(chspred_task)
sl_fit$print()

CVsl <- CV_lrnr_sl(sl_fit, chspred_task, loss_loglik_binomial)
CVsl

varimp <- importance(sl_fit, type = "permute")
varimp %>%
  importance_plot(
    main = "sl3 Variable Importance for Myocardial Infarction Prediction"
  )
\end{lstlisting}

\hypertarget{sl3ex2-sol}{%
\subsection{Exercise 2 Solution}\label{sl3ex2-sol}}

Here is a potential solution to \protect\hyperlink{sl3ex2}{\passthrough{\lstinline!sl3!} Exercise 2 -- Predicting Recurrent
Ischemic Stroke in an RCT with \passthrough{\lstinline!sl3!}}.

\begin{lstlisting}[language=R]
library(ROCR) # for AUC calculation

ist_data <- paste0(
  "https://raw.githubusercontent.com/tlverse/",
  "tlverse-handbook/master/data/ist_sample.csv"
) %>% fread()

# stack
ist_task <- make_sl3_Task(
  data = ist_data,
  outcome = "DRSISC",
  covariates = colnames(ist_data)[-which(names(ist_data) == "DRSISC")],
  drop_missing_outcome = TRUE
)

# learner library
lrn_glm <- Lrnr_glm$new()
lrn_lasso <- Lrnr_glmnet$new(alpha = 1)
lrn_ridge <- Lrnr_glmnet$new(alpha = 0)
lrn_enet <- Lrnr_glmnet$new(alpha = 0.5)
lrn_mean <- Lrnr_mean$new()
lrn_ranger <- Lrnr_ranger$new()
lrn_svm <- Lrnr_svm$new()
# xgboost grid
grid_params <- list(
  max_depth = c(2, 5, 8),
  eta = c(0.01, 0.15, 0.3)
)
grid <- expand.grid(grid_params, KEEP.OUT.ATTRS = FALSE)
params_default <- list(nthread = getOption("sl.cores.learners", 1))
xgb_learners <- apply(grid, MARGIN = 1, function(params_tune) {
  do.call(Lrnr_xgboost$new, c(params_default, as.list(params_tune)))
})
learners <- unlist(list(
  xgb_learners, lrn_ridge, lrn_mean, lrn_lasso,
  lrn_glm, lrn_enet, lrn_ranger, lrn_svm
),
recursive = TRUE
)

# SL
sl <- Lrnr_sl$new(learners)
sl_fit <- sl$train(ist_task)

# AUC
preds <- sl_fit$predict()
obs <- c(na.omit(ist_data$DRSISC))
AUC <- performance(prediction(sl_preds, obs), measure = "auc")@y.values[[1]]
plot(performance(prediction(sl_preds, obs), "tpr", "fpr"))

# CVsl
ist_task_CVsl <- make_sl3_Task(
  data = ist_data,
  outcome = "DRSISC",
  covariates = colnames(ist_data)[-which(names(ist_data) == "DRSISC")],
  drop_missing_outcome = TRUE,
  folds = origami::make_folds(
    n = sum(!is.na(ist_data$DRSISC)),
    fold_fun = folds_vfold,
    V = 5
  )
)
CVsl <- CV_lrnr_sl(sl_fit, ist_task_CVsl, loss_loglik_binomial)
CVsl

# sl3 variable importance plot
ist_varimp <- importance(sl_fit, type = "permute")
ist_varimp %>%
  importance_plot(
    main = "Variable Importance for Predicting Recurrent Ischemic Stroke"
  )
\end{lstlisting}

\hypertarget{tmle3}{%
\chapter{The TMLE Framework}\label{tmle3}}

\emph{Jeremy Coyle}

Based on the \href{https://github.com/tlverse/tmle3}{\passthrough{\lstinline!tmle3!} \passthrough{\lstinline!R!} package}.

\hypertarget{learn-tmle}{%
\section{Learning Objectives}\label{learn-tmle}}

By the end of this chapter, you will be able to

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Understand why we use TMLE for effect estimation.
\item
  Use \passthrough{\lstinline!tmle3!} to estimate an Average Treatment Effect (ATE).
\item
  Understand how to use \passthrough{\lstinline!tmle3!} ``Specs'' objects.
\item
  Fit \passthrough{\lstinline!tmle3!} for a custom set of target parameters.
\item
  Use the delta method to estimate transformations of target parameters.
\end{enumerate}

\hypertarget{tmle-intro}{%
\section{Introduction}\label{tmle-intro}}

In the previous chapter on \passthrough{\lstinline!sl3!} we learned how to estimate a regression
function like \(\mathbb{E}[Y \mid X]\) from data. That's an important first step
in learning from data, but how can we use this predictive model to estimate
statistical and causal effects?

Going back to \protect\hyperlink{intro}{the roadmap for targeted learning}, suppose we'd like to
estimate the effect of a treatment variable \(A\) on an outcome \(Y\). As discussed,
one potential parameter that characterizes that effect is the Average Treatment
Effect (ATE), defined as \(\psi_0 = \mathbb{E}_W[\mathbb{E}[Y \mid A=1,W] - \mathbb{E}[Y \mid A=0,W]]\) and interpreted as the difference in mean outcome
under when treatment \(A=1\) and \(A=0\), averaging over the distribution of
covariates \(W\). We'll illustrate several potential estimators for this
parameter, and motivate the use of the TMLE (targeted maximum likelihood
estimation; targeted minimum loss-based estimation) framework, using the
following example data:

\begin{center}\includegraphics[width=0.8\linewidth]{img/misc/tmle_sim/schematic_1_truedgd} \end{center}

The small ticks on the right indicate the mean outcomes (averaging over \(W\))
under \(A=1\) and \(A=0\) respectively, so their difference is the quantity we'd
like to estimate.

While we hope to motivate the application of TMLE in this chapter, we refer the
interested reader to the two Targeted Learning books and associated works for
full technical details.

\hypertarget{substitution-est}{%
\section{Substitution Estimators}\label{substitution-est}}

We can use \passthrough{\lstinline!sl3!} to fit a Super Learner or other regression model to estimate
the outcome regression function \(\mathbb{E}_0[Y \mid A,W]\), which we often refer
to as \(\overline{Q}_0(A,W)\) and whose estimate we denote \(\overline{Q}_n(A,W)\).
To construct an estimate of the ATE \(\psi_n\), we need only ``plug-in'' the
estimates of \(\overline{Q}_n(A,W)\), evaluated at the two intervention contrasts,
to the corresponding ATE ``plug-in'' formula:
\(\psi_n = \frac{1}{n}\sum(\overline{Q}_n(1,W)-\overline{Q}_n(0,W))\). This kind
of estimator is called a \emph{plug-in} or \emph{substitution} estimator, since accurate
estimates \(\psi_n\) of the parameter \(\psi_0\) may be obtained by substituting
estimates \(\overline{Q}_n(A,W)\) for the relevant regression functions
\(\overline{Q}_0(A,W)\) themselves.

Applying \passthrough{\lstinline!sl3!} to estimate the outcome regression in our example, we can see
that the ensemble machine learning predictions fit the data quite well:

\begin{center}\includegraphics[width=0.8\linewidth]{img/misc/tmle_sim/schematic_2b_sllik} \end{center}

The solid lines indicate the \passthrough{\lstinline!sl3!} estimate of the regression function, with the
dotted lines indicating the \passthrough{\lstinline!tmle3!} updates \protect\hyperlink{tmle-updates}{(described below)}.

While substitution estimators are intuitive, naively using this approach with a
Super Learner estimate of \(\overline{Q}_0(A,W)\) has several limitations. First,
Super Learner is selecting learner weights to minimize risk across the entire
regression function, instead of ``targeting'' the ATE parameter we hope to
estimate, leading to biased estimation. That is, \passthrough{\lstinline!sl3!} is trying to do well on
the full regression curve on the left, instead of focusing on the small ticks on
the right. What's more, the sampling distribution of this approach is not
asymptotically linear, and therefore inference is not possible.

We can see these limitations illustrated in the estimates generated for the
example data:

\begin{center}\includegraphics[width=0.8\linewidth]{img/misc/tmle_sim/schematic_3_effects} \end{center}

We see that Super Learner, estimates the true parameter value (indicated by the
dashed vertical line) more accurately than GLM. However, it is still less
accurate than TMLE, and valid inference is not possible. In contrast, TMLE
achieves a less biased estimator and valid inference.

\hypertarget{tmle}{%
\section{Targeted Maximum Likelihood Estimation}\label{tmle}}

TMLE takes an initial estimate \(\overline{Q}_n(A,W)\) as well as an estimate of
the propensity score \(g_n(A \mid W) = \mathbb{P}(A = 1 \mid W)\) and produces an
updated estimate \(\overline{Q}^{\star}_n(A,W)\) that is ``targeted'' to the
parameter of interest. TMLE keeps the benefits of substitution estimators (it is
one), but augments the original, potentially erratic estimates to \emph{correct for
bias} while also resulting in an \emph{asymptotically linear} (and thus normally
distributed) estimator that accommodates inference via asymptotically consistent
Wald-style confidence intervals.

\hypertarget{tmle-updates}{%
\subsection{TMLE Updates}\label{tmle-updates}}

There are different types of TMLEs (and, sometimes, multiple for the same set of
target parameters) -- below, we give an example of the algorithm for TML
estimation of the ATE. \(\overline{Q}^{\star}_n(A,W)\) is the TMLE-augmented
estimate \(f(\overline{Q}^{\star}_n(A,W)) = f(\overline{Q}_n(A,W)) + \epsilon \cdot H_n(A,W)\), where \(f(\cdot)\) is the appropriate link function (e.g.,
\(\text{logit}(x) = \log(x / (1 - x))\)), and an estimate \(\epsilon_n\) of the
coefficient \(\epsilon\) of the ``clever covariate'' \(H_n(A,W)\) is computed. The
form of the covariate \(H_n(A,W)\) differs across target parameters; in this case
of the ATE, it is \(H_n(A,W) = \frac{A}{g_n(A \mid W)} - \frac{1-A}{1-g_n(A, W)}\), with \(g_n(A,W) = \mathbb{P}(A=1 \mid W)\) being the estimated propensity
score, so the estimator depends both on the initial fit (by \passthrough{\lstinline!sl3!}) of the
outcome regression (\(\overline{Q}_n\)) and of the propensity score (\(g_n\)).

There are several robust augmentations that are used across the \passthrough{\lstinline!tlverse!},
including the use of an additional layer of cross-validation to avoid
over-fitting bias (i.e., CV-TMLE) as well as approaches for more consistently
estimating several parameters simultaneously (e.g., the points on a survival
curve).

\hypertarget{tmle-infer}{%
\subsection{Statistical Inference}\label{tmle-infer}}

Since TMLE yields an \textbf{asymptotically linear} estimator, obtaining statistical
inference is very convenient. Each TML estimator has a corresponding
\textbf{(efficient) influence function} (often, ``EIF'', for short) that describes the
asymptotic distribution of the estimator. By using the estimated EIF, Wald-style
inference (asymptotically correct confidence intervals) can be constructed
simply by plugging into the form of the EIF our initial estimates
\(\overline{Q}_n\) and \(g_n\), then computing the sample standard error.

The following sections describe both a simple and more detailed way of
specifying and estimating a TMLE in the \passthrough{\lstinline!tlverse!}. In designing \passthrough{\lstinline!tmle3!}, we
sought to replicate as closely as possible the very general estimation framework
of TMLE, and so each theoretical object relevant to TMLE is encoded in a
corresponding software object/method. First, we will present the simple
application of \passthrough{\lstinline!tmle3!} to the WASH Benefits example, and then go on to describe
the underlying objects in greater detail.

\hypertarget{easy-bake-example-tmle3-for-ate}{%
\section{\texorpdfstring{Easy-Bake Example: \texttt{tmle3} for ATE}{Easy-Bake Example: tmle3 for ATE}}\label{easy-bake-example-tmle3-for-ate}}

We'll illustrate the most basic use of TMLE using the WASH Benefits data
introduced earlier and estimating an average treatment effect.

\hypertarget{load-the-data}{%
\subsection{Load the Data}\label{load-the-data}}

We'll use the same WASH Benefits data as the earlier chapters:

\begin{lstlisting}[language=R]
library(data.table)
library(dplyr)
library(tmle3)
library(sl3)
washb_data <- fread(
  paste0(
    "https://raw.githubusercontent.com/tlverse/tlverse-data/master/",
    "wash-benefits/washb_data.csv"
  ),
  stringsAsFactors = TRUE
)
\end{lstlisting}

\hypertarget{define-the-variable-roles}{%
\subsection{Define the variable roles}\label{define-the-variable-roles}}

We'll use the common \(W\) (covariates), \(A\) (treatment/intervention), \(Y\)
(outcome) data structure. \passthrough{\lstinline!tmle3!} needs to know what variables in the dataset
correspond to each of these roles. We use a list of character vectors to tell
it. We call this a ``Node List'' as it corresponds to the nodes in a Directed
Acyclic Graph (DAG), a way of displaying causal relationships between variables.

\begin{lstlisting}[language=R]
node_list <- list(
  W = c(
    "month", "aged", "sex", "momage", "momedu",
    "momheight", "hfiacat", "Nlt18", "Ncomp", "watmin",
    "elec", "floor", "walls", "roof", "asset_wardrobe",
    "asset_table", "asset_chair", "asset_khat",
    "asset_chouki", "asset_tv", "asset_refrig",
    "asset_bike", "asset_moto", "asset_sewmach",
    "asset_mobile"
  ),
  A = "tr",
  Y = "whz"
)
\end{lstlisting}

\hypertarget{handle-missingness}{%
\subsection{Handle Missingness}\label{handle-missingness}}

Currently, missingness in \passthrough{\lstinline!tmle3!} is handled in a fairly simple way:

\begin{itemize}
\tightlist
\item
  Missing covariates are median- (for continuous) or mode- (for discrete)
  imputed, and additional covariates indicating imputation are generated, just
  as described in \protect\hyperlink{sl3}{the \passthrough{\lstinline!sl3!} chapter}.
\item
  Missing treatment variables are excluded -- such observations are dropped.
\item
  Missing outcomes are efficiently handled by the automatic calculation (and
  incorporation into estimators) of \emph{inverse probability of censoring weights}
  (IPCW); this is also known as IPCW-TMLE and may be thought of as a joint
  intervention to remove missingness and is analogous to the procedure used with
  classical inverse probability weighted estimators.
\end{itemize}

These steps are implemented in the \passthrough{\lstinline!process\_missing!} function in \passthrough{\lstinline!tmle3!}:

\begin{lstlisting}[language=R]
processed <- process_missing(washb_data, node_list)
washb_data <- processed$data
node_list <- processed$node_list
\end{lstlisting}

\hypertarget{create-a-spec-object}{%
\subsection{Create a ``Spec'' Object}\label{create-a-spec-object}}

\passthrough{\lstinline!tmle3!} is general, and allows most components of the TMLE procedure to be
specified in a modular way. However, most users will not be interested in
manually specifying all of these components. Therefore, \passthrough{\lstinline!tmle3!} implements a
\passthrough{\lstinline!tmle3\_Spec!} object that bundles a set of components into a \emph{specification}
(``Spec'') that, with minimal additional detail, can be run to fit a TMLE.

We'll start with using one of the specs, and then work our way down into the
internals of \passthrough{\lstinline!tmle3!}.

\begin{lstlisting}[language=R]
ate_spec <- tmle_ATE(
  treatment_level = "Nutrition + WSH",
  control_level = "Control"
)
\end{lstlisting}

\hypertarget{define-the-learners}{%
\subsection{Define the learners}\label{define-the-learners}}

Currently, the only other thing a user must define are the \passthrough{\lstinline!sl3!} learners used
to estimate the relevant factors of the likelihood: Q and g.

This takes the form of a list of \passthrough{\lstinline!sl3!} learners, one for each likelihood factor
to be estimated with \passthrough{\lstinline!sl3!}:

\begin{lstlisting}[language=R]
# choose base learners
lrnr_mean <- make_learner(Lrnr_mean)
lrnr_rf <- make_learner(Lrnr_ranger)

# define metalearners appropriate to data types
ls_metalearner <- make_learner(Lrnr_nnls)
mn_metalearner <- make_learner(
  Lrnr_solnp, metalearner_linear_multinomial,
  loss_loglik_multinomial
)
sl_Y <- Lrnr_sl$new(
  learners = list(lrnr_mean, lrnr_rf),
  metalearner = ls_metalearner
)
sl_A <- Lrnr_sl$new(
  learners = list(lrnr_mean, lrnr_rf),
  metalearner = mn_metalearner
)
learner_list <- list(A = sl_A, Y = sl_Y)
\end{lstlisting}

Here, we use a Super Learner as defined in the previous chapter. In the future,
we plan to include reasonable defaults learners.

\hypertarget{fit-the-tmle}{%
\subsection{Fit the TMLE}\label{fit-the-tmle}}

We now have everything we need to fit the tmle using \passthrough{\lstinline!tmle3!}:

\begin{lstlisting}[language=R]
tmle_fit <- tmle3(ate_spec, washb_data, node_list, learner_list)
print(tmle_fit)
A tmle3_Fit that took 1 step(s)
   type                                    param   init_est tmle_est       se
1:  ATE ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] -0.0031611 0.010044 0.050853
       lower   upper psi_transformed lower_transformed upper_transformed
1: -0.089626 0.10971        0.010044         -0.089626           0.10971
\end{lstlisting}

\hypertarget{evaluate-the-estimates}{%
\subsection{Evaluate the Estimates}\label{evaluate-the-estimates}}

We can see the summary results by printing the fit object. Alternatively, we
can extra results from the summary by indexing into it:

\begin{lstlisting}[language=R]
estimates <- tmle_fit$summary$psi_transformed
print(estimates)
[1] 0.010044
\end{lstlisting}

\hypertarget{tmle3-components}{%
\section{\texorpdfstring{\texttt{tmle3} Components}{tmle3 Components}}\label{tmle3-components}}

Now that we've successfully used a spec to obtain a TML estimate, let's look
under the hood at the components. The spec has a number of functions that
generate the objects necessary to define and fit a TMLE.

\hypertarget{tmle3_task}{%
\subsection{\texorpdfstring{\texttt{tmle3\_task}}{tmle3\_task}}\label{tmle3_task}}

First is, a \passthrough{\lstinline!tmle3\_Task!}, analogous to an \passthrough{\lstinline!sl3\_Task!}, containing the data we're
fitting the TMLE to, as well as an NPSEM generated from the \passthrough{\lstinline!node\_list!}
defined above, describing the variables and their relationships.

\begin{lstlisting}[language=R]
tmle_task <- ate_spec$make_tmle_task(washb_data, node_list)
\end{lstlisting}

\begin{lstlisting}[language=R]
tmle_task$npsem
$W
tmle3_Node: W
    Variables: month, aged, sex, momedu, hfiacat, Nlt18, Ncomp, watmin, elec, floor, walls, roof, asset_wardrobe, asset_table, asset_chair, asset_khat, asset_chouki, asset_tv, asset_refrig, asset_bike, asset_moto, asset_sewmach, asset_mobile, momage, momheight, delta_momage, delta_momheight
    Parents: 

$A
tmle3_Node: A
    Variables: tr
    Parents: W

$Y
tmle3_Node: Y
    Variables: whz
    Parents: A, W
\end{lstlisting}

\hypertarget{initial-likelihood}{%
\subsection{Initial Likelihood}\label{initial-likelihood}}

Next, is an object representing the likelihood, factorized according to the
NPSEM described above:

\begin{lstlisting}[language=R]
initial_likelihood <- ate_spec$make_initial_likelihood(
  tmle_task,
  learner_list
)
print(initial_likelihood)
W: Lf_emp
A: LF_fit
Y: LF_fit
\end{lstlisting}

These components of the likelihood indicate how the factors were estimated: the
marginal distribution of \(W\) was estimated using NP-MLE, and the conditional
distributions of \(A\) and \(Y\) were estimated using \passthrough{\lstinline!sl3!} fits (as defined with
the \passthrough{\lstinline!learner\_list!}) above.

We can use this in tandem with the \passthrough{\lstinline!tmle\_task!} object to obtain likelihood
estimates for each observation:

\begin{lstlisting}[language=R]
initial_likelihood$get_likelihoods(tmle_task)
               W       A        Y
   1: 0.00021299 0.34702 -0.32696
   2: 0.00021299 0.37305 -0.88218
   3: 0.00021299 0.34685 -0.79300
   4: 0.00021299 0.33625 -0.89157
   5: 0.00021299 0.34098 -0.63477
  ---                            
4691: 0.00021299 0.24334 -0.61095
4692: 0.00021299 0.24620 -0.21534
4693: 0.00021299 0.22401 -0.79223
4694: 0.00021299 0.27641 -0.94319
4695: 0.00021299 0.20158 -1.08201
\end{lstlisting}

\hypertarget{targeted-likelihood-updater}{%
\subsection{Targeted Likelihood (updater)}\label{targeted-likelihood-updater}}

We also need to define a ``Targeted Likelihood'' object. This is a special type
of likelihood that is able to be updated using an \passthrough{\lstinline!tmle3\_Update!} object. This
object defines the update strategy (e.g., submodel, loss function, CV-TMLE or
not).

\begin{lstlisting}[language=R]
targeted_likelihood <- Targeted_Likelihood$new(initial_likelihood)
\end{lstlisting}

When constructing the targeted likelihood, you can specify different update
options. See the documentation for \passthrough{\lstinline!tmle3\_Update!} for details of the different
options. For example, you can disable CV-TMLE (the default in \passthrough{\lstinline!tmle3!}) as
follows:

\begin{lstlisting}[language=R]
targeted_likelihood_no_cv <-
  Targeted_Likelihood$new(initial_likelihood,
    updater = list(cvtmle = FALSE)
  )
\end{lstlisting}

\hypertarget{parameter-mapping}{%
\subsection{Parameter Mapping}\label{parameter-mapping}}

Finally, we need to define the parameters of interest. Here, the spec defines a
single parameter, the ATE. In the next section, we'll see how to add additional
parameters.

\begin{lstlisting}[language=R]
tmle_params <- ate_spec$make_params(tmle_task, targeted_likelihood)
print(tmle_params)
[[1]]
Param_ATE: ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}]
\end{lstlisting}

\hypertarget{putting-it-all-together}{%
\subsection{Putting it all together}\label{putting-it-all-together}}

Having used the spec to manually generate all these components, we can now
manually fit a \passthrough{\lstinline!tmle3!}:

\begin{lstlisting}[language=R]
tmle_fit_manual <- fit_tmle3(
  tmle_task, targeted_likelihood, tmle_params,
  targeted_likelihood$updater
)
print(tmle_fit_manual)
A tmle3_Fit that took 1 step(s)
   type                                    param   init_est tmle_est       se
1:  ATE ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] -0.0062324 0.017515 0.050591
       lower   upper psi_transformed lower_transformed upper_transformed
1: -0.081641 0.11667        0.017515         -0.081641           0.11667
\end{lstlisting}

The result is equivalent to fitting using the \passthrough{\lstinline!tmle3!} function as above.

\hypertarget{fitting-tmle3-with-multiple-parameters}{%
\section{\texorpdfstring{Fitting \texttt{tmle3} with multiple parameters}{Fitting tmle3 with multiple parameters}}\label{fitting-tmle3-with-multiple-parameters}}

Above, we fit a \passthrough{\lstinline!tmle3!} with just one parameter. \passthrough{\lstinline!tmle3!} also supports fitting
multiple parameters simultaneously. To illustrate this, we'll use the
\passthrough{\lstinline!tmle\_TSM\_all!} spec:

\begin{lstlisting}[language=R]
tsm_spec <- tmle_TSM_all()
targeted_likelihood <- Targeted_Likelihood$new(initial_likelihood)
all_tsm_params <- tsm_spec$make_params(tmle_task, targeted_likelihood)
print(all_tsm_params)
[[1]]
Param_TSM: E[Y_{A=Control}]

[[2]]
Param_TSM: E[Y_{A=Handwashing}]

[[3]]
Param_TSM: E[Y_{A=Nutrition}]

[[4]]
Param_TSM: E[Y_{A=Nutrition + WSH}]

[[5]]
Param_TSM: E[Y_{A=Sanitation}]

[[6]]
Param_TSM: E[Y_{A=WSH}]

[[7]]
Param_TSM: E[Y_{A=Water}]
\end{lstlisting}

This spec generates a Treatment Specific Mean (TSM) for each level of the
exposure variable. Note that we must first generate a new targeted likelihood,
as the old one was targeted to the ATE. However, we can recycle the initial
likelihood we fit above, saving us a super learner step.

\hypertarget{delta-method}{%
\subsection{Delta Method}\label{delta-method}}

We can also define parameters based on Delta Method Transformations of other
parameters. For instance, we can estimate a ATE using the delta method and two
of the above TSM parameters:

\begin{lstlisting}[language=R]
ate_param <- define_param(
  Param_delta, targeted_likelihood,
  delta_param_ATE,
  list(all_tsm_params[[1]], all_tsm_params[[4]])
)
print(ate_param)
Param_delta: E[Y_{A=Nutrition + WSH}] - E[Y_{A=Control}]
\end{lstlisting}

This can similarly be used to estimate other derived parameters like Relative
Risks, and Population Attributable Risks

\hypertarget{fit}{%
\subsection{Fit}\label{fit}}

We can now fit a TMLE simultaneously for all TSM parameters, as well as the
above defined ATE parameter

\begin{lstlisting}[language=R]
all_params <- c(all_tsm_params, ate_param)

tmle_fit_multiparam <- fit_tmle3(
  tmle_task, targeted_likelihood, all_params,
  targeted_likelihood$updater
)

print(tmle_fit_multiparam)
A tmle3_Fit that took 1 step(s)
   type                                       param   init_est tmle_est
1:  TSM                            E[Y_{A=Control}] -0.5953314 -0.61981
2:  TSM                        E[Y_{A=Handwashing}] -0.6179897 -0.66114
3:  TSM                          E[Y_{A=Nutrition}] -0.6119870 -0.60338
4:  TSM                    E[Y_{A=Nutrition + WSH}] -0.6015639 -0.60250
5:  TSM                         E[Y_{A=Sanitation}] -0.5866311 -0.58147
6:  TSM                                E[Y_{A=WSH}] -0.5213051 -0.45027
7:  TSM                              E[Y_{A=Water}] -0.5653576 -0.53554
8:  ATE E[Y_{A=Nutrition + WSH}] - E[Y_{A=Control}] -0.0062324  0.01731
         se     lower    upper psi_transformed lower_transformed
1: 0.030069 -0.678746 -0.56088        -0.61981         -0.678746
2: 0.041821 -0.743111 -0.57917        -0.66114         -0.743111
3: 0.041553 -0.684825 -0.52194        -0.60338         -0.684825
4: 0.040925 -0.682712 -0.52229        -0.60250         -0.682712
5: 0.042313 -0.664402 -0.49854        -0.58147         -0.664402
6: 0.045216 -0.538891 -0.36165        -0.45027         -0.538891
7: 0.039290 -0.612551 -0.45854        -0.53554         -0.612551
8: 0.050596 -0.081857  0.11648         0.01731         -0.081857
   upper_transformed
1:          -0.56088
2:          -0.57917
3:          -0.52194
4:          -0.52229
5:          -0.49854
6:          -0.36165
7:          -0.45854
8:           0.11648
\end{lstlisting}

\hypertarget{exercises-1}{%
\section{Exercises}\label{exercises-1}}

\hypertarget{tmle3-ex1}{%
\subsection{\texorpdfstring{Estimation of the ATE with \texttt{tmle3}}{Estimation of the ATE with tmle3}}\label{tmle3-ex1}}

Follow the steps below to estimate an average treatment effect using data from
the Collaborative Perinatal Project (CPP), available in the \passthrough{\lstinline!sl3!} package. To
simplify this example, we define a binary intervention variable, \passthrough{\lstinline!parity01!} --
an indicator of having one or more children before the current child and a
binary outcome, \passthrough{\lstinline!haz01!} -- an indicator of having an above average height for
age.

\begin{lstlisting}[language=R]
# load the data set
data(cpp)
cpp <- cpp %>%
  as_tibble() %>%
  dplyr::filter(!is.na(haz)) %>%
  mutate(
    parity01 = as.numeric(parity > 0),
    haz01 = as.numeric(haz > 0)
  )
\end{lstlisting}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Define the variable roles \((W,A,Y)\) by creating a list of these nodes.
  Include the following baseline covariates in \(W\): \passthrough{\lstinline!apgar1!}, \passthrough{\lstinline!apgar5!},
  \passthrough{\lstinline!gagebrth!}, \passthrough{\lstinline!mage!}, \passthrough{\lstinline!meducyrs!}, \passthrough{\lstinline!sexn!}. Both \(A\) and \(Y\) are specified
  above. The missingness in the data (specifically, the missingness in the
  columns that are specified in the node list) will need to be taking care of.
  The \passthrough{\lstinline!process\_missing!} function can be used to accomplish this, like the
  \passthrough{\lstinline!washb\_data!} example above.
\item
  Define a \passthrough{\lstinline!tmle3\_Spec!} object for the ATE, \passthrough{\lstinline!tmle\_ATE()!}.
\item
  Using the same base learning libraries defined above, specify \passthrough{\lstinline!sl3!} base
  learners for estimation of \(\overline{Q}_0 = \mathbb{E}_0(Y \mid A, W)\) and
  \(g_0 = \mathbb{P}(A = 1 \mid W)\).
\item
  Define the metalearner like below.
\end{enumerate}

\begin{lstlisting}[language=R]
metalearner <- make_learner(
  Lrnr_solnp,
  loss_function = loss_loglik_binomial,
  learner_function = metalearner_logistic_binomial
)
\end{lstlisting}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Define one super learner for estimating \(\overline{Q}_0\) and another for
  estimating \(g_0\). Use the metalearner above for both super learners.
\item
  Create a list of the two super learners defined in the step above and call
  this object \passthrough{\lstinline!learner\_list!}. The list names should be \passthrough{\lstinline!A!} (defining the super
  learner for estimation of \(g_0\)) and \passthrough{\lstinline!Y!} (defining the super learner for
  estimation of \(\overline{Q}_0\)).
\item
  Fit the TMLE with the \passthrough{\lstinline!tmle3!} function by specifying (1) the \passthrough{\lstinline!tmle3\_Spec!},
  which we defined in Step 2; (2) the data; (3) the list of nodes, which we
  specified in Step 1; and (4) the list of super learners for estimation of
  \(g_0\) and \(\overline{Q}_0\), which we defined in Step 6. \emph{Note}: Like before,
  you will need to explicitly make a copy of the data (to work around
  \passthrough{\lstinline!data.table!} optimizations), e.g., (\passthrough{\lstinline!cpp2 <- data.table::copy(cpp)!}), then
  use the \passthrough{\lstinline!cpp2!} data going forward.
\end{enumerate}

\hypertarget{tmle3-ex2}{%
\subsection{\texorpdfstring{Estimation of Strata-Specific ATEs with \texttt{tmle3}}{Estimation of Strata-Specific ATEs with tmle3}}\label{tmle3-ex2}}

For this exercise, we will work with a random sample of 5,000 patients who
participated in the International Stroke Trial (IST). This data is described in
the \protect\hyperlink{ist}{Chapter 3.2 of the \passthrough{\lstinline!tlverse!} handbook}. We included the data below
and a summarized description that is relevant for this exercise.

The outcome, \(Y\), indicates recurrent ischemic stroke within 14 days after
randomization (\passthrough{\lstinline!DRSISC!}); the treatment of interest, \(A\), is the randomized
aspirin vs.~no aspirin treatment allocation (\passthrough{\lstinline!RXASP!} in \passthrough{\lstinline!ist!}); and the
adjustment set, \(W\), consists simply of other variables measured at baseline. In
this data, the outcome is occasionally missing, but there is no need to create a
variable indicating this missingness (such as \(\Delta\)) for analyses in the
\passthrough{\lstinline!tlverse!}, since the missingness is automatically detected when \passthrough{\lstinline!NA!} are present
in the outcome. Covariates with missing values (\passthrough{\lstinline!RATRIAL!}, \passthrough{\lstinline!RASP3!} and \passthrough{\lstinline!RHEP24!})
have already been imputed. Additional covariates were created
(\passthrough{\lstinline!MISSING\_RATRIAL\_RASP3!} and \passthrough{\lstinline!MISSING\_RHEP24!}), which indicate whether or not
the covariate was imputed. The missingness was identical for \passthrough{\lstinline!RATRIAL!} and
\passthrough{\lstinline!RASP3!}, which is why only one covariate indicating imputation for these two
covariates was created.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Estimate the average effect of randomized aspirin treatment (\passthrough{\lstinline!RXASP!} = 1) on
  recurrent ischemic stroke. Even though the missingness mechanism on \(Y\),
  \(\Delta\), does not need to be specified in the node list, it does still need
  to be accounted for in the TMLE. In other words, for this estimation problem,
  \(\Delta\) is a relevant factor of the likelihood. Thus, when defining the
  list of \passthrough{\lstinline!sl3!} learners for each likelihood factor, be sure to include a list
  of learners for estimation of \(\Delta\), say \passthrough{\lstinline!sl\_Delta!}, and specify this in
  the learner list, like so
  \passthrough{\lstinline!learner\_list <- list(A = sl\_A, delta\_Y = sl\_Delta, Y = sl\_Y)!}.
\item
  Recall that this RCT was conducted internationally. Suppose there is concern
  that the dose of aspirin may have varied across geographical regions, and an
  average across all geographical regions may not be warranted. Calculate the
  strata specific ATEs according to geographical region (\passthrough{\lstinline!REGION!}).
\end{enumerate}

\begin{lstlisting}[language=R]
ist_data <- fread(
  paste0(
    "https://raw.githubusercontent.com/tlverse/deming2019-workshop/",
    "master/data/ist_sample.csv"
  )
)
\end{lstlisting}

\hypertarget{summary}{%
\section{Summary}\label{summary}}

\passthrough{\lstinline!tmle3!} is a general purpose framework for generating TML estimates. The easiest
way to use it is to use a predefined spec, allowing you to just fill in the
blanks for the data, variable roles, and \passthrough{\lstinline!sl3!} learners. However, digging under
the hood allows users to specify a wide range of TMLEs. In the next sections,
we'll see how this framework can be used to estimate advanced parameters such as
optimal treatments and stochastic shift interventions.

\hypertarget{optimal-individualized-treatment-regimes}{%
\chapter{Optimal Individualized Treatment Regimes}\label{optimal-individualized-treatment-regimes}}

\emph{Ivana Malenica}

Based on the \href{https://github.com/tlverse/tmle3mopttx}{\passthrough{\lstinline!tmle3mopttx!} \passthrough{\lstinline!R!} package}
by \emph{Ivana Malenica, Jeremy Coyle, and Mark van der Laan}.

Updated: 2021-04-28

\hypertarget{learning-objectives-4}{%
\section{Learning Objectives}\label{learning-objectives-4}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Differentiate dynamic and optimal dynamic treatment interventions from static
  interventions.
\item
  Explain the benefits, and challenges, associated with using optimal
  individualized treatment regimes in practice.
\item
  Contrast the impact of implementing an optimal individualized treatment
  regime in the population with the impact of implementing static and dynamic
  treatment regimes in the population.
\item
  Estimate causal effects under optimal individualized treatment regimes with
  the \passthrough{\lstinline!tmle3mopttx!} \passthrough{\lstinline!R!} package.
\item
  Assess the mean under optimal individualized treatment with resource
  constraints.
\item
  Implement optimal individualized treatment rules based on sub-optimal
  rules, or ``simple'' rules, and recognize the practical benefit of these rules.
\item
  Construct ``realistic'' optimal individualized treatment regimes that respect
  real data and subject-matter knowledge limitations on interventions by
  only considering interventions that are supported by the data.
\item
  Measure variable importance as defined in terms of the optimal individualized
  treatment interventions.
\end{enumerate}

\hypertarget{introduction-to-optimal-individualized-interventions}{%
\section{Introduction to Optimal Individualized Interventions}\label{introduction-to-optimal-individualized-interventions}}

Identifying which intervention will be effective for which patient based on
lifestyle, genetic and environmental factors is a common goal in precision
medicine. To put it in context, Abacavir and Tenofovir are commonly prescribed
as part of the antiretroviral therapy to Human Immunodeficiency Virus (HIV)
patients. However, not all individuals benefit from the two medications equally.
In particular, patients with renal dysfunction might further deteriorate if
prescribed Tenofovir, due to the high nephrotoxicity caused by the medication.
While Tenofovir is still highly effective treatment option for HIV patients, in
order to maximize the patient's well-being, it would be beneficial to prescribe
Tenofovir only to individuals with healthy kidney function. Along the same
lines, one might seek to improve retention in HIV care. In a randomized clinical
trial, several interventions show efficacy- including appointment reminders
through text messages, small cash incentives for on time clinic visits, and peer
health workers. Ideally, we want to improve effectiveness by assigning each
patient the intervention they are most likely to benefit from, as well as
improve efficiency by not allocating resources to individuals that do not need
them, or would not benefit from it.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{img/image/DynamicA_Illustration} 

}

\caption{Dynamic Treatment Regime in a Clinical Setting}\label{fig:unnamed-chunk-1}
\end{figure}

One opts to administer the intervention to individuals who will profit from it instead,
instead of assigning treatment on a population level. But how do we know which
intervention works for which patient? This aim motivates a different type of
intervention, as opposed to the static exposures we described in previous chapters. In
particular, in this chapter we learn about dynamic or ``individualized''
interventions that tailor the treatment decision based on the collected
covariates. Formally, dynamic treatments represent interventions that at each
treatment-decision stage are allowed to respond to the currently available
treatment and covariate history.

In the statistics community such a treatment strategy is termed an
\textbf{individualized treatment regime} (ITR), and the (counterfactual) population
mean outcome under an ITR is the value of the ITR \citep{neyman1990, robins1986, pearl2009}. Even more, suppose one wishes to maximize the population mean of an
outcome, where for each individual we have access to some set of measured
covariates. This means, for example, that we can learn for which individual
characteristics assigning treatment increases the probability of a beneficial
outcome. An ITR with the maximal value is referred to as an
optimal ITR or the \textbf{optimal individualized treatment}. Consequently, the value
of an optimal ITR is termed the optimal value, or the \textbf{mean under the optimal
individualized treatment}.

The problem of estimating the optimal individualized treatment has received much
attention in the statistics literature over the years, especially with the
advancement of precision medicine; see \citet{murphy2003}, \citet{robins2004}, \citet{laber2012},
\citet{kosorok2012}, \citet{moodie2013} and \citet{robins2014} to name a few. However, much of the
early work depends on parametric assumptions. As such, even in a randomized
trial, the statistical inference for the optimal individualized treatment relies
on assumptions that are generally believed to be false, and can lead to biased
results.

In this chapter, we consider estimation of the mean outcome under the optimal
individualized treatment where the candidate rules are restricted to depend only
on user-supplied subset of the baseline covariates. The estimation problem is
addressed in a statistical model for the data distribution that is
nonparametric, and at most places restrictions on the probability of a patient
receiving treatment given covariates (as in a randomized trial). As such, we
don't need to make any assumptions about the relationship of the outcome with
the treatment and covariates, or the relationship between the treatment and
covariates. Further, we provide a Targeted Maximum Likelihood Estimator for the
mean under the optimal individualized treatment that allows us to generate valid
inference for our parameter, without having any parametric assumptions. For a
technical presentation of the algorithm, the interested reader is invited to
further consult \citet{vanderLaanLuedtke15} and \citet{luedtke2016super}.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{data-structure-and-notation}{%
\section{Data Structure and Notation}\label{data-structure-and-notation}}

Suppose we observe \(n\) independent and identically distributed observations of
the form \(O=(W,A,Y) \sim P_0\). We denote \(A\) as categorical treatment, and \(Y\)
as the final outcome. In particular, we define \(A \in \mathcal{A}\) where
\(\mathcal{A} \equiv \{a_1, \cdots, a_{n_A} \}\) and \(n_A = |\mathcal{A}|\), with
\(n_A\) denoting the number of categories (possibly only two, for a binary setup).
Note that we treat \(W\) as vector-valued, representing all of our collected
baseline covariates. Therefore, for a single random individual \(i\), we have that
their observed data is \(O_i\): with corresponding baseline covariates \(W_i\),
treatment \(A_i\), and final outcome \(Y_i\). We say that \(O \sim P_0\), or that all
data was drawn from some true probability distribution \(P_0\). Let \(\mathcal{M}\)
denote a statistical model, with \(P_0 \in \mathcal{M}\). We emphasize that we
make no assumptions about the distribution of \(P_0\), hence \(\mathcal{M}\) is a
fully nonparametric model. As previously mentioned, this means that we make no
assumptions on the relationship between variables, but might be able to say
something about the relationship of \(A\) and \(W\), as is the case of a randomized
trial. As in previous chapters, we denote \(P_n\) as the empirical distribution
which gives each observation weight \(1/n\).

We use the nonparametric structural equation model (NPSEM) in order to define
the process that gives rise to the observed (endogenous) and not observed
(exogenous) variables, as described by \citet{pearl2009causality}. In particular, we
denote \(U=(U_W,U_A,U_Y)\) as the exogenous random variables, and \(O=(W,A,Y)\) as
endogenous variables we observe. The joint distribution of exogenous and
endogenous random variables in \(\mathcal{M}^F\) (defined by the NPSEM) is
\(P_{U,X}\). We can define the relationships between variables with the following
structural equations:
\begin{align}
  W &= f_W(U_W) \\ A &= f_A(W, U_A) \\ Y &= f_Y(A, W, U_Y),
  \label{eq:npsem-mopttx}
\end{align}
where the collection \(f=(f_W,f_A,f_Y)\) denotes unspecified functions. Note that
in the case of a randomized trial, we can write the above NPSEM as
\begin{align}
  W &= f_W(U_W) \\ A &= U_A \\ Y &= f_Y(A, W, U_Y),
  \label{eq:npsem-rt-mopttx}
\end{align}
indicating no dependence of treatment on baseline covariates.

The likelihood of the data admits a factorization, implied by the time ordering
of \(O\). We denote the density of \(O\) as \(p_0\), corresponding to the
distribution \(P_0\) and dominating measure \(\mu\).
\begin{equation}
  p_0(O) = p_{Y,0}(Y \mid A,W) p_{A,0}(A \mid W) p_{W,0}(W) =
    q_{Y,0}(Y \mid A,W) q_{A,0}(A \mid W) q_{W,0}(W),
  \label{eq:likelihood-factorization-mopttx}
\end{equation}
where \(p_{Y,0}(Y|A,W)\) is the conditional density of \(Y\) given \((A, W)\) with
respect to some dominating measure \(\mu_Y\), \(p_{A,0}\) is the conditional density
of \(A\) given \(W\) with respect to dominating measure \(\mu_A\), and \(p_{W,0}\) is
the density of \(W\) with respect to dominating measure \(\mu_W\). Consequently, we
define \(P_{Y,0}(Y \mid A, W) = Q_{Y,0}(Y \mid A,W)\), \(P_{A,0}(A \mid W) = g_0(A \mid W)\) and \(P_{W,0}(W)=Q_{W,0}(W)\) as the corresponding conditional
distribution of \(Y\) given \((A,W)\), treatment mechanism \(A\) given \(W\), and
distribution of baseline covariates. For notational simplicity, we also define
\(\bar{Q}_{Y,0}(A,W) \equiv \E_0[Y \mid A,W]\) as the conditional expectation of
\(Y\) given \((A,W)\).

Lastly, we define \(V\) as a subset of the baseline covariates the optimal
individualized rule depends on, where \(V \in W\). Note that \(V\) could be all of
\(W\), or an empty set, depending on the subject matter knowledge. In particular,
a researcher might want to consider known effect modifiers available at the time
of treatment decision as possible \(V\) covariates. Defining \(V\) allows us to
consider possibly sub-optimal rules that are easier to estimate, and thereby
allows for statistical inference for the counterfactual mean outcome under the
sub-optimal rule.

\hypertarget{defining-the-causal-effect-of-an-optimal-individualized-intervention}{%
\section{Defining the Causal Effect of an Optimal Individualized Intervention}\label{defining-the-causal-effect-of-an-optimal-individualized-intervention}}

Consider dynamic treatment rules \(d\) in the set of all possible rules
\(\mathcal{D}\). Then, \(d\) is a function that takes as input \(V\) and outputs a
treatment decision, \(V \rightarrow d(V) \in \{a_1, \cdots, a_{n_A} \} \times \{1\}\). We will use dynamic treatment rules, and the corresponding treatment
decision, to describe an intervention on the treatment mechanism and the
corresponding outcome under a dynamic treatment rule.

As mentioned in the previous section, causal effects are defined in terms of
hypothetical interventions on the NPSEM \eqref{eq:npsem-mopttx}. We can define
counterfactuals \(Y_{d(V)}\) defined by a modified system in which the equation
for \(A\) is replaced by the rule \(d(V)\), dependent on covariates \(V\). Our
modified system then takes the following form:
\begin{align}
  W &= f_W(U_W) \\ A &= d(V) \\ Y_{d(V)} &= f_Y(d(V), W, U_Y),
  \label{eq:npsem-causal-mopttx}
\end{align}
where the dynamic treatment regime may be viewed as an intervention in which \(A\)
is set equal to a value based on a hypothetical regime \(d(V)\), possibly contrary
to the fact, and \(Y_{d(V)}\) is the corresponding outcome under \(d(V)\). We
denote the distribution of the counterfactual quantities as \(P_{0,d(V)}\).

The goal of any causal analysis motivated by such dynamic interventions is to
estimate a parameter defined as the counterfactual mean of the outcome with
respect to the modified intervention distribution. That is, subject's outcome
if, possibly contrary to the fact, the subject received treatment that would
have been assigned by rule \(d(V)\). We can consider different treatment rules,
all in the set \(\mathcal{D}\):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The true rule, \(d_0\), and the corresponding causal parameter
  \(\E_{U,X}[Y_{d_0(V)}]\);
\item
  The estimated rule, \(d_n\), and the corresponding causal parameter
  \(\E_{U,X}[Y_{d_n(V)}]\).
\end{enumerate}

In this chapter, we will focus on the estimated rule \(d_n\), and the
corresponding data-adaptive parameter.

The optimal individualized rule is the rule with the maximal value:
\[d_{opt}(V) \equiv \text{argmax}_{d(V) \in \mathcal{D}}
\E_{P_{U,X}}[Y_{d(V)}]\].

We note that, in case the problem at hand requires minimizing the mean of an
outcome, our optimal individualized rule will be the rule with the minimal value
instead. Our causal target parameter of interest is the expected outcome under
the estimated optimal individualized rule:

\[\Psi_{d_{n, \text{opt}}(V)}(P_{U,X}) \coloneqq \E_{P_{U,X}}[Y_{d_{n,
\text{opt}}(V)}].\]

\hypertarget{identification-and-statistical-estimand}{%
\subsection{Identification and Statistical Estimand}\label{identification-and-statistical-estimand}}

The optimal individualized rule, as well as the value of a optimal
individualized rule, are causal parameters based on the unobserved
counterfactuals. In order for the causal quantities to be estimated from the
observed data, they need to be identified with statistical parameters. This step
of the roadmap requires me make few assumptions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{Strong ignorability}: \(A \indep Y^{d_n(v)} \mid W\), for all \(a \in \mathcal{A}\).
\item
  \emph{Positivity (or overlap)}: \(P_0(\min_{a \in \mathcal{A}} g_0(a \mid W) > 0) = 1\)
\end{enumerate}

Under the above causal assumptions, we can identify \(P_{0,d}\) with observed data
using the G-computation formula:

\[P_{0,d_{n, \text{opt}}}(O) = Q_{Y,0}(Y \mid A=d_{n,\text{opt}}(V),W)
g_0(A=d_{n,\text{opt}}(V) \mid W)Q_{W,0}(W).\]
The value of an individualized rule can now be expressed as

\[\E_0[Y_{d_n(V)}] = \E_{0,W}[\bar{Q}_{Y,0}(A=d_n(V),W)],\]

which, under causal assumptions, can is interpreted as the mean outcome if
(possibly contrary to fact), treatment was assigned according to the rule.
Finally, the statistical counterpart to the causal parameter of interest is
defined as
\[\psi_0 = \E_{0,W}[\bar{Q}_{Y,0}(A=d_{n,\text{opt}}(V),W)].\]

Inference for the optimal value has been shown to be difficult at exceptional
laws, defined as probability distributions for which treatment is neither
beneficial nor harmful. Inference is similarly difficult in finite samples if
the treatment effect is very small in all strata, even though valid asymptotic
estimators exist in this setting. With that in mind, we address the estimation
problem under the assumption of non-exceptional laws in effect.

Many methods for learning the optimal rule from data have been developed
\citep{murphy2003, robins2004, laber2012, kosorok2012, moodie2013}. In this
chapter, we focus on the methods discussed in \citet{luedtke2016super} and
\citet{vanderLaanLuedtke15}. Note however, that \passthrough{\lstinline!tmle3mopttx!} also supports the widely
used Q-learning approach, where the optimal individualized rule is based on the
initial estimate of \(\bar{Q}_{Y,0}(A,W)\) \citep{Sutton1998}.

We follow the methodology outlined in \citet{luedtke2016super} and
\citet{vanderLaanLuedtke15}, where we learn the optimal ITR using Super Learner
\citep{vdl2007super}, and estimate its value with cross-validated Targeted Minimum
Loss-based Estimation (CV-TMLE) \citep{cvtmle2010}. In great generality, we first
need to estimate the true individual treatment regime, \(d_0(V)\), which
corresponds to dynamic treatment rule (\(d(V)\)) that takes a subset of covariates
\(V \in W\) and assigns treatment to each individual based on their observed
covariates \(v\). With the estimate of the true optimal ITR in hand, we can
estimate its corresponding value.

\hypertarget{binary-treatment}{%
\subsection{Binary treatment}\label{binary-treatment}}

How do we estimate the optimal individualized treatment regime? In the case of a
binary treatment, a key quantity for optimal ITR is the blip function. One can
show that any optimal ITR assigns treatment to individuals falling in strata in
which the stratum specific average treatment effect, the blip function, is
positive and does not assign treatment to individuals for which this quantity is
negative. Therefore for a binary treatment, under causal assumptions, we define
the blip function as:
\[\bar{Q}_0(V) \equiv \E_0[Y_1-Y_0 \mid V] \equiv \E_0[\bar{Q}_{Y,0}(1,W) -
\bar{Q}_{Y,0}(0,W) \mid V],\]
or the average treatment effect within a stratum of \(V\). The note that the
optimal individualized rule can now be derived as \(d_{n,\text{opt}}(V) = \mathbb{I}(\bar{Q}_{0}(V) > 0)\).

The package \passthrough{\lstinline!tmle3mopttx!} relies on using the Super Learner to estimate the blip
function, as it easily extends to more general categorical treatment. With that
in mind, the loss function utilized for learning the optimal individualized rule
corresponds to conditional mean type losses. It is however worth mentioning that
\citet{luedtke2016super} present three different approaches for learning the optimal
rule. Namely, they focus on:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Super Learning the Blip Function,
\item
  Super Learning the Weighted Classification Problem,
\item
  Joint Super Learner of the Blip and Weighted Classification Problem.
\end{enumerate}

We refer the interested reader to \citet{luedtke2016super} for further reference on
advantages of each approach.

Relying on the Targeted Maximum Likelihood (TML) estimator and the Super Learner
estimate of the blip function, we follow the below steps in order to obtain
value of the ITR:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Estimate \(\bar{Q}_{Y,0}(A,W)\) and \(g_0(A \mid W)\) using \passthrough{\lstinline!sl3!}. We denote such
  estimates as \(\bar{Q}_{Y,n}(A,W)\) and \(g_n(A \mid W)\).
\item
  Apply the doubly robust Augmented-Inverse Probability Weighted (A-IPW)
  transform to our outcome, where we define:
  \[D_{\bar{Q}_Y,g,a}(O) \equiv \frac{\mathbb{I}(A=a)}{g(A \mid W)} (Y -
  \bar{Q}_Y(A,W)) + \bar{Q}_Y(A=a,W)\]
\end{enumerate}

Note that under the randomization and positivity assumptions we have that
\(\E[D_{\bar{Q}_Y,g,a}(O) \mid V] = \E[Y_a \mid V]\). We emphasize the double
robust nature of the A-IPW transform-consistency of \(\E[Y_a \mid V]\) will depend
on correct estimation of either \(\bar{Q}_{Y,0}(A,W)\) or \(g_0(A \mid W)\). As
such, in a randomized trial, we are guaranteed a consistent estimate of \(\E[Y_a \mid V]\) even if we get \(\bar{Q}_{Y,0}(A,W)\) wrong!

Using this transform, we can define the following contrast:
\(D_{\bar{Q}_Y,g}(O) = D_{\bar{Q}_Y, g, a=1}(O) - D_{\bar{Q}_Y, g, a=0}(O)\)

We estimate the blip function, \(\bar{Q}_{0,a}(V)\), by regressing
\(D_{\bar{Q}_Y,g}(O)\) on \(V\) using the specified \passthrough{\lstinline!sl3!} library of learners and an
appropriate loss function.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Our estimated rule corresponds to \(\text{argmax}_{a \in \mathcal{A}} \bar{Q}_{0,a}(V)\).
\item
  We obtain inference for the mean outcome under the estimated optimal rule
  using CV-TMLE.
\end{enumerate}

\hypertarget{categorical-treatment}{%
\subsection{Categorical treatment}\label{categorical-treatment}}

In line with the approach considered for binary treatment, we extend the blip
function to allow for categorical treatment. We denote such blip function
extensions as \emph{pseudo-blips}, which are our new estimation targets in a
categorical setting. We define pseudo-blips as vector-valued entities where the
output for a given \(V\) is a vector of length equal to the number of treatment
categories, \(n_A\). As such, we define it as:
\[\bar{Q}_0^{pblip}(V) = \{\bar{Q}_{0,a}^{pblip}(V): a \in \mathcal{A} \}\]

We implement three different pseudo-blips in \passthrough{\lstinline!tmle3mopttx!}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{Blip1} corresponds to choosing a reference category of treatment, and
  defining the blip for all other categories relative to the specified
  reference. Hence we have that:
  \[\bar{Q}_{0,a}^{pblip-ref}(V) \equiv \E_0(Y_a-Y_0 \mid V)\] where \(Y_0\) is
  the specified reference category with \(A=0\). Note that, for the case of
  binary treatment, this strategy reduces to the approach described for the
  binary setup.
\item
  \emph{Blip2} approach corresponds to defining the blip relative to the average of
  all categories. As such, we can define \(\bar{Q}_{0,a}^{pblip-avg}(V)\) as:
  \[\bar{Q}_{0,a}^{pblip-avg}(V) \equiv \E_0(Y_a - \frac{1}{n_A} \sum_{a \in
    \mathcal{A}} Y_a \mid V)\]
  In the case where subject-matter knowledge regarding which reference category
  to use is not available, blip2 might be a viable option.
\item
  \emph{Blip3} reflects an extension of Blip2, where the average is now a weighted
  average:
  \[\bar{Q}_{0,a}^{pblip-wavg}(V) \equiv \E_0(Y_a - \frac{1}{n_A} \sum_{a \in
    \mathcal{A}} Y_{a} P(A=a \mid V) \mid V)\]
\end{enumerate}

Just like in the binary case, pseudo-blips are estimated by regressing contrasts
composed using the A-IPW transform on \(V\).

\hypertarget{note-on-inference-and-data-adaptive-parameter}{%
\subsection{Note on Inference and data-adaptive parameter}\label{note-on-inference-and-data-adaptive-parameter}}

In a randomized trial, statistical inference relies on the second-order
difference between the estimator of the optimal individualized treatment and the
optimal individualized treatment itself to be asymptotically negligible. This is
a reasonable condition if we consider rules that depend on a small number of
covariates, or if we are willing to make smoothness assumptions. Alternatively,
we can consider TMLEs and statistical inference for data-adaptive target
parameters defined in terms of an estimate of the optimal individualized
treatment. In particular, instead of trying to estimate the mean under the true
optimal individualized treatment, we aim to estimate the mean under the
estimated optimal individualized treatment. As such, we develop cross-validated
TMLE approach that provides asymptotic inference under minimal conditions for
the mean under the estimate of the optimal individualized treatment. In
particular, considering the data adaptive parameter allows us to avoid
consistency and rate condition for the fitted optimal rule, as required for
asymptotic linearity of the TMLE of the mean under the actual, true optimal
rule. Practically, the estimated (data-adaptive) rule should be preferred, as
this possibly sub-optimal rule is the one implemented in the population.

\hypertarget{why-cv-tmle}{%
\subsection{Why CV-TMLE?}\label{why-cv-tmle}}

As discussed in \citet{vanderLaanLuedtke15}, CV-TMLE is necessary as the
non-cross-validated TMLE is biased upward for the mean outcome under the rule,
and therefore overly optimistic. More generally however, using CV-TMLE allows us
more freedom in estimation and therefore greater data adaptivity, without
sacrificing inference.

\hypertarget{interpreting-the-causal-effect-of-an-optimal-individualized-intervention}{%
\section{Interpreting the Causal Effect of an Optimal Individualized Intervention}\label{interpreting-the-causal-effect-of-an-optimal-individualized-intervention}}

In summary, the mean outcome under the optimal individualized treatment is a
counterfactual quantity of interest representing what the mean outcome would
have been if everybody, contrary to the fact, received treatment that optimized
their outcome. The optimal individualized treatment regime is a rule that
optimizes the mean outcome under the dynamic treatment, where the candidate
rules are restricted to only respond to a user-supplied subset of the baseline
and intermediate covariates. In essence, our target parameter answers the key
aim of precision medicine: allocating the available treatment by tailoring it to
the individual characteristics of the patient, with the goal of optimizing the
final outcome.

\hypertarget{oit-eval-bin}{%
\section{Evaluating the Causal Effect of an OIT with Binary Treatment}\label{oit-eval-bin}}

Finally, we demonstrate how to evaluate the mean outcome under the optimal
individualized treatment using \passthrough{\lstinline!tmle3mopptx!}. To start, let's load the packages
we'll use and set a seed:

\begin{lstlisting}[language=R]
library(data.table)
library(sl3)
library(tmle3)
library(tmle3mopttx)
\end{lstlisting}

\hypertarget{simulated-data}{%
\subsection{Simulated Data}\label{simulated-data}}

First, we load the simulated data. We will start with the more general setup
where the treatment is a binary variable; later in the chapter we will consider
another data-generating distribution where \(A\) is categorical. In this example,
our data generating distribution is of the following form:
\begin{align*}
  W &\sim \mathcal{N}(\bf{0},I_{3 \times 3})\\
  \P(A=1 \mid W) &= \frac{1}{1+\exp^{(-0.8*W_1)}}\\
  \P(Y=1 \mid A,W) &= 0.5\text{logit}^{-1}[-5I(A=1)(W_1-0.5)+5I(A=0)(W_1-0.5)] +
     0.5\text{logit}^{-1}(W_2W_3)
\end{align*}

\begin{lstlisting}[language=R]
data("data_bin")
\end{lstlisting}

The above composes our observed data structure \(O = (W, A, Y)\). Note that the
mean under the true optimal rule is \(\psi=0.578\) for this data generating
distribution.

To formally express this fact using the \passthrough{\lstinline!tlverse!} grammar introduced by the
\passthrough{\lstinline!tmle3!} package, we create a single data object and specify the functional
relationships between the nodes in the \emph{directed acyclic graph} (DAG) via
\emph{nonparametric structural equation models} (NPSEMs), reflected in the node list
that we set up:

\begin{lstlisting}[language=R]
# organize data and nodes for tmle3
data <- data_bin
node_list <- list(
  W = c("W1", "W2", "W3"),
  A = "A",
  Y = "Y"
)
\end{lstlisting}

We now have an observed data structure (\passthrough{\lstinline!data!}) and a specification of the role
that each variable in the data set plays as the nodes in a DAG.

\hypertarget{constructing-optimal-stacked-regressions-with-sl3}{%
\subsection{\texorpdfstring{Constructing Optimal Stacked Regressions with \texttt{sl3}}{Constructing Optimal Stacked Regressions with sl3}}\label{constructing-optimal-stacked-regressions-with-sl3}}

To easily incorporate ensemble machine learning into the estimation procedure,
we rely on the facilities provided in the \href{https://tlverse.org/sl3}{\passthrough{\lstinline!sl3!} R
package}. Using the framework provided by the \href{https://tlverse.org/sl3}{\passthrough{\lstinline!sl3!}
package}, the nuisance parameters of the TML estimator
may be fit with ensemble learning, using the cross-validation framework of the
Super Learner algorithm of \citet{vdl2007super}.

\begin{lstlisting}[language=R]
# Define sl3 library and metalearners:
lrn_xgboost_50 <- Lrnr_xgboost$new(nrounds = 50)
lrn_xgboost_100 <- Lrnr_xgboost$new(nrounds = 100)
lrn_xgboost_300 <- Lrnr_xgboost$new(nrounds = 300)
lrn_mean <- Lrnr_mean$new()
lrn_glm <- Lrnr_glm_fast$new()

## Define the Q learner:
Q_learner <- Lrnr_sl$new(
  learners = list(
    lrn_xgboost_50, lrn_xgboost_100, lrn_xgboost_300, lrn_mean, lrn_glm
  ),
  metalearner = Lrnr_nnls$new()
)

## Define the g learner:
g_learner <- Lrnr_sl$new(
  learners = list(lrn_xgboost_100, lrn_glm),
  metalearner = Lrnr_nnls$new()
)

## Define the B learner:
b_learner <- Lrnr_sl$new(
  learners = list(
    lrn_xgboost_50, lrn_xgboost_100, lrn_xgboost_300, lrn_mean, lrn_glm
  ),
  metalearner = Lrnr_nnls$new()
)
\end{lstlisting}

As seen above, we generate three different ensemble learners that must be fit,
corresponding to the learners for the outcome regression (Q), propensity score
(g), and the blip function (B). We make the above explicit with respect to
standard notation by bundling the ensemble learners into a list object below:

\begin{lstlisting}[language=R]
# specify outcome and treatment regressions and create learner list
learner_list <- list(Y = Q_learner, A = g_learner, B = b_learner)
\end{lstlisting}

The \passthrough{\lstinline!learner\_list!} object above specifies the role that each of the ensemble
learners we've generated is to play in computing initial estimators. Recall that
we need initial estimators of relevant parts of the likelihood in order to
building a TMLE for the parameter of interest. In particular, \passthrough{\lstinline!learner\_list!}
makes explicit the fact that our \passthrough{\lstinline!Y!} is used in fitting the outcome regression,
while \passthrough{\lstinline!A!} is used in fitting the treatment mechanism regression, and finally \passthrough{\lstinline!B!}
is used in fitting the blip function.

\hypertarget{targeted-estimation-of-the-mean-under-the-optimal-individualized-interventions-effects}{%
\subsection{Targeted Estimation of the Mean under the Optimal Individualized Interventions Effects}\label{targeted-estimation-of-the-mean-under-the-optimal-individualized-interventions-effects}}

To start, we will initialize a specification for the TMLE of our parameter of
interest simply by calling \passthrough{\lstinline!tmle3\_mopttx\_blip\_revere!}. We specify the argument
\passthrough{\lstinline!V = c("W1", "W2", "W3")!} when initializing the \passthrough{\lstinline!tmle3\_Spec!} object in order to
communicate that we're interested in learning a rule dependent on \passthrough{\lstinline!V!}
covariates. Note that we don't have to specify \passthrough{\lstinline!V!}- this will result in a rule
that is not based on any collected covariates. We also need to specify the type
of pseudo-blip we will use in this estimation problem, the list of learners used
to estimate the blip function, whether we want to maximize or minimize the final
outcome, and few other more advanced features including searching for a less
complex rule and realistic interventions.

\begin{lstlisting}[language=R]
# initialize a tmle specification
tmle_spec <- tmle3_mopttx_blip_revere(
  V = c("W1", "W2", "W3"), type = "blip1",
  learners = learner_list,
  maximize = TRUE, complex = TRUE, realistic = FALSE
)
\end{lstlisting}

As seen above, the \passthrough{\lstinline!tmle3\_mopttx\_blip\_revere!} specification object
(like all \passthrough{\lstinline!tmle3\_Spec!} objects) does \emph{not} store the data for our
specific analysis of interest. Later,
we'll see that passing a data object directly to the \passthrough{\lstinline!tmle3!} wrapper function,
alongside the instantiated \passthrough{\lstinline!tmle\_spec!}, will serve to construct a \passthrough{\lstinline!tmle3\_Task!}
object internally.

We elaborate more on the initialization specifications. In initializing the
specification for the TMLE of our parameter of interest, we have specified the
set of covariates the rule depends on (\passthrough{\lstinline!V!}), the type of pseudo-blip to use
(\passthrough{\lstinline!type!}), and the learners used for estimating the relevant parts of the
likelihood and the blip function. In addition, we need to specify whether we
want to maximize the mean outcome under the rule (\passthrough{\lstinline!maximize!}), and whether we
want to estimate the rule under all the covariates \(V\) provided by the user
(\passthrough{\lstinline!complex!}). If \passthrough{\lstinline!FALSE!}, \passthrough{\lstinline!tmle3mopttx!} will instead consider all the possible
rules under a smaller set of covariates including the static rules, and optimize
the mean outcome over all the subsets of \(V\). As such, while the user might have
provided a full set of collected covariates as input for \(V\), it is possible
that the true rule only depends on a subset of the set provided by the user. In
that case, our returned mean under the optimal individualized rule will be based
on the smaller subset. In addition, we provide an option to search for realistic
optimal individualized interventions via the \passthrough{\lstinline!realistic!} specification. If
\passthrough{\lstinline!TRUE!}, only treatments supported by the data will be considered, therefore
alleviating concerns regarding practical positivity issues. We explore all the
important extensions of \passthrough{\lstinline!tmle3mopttx!} in later sections.

\begin{lstlisting}[language=R]
# fit the TML estimator
fit <- tmle3(tmle_spec, data, node_list, learner_list)
fit
A tmle3_Fit that took 1 step(s)
   type         param init_est tmle_est       se   lower   upper
1:  TSM E[Y_{A=NULL}]  0.42223  0.56606 0.027015 0.51311 0.61901
   psi_transformed lower_transformed upper_transformed
1:         0.56606           0.51311           0.61901
\end{lstlisting}

We can see that the estimate of \(psi_0\) is \(0.56\), and that the confidence
interval covers our true mean under the true optimal individualized treatment.

\hypertarget{oit-eval-cat}{%
\section{Evaluating the Causal Effect of an optimal ITR with Categorical Treatment}\label{oit-eval-cat}}

In this section, we consider how to evaluate the mean outcome under the optimal
individualized treatment when \(A\) has more than two categories. While the
procedure is analogous to the previously described binary treatment, we now need
to pay attention to the type of blip we define in the estimation stage, as well
as how we construct our learners.

\hypertarget{simulated-data-1}{%
\subsection{Simulated Data}\label{simulated-data-1}}

First, we load the simulated data. Here, our data generating distribution was
of the following form:
\begin{align*}
  W &\sim \mathcal{N}(\bf{0},I_{4 \times 4})\\
  \P(A=a \mid W) &= \frac{1}{1+\exp^{(-0.8*W_1)}}\\
  \P(Y=1 \mid A,W) = 0.5\text{logit}^{-1}[15I(A=1)(W_1-0.5) -
    3I(A=2)(2W_1+0.5) +
    3I(A=3)(3W_1-0.5)] +\text{logit}^{-1}(W_2W_1)
\end{align*}

We can just load the data available as part of the package as follows:

\begin{lstlisting}[language=R]
data("data_cat_realistic")
\end{lstlisting}

The above composes our observed data structure \(O = (W, A, Y)\). Note that the
mean under the true optimal rule is \(\psi=0.658\), which is the quantity we aim
to estimate.

\begin{lstlisting}[language=R]
# organize data and nodes for tmle3
data <- data_cat_realistic
node_list <- list(
  W = c("W1", "W2", "W3", "W4"),
  A = "A",
  Y = "Y"
)
\end{lstlisting}

We'll now create new ensemble learners using the
\passthrough{\lstinline!sl3!} learners initialized previously:

\begin{lstlisting}[language=R]
## Define the Q learner, which is just a regular learner:
Q_learner <- Lrnr_sl$new(
  learners = list(
    lrn_xgboost_50, lrn_xgboost_100, lrn_xgboost_300, lrn_mean, lrn_glm
  ),
  metalearner = Lrnr_nnls$new()
)

# Define the g learner, which is a multinomial learner:
# specify the appropriate loss of the multinomial learner:
mn_metalearner <- make_learner(Lrnr_solnp,
  loss_function = loss_loglik_multinomial,
  learner_function =
    metalearner_linear_multinomial
)
g_learner <- make_learner(
  Lrnr_sl,
  list(lrn_xgboost_100, lrn_xgboost_300, lrn_mean),
  mn_metalearner
)

# Define the Blip learner, which is a multivariate learner:
learners <- list(
  lrn_xgboost_50, lrn_xgboost_100, lrn_xgboost_300, lrn_mean, lrn_glm
)
b_learner <- create_mv_learners(learners = learners)
\end{lstlisting}

As seen above, we generate three different ensemble learners that must be fit,
corresponding to the learners for the outcome regression, propensity score, and
the blip function. Note that we need to estimate \(g_0(A \mid W)\) for a
categorical \(A\) -- therefore, we use the multinomial Super Learner option
available within the \passthrough{\lstinline!sl3!} package with learners that can address multi-class
classification problems. In order to see which learners can be used to estimate
\(g_0(A \mid W)\) in \passthrough{\lstinline!sl3!}, we run the following:

\begin{lstlisting}[language=R]
# See which learners support multi-class classification:
sl3_list_learners(c("categorical"))
 [1] "Lrnr_bound"                "Lrnr_caret"               
 [3] "Lrnr_cv_selector"          "Lrnr_glmnet"              
 [5] "Lrnr_grf"                  "Lrnr_gru_keras"           
 [7] "Lrnr_h2o_glm"              "Lrnr_h2o_grid"            
 [9] "Lrnr_independent_binomial" "Lrnr_lightgbm"            
[11] "Lrnr_lstm_keras"           "Lrnr_mean"                
[13] "Lrnr_multivariate"         "Lrnr_nnet"                
[15] "Lrnr_optim"                "Lrnr_polspline"           
[17] "Lrnr_pooled_hazards"       "Lrnr_randomForest"        
[19] "Lrnr_ranger"               "Lrnr_rpart"               
[21] "Lrnr_screener_correlation" "Lrnr_solnp"               
[23] "Lrnr_svm"                  "Lrnr_xgboost"             
\end{lstlisting}

Note that since the corresponding blip will be vector valued, we will have a
column for each additional level of treatment. As such, we need to create
multivariate learners with the helper function \passthrough{\lstinline!create\_mv\_learners!} that takes a
list of initialized learners as input.

We make the above explicit with respect to standard notation by bundling the
ensemble learners into a list object below:

\begin{lstlisting}[language=R]
# specify outcome and treatment regressions and create learner list
learner_list <- list(Y = Q_learner, A = g_learner, B = b_learner)
\end{lstlisting}

\hypertarget{targeted-estimation-of-the-mean-under-the-optimal-individualized-interventions-effects-1}{%
\subsection{Targeted Estimation of the Mean under the Optimal Individualized Interventions Effects}\label{targeted-estimation-of-the-mean-under-the-optimal-individualized-interventions-effects-1}}

\begin{lstlisting}[language=R]
# initialize a tmle specification
tmle_spec <- tmle3_mopttx_blip_revere(
  V = c("W1", "W2", "W3", "W4"), type = "blip2",
  learners = learner_list, maximize = TRUE, complex = TRUE,
  realistic = FALSE
)
\end{lstlisting}

\begin{lstlisting}[language=R]
# fit the TML estimator
fit <- tmle3(tmle_spec, data, node_list, learner_list)
fit
A tmle3_Fit that took 1 step(s)
   type         param init_est tmle_est       se   lower   upper
1:  TSM E[Y_{A=NULL}]  0.54435  0.61851 0.069083 0.48311 0.75391
   psi_transformed lower_transformed upper_transformed
1:         0.61851           0.48311           0.75391
\end{lstlisting}

We can see that the estimate of \(psi_0\) is \(0.60\), and that the confidence
interval covers our true mean under the true optimal individualized treatment.

\hypertarget{extensions-to-causal-effect-of-an-oit}{%
\section{Extensions to Causal Effect of an OIT}\label{extensions-to-causal-effect-of-an-oit}}

In this section, we consider two extensions to the procedure described for
estimating the value of the OIT. First one considers a setting where the user
might be interested in a grid of possible sub-optimal rules, corresponding to
potentially limited knowledge of potential effect modifiers. The second
extension concerns implementation of a realistic optimal individual
interventions where certain regimes might be preferred, but due to practical or
global positivity restraints are not realistic to implement.

\hypertarget{simpler-rules}{%
\subsection{Simpler Rules}\label{simpler-rules}}

In order to not only consider the most ambitious fully \(V\)-optimal rule, we
define \(S\)-optimal rules as the optimal rule that considers all possible subsets
of \(V\) covariates, with card(\(S\)) \(\leq\) card(\(V\)) and \(\emptyset \in S\). This
allows us to consider sub-optimal rules that are easier to estimate and
potentially provide more realistic rules- as such, we allow for statistical
inference for the counterfactual mean outcome under the sub-optimal rule.
Within the \passthrough{\lstinline!tmle3mopttx!} paradigm, we just need to change the \passthrough{\lstinline!complex!}
parameter to \passthrough{\lstinline!FALSE!}:

\begin{lstlisting}[language=R]
# initialize a tmle specification
tmle_spec <- tmle3_mopttx_blip_revere(
  V = c("W4", "W3", "W2", "W1"), type = "blip2",
  learners = learner_list,
  maximize = TRUE, complex = FALSE, realistic = FALSE
)
\end{lstlisting}

\begin{lstlisting}[language=R]
# fit the TML estimator
fit <- tmle3(tmle_spec, data, node_list, learner_list)
fit
A tmle3_Fit that took 1 step(s)
   type                param init_est tmle_est       se   lower   upper
1:  TSM E[Y_{d(V=W3,W2,W1)}]  0.54841  0.55108 0.062027 0.42951 0.67265
   psi_transformed lower_transformed upper_transformed
1:         0.55108           0.42951           0.67265
\end{lstlisting}

Therefore even though the user specified all baseline covariates as the basis
for rule estimation, a simpler rule based on only \(W_2\) and \(W_1\) is sufficient
to maximize the mean under the optimal individualized treatment.

\hypertarget{realistic-optimal-individual-regimes}{%
\subsection{Realistic Optimal Individual Regimes}\label{realistic-optimal-individual-regimes}}

In addition to considering less complex rules, \passthrough{\lstinline!tmle3mopttx!} also provides an
option to estimate the mean under the realistic, or implementable, optimal
individualized treatment. It is often the case that assigning particular regime
might have the ability to fully maximize (or minimize) the desired outcome, but
due to global or practical positivity constrains, such treatment can never be
implemented in real life (or is highly unlikely). As such, specifying
\passthrough{\lstinline!realistic!} to \passthrough{\lstinline!TRUE!}, we consider possibly suboptimal treatments that optimize
the outcome in question while being supported by the data.

\begin{lstlisting}[language=R]
# initialize a tmle specification
tmle_spec <- tmle3_mopttx_blip_revere(
  V = c("W4", "W3", "W2", "W1"), type = "blip2",
  learners = learner_list,
  maximize = TRUE, complex = TRUE, realistic = TRUE
)
\end{lstlisting}

\begin{lstlisting}[language=R]
# fit the TML estimator
fit <- tmle3(tmle_spec, data, node_list, learner_list)
fit
A tmle3_Fit that took 1 step(s)
   type         param init_est tmle_est       se   lower  upper psi_transformed
1:  TSM E[Y_{A=NULL}]  0.55355  0.65922 0.021419 0.61723 0.7012         0.65922
   lower_transformed upper_transformed
1:           0.61723            0.7012

# How many individuals got assigned each treatment?
table(tmle_spec$return_rule)

  2   3 
502 498 
\end{lstlisting}

\hypertarget{q-learning}{%
\subsection{Q-learning}\label{q-learning}}

Alternatively, we could estimate the mean under the optimal individualized
treatment using Q-learning. The optimal rule can be learned through fitting the
likelihood, and consequently estimating the optimal rule under this fit of the
likelihood \citep{Sutton1998, murphy2003}.

Below we outline how to use \passthrough{\lstinline!tmle3mopttx!} package in order to estimate the mean
under the ITR using Q-learning. As demonstrated in the previous sections, we
first need to initialize a specification for the TMLE of our parameter of
interest. As opposed to the previous section however, we will now use
\passthrough{\lstinline!tmle3\_mopttx\_Q!} instead of \passthrough{\lstinline!tmle3\_mopttx\_blip\_revere!} in order to indicate that
we want to use Q-learning instead of TMLE.

\begin{lstlisting}[language=R]
# initialize a tmle specification
tmle_spec_Q <- tmle3_mopttx_Q(maximize = TRUE)

# Define data:
tmle_task <- tmle_spec_Q$make_tmle_task(data, node_list)

# Define likelihood:
initial_likelihood <- tmle_spec_Q$make_initial_likelihood(
  tmle_task,
  learner_list
)

# Estimate the parameter:
Q_learning(tmle_spec_Q, initial_likelihood, tmle_task)[1]
\end{lstlisting}

\hypertarget{variable-importance-analysis-with-oit}{%
\section{Variable Importance Analysis with OIT}\label{variable-importance-analysis-with-oit}}

Suppose one wishes to assess the importance of each observed covariate, in
terms of maximizing (or minimizing) the population mean of an outcome under an
optimal individualized treatment regime. In particular, a covariate that
maximizes (or minimizes) the population mean outcome the most under an optimal
individualized treatment out of all other considered covariates under optimal
assignment might be considered \emph{more important} for the outcome. To put it in
context, perhaps optimal allocation of treatment 1, denoted \(A_1\), results in a
larger mean outcome than optimal allocation of another treatment (\(A_2\)).
Therefore, we would label \(A_1\) as having a higher variable importance with
regard to maximizing (minimizing) the mean outcome under the optimal
individualized treatment.

\hypertarget{simulated-data-2}{%
\subsection{Simulated Data}\label{simulated-data-2}}

In order to run \passthrough{\lstinline!tmle3mopttx!} variable importance measure, we need to consider
covariates to be categorical variables. For illustration purpose, we bin
baseline covariates corresponding to the data-generating distribution
\protect\hyperlink{oit-eval}{described previously}:

\begin{lstlisting}[language=R]
# bin baseline covariates to 3 categories:
data$W1 <- ifelse(data$W1 < quantile(data$W1)[2], 1,
  ifelse(data$W1 < quantile(data$W1)[3], 2, 3)
)

node_list <- list(
  W = c("W3", "W4", "W2"),
  A = c("W1", "A"),
  Y = "Y"
)
\end{lstlisting}

Note that our node list now includes \(W_1\) as treatments as well! Don't worry,
we will still properly adjust for all baseline covariates.

\hypertarget{variable-importance-using-targeted-estimation-of-the-value-of-the-itr}{%
\subsection{Variable Importance using Targeted Estimation of the value of the ITR}\label{variable-importance-using-targeted-estimation-of-the-value-of-the-itr}}

In the previous sections we have seen how to obtain a contrast between the mean
under the optimal individualized rule and the mean under the observed outcome
for a single covariate- we are now ready to run the variable importance analysis
for all of our specified covariates. In order to run the variable importance
analysis, we first need to initialize a specification for the TMLE of our
parameter of interest as we have done before. In addition, we need to specify
the data and the corresponding list of nodes, as well as the appropriate
learners for the outcome regression, propensity score, and the blip function.
Finally, we need to specify whether we should adjust for all the other
covariates we are assessing variable importance for. We will adjust for all \(W\)s
in our analysis, and if \passthrough{\lstinline!adjust\_for\_other\_A=TRUE!}, also for all \(A\) covariates
that are not treated as exposure in the variable importance loop.

To start, we will initialize a specification for the TMLE of our parameter of
interest (called a \passthrough{\lstinline!tmle3\_Spec!} in the \passthrough{\lstinline!tlverse!} nomenclature) simply by calling
\passthrough{\lstinline!tmle3\_mopttx\_vim!}. First, we indicate the method used for learning the optimal
individualized treatment by specifying the \passthrough{\lstinline!method!} argument of
\passthrough{\lstinline!tmle3\_mopttx\_vim!}. If \passthrough{\lstinline!method="Q"!}, then we will be using Q-learning for rule
estimation, and we do not need to specify \passthrough{\lstinline!V!}, \passthrough{\lstinline!type!} and \passthrough{\lstinline!learners!} arguments
in the spec, since they are not important for Q-learning. However, if
\passthrough{\lstinline!method="SL"!}, which corresponds to learning the optimal individualized
treatment using the above outlined methodology, then we need to specify the type
of pseudo-blip we will use in this estimation problem, whether we want to
maximize or minimize the outcome, complex and realistic rules. Finally, for
\passthrough{\lstinline!method="SL"!} we also need to communicate that we're interested in learning a
rule dependent on \passthrough{\lstinline!V!} covariates by specifying the \passthrough{\lstinline!V!} argument. For both
\passthrough{\lstinline!method="Q"!} and \passthrough{\lstinline!method="SL"!}, we need to indicate whether we want to maximize
or minimize the mean under the optimal individualized rule. Finally, we also
need to specify whether the final comparison of the mean under the optimal
individualized rule and the mean under the observed outcome should be on the
multiplicative scale (risk ratio) or linear (similar to average treatment
effect).

\begin{lstlisting}[language=R]
# initialize a tmle specification
tmle_spec <- tmle3_mopttx_vim(
  V = c("W2"),
  type = "blip2",
  learners = learner_list,
  contrast = "multiplicative",
  maximize = FALSE,
  method = "SL",
  complex = TRUE,
  realistic = FALSE
)
\end{lstlisting}

\begin{lstlisting}[language=R]
# fit the TML estimator
vim_results <- tmle3_vim(tmle_spec, data, node_list, learner_list,
  adjust_for_other_A = TRUE
)
print(vim_results)
\end{lstlisting}

The final result of \passthrough{\lstinline!tmle3\_vim!} with the \passthrough{\lstinline!tmle3mopttx!} spec is an ordered list
of mean outcomes under the optimal individualized treatment for all categorical
covariates in our dataset.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{exercises-2}{%
\section{Exercises}\label{exercises-2}}

\hypertarget{real-world-data-and-tmle3mopttx}{%
\subsection{\texorpdfstring{Real World Data and \texttt{tmle3mopttx}}{Real World Data and tmle3mopttx}}\label{real-world-data-and-tmle3mopttx}}

Finally, we cement everything we learned so far with a real data application.

As in the previous sections, we will be using the WASH Benefits data,
corresponding to the effect of water quality, sanitation, hand washing, and
nutritional interventions on child development in rural Bangladesh.

The main aim of the cluster-randomized controlled trial was to assess the
impact of six intervention groups, including:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  control;
\item
  hand-washing with soap;
\item
  improved nutrition through counseling and provision of lipid-based nutrient
  supplements;
\item
  combined water, sanitation, hand-washing, and nutrition;
\item
  improved sanitation;
\item
  combined water, sanitation, and hand-washing;
\item
  chlorinated drinking water.
\end{enumerate}

We aim to estimate the optimal ITR and the corresponding value under the optimal
ITR for the main intervention in WASH Benefits data.

Our outcome of interest is the weight-for-height Z-score, whereas our primary
treatment is the six intervention groups aimed at improving living conditions.

Questions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Define \(V\) as mother's education (\passthrough{\lstinline!momedu!}), current living conditions (\passthrough{\lstinline!floor!}),
  and possession of material items including the refrigerator (\passthrough{\lstinline!asset\_refrig!}).
  Why do you think we use these covariates as \(V\)? Do we want to minimize or
  maximize the outcome? Which blip type should we use?
\item
  Load the WASH Benefits data, and define the appropriate nodes for treatment
  and outcome. Use all the rest of the covariates as \(W\) except for
  \passthrough{\lstinline!momheight!} for now. Construct an appropriate \passthrough{\lstinline!sl3!} library for \(A\), \(Y\) and
  \(B\).
\item
  Based on the \(V\) defined in the previous question, estimate the mean under
  the ITR for the main randomized intervention used in the WASH Benefits trial
  with weight-for-height Z-score as the outcome. What's the TMLE value of the
  optimal ITR? How does it change from the initial estimate? Which
  intervention is the most dominant? Why do you think that is?
\item
  Using the same formulation as in questions 1 and 2, estimate the realistic
  optimal ITR and the corresponding value of the realistic ITR. Did the results
  change? Which intervention is the most dominant under realistic rules? Why do
  you think that is?
\item
  Consider simpler rules for the WASH benefits data example. What set of rules
  are picked?
\item
  Change the treatment to a binary variable (\passthrough{\lstinline!asset\_sewmach!}), and estimate the
  value under the ITR in this setting under a \(60\%\) resource constraint. What
  do the results indicate?
\item
  Change the treatment once again, now to mother's education (\passthrough{\lstinline!momedu!}), and
  estimate the value under the ITR in this setting. What do the results
  indicate? Can we intervene on such a variable?
\end{enumerate}

\hypertarget{review-of-key-concepts-1}{%
\subsection{Review of Key Concepts}\label{review-of-key-concepts-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  What is the difference between dynamic and optimal individualized regimes?
\item
  What's the intuition behind using different blip types? Why did we switch
  from \passthrough{\lstinline!blip1!} to \passthrough{\lstinline!blip2!} when considering categorical treatment? What are some
  of the advantages of each?
\item
  Look back at the results generated in the \protect\hyperlink{oit-eval-cat}{section on categorical
  treatments}, and compare then to the mean under the optimal
  individualized treatment in the \protect\hyperlink{oit-eval-bin}{section on binary
  treatments}. Why do you think the estimate is higher under the
  less complex rule? How does the set of covariates picked by \passthrough{\lstinline!tmle3mopttx!}
  compare to the baseline covariates the true rule depends on?
\item
  Compare the distribution of treatments assigned under the true optimal
  individualized treatment and realistic optimal individualized treatment.
  Referring back to the data-generating distribution, why do you think the
  distribution of allocated treatment changed?
\item
  Using the same simulation, perform a variable importance analysis using
  Q-learning. How do the results change and why?
\end{enumerate}

\hypertarget{advanced-topics-1}{%
\subsection{Advanced Topics}\label{advanced-topics-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  How can we extend the current approach to include exceptional laws?
\item
  How can we extend the current approach to continuous interventions?
\end{enumerate}

\hypertarget{stochastic-treatment-regimes}{%
\chapter{Stochastic Treatment Regimes}\label{stochastic-treatment-regimes}}

\emph{Nima Hejazi}

Based on the \href{https://github.com/tlverse/tmle3shift}{\passthrough{\lstinline!tmle3shift!} \passthrough{\lstinline!R!} package}
by \emph{Nima Hejazi, Jeremy Coyle, and Mark van der Laan}.

Updated: 2021-04-28

\hypertarget{learning-objectives-5}{%
\section{Learning Objectives}\label{learning-objectives-5}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Differentiate stochastic treatment regimes from static, dynamic, and optimal
  treatment regimes.
\item
  Describe how estimating causal effects of stochastic interventions informs a
  real-world data analysis.
\item
  Contrast a population level stochastic intervention policy from a modified
  treatment policy.
\item
  Estimate causal effects under stochastic treatment regimes with the
  \passthrough{\lstinline!tmle3shift!} \passthrough{\lstinline!R!} package.
\item
  Specify a grid of counterfactual shift interventions to be used for defining
  a set of stochastic intervention policies.
\item
  Interpret a set of effect estimates from a grid of counterfactual shift
  interventions.
\item
  Construct marginal structural models to measure variable importance in terms
  of stochastic interventions, using a grid of shift interventions.
\item
  Implement a shift intervention at the individual level, to facilitate
  shifting each individual to a value that's supported by the data.
\item
  Define novel shift intervention functions to extend the \passthrough{\lstinline!tmle3shift!} \passthrough{\lstinline!R!}
  package.
\end{enumerate}

\hypertarget{introduction-to-stochastic-interventions}{%
\section{Introduction to Stochastic Interventions}\label{introduction-to-stochastic-interventions}}

Stochastic treatment regimes present a relatively simple, yet extremely flexible
manner by which \emph{realistic} causal effects (and contrasts thereof) may be
defined. Importantly, stochastic treatment regimes may be applied to nearly
any manner of treatment variable -- continuous, ordinal, categorical, binary --
allowing for a rich set of causal effects to be defined through this formalism.
In this chapter, we examine a simple example of stochastic treatment regimes in
the context of a continuous treatment variable of interest, defining an
intuitive causal effect through which to examine stochastic interventions more
generally. In later sections, we introduce numerous extensions based on this
broad class of interventions -- from stochastic interventions on binary
treatment variables to stochastic mediation effects and data-adaptive inference
for stochastic intervention effects. As a first step to using stochastic
treatment regimes in practice, we present the \href{https://github.com/tlverse/tmle3shift}{\passthrough{\lstinline!tmle3shift!} R
package}, which features an
implementation of a recently developed algorithm for computing targeted minimum
loss-based estimates of a causal effect based on a stochastic treatment regime
that shifts the natural value of the treatment based on a shifting function
\(d(A,W)\). For a comprehensive technical presentation of some of the material in
this chapter, the interested reader is invited to consult \citet{diaz2018stochastic}.
Additional background on the field of Targeted Learning, as well as prior work
on stochastic treatment regimes, is available in \citet{vdl2011targeted},
\citet{vdl2018targeted}, and \citet{diaz2012population}.

While stochastic treatment regimes are arguably the most general of the
classes of interventions through which causal effects may be defined, such
interventions are conceptually simple.

\hypertarget{data-structure-and-notation-1}{%
\section{Data Structure and Notation}\label{data-structure-and-notation-1}}

Consider \(n\) observed units \(O_1, \ldots, O_n\), where each random variable \(O = (W, A, Y)\) corresponds to a single observational unit. Let \(W\) denote baseline
covariates (e.g., age, sex, education level), \(A\) an intervention variable of
interest (e.g., nutritional supplements), and \(Y\) an outcome of interest (e.g.,
disease status). Though it need not be the case, let \(A\) be continuous-valued,
i.e. \(A \in \R\). Let \(O_i \sim \mathcal{P} \in \M\), where \(\M\) is the
nonparametric statistical model defined as the set of continuous densities on
\(O\) with respect to some dominating measure. To formalize the definition of
stochastic interventions and their corresponding causal effects, we introduce a
nonparametric structural equation model (NPSEM), based on \citet{pearl2009causality},
to define how the system changes under posited interventions:
\begin{align}
  W &= f_W(U_W) \\ A &= f_A(W, U_A) \\ Y &= f_Y(A, W, U_Y),
  \label{eq:npsem-shift}
\end{align}
where the set of structural equations provide a mechanistic model by which the
observed data \(O\) is assumed to have been generated. There are several standard
assumptions embedded in the NPSEM -- specifically, a temporal ordering that
supposes that \(Y\) occurs after \(A\), which occurs after \(W\); each variable (i.e.,
\(\{W, A, Y\}\)) is assumed to have been generated from its corresponding
deterministic function (i.e., \(\{f_W, f_A, f_Y\}\)) of the observed variables
that precede it temporally, as well as an exogenous variable, denoted by \(U\);
lastly, each exogenous variable is assumed to contain all unobserved causes of
the corresponding observed variable.

The likelihood of the data \(O\) admits a factorization, wherein, for \(p_0^O\),
the density of \(O\) with respect to the product measure, the density evaluated
on a particular observation \(o\) may be a written
\begin{equation}
  p_0^O(x) = q^O_{0,Y}(y \mid A = a, W = w) q^O_{0,A}(a \mid W = w)
  q^O_{0,W}(w),
  \label{eq:likelihood-factorization-shift}
\end{equation}
where \(q_{0, Y}\) is the conditional density of \(Y\) given \((A, W)\) with respect
to some dominating measure, \(q_{0, A}\) is the conditional density of \(A\) given
\(W\) with respect to dominating measure \(\mu\), and \(q_{0, W}\) is the density of
\(W\) with respect to dominating measure \(\nu\). Further, for ease of notation, let
\(Q(A, W) = \E[Y \mid A, W]\), \(g(A \mid W) = \P(A \mid W)\), and \(q_W\) the
marginal distribution of \(W\). These components of the likelihood will be
essential in developing an understanding of the manner in which stochastic
treatment regimes perturb a system and how a corresponding causal effect may be
evaluated. Importantly, the NPSEM parameterizes \(p_0^O\) in terms of the
distribution of random variables \((O, U)\) modeled by the system of equations. In
turn, this implies a model for the distribution of counterfactual random
variables generated by interventions on the data-generating process.

\hypertarget{defining-the-causal-effect-of-a-stochastic-intervention}{%
\section{Defining the Causal Effect of a Stochastic Intervention}\label{defining-the-causal-effect-of-a-stochastic-intervention}}

As causal effects are defined in terms of hypothetical interventions on the
NPSEM \eqref{eq:npsem-shift}, we may consider stochastic interventions in two
equivalent ways: (1) where the equation \(f_A\), giving rise to \(A\), is replaced
by a probabilistic mechanism \(g_{\delta}(A \mid W)\) that differs from the
original \(g(A \mid W)\), or (2) where the observed value \(A\) is replaced by a
new value \(A_{d(A,W)}\) based on applying a user-defined function \(d(A,W)\) to
\(A\). In the former case, the \emph{stochastically modified} value of the treatment
\(A_{\delta}\) is drawn from a user-specified distribution \(g_\delta(A \mid W)\),
which may depend on the original distribution \(g(A \mid W)\) and is indexed by
a user-specified parameter \(\delta\). In this case, the stochastically modified
value of the treatment \(A_{\delta} \sim g_{\delta}(\cdot \mid W)\).
Alternatively, in the latter case, the stochastic treatment regime may be
viewed as an intervention in which \(A\) is set equal to a value based on a
hypothetical regime \(d(A, W)\), where regime \(d\) depends on the treatment level
\(A\) that would be assigned in the absence of the regime as well as the
covariates \(W\). In either case, one may view the stochastic intervention as
generating a counterfactual random variable \(Y_{d(A,W)} := f_Y(d(A,W), W, U_Y) \equiv Y_{g_{\delta}} := f_Y(A_{\delta}, W, U_Y)\), where the counterfactual
outcome \(Y_{d(A,W)} \sim \mathcal{P}_0^{\delta}\).

Stochastic interventions of this second variety may be referred to as depending
on the \emph{natural value of treatment} or as \emph{modified treatment policies}.
\citet{haneuse2013estimation} and \citet{young2014identification} provide a discussion of the
critical differences and similarities in the identification and interpretation
of these two classes of stochastic intervention. In the sequel, we will
restrict our attention to a simple stochastic treatment regime that has been
characterized as a \emph{modified treatment policy} (MTP). Letting \(A\) denote a
continuous-valued treatment, such as the taking of nutritional supplements
(e.g., number of vitamin pills) and assume that the distribution of \(A\)
conditional on \(W = w\) has support in the interval \((l(w), u(w))\). That is, the
minimum observed number of pills taken \(A\) for an individual with covariates
\(W = w\) is \(l(w)\); similarly, the maximum is \(u(w)\). Then, a simple stochastic
intervention, based on a shift \(\delta\), may be defined
\begin{equation}
  d(a, w) =
  \begin{cases}
    a - \delta & \text{if } a > l(w) + \delta \\
    a & \text{if } a \leq l(w) + \delta,
  \end{cases}
  \label{eq:shift}
\end{equation}
where \(0 \leq \delta \leq u(w)\) is an arbitrary pre-specified value that
defines the degree to which the observed value \(A\) is to be shifted, where
possible. Such a stochastic treatment regime may be interpreted as the result
of a clinic policy that encourages individuals to consume \(\delta\) more vitamin
pills than they would normally, i.e., based on their baseline characteristics.
The interpretation of this stochastic intervention may be made more interesting
by allowing the modification \(\delta\) that it engenders to be a function of the
baseline covariates \(W\), thereby allowing for the number of vitamin pills taken
to be a function of covariates such as age, sex, comorbidities, etc. This class
of stochastic interventions was first introduced by \citet{diaz2012population} and has
been further discussed in \citet{haneuse2013estimation}, \citet{diaz2018stochastic}, and
\citet{hejazi2020efficient}. Note that this intervention may be written in a manner
consistent with the first class of stochastic treatment regimes discussed as
well -- that is, as per \citet{diaz2012population}, \(\P_{\delta}(g_0)(A = a \mid W) = g_0(a - \delta(W) \mid W)\).

The goal of any causal analysis motivated by such a stochastic intervention is
to estimate a parameter defined as the counterfactual mean of the outcome with
respect to the stochastically modified intervention distribution. In
particular, the target causal estimand of our analysis is \(\psi_{0, \delta} \coloneqq \E_{P_0^{\delta}}\{Y_{d(A,W)}\}\), the mean of the counterfactual
outcome variable \(Y_{d(A, W)}\). In prior work, \citet{diaz2012population} showed that
the causal quantity of interest \(\E_0 \{Y_{d(A, W)}\}\) is identified by
a functional of the distribution of \(O\):
\begin{align}
  \psi_{0,d} = \int_{\mathcal{W}} \int_{\mathcal{A}} & \E_{P_0}
   \{Y \mid A = d(a, w), W = w\} \cdot \\ &q_{0, A}^O(a \mid W = w) \cdot
   q_{0, W}^O(w) d\mu(a)d\nu(w).
  \label{eq:identification2012}
\end{align}
If the identification conditions may be assumed to hold, then the statistical
parameter in \eqref{eq:identification2012} matches exactly the counterfactual
outcome \(\psi_{0, \delta}\) under such an intervention, allowing for the causal
effect to be learned from the observed data \(O\). \citet{diaz2012population} provide a
derivation based on the efficient influence function (EIF) in the nonparametric
model \(\M\) and develop several estimators of this quantity, including
substitution, inverse probability weighted (IPW), one-step (OS) and targeted
maximum likelihood (TML) estimators, allowing for semiparametric-efficient
estimation and inference on the quantity of interest. As per
\citet{diaz2018stochastic}, the statistical target parameter may also be denoted
\(\Psi(P_0) = \E_{P_0}{\overline{Q}(d(A, W), W)}\), where \(\overline{Q}(d(A, W), W)\) is the counterfactual outcome value of a given individual under the
stochastic intervention distribution.

Although the focus of this work is neither the establishment of identification
results nor the development of theoretical details, we review the necessary
identification details for the counterfactual mean under a stochastic
intervention here, in the interest of completeness. Paraphrasing from
\citet{diaz2012population} and \citet{diaz2018stochastic}, four standard assumptions are
necessary in order to establish identifiability of the causal parameter from
the observed data via the statistical functional -- these are

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{Consistency}: \(Y^{d(a_i, w_i)}_i = Y_i\) in the event \(A_i = d(a_i, w_i)\),
  for \(i = 1, \ldots, n\)
\item
  \emph{Stable unit value treatment assumption (SUTVA)}: \(Y^{d(a_i, w_i)}_i\) does
  not depend on \(d(a_j, w_j)\) for \(i = 1, \ldots, n\) and \(j \neq i\), or lack
  of interference \citep{rubin1978bayesian, rubin1980randomization}.
\item
  \emph{Strong ignorability}: \(A_i \indep Y^{d(a_i, w_i)}_i \mid W_i\), for \(i = 1, \ldots, n\).
\item
  \emph{Positivity (or overlap)}: \(a_i \in \mathcal{A} \implies d(a_i, w_i) \in \mathcal{A}\) for all \(w \in \mathcal{W}\), where \(\mathcal{A}\) denotes the
  support of \(A \mid W = w_i \quad \forall i = 1, \ldots n\).
\end{enumerate}

With the identification assumptions satisfied, \citet{diaz2012population} and
\citet{diaz2018stochastic} provide an efficient influence function with respect to
the nonparametric model \(\M\) as
\begin{equation}
  D(P_0)(x) = H(a, w)({y - \overline{Q}(a, w)}) +
  \overline{Q}(d(a, w), w) - \Psi(P_0),
  \label{eq:eif-shift}
\end{equation}
where the auxiliary covariate \(H(a,w)\) may be expressed
\begin{equation}
  H(a,w) = \mathbb{I}(a + \delta < u(w)) \frac{g_0(a - \delta \mid w)}
  {g_0(a \mid w)} + \mathbb{I}(a + \delta \geq u(w)),
  \label{eq:aux-covar-full-shift}
\end{equation}
which may be reduced to
\begin{equation}
  H(a,w) = \frac{g_0(a - \delta \mid w)}{g_0(a \mid w)} + 1
  \label{eq:aux-covar-simple-shift}
\end{equation}
in the case that the treatment is within the limits that arise from conditioning
on \(W\), i.e., for \(A_i \in (u(w) - \delta, u(w))\).

The efficient influence function allows the construction of a
semiparametric-efficient estimators may be constructed. In the sequel, we focus
on a targeted maximum likelihood (TML) estimator, for which \citet{diaz2018stochastic}
give a recipe:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Construct initial estimators \(g_n\) of \(g_0(A, W)\) and \(Q_n\) of
  \(\overline{Q}_0(A, W)\), perhaps using data-adaptive regression techniques.
\item
  For each observation \(i\), compute an estimate \(H_n(a_i, w_i)\) of the
  auxiliary covariate \(H(a_i,w_i)\).
\item
  Estimate the parameter \(\epsilon\) in the logistic regression model
  \[ \text{logit}\overline{Q}_{\epsilon, n}(a, w) =
  \text{logit}\overline{Q}_n(a, w) + \epsilon H_n(a, w),\]
  or an alternative regression model incorporating weights.
\item
  Compute TML estimator \(\Psi_n\) of the target parameter, defining update
  \(\overline{Q}_n^{\star}\) of the initial estimate
  \(\overline{Q}_{n, \epsilon_n}\):
  \begin{equation}
    \Psi_n = \Psi(P_n^{\star}) = \frac{1}{n} \sum_{i = 1}^n
    \overline{Q}_n^{\star}(d(A_i, W_i), W_i).
    \label{eq:tmle}
  \end{equation}
\end{enumerate}

\hypertarget{evaluating-the-causal-effect-of-a-stochastic-intervention}{%
\section{Evaluating the Causal Effect of a Stochastic Intervention}\label{evaluating-the-causal-effect-of-a-stochastic-intervention}}

To start, let's load the packages we'll be using throughout our simple data example

\begin{lstlisting}[language=R]
library(data.table)
library(haldensify)
library(sl3)
library(tmle3)
library(tmle3shift)
\end{lstlisting}

We need to estimate two components of the likelihood in order to construct a TML
estimator. The first of these components is the outcome regression, \(\hat{Q}_n\),
which is a simple regression of the form \(\E[Y \mid A,W]\). An estimate
for such a quantity may be constructed using the Super Learner algorithm. We
construct the components of an \passthrough{\lstinline!sl3!}-style Super Learner for a regression below,
using a small variety of parametric and nonparametric regression techniques:

\begin{lstlisting}[language=R]
# learners used for conditional mean of the outcome
mean_lrnr <- Lrnr_mean$new()
fglm_lrnr <- Lrnr_glm_fast$new()
rf_lrnr <- Lrnr_ranger$new()
hal_lrnr <- Lrnr_hal9001$new(max_degree = 3, n_folds = 3)

# SL for the outcome regression
sl_reg_lrnr <- Lrnr_sl$new(
  learners = list(mean_lrnr, fglm_lrnr, rf_lrnr, hal_lrnr),
  metalearner = Lrnr_nnls$new()
)
\end{lstlisting}

The second of these is an estimate of the treatment mechanism, \(\hat{g}_n\),
i.e., the \emph{propensity score}. In the case of a continuous intervention node \(A\),
such a quantity takes the form \(p(A \mid W)\), which is a conditional density.
Generally speaking, conditional density estimation is a challenging problem that
has received much attention in the literature. To estimate the treatment
mechanism, we must make use of learning algorithms specifically suited to
conditional density estimation; a list of such learners may be extracted from
\passthrough{\lstinline!sl3!} by using \passthrough{\lstinline!sl3\_list\_learners()!}:

\begin{lstlisting}[language=R]
sl3_list_learners("density")
[1] "Lrnr_density_discretize"     "Lrnr_density_hse"           
[3] "Lrnr_density_semiparametric" "Lrnr_haldensify"            
[5] "Lrnr_solnp_density"         
\end{lstlisting}

To proceed, we'll select two of the above learners, \passthrough{\lstinline!Lrnr\_haldensify!} for using
the highly adaptive lasso for conditional density estimation, based on an
algorithm given by \citet{diaz2011super} and implemented in \citet{hejazi2020haldensify}, and
semiparametric location-scale conditional density estimators implemented in the
\href{https://github.com/tlverse/sl3}{\passthrough{\lstinline!sl3!} package}. A Super Learner may be
constructed by pooling estimates from each of these modified conditional density
regression techniques (note that we exclude the approach based on the
\passthrough{\lstinline!haldensify!} learner from our Super Learner on account of the computationally
intensive nature of the approach).

\begin{lstlisting}[language=R]
# learners used for conditional densities (i.e., generalized propensity score)
haldensify_lrnr <- Lrnr_haldensify$new(
  n_bins = c(5, 10, 20),
  lambda_seq = exp(seq(-1, -10, length = 200))
)
# semiparametric density estimator based on homoscedastic errors (HOSE)
hose_hal_lrnr <- make_learner(Lrnr_density_semiparametric,
  mean_learner = hal_lrnr
)
# semiparametric density estimator based on heteroscedastic errors (HESE)
hese_rf_glm_lrnr <- make_learner(Lrnr_density_semiparametric,
  mean_learner = rf_lrnr,
  var_learner = fglm_lrnr
)

# SL for the conditional treatment density
sl_dens_lrnr <- Lrnr_sl$new(
  learners = list(hose_hal_lrnr, hese_rf_glm_lrnr),
  metalearner = Lrnr_solnp_density$new()
)
\end{lstlisting}

Finally, we construct a \passthrough{\lstinline!learner\_list!} object for use in constructing a TML
estimator of our target parameter of interest:

\begin{lstlisting}[language=R]
learner_list <- list(Y = sl_reg_lrnr, A = sl_dens_lrnr)
\end{lstlisting}

The \passthrough{\lstinline!learner\_list!} object above specifies the role that each of the ensemble
learners we have generated is to play in computing initial estimators to be
used in building a TMLE for the parameter of interest here. In particular, it
makes explicit the fact that our \passthrough{\lstinline!Q\_learner!} is used in fitting the outcome
regression while our \passthrough{\lstinline!g\_learner!} is used in estimating the treatment mechanism.

\hypertarget{example-with-simulated-data}{%
\subsection{Example with Simulated Data}\label{example-with-simulated-data}}

\begin{lstlisting}[language=R]
# simulate simple data for tmle-shift sketch
n_obs <- 400 # number of observations
tx_mult <- 2 # multiplier for the effect of W = 1 on the treatment

## baseline covariates -- simple, binary
W <- replicate(2, rbinom(n_obs, 1, 0.5))

## create treatment based on baseline W
A <- rnorm(n_obs, mean = tx_mult * W, sd = 1)

## create outcome as a linear function of A, W + white noise
Y <- rbinom(n_obs, 1, prob = plogis(A + W))

# organize data and nodes for tmle3
data <- data.table(W, A, Y)
setnames(data, c("W1", "W2", "A", "Y"))
node_list <- list(
  W = c("W1", "W2"),
  A = "A",
  Y = "Y"
)
head(data)
   W1 W2         A Y
1:  1  1  0.271651 1
2:  0  0 -0.663368 1
3:  0  0  0.113366 0
4:  0  1 -0.732558 0
5:  1  1  0.388835 1
6:  0  0  0.043986 0
\end{lstlisting}

The above composes our observed data structure \(O = (W, A, Y)\). To formally
express this fact using the \passthrough{\lstinline!tlverse!} grammar introduced by the \passthrough{\lstinline!tmle3!} package,
we create a single data object and specify the functional relationships between
the nodes in the \emph{directed acyclic graph} (DAG) via \emph{nonparametric structural
equation models} (NPSEMs), reflected in the node list that we set up:

We now have an observed data structure (\passthrough{\lstinline!data!}) and a specification of the role
that each variable in the data set plays as the nodes in a DAG.

To start, we will initialize a specification for the TMLE of our parameter of
interest (called a \passthrough{\lstinline!tmle3\_Spec!} in the \passthrough{\lstinline!tlverse!} nomenclature) simply by calling
\passthrough{\lstinline!tmle\_shift!}. We specify the argument \passthrough{\lstinline!shift\_val = 0.5!} when initializing the
\passthrough{\lstinline!tmle3\_Spec!} object to communicate that we're interested in a shift of \(0.5\) on
the scale of the treatment \(A\) -- that is, we specify \(\delta = 0.5\) (note that
this is an arbitrarily chosen value for this example).

\begin{lstlisting}[language=R]
# initialize a tmle specification
tmle_spec <- tmle_shift(
  shift_val = 0.5,
  shift_fxn = shift_additive,
  shift_fxn_inv = shift_additive_inv
)
\end{lstlisting}

As seen above, the \passthrough{\lstinline!tmle\_shift!} specification object (like all \passthrough{\lstinline!tmle3\_Spec!}
objects) does \emph{not} store the data for our specific analysis of interest. Later,
we'll see that passing a data object directly to the \passthrough{\lstinline!tmle3!} wrapper function,
alongside the instantiated \passthrough{\lstinline!tmle\_spec!}, will serve to construct a \passthrough{\lstinline!tmle3\_Task!}
object internally (see the \passthrough{\lstinline!tmle3!} documentation for details).

\hypertarget{targeted-estimation-of-stochastic-interventions-effects}{%
\subsection{Targeted Estimation of Stochastic Interventions Effects}\label{targeted-estimation-of-stochastic-interventions-effects}}

\begin{lstlisting}[language=R]
tmle_fit <- tmle3(tmle_spec, data, node_list, learner_list)

Iter: 1 fn: 547.5482     Pars:  0.999997601 0.000002399
Iter: 2 fn: 547.5482     Pars:  0.9999991325 0.0000008675
solnp--> Completed in 2 iterations
tmle_fit
A tmle3_Fit that took 1 step(s)
   type         param init_est tmle_est       se   lower  upper psi_transformed
1:  TSM E[Y_{A=NULL}]  0.76373  0.75992 0.022795 0.71524 0.8046         0.75992
   lower_transformed upper_transformed
1:           0.71524            0.8046
\end{lstlisting}

The \passthrough{\lstinline!print!} method of the resultant \passthrough{\lstinline!tmle\_fit!} object conveniently displays the
results from computing our TML estimator.

\hypertarget{statistical-inference-for-targeted-maximum-likelihood-estimates}{%
\subsection{Statistical Inference for Targeted Maximum Likelihood Estimates}\label{statistical-inference-for-targeted-maximum-likelihood-estimates}}

Recall that the asymptotic distribution of TML estimators has been studied
thoroughly:
\[\psi_n - \psi_0 = (P_n - P_0) \cdot D(\bar{Q}_n^{\star}, g_n) +
R(\hat{P}^{\star}, P_0),\]
which, provided the following two conditions,

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  If \(D(\bar{Q}_n^{\star}, g_n)\) converges to \(D(P_0)\) in \(L_2(P_0)\) norm, and
\item
  the size of the class of functions considered for estimation of
  \(\bar{Q}_n^{\star}\) and \(g_n\) is bounded (technically, \(\exists \mathcal{F}\)
  such that \(D(\bar{Q}_n^{\star}, g_n) \in \mathcal{F}\) \emph{whp}, where
  \(\mathcal{F}\) is a Donsker class),
  readily admits the conclusion that
  \(\psi_n - \psi_0 = (P_n - P_0) \cdot D(P_0) + R(\hat{P}^{\star}, P_0)\).
\end{enumerate}

Under the additional condition that the remainder term \(R(\hat{P}^{\star}, P_0)\)
decays as \(o_P \left( \frac{1}{\sqrt{n}} \right),\) we have that
\[\psi_n - \psi_0 = (P_n - P_0) \cdot D(P_0) + o_P \left( \frac{1}{\sqrt{n}}
\right),\]
which, by a central limit theorem, establishes a Gaussian limiting distribution
for the estimator:

\[\sqrt{n}(\psi_n - \psi) \to N(0, V(D(P_0))),\]
where \(V(D(P_0))\) is the variance of the efficient influence curve (canonical
gradient) when \(\psi\) admits an asymptotically linear representation.

The above implies that \(\psi_n\) is a \(\sqrt{n}\)-consistent estimator of \(\psi\),
that it is asymptotically normal (as given above), and that it is locally
efficient. This allows us to build Wald-type confidence intervals in a
straightforward manner:

\[\psi_n \pm z_{\alpha} \cdot \frac{\sigma_n}{\sqrt{n}},\]
where \(\sigma_n^2\) is an estimator of \(V(D(P_0))\). The estimator \(\sigma_n^2\)
may be obtained using the bootstrap or computed directly via the following

\[\sigma_n^2 = \frac{1}{n} \sum_{i = 1}^{n} D^2(\bar{Q}_n^{\star}, g_n)(O_i)\]

Having now re-examined these facts, let's simply examine the results of
computing our TML estimator:

\hypertarget{extensions-variable-importance-analysis-with-stochastic-interventions}{%
\section{Extensions: Variable Importance Analysis with Stochastic Interventions}\label{extensions-variable-importance-analysis-with-stochastic-interventions}}

\hypertarget{defining-a-grid-of-counterfactual-interventions}{%
\subsection{Defining a grid of counterfactual interventions}\label{defining-a-grid-of-counterfactual-interventions}}

In order to specify a \emph{grid} of shifts \(\delta\) to be used in defining a set of
stochastic intervention policies in an \emph{a priori} manner, let us consider an
arbitrary scalar \(\delta\) that defines a counterfactual outcome \(\psi_n = Q_n(d(A, W), W)\), where, for simplicity, let \(d(A, W) = A + \delta\). A
simplified expression of the auxiliary covariate for the TMLE of \(\psi\) is
\(H_n = \frac{g^{\star}(a \mid w)}{g(a \mid w)}\), where \(g^{\star}(a \mid w)\)
defines the treatment mechanism with the stochastic intervention implemented.
Then, to ascertain whether a given choice of the shift \(\delta\) is admissable
(in the sense of avoiding violations of the positivity assumption), let there
be a bound \(C(\delta) = \frac{g^{\star}(a \mid w)}{g(a \mid w)} < M\), where
\(g^{\star}(a \mid w)\) is a function of \(\delta\) in part, and \(M\) is a potentially
user-specified upper bound of \(C(\delta)\). Then, \(C(\delta)\) is a measure of
the influence of a given observation, thereby providing a way to limit the
maximum influence of a given observation (by way of the bound \(M\) placed on
\(C(\delta)\)) through a choice of the shift \(\delta\).

We formalize and extend the procedure to determine an acceptable set of values
for the shift \(\delta\) in the sequel. Specifically, let there be a shift \(d(A, W) = A + \delta(A, W)\), where the shift \(\delta(A, W)\) is defined as
\begin{equation}
  \delta(a, w) =
    \begin{cases}
      \delta, & \delta_{\text{min}}(a,w) \leq \delta \leq
        \delta_{\text{max}}(a,w) \\
      \delta_{\text{max}}(a,w), & \delta \geq \delta_{\text{max}}(a,w) \\
      \delta_{\text{min}}(a,w), & \delta \leq \delta_{\text{min}}(a,w) \\
    \end{cases},
\end{equation}
where \[\delta_{\text{max}}(a, w) = \text{argmax}_{\left\{\delta \geq 0,
\frac{g(a - \delta \mid w)}{g(a \mid w)} \leq M \right\}} \frac{g(a - \delta
\mid w)}{g(a \mid w)}\] and
\[\delta_{\text{min}}(a, w) = \text{argmin}_{\left\{\delta \leq 0,
\frac{g(a - \delta \mid w)}{g(a \mid w)} \leq M \right\}} \frac{g(a - \delta
\mid w)}{g(a \mid w)}.\]

The above provides a strategy for implementing a shift at the level of a given
observation \((a_i, w_i)\), thereby allowing for all observations to be shifted
to an appropriate value -- whether \(\delta_{\text{min}}\), \(\delta\), or
\(\delta_{\text{max}}\).

For the purpose of using such a shift in practice, the present software
provides the functions \passthrough{\lstinline!shift\_additive\_bounded!} and
\passthrough{\lstinline!shift\_additive\_bounded\_inv!}, which define a variation of this shift:
\begin{equation}
  \delta(a, w) =
    \begin{cases}
      \delta, & C(\delta) \leq M \\
      0, \text{otherwise} \\
    \end{cases},
  \label{eq:shift-simple}
\end{equation}
which corresponds to an intervention in which the natural value of treatment
of a given observational unit is shifted by a value \(\delta\) in the case that
the ratio of the intervened density \(g^{\star}(a \mid w)\) to the natural
density \(g(a \mid w)\) (that is, \(C(\delta)\)) does not exceed a bound \(M\). In
the case that the ratio \(C(\delta)\) exceeds the bound \(M\), the stochastic
intervention policy does not apply to the given unit and they remain at their
natural value of treatment \(a\).

\hypertarget{initializing-vimshift-through-its-tmle3_spec}{%
\subsection{\texorpdfstring{Initializing \texttt{vimshift} through its \texttt{tmle3\_Spec}}{Initializing vimshift through its tmle3\_Spec}}\label{initializing-vimshift-through-its-tmle3_spec}}

To start, we will initialize a specification for the TMLE of our parameter of
interest (called a \passthrough{\lstinline!tmle3\_Spec!} in the \passthrough{\lstinline!tlverse!} nomenclature) simply by calling
\passthrough{\lstinline!tmle\_shift!}. We specify the argument \passthrough{\lstinline!shift\_grid = seq(-1, 1, by = 1)!}
when initializing the \passthrough{\lstinline!tmle3\_Spec!} object to communicate that we're interested
in assessing the mean counterfactual outcome over a grid of shifts -1, 0, 1 on the scale of the treatment \(A\) (note that the numerical
choice of shift is an arbitrarily chosen set of values for this example).

\begin{lstlisting}[language=R]
# what's the grid of shifts we wish to consider?
delta_grid <- seq(-1, 1, 1)

# initialize a tmle specification
tmle_spec <- tmle_vimshift_delta(
  shift_grid = delta_grid,
  max_shifted_ratio = 2
)
\end{lstlisting}

As seen above, the \passthrough{\lstinline!tmle\_vimshift!} specification object (like all \passthrough{\lstinline!tmle3\_Spec!}
objects) does \emph{not} store the data for our specific analysis of interest. Later,
we'll see that passing a data object directly to the \passthrough{\lstinline!tmle3!} wrapper function,
alongside the instantiated \passthrough{\lstinline!tmle\_spec!}, will serve to construct a \passthrough{\lstinline!tmle3\_Task!}
object internally (see the \passthrough{\lstinline!tmle3!} documentation for details).

\hypertarget{targeted-estimation-of-stochastic-interventions-effects-1}{%
\subsection{Targeted Estimation of Stochastic Interventions Effects}\label{targeted-estimation-of-stochastic-interventions-effects-1}}

One may walk through the step-by-step procedure for fitting the TML estimator
of the mean counterfactual outcome under each shift in the grid, using the
machinery exposed by the \href{https://tmle3.tlverse.org/}{\passthrough{\lstinline!tmle3!} R package}.

One may invoke the \passthrough{\lstinline!tmle3!} wrapper function (a user-facing convenience utility)
to fit the series of TML estimators (one for each parameter defined by the grid
delta) in a single function call:

\begin{lstlisting}[language=R]
tmle_fit <- tmle3(tmle_spec, data, node_list, learner_list)
tmle_fit
\end{lstlisting}

\emph{Remark}: The \passthrough{\lstinline!print!} method of the resultant \passthrough{\lstinline!tmle\_fit!} object conveniently
displays the results from computing our TML estimator.

\hypertarget{inference-with-marginal-structural-models}{%
\subsection{Inference with Marginal Structural Models}\label{inference-with-marginal-structural-models}}

Since we consider estimating the mean counterfactual outcome \(\psi_n\) under
several values of the intervention \(\delta\), taken from the aforementioned
\(\delta\)-grid, one approach for obtaining inference on a single summary measure
of these estimated quantities involves leveraging working marginal structural
models (MSMs). Summarizing the estimates \(\psi_n\) through a working MSM allows
for inference on the \emph{trend} imposed by a \(\delta\)-grid to be evaluated via a
simple hypothesis test on a parameter of this working MSM. Letting
\(\psi_{\delta}(P_0)\) be the mean outcome under a shift \(\delta\) of the
treatment, we have \(\vec{\psi}_{\delta} = (\psi_{\delta}: \delta)\) with
corresponding estimators \(\vec{\psi}_{n, \delta} = (\psi_{n, \delta}: \delta)\).
Further, let \(\beta(\vec{\psi}_{\delta}) = \phi((\psi_{\delta}: \delta))\).

For a given MSM \(m_{\beta}(\delta)\), we have that
\[\beta_0 = \text{argmin}_{\beta} \sum_{\delta}(\psi_{\delta}(P_0) -
m_{\beta}(\delta))^2 h(\delta),\]
which is the solution to
\[u(\beta, (\psi_{\delta}: \delta)) = \sum_{\delta}h(\delta)
\left(\psi_{\delta}(P_0) - m_{\beta}(\delta) \right) \frac{d}{d\beta}
m_{\beta}(\delta) = 0.\]
This then leads to the following expansion
\[\beta(\vec{\psi}_n) - \beta(\vec{\psi}_0) \approx -\frac{d}{d\beta}
  u(\beta_0, \vec{\psi}_0)^{-1} \frac{d}{d\psi} u(\beta_0, \psi_0)
  (\vec{\psi}_n - \vec{\psi}_0),\]
where we have
\[\frac{d}{d\beta} u(\beta, \psi) = -\sum_{\delta} h(\delta) \frac{d}{d\beta}
m_{\beta}(\delta)^t \frac{d}{d\beta} m_{\beta}(\delta)
-\sum_{\delta} h(\delta) m_{\beta}(\delta) \frac{d^2}{d\beta^2}
m_{\beta}(\delta),\]
which, in the case of an MSM that is a linear model (since
\(\frac{d^2}{d\beta^2} m_{\beta}(\delta) = 0\)), reduces simply to
\[\frac{d}{d\beta} u(\beta, \psi) = -\sum_{\delta} h(\delta) \frac{d}{d\beta}
m_{\beta}(\delta)^t \frac{d}{d\beta} m_{\beta}(\delta),\]
and
\[\frac{d}{d\psi}u(\beta, \psi)(\psi_n - \psi_0) = \sum_{\delta} h(\delta)
\frac{d}{d\beta} m_{\beta}(\delta) (\psi_n - \psi_0)(\delta),\]
which we may write in terms of the efficient influence function (EIF) of \(\psi\)
by using the first order approximation \((\psi_n - \psi_0)(\delta) = \frac{1}{n}\sum_{i = 1}^n \text{EIF}_{\psi_{\delta}}(O_i)\),
where \(\text{EIF}_{\psi_{\delta}}\) is the efficient influence function (EIF) of
\(\vec{\psi}\).

Now, say, \(\vec{\psi} = (\psi(\delta): \delta)\) is d-dimensional, then we may
write the efficient influence function of the MSM parameter \(\beta\) as follows
\[\text{EIF}_{\beta}(O) = \left(\sum_{\delta} h(\delta) \frac{d}{d\beta}
m_{\beta}(\delta) \frac{d}{d\beta} m_{\beta}(\delta)^t \right)^{-1} \cdot
\sum_{\delta} h(\delta) \frac{d}{d\beta} m_{\beta}(\delta)
\text{EIF}_{\psi_{\delta}}(O),\] where the first term is of dimension
\(d \times d\) and the second term is of dimension \(d \times 1\). In the above, we
assume a linear working MSM; however, an analogous procedure may be applied for
working MSMs based on GLMs.

Inference for a parameter of an MSM may be obtained by straightforward
application of the delta method (discussed previously) -- that is, we may
write the efficient influence function of the MSM parameter \(\beta\) in terms of
the EIFs of each of the corresponding point estimates. Based on this, inference
from a working MSM is rather straightforward. To wit, the limiting distribution
for \(m_{\beta}(\delta)\) may be expressed \[\sqrt{n}(\beta_n - \beta_0) \to N(0,
\Sigma),\] where \(\Sigma\) is the empirical covariance matrix of
\(\text{EIF}_{\beta}(O)\).

\hypertarget{directly-targeting-the-msm-parameter-beta}{%
\subsubsection{\texorpdfstring{Directly Targeting the MSM Parameter \(\beta\)}{Directly Targeting the MSM Parameter \textbackslash{}beta}}\label{directly-targeting-the-msm-parameter-beta}}

Note that in the above, a working MSM is fit to the individual TML estimates of
the mean counterfactual outcome under a given value of the shift \(\delta\) in the
supplied grid. The parameter of interest \(\beta\) of the MSM is asymptotically
linear (and, in fact, a TML estimator) as a consequence of its construction from
individual TML estimators. In smaller samples, it may be prudent to perform a
TML estimation procedure that targets the parameter \(\beta\) directly, as opposed
to constructing it from several independently targeted TML estimates. An
approach for constructing such an estimator is proposed in the sequel.

Suppose a simple working MSM \(\mathbb{E}Y_{g^0_{\delta}} = \beta_0 + \beta_1 \delta\), then a TML estimator targeting \(\beta_0\) and \(\beta_1\) may be
constructed as
\[\overline{Q}_{n, \epsilon}(A,W) = \overline{Q}_n(A,W) + \epsilon (H_1(g),
H_2(g),\] for all \(\delta\), where \(H_1(g)\) is the auxiliary covariate for
\(\beta_0\) and \(H_2(g)\) is the auxiliary covariate for \(\beta_1\).

To construct a targeted maximum likelihood estimator that directly targets the
parameters of the working marginal structural model, we may use the
\passthrough{\lstinline!tmle\_vimshift\_msm!} Spec (instead of the \passthrough{\lstinline!tmle\_vimshift\_delta!} Spec that
appears above):

\begin{lstlisting}[language=R]
# initialize a tmle specification
tmle_msm_spec <- tmle_vimshift_msm(
  shift_grid = delta_grid,
  max_shifted_ratio = 2
)

# fit the TML estimator and examine the results
tmle_msm_fit <- tmle3(tmle_msm_spec, data, node_list, learner_list)
tmle_msm_fit
\end{lstlisting}

\hypertarget{example-with-the-wash-benefits-data}{%
\subsection{Example with the WASH Benefits Data}\label{example-with-the-wash-benefits-data}}

To complete our walk through, let's turn to using stochastic interventions to
investigate the data from the WASH Benefits trial. To start, let's load the
data, convert all columns to be of class \passthrough{\lstinline!numeric!}, and take a quick look at it

\begin{lstlisting}[language=R]
washb_data <- fread(
  paste0(
    "https://raw.githubusercontent.com/tlverse/tlverse-data/master/",
    "wash-benefits/washb_data.csv"
  ),
  stringsAsFactors = TRUE
)
washb_data <- washb_data[!is.na(momage), lapply(.SD, as.numeric)]
head(washb_data, 3)
     whz tr fracode month aged sex momage momedu momheight hfiacat Nlt18 Ncomp
1:  0.00  1       4     9  268   2     30      2    146.40       1     3    11
2: -1.16  1       4     9  286   2     25      2    148.75       3     2     4
3: -1.05  1      20     9  264   2     25      2    152.15       1     1    10
   watmin elec floor walls roof asset_wardrobe asset_table asset_chair
1:      0    1     0     1    1              0           1           1
2:      0    1     0     1    1              0           1           0
3:      0    0     0     1    1              0           0           1
   asset_khat asset_chouki asset_tv asset_refrig asset_bike asset_moto
1:          1            0        1            0          0          0
2:          1            1        0            0          0          0
3:          0            1        0            0          0          0
   asset_sewmach asset_mobile
1:             0            1
2:             0            1
3:             0            1
\end{lstlisting}

Next, we specify our NPSEM via the \passthrough{\lstinline!node\_list!} object. For our example analysis,
we'll consider the outcome to be the weight-for-height Z-score (as in previous
chapters), the intervention of interest to be the mother's age at time of
child's birth, and take all other covariates to be potential confounders.

\begin{lstlisting}[language=R]
node_list <- list(
  W = names(washb_data)[!(names(washb_data) %in%
    c("whz", "momage"))],
  A = "momage",
  Y = "whz"
)
\end{lstlisting}

Were we to consider the counterfactual weight-for-height Z-score under shifts in
the age of the mother at child's birth, how would we interpret estimates of our
parameter? To simplify our interpretation, consider a shift of just a year in
the mother's age (i.e., \(\delta = 1\)); in this setting, a stochastic
intervention would correspond to a policy advocating that potential mothers
defer having a child for a single calendar year, possibly implemented through an
encouragement design deployed in a clinical setting.

For this example, we'll use the variable importance strategy of considering a
grid of stochastic interventions to evaluate the weight-for-height Z-score under
a shift in the mother's age down by two years (\(\delta = -2\)) or up by two years
(\(\delta = 2\)). To do this, we simply initialize a \passthrough{\lstinline!Spec!} \passthrough{\lstinline!tmle\_vimshift\_delta!}
just as we did in a previous example:

\begin{lstlisting}[language=R]
# initialize a tmle specification for the variable importance parameter
washb_vim_spec <- tmle_vimshift_delta(
  shift_grid = c(-2, 2),
  max_shifted_ratio = 2
)
\end{lstlisting}

Prior to running our analysis, we'll modify the \passthrough{\lstinline!learner\_list!} object we had
created such that the density estimation procedure we rely on will be only the
location-scale conditional density estimation procedure, as the nonparametric
conditional density approach based on the highly adaptive lasso \citep{diaz2011super, benkeser2016hal, coyle2020hal9001, hejazi2020hal9001, hejazi2020haldensify}
is currently unable to accommodate larger datasets.

\begin{lstlisting}[language=R]
# we need to turn on cross-validation for the HOSE learner
cv_hose_hal_lrnr <- Lrnr_cv$new(
  learner = hose_hal_lrnr,
  full_fit = TRUE
)

# modify learner list, using existing SL for Q fit
learner_list <- list(Y = sl_reg_lrnr, A = cv_hose_hal_lrnr)
\end{lstlisting}

Having made the above preparations, we're now ready to estimate the
counterfactual mean of the weight-for-height Z-score under a small grid of
shifts in the mother's age at child's birth. Just as before, we do this through
a simple call to our \passthrough{\lstinline!tmle3!} wrapper function:

\begin{lstlisting}[language=R]
washb_tmle_fit <- tmle3(washb_vim_spec, washb_data, node_list, learner_list)
washb_tmle_fit
\end{lstlisting}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{exercises-3}{%
\section{Exercises}\label{exercises-3}}

\hypertarget{the-ideas-in-action-1}{%
\subsection{The Ideas in Action}\label{the-ideas-in-action-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Set the \passthrough{\lstinline!sl3!} library of algorithms for the Super Learner to a simple,
  interpretable library and use this new library to estimate the
  counterfactual mean of mother's age at child's birth (\passthrough{\lstinline!momage!}) under a
  shift \(\delta = 0\). What does this counterfactual mean equate to in terms
  of the observed data?
\item
  Using a grid of values of the shift parameter \(\delta\) (e.g., \(\{-1, 0, +1\}\)), repeat the analysis on the variable chosen in the preceding
  question, summarizing the trend for this sequence of shifts using a marginal
  structural model.
\item
  Repeat the preceding analysis, using the same grid of shifts, but instead
  directly targeting the parameters of the marginal structural model.
  Interpret the results -- that is, what does the slope of the marginal
  structural model tell us about the trend across the chosen sequence of
  shifts?
\end{enumerate}

\hypertarget{review-of-key-concepts-2}{%
\subsection{Review of Key Concepts}\label{review-of-key-concepts-2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Describe two (equivalent) ways in which the causal effects of stochastic
  interventions may be interpreted.
\item
  How does the marginal structural model we used to summarize the trend along
  the sequence of shifts previously help to contextualize the estimated effect
  for a single shift? That is, how does access to estimates across several
  shifts and the marginal structural model parameters allow us to more richly
  interpret our findings?
\item
  What advantages, if any, are there to targeting directly the parameters of a
  marginal structural model?
\end{enumerate}

\hypertarget{causal-mediation-analysis}{%
\chapter{Causal Mediation Analysis}\label{causal-mediation-analysis}}

\emph{Nima Hejazi}

Based on the \href{https://github.com/tlverse/tmle3mediate}{\passthrough{\lstinline!tmle3mediate!} \passthrough{\lstinline!R!}
package} by \emph{Nima Hejazi, James
Duncan, and David McCoy}.

Updated: 2021-04-28

\hypertarget{learning-objectives-6}{%
\section{Learning Objectives}\label{learning-objectives-6}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Appreciate how the presence of a mediating variable in a causal pathway can
  allow direct and indirect effects of the treatment on the outcome to be
  defined.
\item
  Describe the major differences between direct and indirect causal effects.
\item
  Differentiate the joint interventions required to define direct and indirect
  effects from the static, dynamic, and stochastic interventions that yield
  the \emph{total} causal effects previously described.
\item
  Describe the assumptions needed for identification of the natural direct and
  indirect effects, as well as the limitations of these effect definitions.
\item
  Estimate the natural direct and indirect effects of a binary treatment using
  the \passthrough{\lstinline!tmle3mediate!} \passthrough{\lstinline!R!} package.
\item
  Differentiate the population intervention direct and indirect effects of
  stochastic interventions from the natural direct and indirect effects,
  including differences in the assumptions required for their identification.
\item
  Estimate the population intervention direct effect of a binary treatment
  using the \passthrough{\lstinline!tmle3mediate!} \passthrough{\lstinline!R!} package.
\end{enumerate}

\hypertarget{introduction-to-causal-mediation-analysis}{%
\section{Introduction to Causal Mediation Analysis}\label{introduction-to-causal-mediation-analysis}}

A treatment often affects an outcome indirectly, through a particular pathway,
by its effect on \emph{intermediate variables} (mediators). Causal mediation analysis
concerns the construction and evaluation of these \emph{indirect effects} and their
complementary \emph{direct effects}. Generally, the indirect effect (IE) of a
treatment on an outcome is the portion of the total effect that is found to work
\emph{through} mediator variables, while the direct effect often encompasses all
other components of the total effect, including both the effect of the treatment
on the outcome \emph{and} the effect through all paths not explicitly involving the
mediators). Identifying and quantifying the mechanisms underlying causal effects
is an increasingly desirable endeavor in public health, medicine, and the social
sciences, as such mechanistic knowledge improves understanding of both \emph{why} and
\emph{how} treatments may be effective.

While the study of mediation analysis may be traced back quite far, the field
only came into its modern form with the identification and careful study of the
natural direct and indirect effects \citep{robins1992identifiability, pearl2001direct}. The natural direct effect (NDE) and the natural indirect
effect (NIE) are based on a decomposition of the average treatment effect (ATE)
in the presence of mediators \citep{vanderweele2015explanation}; requisite
theory for the construction of efficient estimators of these quantities only
receiving attention relatively recently \citep{tchetgen2012semiparametric}.

\hypertarget{data-structure-and-notation-2}{%
\section{Data Structure and Notation}\label{data-structure-and-notation-2}}

Consider \(n\) observed units \(O_1, \ldots, O_n\), where each observed data random
variable takes the form \(O = (W, A, Z, Y)\), for a vector of observed covariates
\(W\), a binary or continuous treatment \(A\), possibly multivariate mediators \(Z\),
and a binary or continuous outcome \(Y\). To avoid undue assumptions, we assume
only that \(O \sim \mathcal{P} \in \M\) where \(\M\) is the nonparametric
statistical model defined as all continuous densities on \(O\) with respect to an
arbitrary dominating measure.

We formalize the definition of our counterfactual variables using the following
non-parametric structural equation model (NPSEM):
\begin{align}
  W &= f_W(U_W) \\
  A &= f_A(W, U_A) \\
  Z &= f_Z(W, A, U_Z) \\
  Y &= f_Y(W, A, Z, U_Y).
  \label{eq:npsem-mediate}
\end{align}
This set of equations
represents a mechanistic model generating the observed data \(O\); furthermore,
the NPSEM encodes several fundamental assumptions. Firstly, there is an implicit
temporal ordering: \(W\) occurs first, depending only on exogenous factors \(U_W\);
\(A\) happens next, based on both \(W\) and exogenous factors \(U_A\); then come the
mediators \(Z\), which depend on \(A\), \(W\), and another set of exogenous factors
\(U_Z\); and finally appears the outcome \(Y\). We assume neither access to the set
of exogenous factors \(\{U_W, U_A, U_Z, U_Y\}\) nor knowledge of the forms of the
deterministic generating functions \(\{f_W, f_A, f_Z, f_Y\}\). The NPSEM
corresponds to the following DAG:

\begin{lstlisting}[language=R]
library(dagitty)
library(ggdag)

# make DAG by specifying dependence structure
dag <- dagitty(
  "dag {
    W -> A
    W -> Z
    W -> Y
    A -> Z
    A -> Y
    Z -> Y
    W -> A -> Y
    W -> A -> Z -> Y
  }"
)
exposures(dag) <- c("A")
outcomes(dag) <- c("Y")
tidy_dag <- tidy_dagitty(dag)

# visualize DAG
ggdag(tidy_dag) +
  theme_dag()
\end{lstlisting}

\begin{center}\includegraphics[width=0.8\linewidth]{10-tmle3mediate_files/figure-latex/mediation-DAG-1} \end{center}

The likelihood of the data \(O\) admits a factorization, wherein, for \(p_0^O\),
the density of \(O\) with respect to the product measure, the density evaluated
on a particular observation \(o\) may be a written
\begin{align}
  p_0^O(x) = &q^O_{0,Y}(y \mid Z = z, A = a, W = w) \cdot \\
    &q^O_{0,Z}(z \mid A = a, W = w) \cdot \\
    &q^O_{0,A}(a \mid W = w) \cdot \\
    &q^O_{0,W}(w),\\
  \label{eq:likelihood-factorization-mediate}
\end{align}
where \(q_{0, Y}\) is the conditional density of \(Y\) given \((Z, A, W)\), \(q_{0, Z}\)
is the conditional density of \(Z\) given \((A, W)\), \(q_{0, A}\) is the conditional
density of \(A\) given \(W\), and \(q_{0, W}\) is the density of \(W\). For ease of
notation, we let \(\bar{Q}_Y(Z, A, W) = \E[Y \mid Z, A, W]\), \(Q_Z(A, W) = P[Z \mid A, W]\), \(g(A \mid W) = \P(A \mid W)\), and \(q_W\) the marginal
distribution of \(W\).

Finally, note that we have explicitly excluded potential confounders of the
mediator-outcome relationship affected by exposure (i.e., variables affected by
\(A\) and affecting both \(Z\) and \(Y\)). Mediation analysis in the presence of such
variables is exceptionally challenging \citep{avin2005identifiability}; thus, most
efforts to develop definitions of causal direct and indirect effects explicitly
disallowed such a form of confounding. While we will not discuss the matter
here, the interested reader may consult recent advances in the vast literature
on causal mediation analysis, among them \citet{diaz2020nonparametric} and
\citet{hejazi2021nonparametric}.

\hypertarget{decomposing-the-average-treatment-effect}{%
\section{Decomposing the Average Treatment Effect}\label{decomposing-the-average-treatment-effect}}

The natural direct and indirect effects arise from a decomposition of the ATE:
\begin{equation*}
  \E[Y(1) - Y(0)] =
    \underbrace{\E[Y(1, Z(0)) - Y(0, Z(0))]}_{NDE} +
    \underbrace{\E[Y(1, Z(1)) - Y(1, Z(0))]}_{NIE}.
\end{equation*}
In particular, the natural indirect effect (NIE) measures the effect of the
treatment \(A \in \{0, 1\}\) on the outcome \(Y\) through the mediators \(Z\), while
the natural direct effect (NDE) measures the effect of the treatment on the
outcome \emph{through all other paths}. Identification of the natural direct and
indirect effects requires the following non-testable causal assumptions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{Exchangeability} (randomization): \(Y(a, z) \indep (A, Z) \mid W\), further
  implying \(\E\{Y(a, z) \mid A=a, W=w, Z=z\} = \E\{Y(a, z) \mid W=w\}\). This
  is a special case of the randomization assumption, extended to observational
  studies with mediators.
\item
  \emph{Treatment positivity}: For any \(a \in \mathcal{A}\) and \(w \in \mathcal{W}\), \(\xi < g(a \mid w) < 1 - \xi\), \(\xi > 0\). This mirrors the
  assumption required for static intervention, discussed previously.
\item
  \emph{Mediator positivity}: For any \(z \in \mathcal{Z}\), \(a \in \mathcal{A}\), and
  \(w \in \mathcal{W}\), \(\epsilon < Q(z \mid a, w)\), for \(\epsilon > 0\). This
  only requires that the conditional density of the mediators be bounded away
  from zero for all \((z, a, w)\) in their joint support \(\mathcal{Z} \times \mathcal{A} \times \mathcal{W}\).
\item
  \emph{Cross-world counterfactual independence}: For all \(a \neq a'\), both
  contained in \(\mathcal{A}\) and \(z \in \mathcal{Z}\), \(Y(a', z)\) is independent
  of \(Z(a)\), given \(W\). That is, the counterfactual outcome under the treatment
  contrast \(a' \in \mathcal{A}\) and the counterfactual mediator \(Z(a) \in \mathcal{Z}\) (under a different contrast \(a \in \mathcal{A}\)) are
  independent. Note that the counterfactual outcome and mediator are defined
  under differing contrasts, hence the ``cross-world'' designation.
\end{enumerate}

We note that many attempts have been made to weaken the last assumption, that of
cross-world counterfactual independence, including work by
\citet{petersen2006estimation} and \citet{imai2010identification}; however, importantly,
\citet{robins2010alternative} established that this assumption cannot be satisfied in
randomized experiments. Thus, the natural direct and indirect effects are not
identifiable in randomized experiments, calling into question their utility.
Despite this significant limitation, we will turn to considering estimation of
the statistical functionals corresponding to these effects in observational
studies.

\hypertarget{the-natural-direct-effect}{%
\section{The Natural Direct Effect}\label{the-natural-direct-effect}}

The NDE is defined as
\begin{align*}
  \Psi_{NDE} &= \E[Y(1, Z(0)) - Y(0, Z(0))] \\
  &\overset{\text{rand.}}{=} \sum_w \sum_z
  [\underbrace{\E(Y \mid A = 1, z, w)}_{\bar{Q}_Y(A = 1, z, w)} -
  \underbrace{\E(Y \mid A = 0, z, w)}_{\bar{Q}_Y(A = 0, z, w)}] \times
  \underbrace{p(z \mid A = 0, w)}_{Q_Z(0, w))} \underbrace{p(w)}_{q_W},
\end{align*}
where the likelihood factors \(p(z \mid A = 0, w)\) and \(p(w)\) (among other
conditional densities) arise from a factorization of the joint likelihood:
\begin{equation*}
  p(w, a, z, y) = \underbrace{p(y \mid w, a, z)}_{Q_Y(A, W, Z)}
  \underbrace{p(z \mid w, a)}_{Q_Z(Z \mid A, W)}
  \underbrace{p(a \mid w)}_{g(A \mid W)}
  \underbrace{p(w)}_{Q_W}.
\end{equation*}

The process of estimating the NDE begins by constructing \(\bar{Q}_{Y, n}\), an
estimate of the outcome mechanism \(\bar{Q}_Y(Z, A, W) = \E \{Y \mid Z, A, W\}\) (i.e., the conditional mean of \(Y\), given \(Z\), \(A\), and \(W\)). With an
estimate of this conditional expectation in hand, predictions of the
counterfactual quantities \(\bar{Q}_Y(Z, 1, W)\) (setting \(A = 1\)) and, likewise,
\(\bar{Q}_Y(Z, 0, W)\) (setting \(A = 0\)) can readily be obtained. We denote the
difference of these counterfactual quantities \(\bar{Q}_{\text{diff}}\), i.e.,
\(\bar{Q}_{\text{diff}} = \bar{Q}_Y(Z, 1, W) - \bar{Q}_Y(Z, 0, W)\).
\(\bar{Q}_{\text{diff}}\) represents the difference in the conditional mean of
\(Y\) attributable to changes in \(A\) while keeping \(Z\) and \(W\) at their \emph{natural}
(that is, observed) values.

The estimation procedure treats \(\bar{Q}_{\text{diff}}\) itself as a nuisance
parameter, regressing its estimate \(\bar{Q}_{\text{diff}, n}\) on \(W\), among
control observations only (i.e., those for whom \(A = 0\) is observed); the goal
of this step is to remove part of the marginal impact of \(Z\) on
\(\bar{Q}_{\text{diff}}\), since \(W\) is a parent of \(Z\). Regressing this
difference on \(W\) among the controls recovers the expected
\(\bar{Q}_{\text{diff}}\), had all individuals been set to the control condition
\(A = 0\). Any residual additive effect of \(Z\) on \(\bar{Q}_{\text{diff}}\) is
removed during the TML estimation step using the auxiliary (or ``clever'')
covariate, which accounts for the mediators \(Z\). This auxiliary covariate takes
the form
\begin{equation*}
  C_Y(Q_Z, g)(O) = \Bigg\{\frac{\mathbb{I}(A = 1)}{g(1 \mid W)}
  \frac{Q_Z(Z \mid 0, W)}{Q_Z(Z \mid 1, W)} -
  \frac{\mathbb{I}(A = 0)}{g(0 \mid W)} \Bigg\}.
\end{equation*}
Breaking this down, \(\frac{\mathbb{I}(A = 1)}{g(1 \mid W)}\) is the inverse
propensity score weight for \(A = 1\) and, likewise, \(\frac{\mathbb{I}(A = 0)} {g(0 \mid W)}\) is the inverse propensity score weight for \(A = 0\). The middle
term is the ratio of the conditional densities of the mediator under the control
(\(A = 0\)) and treatment (\(A = 1\)) conditions.

This subtle appearance of a ratio of conditional densities is concerning --
tools to estimate such quantities are sparse in the statistics literature,
unfortunately, and the problem is still more complicated (and computationally
taxing) when \(Z\) is high-dimensional. As only the ratio of these conditional
densities is required, a convenient re-parametrization may be achieved, that is,
\begin{equation*}
  \frac{p(A = 0 \mid Z, W) g(0 \mid W)}{p(A = 1 \mid Z, W) g(1 \mid W)}.
\end{equation*}
Going forward, we will denote this re-parameterized conditional probability
\(e(A \mid Z, W) := p(A \mid Z, W)\). Similar re-parameterizations have been used
in \citet{zheng2012targeted} and \citet{tchetgen2013inverse}. This is particularly useful
since this reformulation reduces the problem to one concerning only the
estimation of conditional means, opening the door to the use of a wide range of
machine learning algorithms (e.g., most of those in
\href{https://github.com/tlverse/sl3}{\passthrough{\lstinline!sl3!}}).

Underneath the hood, the counterfactual outcome difference
\(\bar{Q}_{\text{diff}}\) and \(e(A \mid Z, W)\), the conditional probability of \(A\)
given \(Z\) and \(W\), are used in constructing the auxiliary covariate for TML
estimation. These nuisance parameters play an important role in the
bias-correcting update step of the TMLE procedure.

\hypertarget{the-natural-indirect-effect}{%
\section{The Natural Indirect Effect}\label{the-natural-indirect-effect}}

Derivation and estimation of the NIE is analogous to that of the NDE. The NIE
is the effect of \(A\) on \(Y\) \emph{only through the mediator(s) \(Z\)}. This quantity
-- known as the natural indirect effect \(\E(Y(Z(1), 1) - \E(Y(Z(0), 1)\) --
corresponds to the difference of the conditional expectation of \(Y\) given \(A = 1\) and \(Z(1)\) (the values the mediator would take under \(A = 1\)) and the
conditional expectation of \(Y\) given \(A = 1\) and \(Z(0)\) (the values the mediator
would take under \(A = 0\)).

As with the NDE, the re-parameterization trick can be used to estimate \(\E(A \mid Z, W)\), avoiding estimation of a possibly multivariate conditional density.
However, in this case, the mediated mean outcome difference, denoted
\(\Psi_Z(Q)\), is instead estimated as follows
\begin{equation*}
  \Psi_{NIE}(Q) = \E (\Psi_{NIE, Z}(Q)(1, W) - \Psi_{NIE, Z}(Q)(0, W))
\end{equation*}

Here, \(\bar{Q}_Y(Z, 1, W)\) (the predicted values for \(Y\) given \(Z\) and \(W\) when
\(A = 1\)) is regressed on \(W\), among the treated units (for whom \(A = 1\) is
observed) to obtain the conditional mean \(\Psi_{NIE, Z}(Q)(1, W)\). Performing
the same procedure, but now regressing \(\bar{Q}_Y(Z, 1, W)\) on \(W\) among the
control units (for whom \(A = 0\) is observed) yields \(\Psi_{NIE,Z}(Q)(0, W)\). The
difference of these two estimates is the NIE and can be thought of as the
additive marginal effect of treatment on the conditional expectation of \(Y\)
given \(W\), \(A = 1\), \(Z\) through its effects on \(Z\). So, in the case of the NIE,
our estimate \(\psi_n\) is slightly different, but the same quantity \(e(A \mid Z, W)\) comes into play as the auxiliary covariate.

\hypertarget{the-population-intervention-indirect-effects}{%
\section{The Population Intervention (In)Direct Effects}\label{the-population-intervention-indirect-effects}}

At times, the natural direct and indirect effects may prove too limiting, as
these effect definitions are based on \emph{static interventions} (i.e., setting
\(A = 0\) or \(A = 1\)), which may be unrealistic for real-world interventions. In
such cases, one may turn instead to the population intervention direct effect
(PIDE) and the population intervention indirect effect (PIIE), which are based
on decomposing the effect of the population intervention effect (PIE) of
flexible stochastic interventions \citep{diaz2020causal}.

A particular type of stochastic intervention well-suited to working with binary
treatments is the \emph{incremental propensity score intervention} (IPSI), first
proposed by \citet{kennedy2017nonparametric}. Such interventions do not
deterministically set the treatment level of an observed unit to a fixed
quantity (i.e., setting \(A = 1\)), but instead \emph{alter the odds of receiving the
treatment} by a fixed amount (\(0 \leq \delta \leq \infty\)) for each individual.
In particular, this intervention takes the form
\begin{equation*}
  g_{\delta}(1 \mid w) = \frac{\delta g(1 \mid w)}{\delta g(1 \mid w) + 1
  - g(1\mid w)},
\end{equation*}
where the scalar \(0 < \delta < \infty\) specifies a \emph{change in the odds of
receiving treatment}. As described by \citet{diaz2020causal}, this stochastic
intervention is a special case of exponential tilting, a framework that unifies
post-intervention treatment values that are draws from an altered distribution.

Unlike the natural direct and indirect effects, the conditions required for
identifiability of the population intervention direct and indirect effects are
more lax. Most importantly, these differences involve a (1) treatment positivity
assumption that only requires that the counterfactual treatment be in the
observed support of the treatment \(\mathcal{A}\), and (2) no requirement of the
independence any cross-world counterfactuals.

\hypertarget{decomposing-the-population-intervention-effect}{%
\section{Decomposing the Population Intervention Effect}\label{decomposing-the-population-intervention-effect}}

We may decompose the population intervention effect (PIE) in terms of the
\emph{population intervention direct effect} (PIDE) and the \emph{population
intervention indirect effect} (PIIE):
\begin{equation*}
  \mathbb{E}\{Y(A_\delta)\} - \mathbb{E}Y =
    \overbrace{\mathbb{E}\{Y(A_\delta, Z(A_\delta))
      - Y(A_\delta, Z)\}}^{\text{PIIE}} +
    \overbrace{\mathbb{E}\{Y(A_\delta, Z) - Y(A, Z)\}}^{\text{PIDE}}.
\end{equation*}

This decomposition of the PIE as the sum of the population intervention direct
and indirect effects has an interpretation analogous to the corresponding
standard decomposition of the average treatment effect. In the sequel, we will
compute each of the components of the direct and indirect effects above using
appropriate estimators as follows

\begin{itemize}
\tightlist
\item
  For \(\mathbb{E}\{Y(A, Z)\}\), the sample mean \(\frac{1}{n}\sum_{i=1}^n Y_i\) is
  consistent;
\item
  for \(\mathbb{E}\{Y(A_{\delta}, Z)\}\), a TML estimator for the effect of a
  joint intervention altering the treatment mechanism but not the mediation
  mechanism, based on the proposal in \citet{diaz2020causal}; and,
\item
  for \(\mathbb{E}\{Y(A_{\delta}, Z_{A_{\delta}})\}\), an efficient estimator for
  the effect of a joint intervention altering both the treatment and mediation
  mechanisms, as proposed in \citet{kennedy2017nonparametric} and implemented in the
  \href{https://github.com/ehkennedy/npcausal}{\passthrough{\lstinline!npcausal!} R package}.
\end{itemize}

\hypertarget{estimating-the-effect-decomposition-term}{%
\section{Estimating the Effect Decomposition Term}\label{estimating-the-effect-decomposition-term}}

As described by \citet{diaz2020causal}, the statistical functional identifying the
decomposition term that appears in both the PIDE and PIIE
\(\mathbb{E}\{Y(A_{\delta}, Z)\}\), which corresponds to altering the treatment
mechanism while keeping the mediation mechanism fixed, is
\begin{equation*}
  \theta_0(\delta) = \int m_0(a, z, w) g_{0,\delta}(a \mid w) p_0(z, w)
    d\nu(a, z, w),
\end{equation*}
for which a TML estimator is available. The corresponding \emph{efficient influence
function} (EIF) with respect to the nonparametric model \(\mathcal{M}\) is
\(D_{\eta,\delta}(o) = D^Y_{\eta,\delta}(o) + D^A_{\eta,\delta}(o) + D^{Z,W}_{\eta,\delta}(o) - \theta(\delta)\).

The TML estimator may be computed basd on the EIF estimating equation and may
incorporate cross-validation \citep{zheng2011cross, chernozhukov2018double} to
circumvent possibly restrictive entropy conditions (e.g., Donsker class). The
resultant estimator is
\begin{equation*}
  \hat{\theta}(\delta) = \frac{1}{n} \sum_{i = 1}^n D_{\hat{\eta}_{j(i)},
  \delta}(O_i) = \frac{1}{n} \sum_{i = 1}^n \left\{ D^Y_{\hat{\eta}_{j(i)},
  \delta}(O_i) + D^A_{\hat{\eta}_{j(i)}, \delta}(O_i) +
  D^{Z,W}_{\hat{\eta}_{j(i)}, \delta}(O_i) \right\},
\end{equation*}
which is implemented in \passthrough{\lstinline!tmle3mediate!} (a one-step estimator is also avaialble,
in the \href{https://github.com/nhejazi/medshift}{\passthrough{\lstinline!medshift!} R package}). We
demonstrate the use of \passthrough{\lstinline!tmle3mediate!} to obtain \(\mathbb{E}\{Y(A_{\delta}, Z)\}\)
via its TML estimator.

\hypertarget{evaluating-the-direct-and-indirect-effects}{%
\section{Evaluating the Direct and Indirect Effects}\label{evaluating-the-direct-and-indirect-effects}}

We now turn to estimating the natural direct and indirect effects, as well as
the population intervention direct effect, using the WASH Benefits data,
introduced in earlier chapters. Let's first load the data:

\begin{lstlisting}[language=R]
library(data.table)
library(sl3)
library(tmle3)
library(tmle3mediate)

# download data
washb_data <- fread(
  paste0(
    "https://raw.githubusercontent.com/tlverse/tlverse-data/master/",
    "wash-benefits/washb_data.csv"
  ),
  stringsAsFactors = TRUE
)

# make intervention node binary and subsample
washb_data <- washb_data[sample(.N, 600), ]
washb_data[, tr := as.numeric(tr != "Control")]
\end{lstlisting}

We'll next define the baseline covariates \(W\), treatment \(A\), mediators \(Z\),
and outcome \(Y\) nodes of the NPSEM via a ``Node List'' object:

\begin{lstlisting}[language=R]
node_list <- list(
  W = c(
    "momage", "momedu", "momheight", "hfiacat", "Nlt18", "Ncomp", "watmin",
    "elec", "floor", "walls", "roof"
  ),
  A = "tr",
  Z = c("sex", "month", "aged"),
  Y = "whz"
)
\end{lstlisting}

Here the \passthrough{\lstinline!node\_list!} encodes the parents of each node -- for example, \(Z\) (the
mediators) have parents \(A\) (the treatment) and \(W\) (the baseline confounders),
and \(Y\) (the outcome) has parents \(Z\), \(A\), and \(W\). We'll also handle any
missingness in the data by invoking \passthrough{\lstinline!process\_missing!}:

\begin{lstlisting}[language=R]
processed <- process_missing(washb_data, node_list)
washb_data <- processed$data
node_list <- processed$node_list
\end{lstlisting}

We'll now construct an ensemble learner using a handful of popular machine
learning algorithms:

\begin{lstlisting}[language=R]
# SL learners used for continuous data (the nuisance parameter Z)
enet_contin_learner <- Lrnr_glmnet$new(
  alpha = 0.5, family = "gaussian", nfolds = 3
)
lasso_contin_learner <- Lrnr_glmnet$new(
  alpha = 1, family = "gaussian", nfolds = 3
)
fglm_contin_learner <- Lrnr_glm_fast$new(family = gaussian())
mean_learner <- Lrnr_mean$new()
contin_learner_lib <- Stack$new(
  enet_contin_learner, lasso_contin_learner, fglm_contin_learner, mean_learner
)
sl_contin_learner <- Lrnr_sl$new(learners = contin_learner_lib)

# SL learners used for binary data (nuisance parameters G and E in this case)
enet_binary_learner <- Lrnr_glmnet$new(
  alpha = 0.5, family = "binomial", nfolds = 3
)
lasso_binary_learner <- Lrnr_glmnet$new(
  alpha = 1, family = "binomial", nfolds = 3
)
fglm_binary_learner <- Lrnr_glm_fast$new(family = binomial())
binary_learner_lib <- Stack$new(
  enet_binary_learner, lasso_binary_learner, fglm_binary_learner, mean_learner
)
sl_binary_learner <- Lrnr_sl$new(learners = binary_learner_lib)

# create list for treatment and outcome mechanism regressions
learner_list <- list(
  Y = sl_contin_learner,
  A = sl_binary_learner
)
\end{lstlisting}

\hypertarget{estimating-the-natural-indirect-effect}{%
\section{Estimating the Natural Indirect Effect}\label{estimating-the-natural-indirect-effect}}

We demonstrate calculation of the NIE below, starting by instantiating a ``Spec''
object that encodes exactly which learners to use for the nuisance parameters
\(e(A \mid Z, W)\) and \(\Psi_Z\). We then pass our Spec object to the \passthrough{\lstinline!tmle3!}
function, alongside the data, the node list (created above), and a learner list
indicating which machine learning algorithms to use for estimating the nuisance
parameters based on \(A\) and \(Y\).

\begin{lstlisting}[language=R]
tmle_spec_NIE <- tmle_NIE(
  e_learners = Lrnr_cv$new(lasso_binary_learner, full_fit = TRUE),
  psi_Z_learners = Lrnr_cv$new(lasso_contin_learner, full_fit = TRUE),
  max_iter = 1
)
washb_NIE <- tmle3(
  tmle_spec_NIE, washb_data, node_list, learner_list
)
washb_NIE
A tmle3_Fit that took 1 step(s)
   type                  param  init_est  tmle_est      se     lower    upper
1:  NIE NIE[Y_{A=1} - Y_{A=0}] 0.0011663 0.0010331 0.04461 -0.086401 0.088467
   psi_transformed lower_transformed upper_transformed
1:       0.0010331         -0.086401          0.088467
\end{lstlisting}

Based on the output, we conclude that the indirect effect of the treatment
through the mediators (sex, month, aged) is
0.00103.

\hypertarget{estimating-the-natural-direct-effect}{%
\section{Estimating the Natural Direct Effect}\label{estimating-the-natural-direct-effect}}

An analogous procedure applies for estimation of the NDE, only replacing the
Spec object for the NIE with \passthrough{\lstinline!tmle\_spec\_NDE!} to define learners for the NDE
nuisance parameters:

\begin{lstlisting}[language=R]
tmle_spec_NDE <- tmle_NDE(
  e_learners = Lrnr_cv$new(lasso_binary_learner, full_fit = TRUE),
  psi_Z_learners = Lrnr_cv$new(lasso_contin_learner, full_fit = TRUE),
  max_iter = 1
)
washb_NDE <- tmle3(
  tmle_spec_NDE, washb_data, node_list, learner_list
)
washb_NDE
A tmle3_Fit that took 1 step(s)
   type                  param init_est tmle_est       se    lower  upper
1:  NDE NDE[Y_{A=1} - Y_{A=0}] 0.012981 0.012981 0.085879 -0.15534 0.1813
   psi_transformed lower_transformed upper_transformed
1:        0.012981          -0.15534            0.1813
\end{lstlisting}

From this, we can draw the conclusion that the direct effect of the treatment
(through all paths not involving the mediators (sex, month, aged)) is
0.01298. Note that, together, the estimates of
the natural direct and indirect effects approximately recover the \emph{average
treatment effect}, that is, based on these estimates of the NDE and NIE, the
ATE is roughly
0.01401.

\hypertarget{estimating-the-population-intervention-direct-effect}{%
\section{Estimating the Population Intervention Direct Effect}\label{estimating-the-population-intervention-direct-effect}}

As previously noted, the assumptions underlying the natural direct and indirect
effects may be challenging to justify; moreover, the effect definitions
themselves depend on the application of a static intervention to the treatment,
sharply limiting their flexibility. When considering binary treatments,
incremental propensity score shifts provide an alternative class of flexible,
stochastic interventions. We'll now consider estimating the PIDE with an IPSI
that modulates the odds of receiving treatment by \(\delta = 3\). Such an
intervention may be interpreted (hypothetically) as the effect of a design that
encourages study participants to opt in to receiving the treatment, thus
increasing their relative odds of receiving said treatment. To exemplify our
approach, we postulate a motivational intervention that \emph{triples the odds}
(i.e., \(\delta = 3\)) of receiving the treatment for each individual:

\begin{lstlisting}[language=R]
# set the IPSI multiplicative shift
delta_ipsi <- 3

# instantiate tmle3 spec for stochastic mediation
tmle_spec_pie_decomp <- tmle_medshift(
  delta = delta_ipsi,
  e_learners = Lrnr_cv$new(lasso_binary_learner, full_fit = TRUE),
  phi_learners = Lrnr_cv$new(lasso_contin_learner, full_fit = TRUE)
)

# compute the TML estimate
washb_pie_decomp <- tmle3(
  tmle_spec_pie_decomp, washb_data, node_list, learner_list
)
washb_pie_decomp

# get the PIDE
washb_pie_decomp$summary$tmle_est - mean(washb_data[, get(node_list$Y)])
\end{lstlisting}

Recall that, based on the decomposition outlined previously, the PIDE may be
denoted \(\beta_{\text{PIDE}}(\delta) = \theta_0(\delta) - \mathbb{E}Y\). Thus,
an estimator of the PIDE, \(\hat{\beta}_{\text{PIDE}}(\delta)\) may be expressed
as a composition of estimators of its constituent parameters:
\begin{equation*}
  \hat{\beta}_{\text{PIDE}}({\delta}) = \hat{\theta}(\delta) -
  \frac{1}{n} \sum_{i = 1}^n Y_i.
\end{equation*}

\hypertarget{r6}{%
\chapter{\texorpdfstring{A Primer on the \texttt{R6} Class System}{A Primer on the R6 Class System}}\label{r6}}

A central goal of the Targeted Learning statistical paradigm is to estimate
scientifically relevant parameters in realistic (usually nonparametric) models.

The \passthrough{\lstinline!tlverse!} is designed using basic OOP principles and the \passthrough{\lstinline!R6!} OOP framework.
While we've tried to make it easy to use the \passthrough{\lstinline!tlverse!} packages without worrying
much about OOP, it is helpful to have some intuition about how the \passthrough{\lstinline!tlverse!} is
structured. Here, we briefly outline some key concepts from OOP. Readers
familiar with OOP basics are invited to skip this section.

\hypertarget{classes-fields-and-methods}{%
\section{Classes, Fields, and Methods}\label{classes-fields-and-methods}}

The key concept of OOP is that of an object, a collection of data and functions
that corresponds to some conceptual unit. Objects have two main types of
elements:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{fields}, which can be thought of as nouns, are information about an object,
  and
\item
  \emph{methods}, which can be thought of as verbs, are actions an object can
  perform.
\end{enumerate}

Objects are members of classes, which define what those specific fields and
methods are. Classes can inherit elements from other classes (sometimes called
base classes) -- accordingly, classes that are similar, but not exactly the
same, can share some parts of their definitions.

Many different implementations of OOP exist, with variations in how these
concepts are implemented and used. R has several different implementations,
including \passthrough{\lstinline!S3!}, \passthrough{\lstinline!S4!}, reference classes, and \passthrough{\lstinline!R6!}. The \passthrough{\lstinline!tlverse!} uses the \passthrough{\lstinline!R6!}
implementation. In \passthrough{\lstinline!R6!}, methods and fields of a class object are accessed using
the \passthrough{\lstinline!$!} operator. For a more thorough introduction to \passthrough{\lstinline!R!}'s various OOP systems,
see \url{http://adv-r.had.co.nz/OO-essentials.html}, from Hadley Wickham's \emph{Advanced
R} \citep{wickham2014advanced}.

\hypertarget{object-oriented-programming-python-and-r}{%
\section{\texorpdfstring{Object Oriented Programming: \texttt{Python} and \texttt{R}}{Object Oriented Programming: Python and R}}\label{object-oriented-programming-python-and-r}}

OO concepts (classes with inherentence) were baked into Python from the first
published version (version 0.9 in 1991). In contrast, \passthrough{\lstinline!R!} gets its OO ``approach''
from its predecessor, \passthrough{\lstinline!S!}, first released in 1976. For the first 15 years, \passthrough{\lstinline!S!}
had no support for classes, then, suddenly, \passthrough{\lstinline!S!} got two OO frameworks bolted on
in rapid succession: informal classes with \passthrough{\lstinline!S3!} in 1991, and formal classes with
\passthrough{\lstinline!S4!} in 1998. This process continues, with new OO frameworks being periodically
released, to try to improve the lackluster OO support in \passthrough{\lstinline!R!}, with reference
classes (\passthrough{\lstinline!R5!}, 2010) and \passthrough{\lstinline!R6!} (2014). Of these, \passthrough{\lstinline!R6!} behaves most like Python
classes (and also most like OOP focused languages like C++ and Java), including
having method definitions be part of class definitions, and allowing objects to
be modified by reference.

\bibliography{book.bib,packages.bib}

\backmatter
\printindex

\end{document}
