\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames*,x11names*}{xcolor}
%
\documentclass[12pt, krantz2,]{krantz}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\usepackage{xcolor}
\usepackage{hyperref}
\hypersetup{
            pdftitle={Targeted Learning in R},
            pdfauthor={Mark van der Laan, Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips, Alan Hubbard},
            colorlinks=true,
            linkcolor=Maroon,
            citecolor=Blue,
            urlcolor=Blue,
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{listings}
\newcommand{\passthrough}[1]{#1}
\usepackage{longtable,booktabs}
% Fix footnotes in tables (requires footnote package)
\IfFileExists{footnote.sty}{\usepackage{footnote}\makesavenoteenv{longtable}}{}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{booktabs}
\usepackage[inline]{enumitem}
\usepackage{float}
\usepackage{graphicx}
%\usepackage[round]{natbib}
\usepackage{geometry}
\usepackage{tikz}
\usepackage[english]{babel}
\usepackage{longtable}
\usepackage{color}
\usepackage{mathtools,bm,amssymb,amsmath,amsthm}
\usepackage{multirow}
\usepackage[titletoc,title]{appendix}
\usepackage{authblk}
\usepackage{setspace}
\usepackage{dsfont}
\PassOptionsToPackage{utf8x}{inputenc}
\usepackage[OT1]{fontenc}
\usepackage[bf,singlelinecheck=off]{caption}
\usepackage{refcount}
\usepackage{framed,color}
\definecolor{shadecolor}{RGB}{248,248,248}
\urlstyle{tt}
\usepackage[none]{hyphenat} 

\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.8}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\floatpagefraction}{0.75}

\usepackage{makeidx}
\makeindex

\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\newtheorem*{remark}{Remark}
\newtheorem{theorem}{Theorem}
\AtEndDocument{\refstepcounter{theorem}\label{finalthm}}
{
  \theoremstyle{definition}
  \newtheorem{assumption}{}
}
{
  \theoremstyle{definition}
  \newtheorem{assumptioniden}{}
}
{
  \theoremstyle{definition}
  \newtheorem{example}{Example}[section]
}
\DeclareMathOperator{\opt}{opt}
\DeclareMathOperator{\dr}{IF}
\newcommand{\hopt}{\hat h_{\opt}}
\newcommand{\supp}{\mathop{\mathrm{supp}}}
\renewcommand\theassumptioniden{{A}\arabic{assumptioniden}}
\renewcommand\theassumption{{C}\arabic{assumption}}
\renewcommand\theexample{\arabic{example}}

\newtheorem{lemma}{Lemma}
\newtheorem{coro}{Corollary}
\newtheorem{definition}{Definition}
\DeclareMathOperator{\bern}{Bern}
\DeclareMathOperator{\var}{Var}
\DeclareMathOperator{\Rem}{Rem}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\1}{\mathbbm{1}}
\DeclareMathOperator{\expit}{expit}
\DeclareMathOperator{\logit}{logit}
\newcommand{\indep}{\mbox{$\perp\!\!\!\perp$}}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\usepackage{color}
\lstset{
  breaklines=true,
  language=R,
  showspaces=false, 
  showstringspaces=false,
  basicstyle=\footnotesize\ttfamily,
  keywordstyle=\bfseries\color{green!40!black},
  commentstyle=\itshape\color{purple!40!black},
  identifierstyle=\color{blue},
  stringstyle=\color{orange}
}
\DeclareUnicodeCharacter{2212}{-}
% setting bookdown frontmatter option
\frontmatter

\usepackage{framed}
\setlength{\fboxsep}{.8em}
\usepackage{tcolorbox}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Targeted Learning in R}
\providecommand{\subtitle}[1]{}
\subtitle{Causal Data Science with the tlverse Software Ecosystem}
\author{Mark van der Laan, Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips, Alan Hubbard}
\date{September 21, 2021}

\begin{document}
\maketitle

% you may need to leave a few empty pages before the dedication page

%\cleardoublepage\newpage\thispagestyle{empty}\null
%\cleardoublepage\newpage\thispagestyle{empty}\null
%\cleardoublepage\newpage
\thispagestyle{empty}

\begin{center}
%\includegraphics{images/dedication.pdf}
\end{center}

\setlength{\abovedisplayskip}{-5pt}
\setlength{\abovedisplayshortskip}{-5pt}

% setting bookdown mainmatter (e.g., arabic numerals for page numbering)
\mainmatter

{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\hypertarget{about-this-book}{%
\chapter*{About this book}\label{about-this-book}}


\emph{Targeted Learning in \passthrough{\lstinline!R!}: Causal Data Science with the \passthrough{\lstinline!tlverse!} Software
Ecosystem} is an open source, reproducible electronic handbook for applying the
Targeted Learning methodology in practice using the \href{https://github.com/tlverse}{\passthrough{\lstinline!tlverse!} software
ecosystem}. This work is currently in an early draft
phase and is available to facilitate input from the community. To view or
contribute to the available content, consider visiting the \href{https://github.com/tlverse/tlverse-handbook}{GitHub
repository}.

\hypertarget{outline}{%
\section{Outline}\label{outline}}

The contents of this handbook are meant to serve as a reference guide for
applied research as well as materials that can be taught in a series of short
courses focused on the applications of Targeted Learning. Each section
introduces a set of distinct causal questions, motivated by a case study,
alongside statistical methodology and software for assessing the causal claim of
interest. The (evolving) set of materials includes

\begin{itemize}
\tightlist
\item
  Motivation: \href{https://senseaboutscienceusa.org/super-learning-and-the-revolution-in-knowledge/}{Why we need a statistical
  revolution}
\item
  The Roadmap and introductory case study: the WASH Beneifits data
\item
  Introduction to the \href{https://tlverse.org}{\passthrough{\lstinline!tlverse!} software
  ecosystem}
\item
  Cross-validation with the \href{https://github.com/tlverse/origami}{\passthrough{\lstinline!origami!}}
  package
\item
  Ensemble machine learning with the
  \href{https://github.com/tlverse/sl3}{\passthrough{\lstinline!sl3!}} package
\item
  Targeted learning for causal inference with the
  \href{https://github.com/tlverse/tmle3}{\passthrough{\lstinline!tmle3!}} package
\item
  Optimal treatments regimes and the
  \href{https://github.com/tlverse/tmle3mopttx}{\passthrough{\lstinline!tmle3mopttx!}} package
\item
  Stochastic treatment regimes and the
  \href{https://github.com/tlverse/tmle3shift}{\passthrough{\lstinline!tmle3shift!}} package
\item
  Causal mediation analysis with the
  \href{https://github.com/tlverse/tmle3mediate}{\passthrough{\lstinline!tmle3mediate!}} package
\item
  \emph{Coda}: \href{https://senseaboutscienceusa.org/super-learning-and-the-revolution-in-knowledge/}{Why we need a statistical
  revolution}
\end{itemize}

\hypertarget{what-this-book-is-not}{%
\section*{What this book is not}\label{what-this-book-is-not}}


The focus of this work is \textbf{not} on providing in-depth technical descriptions
of current statistical methodology or recent advancements. Instead, the goal is
to convey key details of state-of-the-art techniques in an manner that is both
clear and complete, without burdening the reader with extraneous information.
We hope that the presentations herein will serve as references for researchers
-- methodologists and domain specialists alike -- that empower them to deploy
the central tools of Targeted Learning in an efficient manner. For technical
details and in-depth descriptions of both classical theory and recent advances
in the field of Targeted Learning, the interested reader is invited to consult
\citet{vdl2011targeted} and/or \citet{vdl2018targeted} as appropriate. The primary literature
in statistical causal inference, machine learning, and non/semiparametric theory
include many of the most recent advances in Targeted Learning and related areas.

\hypertarget{about-the-authors}{%
\section*{About the authors}\label{about-the-authors}}


\hypertarget{mark-van-der-laan}{%
\subsection*{Mark van der Laan}\label{mark-van-der-laan}}


Mark van der Laan, PhD, is Professor of Biostatistics and Statistics at UC
Berkeley. His research interests include statistical methods in computational
biology, survival analysis, censored data, adaptive designs, targeted maximum
likelihood estimation, causal inference, data-adaptive loss-based learning, and
multiple testing. His research group developed loss-based super learning in
semiparametric models, based on cross-validation, as a generic optimal tool for
the estimation of infinite-dimensional parameters, such as nonparametric density
estimation and prediction with both censored and uncensored data. Building on
this work, his research group developed targeted maximum likelihood estimation
for a target parameter of the data-generating distribution in arbitrary
semiparametric and nonparametric models, as a generic optimal methodology for
statistical and causal inference. Most recently, Mark's group has focused in
part on the development of a centralized, principled set of software tools for
targeted learning, the \passthrough{\lstinline!tlverse!}.

\hypertarget{jeremy-coyle}{%
\subsection*{Jeremy Coyle}\label{jeremy-coyle}}


Jeremy Coyle, PhD, is a consulting data scientist and statistical programmer,
currently leading the software development effort that has produced the
\passthrough{\lstinline!tlverse!} ecosystem of R packages and related software tools. Jeremy earned his
PhD in Biostatistics from UC Berkeley in 2016, primarily under the supervision
of Alan Hubbard.

\hypertarget{nima-hejazi}{%
\subsection*{Nima Hejazi}\label{nima-hejazi}}


Nima Hejazi is a PhD candidate in biostatistics, working under the collaborative
direction of Mark van der Laan and Alan Hubbard. Nima is affiliated with UC
Berkeley's Center for Computational Biology and NIH Biomedical Big Data training
program, as well as with the Fred Hutchinson Cancer Research Center. Previously,
he earned an MA in Biostatistics and a BA (with majors in Molecular and Cell
Biology, Psychology, and Public Health), both at UC Berkeley. His research
interests fall at the intersection of causal inference and machine learning,
drawing on ideas from non/semi-parametric estimation in large, flexible
statistical models to develop efficient and robust statistical procedures for
evaluating complex target estimands in observational and randomized studies.
Particular areas of current emphasis include mediation/path analysis,
outcome-dependent sampling designs, targeted loss-based estimation, and vaccine
efficacy trials. Nima is also passionate about statistical computing and open
source software development for applied statistics.

\hypertarget{ivana-malenica}{%
\subsection*{Ivana Malenica}\label{ivana-malenica}}


Ivana Malenica is a PhD student in biostatistics advised by Mark van der Laan.
Ivana is currently a fellow at the Berkeley Institute for Data Science, after
serving as a NIH Biomedical Big Data and Freeport-McMoRan Genomic Engine fellow.
She earned her Master's in Biostatistics and Bachelor's in Mathematics, and
spent some time at the Translational Genomics Research Institute. Very broadly,
her research interests span non/semi-parametric theory, probability theory,
machine learning, causal inference and high-dimensional statistics. Most of her
current work involves complex dependent settings (dependence through time and
network) and adaptive sequential designs.

\hypertarget{rachael-phillips}{%
\subsection*{Rachael Phillips}\label{rachael-phillips}}


Rachael Phillips is a PhD student in biostatistics, advised by Alan Hubbard and
Mark van der Laan. She has an MA in Biostatistics, BS in Biology, and BA in
Mathematics. A student of targeted learning and causal inference, Rachael's
research focuses on statistical estimation and inference in realistic
statistical models. Her current projects involve personalized online machine
learning from EHR streaming data of vital signs, automated learning with
highly adaptive lasso, and causal effect estimation for community-level
interventions. She is also working on an FDA-funded project led Dr.~Susan
Gruber, A Targeted Learning Framework for Causal Effect Estimation Using
Real-World Data. Rachael is an active contributor to the \passthrough{\lstinline!hal9001!} and \passthrough{\lstinline!sl3!}
R packages in the \passthrough{\lstinline!tlverse!}.

\hypertarget{alan-hubbard}{%
\subsection*{Alan Hubbard}\label{alan-hubbard}}


Alan Hubbard is Professor of Biostatistics, former head of the Division of
Biostatistics at UC Berkeley, and head of data analytics core at UC Berkeley's
SuperFund research program. His current research interests include causal
inference, variable importance analysis, statistical machine learning,
estimation of and inference for data-adaptive statistical target parameters, and
targeted minimum loss-based estimation. Research in his group is generally
motivated by applications to problems in computational biology, epidemiology,
and precision medicine.

\hypertarget{learn}{%
\section{Learning resources}\label{learn}}

To effectively utilize this handbook, the reader need not be a fully trained
statistician to begin understanding and applying these methods. However, it is
highly recommended for the reader to have an understanding of basic statistical
concepts such as confounding, probability distributions, confidence intervals,
hypothesis tests, and regression. Advanced knowledge of mathematical statistics
may be useful but is not necessary. Familiarity with the \passthrough{\lstinline!R!} programming
language will be essential. We also recommend an understanding of introductory
causal inference.

For learning the \passthrough{\lstinline!R!} programming language we recommend the following (free)
introductory resources:

\begin{itemize}
\tightlist
\item
  \href{http://swcarpentry.github.io/r-novice-inflammation/}{Software Carpentry's \emph{Programming with
  \passthrough{\lstinline!R!}}}
\item
  \href{http://swcarpentry.github.io/r-novice-gapminder/}{Software Carpentry's \emph{\passthrough{\lstinline!R!} for Reproducible Scientific
  Analysis}}
\item
  \href{https://r4ds.had.co.nz}{Garret Grolemund and Hadley Wickham's \emph{\passthrough{\lstinline!R!} for Data
  Science}}
\end{itemize}

For a general introduction to causal inference, we recommend

\begin{itemize}
\tightlist
\item
  \href{https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/}{Miguel A. Hernán and James M. Robins' \emph{Causal Inference: What If},
  2021}
\item
  \href{https://www.coursera.org/learn/crash-course-in-causality}{Jason A. Roy's \emph{A Crash Course in Causality: Inferring Causal Effects from
  Observational Data} on
  Coursera}
\end{itemize}

\hypertarget{setup}{%
\section{Setup instructions}\label{setup}}

\hypertarget{r-and-rstudio}{%
\subsection{R and RStudio}\label{r-and-rstudio}}

\textbf{R} and \textbf{RStudio} are separate downloads and installations. R is the
underlying statistical computing environment. RStudio is a graphical integrated
development environment (IDE) that makes using R much easier and more
interactive. You need to install R before you install RStudio.

\hypertarget{windows}{%
\subsubsection{Windows}\label{windows}}

\hypertarget{if-you-already-have-r-and-rstudio-installed}{%
\paragraph{If you already have R and RStudio installed}\label{if-you-already-have-r-and-rstudio-installed}}

\begin{itemize}
\tightlist
\item
  Open RStudio, and click on ``Help'' \textgreater{} ``Check for updates''. If a new version is
  available, quit RStudio, and download the latest version for RStudio.
\item
  To check which version of R you are using, start RStudio and the first thing
  that appears in the console indicates the version of R you are
  running. Alternatively, you can type \passthrough{\lstinline!sessionInfo()!}, which will also display
  which version of R you are running. Go on the \href{https://cran.r-project.org/bin/windows/base/}{CRAN
  website} and check whether a
  more recent version is available. If so, please download and install it. You
  can \href{https://cran.r-project.org/bin/windows/base/rw-FAQ.html\#How-do-I-UNinstall-R_003f}{check here}
  for more information on how to remove old versions from your system if you
  wish to do so.
\end{itemize}

\hypertarget{if-you-dont-have-r-and-rstudio-installed}{%
\paragraph{If you don't have R and RStudio installed}\label{if-you-dont-have-r-and-rstudio-installed}}

\begin{itemize}
\tightlist
\item
  Download R from
  the \href{http://cran.r-project.org/bin/windows/base/release.htm}{CRAN website}.
\item
  Run the \passthrough{\lstinline!.exe!} file that was just downloaded
\item
  Go to the \href{https://www.rstudio.com/products/rstudio/download/\#download}{RStudio download page}
\item
  Under \emph{Installers} select \textbf{RStudio x.yy.zzz - Windows
  XP/Vista/7/8} (where x, y, and z represent version numbers)
\item
  Double click the file to install it
\item
  Once it's installed, open RStudio to make sure it works and you don't get any
  error messages.
\end{itemize}

\hypertarget{macos-mac-os-x}{%
\subsubsection{macOS / Mac OS X}\label{macos-mac-os-x}}

\hypertarget{if-you-already-have-r-and-rstudio-installed-1}{%
\paragraph{If you already have R and RStudio installed}\label{if-you-already-have-r-and-rstudio-installed-1}}

\begin{itemize}
\tightlist
\item
  Open RStudio, and click on ``Help'' \textgreater{} ``Check for updates''. If a new version is
  available, quit RStudio, and download the latest version for RStudio.
\item
  To check the version of R you are using, start RStudio and the first thing
  that appears on the terminal indicates the version of R you are running.
  Alternatively, you can type \passthrough{\lstinline!sessionInfo()!}, which will also display which
  version of R you are running. Go on the \href{https://cran.r-project.org/bin/macosx/}{CRAN
  website} and check whether a more
  recent version is available. If so, please download and install it.
\end{itemize}

\hypertarget{if-you-dont-have-r-and-rstudio-installed-1}{%
\paragraph{If you don't have R and RStudio installed}\label{if-you-dont-have-r-and-rstudio-installed-1}}

\begin{itemize}
\tightlist
\item
  Download R from
  the \href{http://cran.r-project.org/bin/macosx}{CRAN website}.
\item
  Select the \passthrough{\lstinline!.pkg!} file for the latest R version
\item
  Double click on the downloaded file to install R
\item
  It is also a good idea to install \href{https://www.xquartz.org/}{XQuartz} (needed
  by some packages)
\item
  Go to the \href{https://www.rstudio.com/products/rstudio/download/\#download}{RStudio download
  page}
\item
  Under \emph{Installers} select \textbf{RStudio x.yy.zzz - Mac OS X 10.6+ (64-bit)}
  (where x, y, and z represent version numbers)
\item
  Double click the file to install RStudio
\item
  Once it's installed, open RStudio to make sure it works and you don't get any
  error messages.
\end{itemize}

\hypertarget{linux}{%
\subsubsection{Linux}\label{linux}}

\begin{itemize}
\tightlist
\item
  Follow the instructions for your distribution
  from \href{https://cloud.r-project.org/bin/linux}{CRAN}, they provide information
  to get the most recent version of R for common distributions. For most
  distributions, you could use your package manager (e.g., for Debian/Ubuntu run
  \passthrough{\lstinline!sudo apt-get install r-base!}, and for Fedora \passthrough{\lstinline!sudo yum install R!}), but we
  don't recommend this approach as the versions provided by this are
  usually out of date. In any case, make sure you have at least R 3.3.1.
\item
  Go to the \href{https://www.rstudio.com/products/rstudio/download/\#download}{RStudio download
  page}
\item
  Under \emph{Installers} select the version that matches your distribution, and
  install it with your preferred method (e.g., with Debian/Ubuntu \passthrough{\lstinline!sudo dpkg -i rstudio-x.yy.zzz-amd64.deb!} at the terminal).
\item
  Once it's installed, open RStudio to make sure it works and you don't get any
  error messages.
\end{itemize}

These setup instructions are adapted from those written for \href{http://www.datacarpentry.org/R-ecology-lesson/}{Data Carpentry: R
for Data Analysis and Visualization of Ecological
Data}.

\hypertarget{robust}{%
\chapter{Robust Statistics and Reproducible Science}\label{robust}}

\begin{quote}
``One enemy of robust science is our humanity -- our appetite for
being right, and our tendency to find patterns in noise, to see supporting
evidence for what we already believe is true, and to ignore the facts that do
not fit.''

--- \citet{naturenews_2015}
\end{quote}

Scientific research is at a unique point in its history. The need to improve
rigor and reproducibility in our field is greater than ever; corroboration moves
science forward, yet there is growing alarm that results cannot be reproduced or
validated, suggesting the possibility that many discoveries may be false
\citep{baker2016there}. Consequences of not meeting this need will result in further
decline in the rate of scientific progress, the reputation of the sciences, and
the public's trust in scientific findings \citep{munafo2017manifesto, naturenews2_2015}.

\begin{quote}
``The key question we want to answer when seeing the results of any scientific
study is whether we can trust the data analysis.''

--- \citet{peng2015reproducibility}
\end{quote}

Unfortunately, in its current state, the culture of statistical data analysis
enables, rather than precludes, the manner in which human bias may affect the
results of (ideally objective) data analytic efforts. A significant degree of
human bias enters statistical analysis efforts in the form improper model
selection. All procedures for estimation and hypothesis testing are derived
based on a choice of statistical model; thus, obtaining valid estimates and
statistical inference relies critically on the chosen statistical model
containing an accurate representation of the process that generated the data.
Consider, for example, a hypothetical study in which a treatment was assigned to
a group of patients: Was the treatment assigned randomly or were characteristics
of the individuals (i.e., baseline covariates) used in making the treatment
decision? Such knowledge can should be incorporated in the statistical model.
Alternatively, the data could be from an observational study, in which there is
no control over the treatment assignment mechanism. In such cases, available
knowledge about the data-generating process (DGP) is more limited still. If
this is the case, then the statistical model should contain \emph{all} possible
distributions of the data. In practice, however, models are not selected based
on scientific knowledge available about the DGP; instead, models are often
selected based on (1) the philosophical leanings of the analyst, (2) the
relative convenience of implementation of statistical methods admissible within
the choice of model, and (3) the results of significance testing (i.e.,
p-values) applied within the choice of model.

This practice of ``cargo-cult statistics --- the ritualistic miming of statistics
rather than conscientious practice,'' \citep{stark2018cargo} is characterized by
arbitrary modeling choices, even though these choices often result in different
answers to the same research question. That is, ``increasingly often,
{[}statistics{]} is used instead to aid and abet weak science, a role it can perform
well when used mechanically or ritually,'' as opposed to its original purpose of
safeguarding against weak science by providing formal techniques for evaluating
the veracity of a claim using properly collected data \citep{stark2018cargo}. This
presents a fundamental drive behind the epidemic of false findings from which
scientific research is suffering \citep{vdl2014entering}.

\begin{quote}
``We suggest that the weak statistical understanding is probably due to
inadequate''statistics lite" education. This approach does not build up
appropriate mathematical fundamentals and does not provide scientifically
rigorous introduction into statistics. Hence, students' knowledge may remain
imprecise, patchy, and prone to serious misunderstandings. What this approach
achieves, however, is providing students with false confidence of being able
to use inferential tools whereas they usually only interpret the p-value
provided by black box statistical software. While this educational problem
remains unaddressed, poor statistical practices will prevail regardless of
what procedures and measures may be favored and/or banned by editorials."

--- \citet{szucs2017null}
\end{quote}

Our team at the University of California, Berkeley is uniquely positioned to
provide such an education. Spearheaded by Professor Mark van der Laan, and
spreading rapidly by many of his students and colleagues who have greatly
enriched the field, the aptly named ``Targeted Learning'' methodology emphasizes a
focus of (i.e., ``targeting of'') the scientific question at hand, running counter
to the current culture problem of ``convenience statistics,'' which opens the door
to biased estimation, misleading analytic results, and erroneous discoveries.
Targeted Learning embraces the fundamentals that formalized the field of
statistics, notably including the notions that a statistical model must
represent real knowledge about the experiment that generated the data and that a
target parameter represents what we are seeking to learn from the data as a
feature of the distribution that generated it \citep{vdl2014entering}. In this way,
Targeted Learning defines a truth and establishes a principled standard for
estimation, thereby curtailing our all-too-human biases (e.g., hindsight bias,
confirmation bias, and outcome bias) from infiltrating our objective analytic
efforts.

\begin{quote}
``The key for effective classical {[}statistical{]} inference is to have
well-defined questions and an analysis plan that tests those questions.''

--- \citet{nosek2018preregistration}
\end{quote}

This handbook aims to provide practical training to students, researchers,
industry professionals, and academicians in the sciences (whether biological,
physical, economic, or social), public health, statistics, and numerous other
fields, to equip them with the necessary knowledge and skills to utilize the the
methodological developments of Targeted Learning --- a technique that provides
tailored pre-specified machines for answering queries --- taking advantage of
estimators that are efficient, minimally biased, and that provide formal
statistical inference --- so that each and every data analysis incorporates
state-of-the-art statistical methodology, all while ensuring compatibility with
the guiding principles of computational reproducibility.

Just as the conscientious use of modern statistical methodology is necessary to
ensure that scientific practice thrives, robust, well-tested software plays a
critical role in allowing practitioners to direct access the published results
of a given scientific investigation. In fact, ``an article\ldots{}in a scientific
publication is not the scholarship itself, it is merely advertising of the
scholarship. The actual scholarship is the complete software development
environment and the complete set of instructions which generated the figures,''
thus making the availability and adoption of robust statistical software key to
enhancing the transparency that is an inherent (and assumed) aspect of the
scientific process \citep{buckheit1995wavelab}.

For a statistical methodology to be readily accessible in practice, it is
crucial that it is accompanied by user-friendly software
\citep{pullenayegum2016knowledge, stromberg2004write}. The \passthrough{\lstinline!tlverse!} software
ecosystem, composed of a set of package for the \passthrough{\lstinline!R!} language and environment for
statistical computing \citep{R}, was developed to fulfill this need for the Targeted
Learning methodological framework. Not only does this suite of software tools
facilitate computationally reproducible and efficient analyses, it is also a
tool for Targeted Learning education, since its workflow mirrors the central
aspects of the statistical methodology. In particular, the programming paradigm
central to the \passthrough{\lstinline!tlverse!} ecosystem does not focus on implementing a specific
estimator or a small set of related estimators. Instead, the focus is on
exposing the statistical framework of Targeted Learning itself --- all software
packages in the \passthrough{\lstinline!tlverse!} ecosystem directly model the key objects defined in
the mathematical and theoretical framework of Targeted Learning. What's more,
the \passthrough{\lstinline!tlverse!} software packages share a core set of design principles centered
on extensibility, allowing for them all to be used in conjunction with each
other and even used cohesively as building blocks for formulating sophisticated
statistical analyses. For an introduction to the Targeted Learning framework, we
recommend a \href{https://arxiv.org/abs/2006.07333}{recent review paper} from
\citet{coyle2021targeted}.

In this handbook, the reader will embark on a journey through the \passthrough{\lstinline!tlverse!}
ecosystem. Guided by \passthrough{\lstinline!R!} programming exercises, case studies, and
intuition-building explanations, readers will learn to use a toolbox for
applying the Targeted Learning statistical methodology, which will translate to
real-world causal inference analyses. Some preliminaries are required prior to
this learning endeavor -- we have made available a list of \protect\hyperlink{learn}{recommended learning
resources}.

\hypertarget{intro}{%
\chapter{The Roadmap for Targeted Learning}\label{intro}}

\emph{Nima Hejazi} and \emph{Rachael Phillips}

Updated: 2021-09-21

\begin{VT1}
\VH{Learning Objectives}



In this chapter, we provide guidance on how to

1. Translate scientific questions to statistical questions.
2. Define a statistical model based on the knowledge of the experiment that
   generated the data.
3. Identify a causal parameter as a function of the observed data distribution.
4. Explain the following statistical and causal assumptions and their
   implications: i.i.d., consistency, no unmeasured confounding, interference,
   positivity.

\end{VT1}

\hypertarget{introduction}{%
\section*{Introduction}\label{introduction}}


The roadmap of statistical learning is concerned with the translation from
real-world data applications to a mathematical and statistical formulation of
the relevant estimation problem. This involves data as a random variable having
a probability distribution, scientific knowledge represented by a statistical
model, a statistical target parameter representing an answer to the question of
interest, and the notion of an estimator and sampling distribution of the
estimator.

\hypertarget{roadmap}{%
\section{The Roadmap}\label{roadmap}}

The roadmap is a five-stage process of defining the following.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Data as a random variable with a probability distribution, \(O \sim P_0\).
\item
  The statistical model \(\M\) such that \(P_0 \in \M\).
\item
  The statistical target parameter \(\Psi\) and estimand \(\Psi(P_0)\).
\item
  The estimator \(\hat{\Psi}\) and estimate \(\hat{\Psi}(P_n)\).
\item
  A measure of uncertainty for the estimate \(\hat{\Psi}(P_n)\).
\end{enumerate}

\hypertarget{data-a-random-variable-with-a-probability-distribution-o-sim-p_0}{%
\subsection*{\texorpdfstring{(1) Data: A random variable with a probability distribution, \(O \sim P_0\)}{(1) Data: A random variable with a probability distribution, O \textbackslash{}sim P\_0}}\label{data-a-random-variable-with-a-probability-distribution-o-sim-p_0}}


The data set we are confronted with is the collection of the results of an
experiment, and we can view the data as a \emph{random variable} -- that is, if we
were to repeat the experiment, we would have a different realization of the data
generated by the experiment in question. In particular, if the experiment were
repeated many times, the probability distribution generating the data, \(P_0\),
could be learned. So, the observed data on a single unit, \(O\), may be thought of
as being drawn from a probability distribution \(P_0\). Most often, we observe \(n\)
\emph{independent identically distributed} (i.i.d.) observations of the random
variable \(O\), so the observed data is the collection \(O_1, \ldots, O_n\), where
the subscripts denote the individual observational units. While not all data
are i.i.d., this is certainly the most common case in applied data analysis;
moreover, there are a number of techniques for handling non-i.i.d. data, such as
establishing conditional independence, stratifying data to create distinct sets
of identically distributed data, and inferential corrections for repeated or
clustered observations, to name but a few.

It is crucial that the domain scientist (i.e., researcher) have absolute clarity
about what is actually known about the data-generating distribution for a given
problem of interest. Just as critical is that this scientific information be
communicated to the statistician, whose job it is to use such knowledge to guide
any assumptions encoded in the choice of statistical model. Unfortunately,
communication between statisticians and researchers is often fraught with
misinterpretation. The roadmap provides a mechanism by which to ensure clear
communication between the researcher and the statistician -- it is an invaluable
tool for such communication!

\hypertarget{the-empirical-probability-measure-p_n}{%
\subsubsection*{\texorpdfstring{The empirical probability measure, \(P_n\)}{The empirical probability measure, P\_n}}\label{the-empirical-probability-measure-p_n}}


With \(n\) i.i.d. observations in hand, we can define an empirical probability
measure, \(P_n\). The empirical probability measure is an approximation of the
true probability measure, \(P_0\), allowing us to learn from the observed data.
For example, we can define the empirical probability measure of a set \(X\) to be
the proportion of observations that belong in \(X\). That is,
\begin{equation*}
  P_n(X) = \frac{1}{n}\sum_{i=1}^{n} \I(O_i \in X)
\end{equation*}

In order to start learning from the data, we next need to ask \emph{``What do we know
about the probability distribution of the data?''} This brings us on to Step 2.

\hypertarget{defining-the-statistical-model-m-such-that-p_0-in-m}{%
\subsection*{\texorpdfstring{(2) Defining the statistical model \(\M\) such that \(P_0 \in \M\)}{(2) Defining the statistical model \textbackslash{}M such that P\_0 \textbackslash{}in \textbackslash{}M}}\label{defining-the-statistical-model-m-such-that-p_0-in-m}}


The statistical model \(\M\) is defined by the question we asked at the end of
Step 1. It is the set of possible probability distributions that
could describe our observed data, appropriately constrained by background
scientific knowledge. Often \(\M\) is very large (e.g., nonparametric),
reflecting the fact that statistical knowledge about
the data-generating process is limited.

Alternatively, if the probability distribution of the data at hand is described
by a finite number of parameters, then the statistical model is referred to as
\emph{parametric}. Such an assumption is made, for example, by the proposition that
the random variable of interest, \(O\), has a normal distribution with mean \(\mu\)
and variance \(\sigma^2\). More generally, a parametric model may be defined as

\begin{equation*}
  \M = \{P_{\theta} : \theta \in \R^d \},
\end{equation*}
which describes a statistical model consisting of all distributions
\(P_{\theta}\), that is all distributions indexed only by the parameter \(\theta\).

The assumption that the data-generating distribution has a specific, parametric
form is made quite commonly, even when such assumptions are not supported by
existing knowledge. This practice of oversimplification in the current culture
of data analysis typically complicates any attempt at trying to answer the
scientific question at hand, owing to the fact that possible model
misspecification introduces bias of unknown magnitude. The philosophy used to
justify such parametric assumptions is captured by the quote of George Box that
``All models are wrong but some are useful,'' which encourages the data analyst to
make arbitrary modeling choices. The result is a practice of data science that
often yields starkly different answers to the same scientific problem, due to
the differing modeling decisions and assumptions made by different analysts.
Even in the nascent days of data analysis, it was recognized that it is ``far
better {[}to develop{]} an approximate answer to the right question\ldots{}than an exact
answer to the wrong question, which can always be made precise''
\citep{tukey1962future}, though traditional statistics failed to heed this advice for
a number of decades \citep{donoho2017fifty}. The Targeted Learning paradigm avoids
this bias by defining the statistical model through a representation of the true
data-generating distribution corresponding to the observed data. The ultimate
goal is to formulate the statistical estimation problem \emph{exactly}, so that one
can then set out to tailor to the problem the best possible estimation
procedure.

Now, on to Step 3: \emph{``What are we trying to learn from the data?''}

\hypertarget{the-statistical-target-parameter-psi-and-estimand-psip_0}{%
\subsection*{\texorpdfstring{(3) The statistical target parameter \(\Psi\) and estimand \(\Psi(P_0)\)}{(3) The statistical target parameter \textbackslash{}Psi and estimand \textbackslash{}Psi(P\_0)}}\label{the-statistical-target-parameter-psi-and-estimand-psip_0}}


The statistical target parameter, \(\Psi\), is defined as a mapping from the
statistical model, \(\M\), to the parameter space (i.e., a real number) \(\R\) --
that is, the target parameter is the mapping \(\Psi: \M \rightarrow \R\). The
estimand may be seen as a representation of the quantity that we wish to learn
from the data, the answer to a well-specified (often causal) question of
interest. In contrast to purely statistical estimands, causal estimands require
\emph{identification from the observed data}, based on causal models that include
several untestable assumptions, described in greater detail in the section on
\protect\hyperlink{causal}{causal target parameters}.

For a simple example, consider a data set which contains observations of a
survival time on every subject, for which our question of interest is ``What's
the probability that someone lives longer than five years?'' We have,

\begin{equation*}
  \Psi(P_0) = \P_O(O > 5) = \int_5^{\infty} dP_O(o)
\end{equation*}

This answer to this question is the \textbf{estimand, \(\Psi(P_0)\)}, which is the
quantity we wish to learn from the data. Once we have defined \(O\), \(\M\) and
\(\Psi(P_0)\) we have formally defined the statistical estimation problem.

\hypertarget{the-estimator-hatpsi-and-estimate-hatpsip_n}{%
\subsection*{\texorpdfstring{(4) The estimator \(\hat{\Psi}\) and estimate \(\hat{\Psi}(P_n)\)}{(4) The estimator \textbackslash{}hat\{\textbackslash{}Psi\} and estimate \textbackslash{}hat\{\textbackslash{}Psi\}(P\_n)}}\label{the-estimator-hatpsi-and-estimate-hatpsip_n}}


Typically, we will focus on estimation in realistic, nonparametric models. To
obtain a good approximation of the estimand, we need an estimator, an \emph{a
priori}-specified algorithm defined as a mapping from the set of possible
empirical distributions, \(P_n\), which live in a non-parametric statistical
model, \(\M_{NP}\) (\(P_n \in \M_{NP}\)), to the parameter space of the parameter of
interest. That is, \(\hat{\Psi} : \M_{NP} \rightarrow \R^d\). The estimator is a
function that takes as input the observed data, a realization of \(P_n\), and
gives as output a value in the parameter space, which is the \textbf{estimate,
\(\hat{\Psi}(P_n)\)}.

Where the estimator may be seen as an operator that maps the observed data and
corresponding empirical distribution to a value in the parameter space, the
numerical output that produced such a function is the estimate. Thus, it is an
element of the parameter space based on the empirical probability distribution
of the observed data. If we plug in a realization of \(P_n\) (based on a sample
size \(n\) of the random variable \(O\)), we get back an estimate \(\hat{\Psi}(P_n)\)
of the true parameter value \(\Psi(P_0)\).

In order to quantify the uncertainty in our estimate of the target parameter
(i.e., to construct statistical inference), an understanding of the sampling
distribution of our estimator will be necessary. This brings us to Step 5.

\hypertarget{a-measure-of-uncertainty-for-the-estimate-hatpsip_n}{%
\subsection*{\texorpdfstring{(5) A measure of uncertainty for the estimate \(\hat{\Psi}(P_n)\)}{(5) A measure of uncertainty for the estimate \textbackslash{}hat\{\textbackslash{}Psi\}(P\_n)}}\label{a-measure-of-uncertainty-for-the-estimate-hatpsip_n}}


Since the estimator \(\hat{\Psi}\) is a function of the empirical distribution
\(P_n\), the estimator itself is a random variable with a sampling distribution.
So, if we repeat the experiment of drawing \(n\) observations we would every time
end up with a different realization of our estimate and our estimator has a
sampling distribution.

A primary goal in the construction of estimators is to be able to derive their
asymptotic sampling distributions through a theoretical analysis of a given
estimator. In this regard, an important property of the estimators on which we
focus is their asymptotic linearity, which states that the difference between
the estimator and the target estimand (i.e., the truth) can be represented,
asymptotically, as an average of i.i.d. random variables:

\begin{equation*}
  \hat{\Psi}(P_n) - \Psi(P_0) = \frac{1}{n} \sum_{i=1}^n IC(O_i; \nu) +
    o_p(n^{-1/2}),
\end{equation*}
where \(\nu\) represents possible nuisance parameters on which the influence curve
(IC) depends. Based on the validity of the asymptotic approximation, one can
then invoke the central limit theorem (CLT) to show

\begin{equation*}
  \sqrt{n} \left(\hat{\Psi}(P_n) - \Psi(P_0)\right) \sim N(0, \sigma^2_{IC}),
\end{equation*}
where \(\sigma^2_{IC}\) is the variance of \(IC(O_i; \nu)\). Given an estimate of
\(\sigma^2_{IC}\), it is then possible to construct classic, \emph{asymptotically
accurate} Wald-type confidence intervals (CIs) and hypothesis tests. For
example, a standard \((1 - \alpha)\) CI of the form

\begin{equation*}
  \Psi(P_n) \pm Z_{1 - \frac{\alpha}{2}} \hat{\sigma_{IC}} / \sqrt{n},
\end{equation*}
can be constructed, where \(Z_{1 - \frac{\alpha}{2}}\) is the \((1 - \frac{\alpha}{2})^\text{th}\) quantile of the standard normal distribution.
Often, we will be interested in constructing 95\% confidence intervals,
corresponding to mass \(\alpha = 0.05\) in either tail of the limit distribution;
thus, we will typically take \(Z_{1 - \frac{\alpha}{2}} \approx 1.96\).

\hypertarget{roadmap-summary}{%
\section{Summary of the Roadmap}\label{roadmap-summary}}

Data collected across \(n\) i.i.d. units, \(O_1, \ldots, O_n\), can be viewed as a
collection of random variables, \(O\), all arising from the same probability
distribution \(\P_0\). This collection of data may be expressed \(O_1, \ldots, O_n \sim P_0\), where we leverage statistical knowledge available about the
experiment that generated the data. to support the statement that the true data
distribution \(P_0\) falls in a statistical model, \(\M\), which is itself a
collection of candidate probability distributions reflecting the data-generating
experiment. Often these sets -- that is, the statistical model \(\M\) -- must be
very large, to appropriately reflect the fact that statistical knowledge is very
limited. Hence, these \emph{realistic} statistical models are often termed \emph{semi-} or
\emph{non-parametric}, since they are too large to be indexed by a finite-dimensional
set of parameters. Necessarily, our statistical query must begin with, ``What
are we trying to learn from the data?'', a question whose answer is captured by
the statistical target parameter, \(\Psi\), which maps the true data-generating
distribution \(P_0\) into the statistical estimand, \(\Psi(P_0)\). At this point the
statistical estimation problem is formally defined, allowing for the use of
statistical theory to guide the construction of optimal estimators.

\hypertarget{causal}{%
\section{Causal Target Parameters}\label{causal}}

In many cases, we are interested in problems that ask questions regarding the
\emph{causal} effect of an intervention on a future outcome of interest. These causal
effects may be defined as summaries of the population of interest (e.g., the
population mean of a particular outcome) under different conditions (e.g.,
treated versus untreated). For example, a causal effect could be defined as the
difference in the means of a disease outcome between \emph{causal contrasts} in which
the population were to experience low pollution levels (for some pollutant) and
the mean in the same population in the case that high pollution levels were
experienced. There are different ways of operationalizing the theoretical
experiments that generate the counterfactual data necessary for describing our
causal contrasts of interest, including simply assuming that the counterfactual
outcomes exist in theory for all treatment contrasts of interest
\citep{neyman1938contribution, rubin2005causal, imbens2015causal} or through
considering interventions on directed acyclic graphs (DAGs) or nonparametric
structural equation models (NPSEMs) \citep{pearl1995causal, pearl2009causality},
both of which encode the known or hypothesized set of relationships between
variables in the system under study.

\hypertarget{the-causal-model}{%
\subsection*{The Causal Model}\label{the-causal-model}}


We focus on the use of DAGs and NPSEMs for the description of causal parameters.
Estimators of statistical parameters that correspond, under standard but
untestable \emph{identifiability} assumptions, to these causal parameters are
introduced below. DAGs are a particularly useful tool for expressing what we
know about the causal relations among variables in the system under study.
Ignoring exogenous \(U\) terms (explained below), we assume the following ordering
of the variables in the observed data \(O\). We demonstrate the construction of a
DAG below using \passthrough{\lstinline!DAGitty!} \citep{textor2011dagitty}:

\begin{lstlisting}[language=R]
library(dagitty)
library(ggdag)

# make DAG by specifying dependence structure
dag <- dagitty(
  "dag {
    W -> A
    W -> Y
    A -> Y
    W -> A -> Y
  }"
)
exposures(dag) <- c("A")
outcomes(dag) <- c("Y")
tidy_dag <- tidy_dagitty(dag)

# visualize DAG
ggdag(tidy_dag) +
  theme_dag()
\end{lstlisting}

\begin{center}\includegraphics[width=0.8\linewidth]{02-roadmap_files/figure-latex/simple-DAG-1} \end{center}

While DAGs like the above provide a convenient means by which to visualize
causal relations between variables, the same causal relations among variables
can be equivalently represented by an NPSEM:
\begin{align*}
  W &= f_W(U_W) \\
  A &= f_A(W, U_A) \\
  Y &= f_Y(W, A, U_Y),
\end{align*}
where the \(f\)'s are unspecified (non-parametric) functions that generate the
corresponding random variable as a function of the variable's parents (i.e.,
nodes with arrows into the variable) in the DAG and the unobserved, exogenous
error terms (i.e., the \(U\)'s). An NPSEM may be thought of as a representation
of the algorithm that produces the data, \(O\), in the population of interest.
Much of statistics and data science is devoted to discovering properties of this
system of equations (e.g., estimation of the prediction function \(f_Y\)).

The first hypothetical experiment we will consider is assigning exposure to the
entire population and observing the outcome, and then withholding exposure to
the same population and observing the outcome. This corresponds to a comparison
of the outcome distribution in the population under two interventions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(A\) is set to \(1\) for all individuals, and
\item
  \(A\) is set to \(0\) for all individuals.
\end{enumerate}

These interventions imply two new sets of nonparametric structural equations
For the case \(A = 1\), we have
\begin{align*}
  W &= f_W(U_W) \\
  A &= 1 \\
  Y(1) &= f_Y(W, 1, U_Y),
\end{align*}
while, for the case \(A=0\),
\begin{align*}
  W &= f_W(U_W) \\
  A &= 0 \\
  Y(0) &= f_Y(W, 0, U_Y).
\end{align*}

In these equations, \(A\) is no longer a function of \(W\) because of the
intervention on the system that set \(A\) deterministically to either of the
values \(1\) or \(0\). The new symbols \(Y(1)\) and \(Y(0)\) indicate the outcome
variable in the population of interest when it is generated by the respective
NPSEMs above; these are often called \emph{counterfactuals}. The difference between
the means of the outcome under these two interventions defines a parameter that
is often called the ``average treatment effect'' (ATE), denoted

\begin{equation}
  ATE = \E_X(Y(1) - Y(0)),
  \label{eq:ate}
\end{equation}
where \(\E_X\) is the mean under the theoretical (unobserved) full data \(X = (W, Y(1), Y(0))\).

Note, we can define much more complicated interventions on NPSEM's, such as
interventions based upon rules (themselves based upon covariates), stochastic
rules, etc. and each results in a different targeted parameter and entails
different identifiability assumptions discussed below.

\hypertarget{identifiability}{%
\subsection*{Identifiability}\label{identifiability}}


Because we can never observe both \(Y(0)\) (the counterfactual outcome when \(A=0\))
and \(Y(1)\) (similarly, the counterfactual outcome when \(A=1\)), we cannot
estimate the quantity in Equation \eqref{eq:ate} directly. Thus, the primary task
of causal inference methods in our context is to \emph{identify} the assumptions
necessary to express causal quantities of interest as functions of the
data-generating distribution. We have to make assumptions under which this
quantity may be estimated from the observed data \(O \sim P_0\) under the
data-generating distribution \(P_0\). Fortunately, given the causal model
specified in the NPSEM above, we can, with a handful of untestable assumptions,
estimate the ATE from observational data. These assumptions may be summarized as
follows.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{No unmeasured confounding}: \(A \perp Y(a) \mid W\) for all \(a \in \mathcal{A}\), which states that the potential outcomes \((Y(a) : a \in \mathcal{A})\) arise independently from exposure status \(A\), conditional on
  the observed covariates \(W\). This is the analog of the \emph{randomization}
  assumption in data arising from natural experiments, ensuring that the effect
  of \(A\) on \(Y\) can be disentangled from that of \(W\) on \(Y\), even though \(W\)
  affects both.
\item
  \emph{No interference} between units: the outcome for unit \(i\), \(Y_i\), cannot
  be affected by the exposure of unit \(j\), \(A_j\), for all \(i \neq j\).
\item
  \emph{Consistency} of the treatment mechanism is also required, i.e., the outcome
  for unit \(i\) is \(Y_i(a)\) whenever \(A_i = a\), an assumption also known as ``no
  other versions of treatment''.
\item
  \emph{Positivity} or \emph{overlap}: All observed units, across strata defined by \(W\),
  must have a bounded (non-deterministic) probability of receiving treatment --
  that is, \(0 < \P(A = a \mid W) < 1\) for all \(a\) and \(W\)).
\end{enumerate}

Given these assumptions, the ATE may be re-written as a function of \(P_0\),
specifically

\begin{equation}
  ATE = \E_0(Y(1) - Y(0)) = \E_0
    \left(\E_0[Y \mid A = 1, W] - \E_0[Y \mid A = 0, W]\right).
  \label{eq:estimand}
\end{equation}
In words, the ATE is the difference in the predicted outcome values for each
subject, under the contrast of treatment conditions (\(A = 0\) versus \(A = 1\)),
in the population, averaged over all observations. Thus, a parameter of a
theoretical ``full'' data distribution can be represented as an estimand of the
observed data distribution. Significantly, there is nothing about the
representation in Equation \eqref{eq:estimand} that requires parameteric
assumptions; thus, the regressions on the right hand side may be estimated.
With different parameters, there will be potentially different identifiability
assumptions and the resulting estimands can be functions of different components
of \(P_0\). We discuss several more complex estimands in later sections.

\hypertarget{tlverse}{%
\chapter{\texorpdfstring{Welcome to the \texttt{tlverse}}{Welcome to the tlverse}}\label{tlverse}}

Updated: 2021-09-21

\begin{VT1}
\VH{Learning Objectives}



This chapter introduces the `tlverse` software ecosystem, including

1. Understanding the `tlverse` ecosystem conceptually.
2. Identifying the core components of the `tlverse`.
3. Installing `tlverse` `R` packages.
4. Understanding the Targeted Learning roadmap.
5. Learning about the WASH Benefits example data.

\end{VT1}

\hypertarget{what-is-the-tlverse}{%
\section*{\texorpdfstring{What is the \texttt{tlverse}?}{What is the tlverse?}}\label{what-is-the-tlverse}}


The \passthrough{\lstinline!tlverse!} is a new framework for doing Targeted Learning in R, inspired by
the \href{https://tidyverse.org}{\passthrough{\lstinline!tidyverse!} ecosystem} of R packages.

By analogy to the \href{https://tidyverse.org/}{\passthrough{\lstinline!tidyverse!}}:

\begin{quote}
The \passthrough{\lstinline!tidyverse!} is an opinionated collection of R packages designed for data
science. All packages share an underlying design philosophy, grammar, and data
structures.
\end{quote}

So, the \href{https://tlverse.org}{\passthrough{\lstinline!tlverse!}} is

\begin{itemize}
\tightlist
\item
  an opinionated collection of R packages for Targeted Learning
\item
  sharing an underlying philosophy, grammar, and set of data structures
\end{itemize}

\hypertarget{anatomy-of-the-tlverse}{%
\section*{\texorpdfstring{Anatomy of the \texttt{tlverse}}{Anatomy of the tlverse}}\label{anatomy-of-the-tlverse}}


All Targeted Learning methods are targeted maximum likelihood (or minimum
loss-based) estimators (TMLEs). The construction of any Targeted Learning
estimator proceeds through a two-stage process:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Flexibly learning particular components of the data-generating distribution
  through macchine learning (e.g., Super Learning), resulting in \emph{initial
  estimates} of nuisance parameters.
\item
  Use of a parametric model-based update via maximum likelihood estimation
  (i.e., MLE), incorporating the initial estimates produced by the prior step.
\end{enumerate}

The packages making up the core components of the \passthrough{\lstinline!tlverse!} software ecosystem,
\passthrough{\lstinline!sl3!} and \passthrough{\lstinline!tmle3!}, address the above two goals, respectively. Together, the very
general functionality exposed by both allows one to build specific TMLEs
tailored exactly to a particular estimation problem.

The software packages that make up the \textbf{core} of the \passthrough{\lstinline!tlverse!} are

\begin{itemize}
\tightlist
\item
  \href{https://github.com/tlverse/sl3}{\passthrough{\lstinline!sl3!}}: Modern Super Machine Learning

  \begin{itemize}
  \tightlist
  \item
    \emph{What?} A modern object-oriented re-implementation of the Super Learner
    algorithm, employing recently developed paradigms in \passthrough{\lstinline!R!} programming.
  \item
    \emph{Why?} A design that leverages modern ideas for faster computation, is
    easily extensible and forward-looking, and forms one of the cornerstones of
    the \passthrough{\lstinline!tlverse!}.
  \end{itemize}
\item
  \href{https://github.com/tlverse/tmle3}{\passthrough{\lstinline!tmle3!}}: An Engine for Targeted Learning

  \begin{itemize}
  \tightlist
  \item
    \emph{What?} A generalized framework that simplifies Targeted Learning by
    identifying and implementing a series of common statistical estimation
    procedures.
  \item
    \emph{Why?} A common interface and engine that accommodates current algorithmic
    approaches to Targeted Learning and yet remains a flexible enough engine to
    power the implementation of emerging statistical techniques as they are
    developed.
  \end{itemize}
\end{itemize}

Beyond these engines that provide the driving force behind the \passthrough{\lstinline!tlverse!}, there
are a few supporting packages that play important roles in the background:

\begin{itemize}
\tightlist
\item
  \href{https://github.com/tlverse/origami}{\passthrough{\lstinline!origami!}}: A Generalized Framework for
  Cross-Validation \citep{coyle2018origami}

  \begin{itemize}
  \tightlist
  \item
    \emph{What?} A generalized framework for flexible cross-validation.
  \item
    \emph{Why?} Cross-validation is a key part of ensuring error estimates are honest
    and in preventing overfitting. It is an essential part of the both the Super
    Learner ensemble modeling algorithm and in the construction of Targeted
    Learning estimators.
  \end{itemize}
\item
  \href{https://github.com/tlverse/delayed}{\passthrough{\lstinline!delayed!}}: Parallelization Framework for
  Dependent Tasks

  \begin{itemize}
  \tightlist
  \item
    \emph{What?} A framework for delayed computations (i.e., futures) based on task
    dependencies.
  \item
    \emph{Why?} Efficient allocation of compute resources is essential when deploying
    computationally intensive algorithms at large scale.
  \end{itemize}
\end{itemize}

A key principle of the \passthrough{\lstinline!tlverse!} is extensibility. That is, the software
ecosystem aims to support the development of new Targeted Learning estimators as
they reaching maturity. To achieve this degree of flexibility, we follow the
model of implementing new classes of estimators, for distinct causal inference
problems, in separate packages, all of which use the core machinery provided by
the \passthrough{\lstinline!sl3!} and \passthrough{\lstinline!tmle3!} packages There are currently three examples:

\begin{itemize}
\tightlist
\item
  \href{https://github.com/tlverse/tmle3mopttx}{\passthrough{\lstinline!tmle3mopttx!}}: Optimal Treatments
  in the \passthrough{\lstinline!tlverse!}

  \begin{itemize}
  \tightlist
  \item
    \emph{What?} Learn an optimal rule and estimate the mean outcome under the rule.
  \item
    \emph{Why?} Optimal treatments are a powerful tool in precision healthcare and
    other settings where a one-size-fits-all treatment approach is not
    appropriate.
  \end{itemize}
\item
  \href{https://github.com/tlverse/tmle3shift}{\passthrough{\lstinline!tmle3shift!}}: Stochastic Shift
  Interventions in the \passthrough{\lstinline!tlverse!}

  \begin{itemize}
  \tightlist
  \item
    \emph{What?} Stochastic shift interventions for continuous-valued treatments.
  \item
    \emph{Why?} Not all treatment variables are binary or categorical. Estimating the
    total effects of intervening on continuous-valued treatments provides a way
    to probe how an effect changes with shifts in the treatment variable.
  \end{itemize}
\item
  \href{https://github.com/tlverse/tmle3mediate}{\passthrough{\lstinline!tmle3mediate!}}: Causal Mediation
  Analysis in the \passthrough{\lstinline!tlverse!}

  \begin{itemize}
  \tightlist
  \item
    \emph{What?} Techniques for evaluating the direct and indirect effects of
    treatments through mediating variables.
  \item
    \emph{Why?} Evaluating the total effect of a treatment does not provide
    information about the pathways through which it may operate. When mediating
    variables have been collected, one can instead evaluate direct and indirect
    effect parameters that speak to the \emph{action mechanism} of the treatment.
  \end{itemize}
\end{itemize}

\hypertarget{installtlverse}{%
\section{Installation}\label{installtlverse}}

The \passthrough{\lstinline!tlverse!} ecosystem of packages are currently hosted at
\url{https://github.com/tlverse}, not yet on \href{https://CRAN.R-project.org/}{CRAN}. You
can use the \href{https://usethis.r-lib.org/}{\passthrough{\lstinline!usethis!} package} to install them:

\begin{lstlisting}[language=R]
install.packages("devtools")
devtools::install_github("tlverse/tlverse")
\end{lstlisting}

The \passthrough{\lstinline!tlverse!} depends on a large number of other packages that are also hosted
on GitHub. Because of this, you may see the following error:

\begin{lstlisting}
Error: HTTP error 403.
  API rate limit exceeded for 71.204.135.82. (But here's the good news:
  Authenticated requests get a higher rate limit. Check out the documentation
  for more details.)

  Rate limit remaining: 0/60
  Rate limit reset at: 2019-03-04 19:39:05 UTC

  To increase your GitHub API rate limit
  - Use `usethis::browse_github_pat()` to create a Personal Access Token.
  - Use `usethis::edit_r_environ()` and add the token as `GITHUB_PAT`.
\end{lstlisting}

This just means that R tried to install too many packages from GitHub in too
short of a window. To fix this, you need to tell R how to use GitHub as your
user (you'll need a GitHub user account). Follow these two steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Type \passthrough{\lstinline!usethis::browse\_github\_pat()!} in your R console, which will direct
  you to GitHub's page to create a New Personal Access Token (PAT).
\item
  Create a PAT simply by clicking ``Generate token'' at the bottom of the page.
\item
  Copy your PAT, a long string of lowercase letters and numbers.
\item
  Type \passthrough{\lstinline!usethis::edit\_r\_environ()!} in your R console, which will open your
  \passthrough{\lstinline!.Renviron!} file in the source window of RStudio.

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    If your \passthrough{\lstinline!.Renviron!} file does not pop-up after calling
    \passthrough{\lstinline!usethis::edit\_r\_environ()!}; then try inputting
    \passthrough{\lstinline!Sys.setenv(GITHUB\_PAT = "yourPAT")!}, replacing your PAT with inside the
    quotes. If this does not error, then skip to step 8.
  \end{enumerate}
\item
  In your \passthrough{\lstinline!.Renviron!} file, type \passthrough{\lstinline!GITHUB\_PAT=!} and then paste your PAT after
  the equals symbol with no space.
\item
  In your \passthrough{\lstinline!.Renviron!} file, press the enter key to ensure that your \passthrough{\lstinline!.Renviron!}
  ends with a new line.
\item
  Save your \passthrough{\lstinline!.Renviron!} file. The example below shows how this syntax should
  look.
\end{enumerate}

\begin{lstlisting}[language=R]
GITHUB_PAT <- yourPAT
\end{lstlisting}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Restart R. You can restart R via the drop-down menu on RStudio's ``Session''
  tab, which is located at the top of the RStudio interface. You have to
  restart R for the changes to take effect!
\end{enumerate}

After following these steps, you should be able to successfully install the
package which threw the error above.

\hypertarget{data}{%
\chapter{Meet the Data}\label{data}}

\hypertarget{wash}{%
\section{WASH Benefits Example Dataset}\label{wash}}

The data come from a study of the effect of water quality, sanitation, hand
washing, and nutritional interventions on child development in rural Bangladesh
(WASH Benefits Bangladesh): a cluster randomized controlled trial
\citep{luby2018effect}. The study enrolled pregnant women in their first or second
trimester from the rural villages of Gazipur, Kishoreganj, Mymensingh, and
Tangail districts of central Bangladesh, with an average of eight women per
cluster. Groups of eight geographically adjacent clusters were block randomized,
using a random number generator, into six intervention groups (all of which
received weekly visits from a community health promoter for the first 6 months
and every 2 weeks for the next 18 months) and a double-sized control group (no
intervention or health promoter visit). The six intervention groups were:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  chlorinated drinking water;
\item
  improved sanitation;
\item
  hand-washing with soap;
\item
  combined water, sanitation, and hand washing;
\item
  improved nutrition through counseling and provision of lipid-based nutrient
  supplements; and
\item
  combined water, sanitation, handwashing, and nutrition.
\end{enumerate}

In the handbook, we concentrate on child growth (size for age) as the outcome of
interest. For reference, this trial was registered with ClinicalTrials.gov as
NCT01590095.

\begin{lstlisting}[language=R]
library(readr)
# read in data via readr::read_csv
dat <- read_csv(
  paste0(
    "https://raw.githubusercontent.com/tlverse/tlverse-data/master/",
    "wash-benefits/washb_data.csv"
  )
)
\end{lstlisting}

For the purposes of this handbook, we start by treating the data as independent
and identically distributed (i.i.d.) random draws from a very large target
population. We could, with available options, account for the clustering of the
data (within sampled geographic units), but, for simplification, we avoid these
details in the handbook, although modifications of our methodology for biased
samples, repeated measures, and related complications, are available.

We have 28 variables measured, of which a single variable is set to
be the outcome of interest. This outcome, \(Y\), is the weight-for-height Z-score
(\passthrough{\lstinline!whz!} in \passthrough{\lstinline!dat!}); the treatment of interest, \(A\), is the randomized treatment
group (\passthrough{\lstinline!tr!} in \passthrough{\lstinline!dat!}); and the adjustment set, \(W\), consists simply of
\emph{everything else}. This results in our observed data structure being \(n\) i.i.d.
copies of \(O_i = (W_i, A_i, Y_i)\), for \(i = 1, \ldots, n\).

Using the \href{https://CRAN.R-project.org/package=skimr}{\passthrough{\lstinline!skimr!} package}, we can
quickly summarize the variables measured in the WASH Benefits data set:

\begin{tabular}{l|l|r|r|r|r|r|r|r|r|r|r|r|r|r|r}
\hline
skim\_type & skim\_variable & n\_missing & complete\_rate & character.min & character.max & character.empty & character.n\_unique & character.whitespace & numeric.mean & numeric.sd & numeric.p0 & numeric.p25 & numeric.p50 & numeric.p75 & numeric.p100\\
\hline
character & tr & 0 & 1.00000 & 3 & 15 & 0 & 7 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & fracode & 0 & 1.00000 & 2 & 6 & 0 & 20 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & sex & 0 & 1.00000 & 4 & 6 & 0 & 2 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & momedu & 0 & 1.00000 & 12 & 15 & 0 & 3 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
character & hfiacat & 0 & 1.00000 & 11 & 24 & 0 & 4 & 0 & NA & NA & NA & NA & NA & NA & NA\\
\hline
numeric & whz & 0 & 1.00000 & NA & NA & NA & NA & NA & -0.58608 & 1.03212 & -4.67 & -1.28 & -0.6 & 0.08 & 4.97\\
\hline
numeric & month & 0 & 1.00000 & NA & NA & NA & NA & NA & 6.45474 & 3.33214 & 1.00 & 4.00 & 6.0 & 9.00 & 12.00\\
\hline
numeric & aged & 0 & 1.00000 & NA & NA & NA & NA & NA & 266.31502 & 52.17465 & 42.00 & 230.00 & 266.0 & 303.00 & 460.00\\
\hline
numeric & momage & 18 & 0.99617 & NA & NA & NA & NA & NA & 23.90592 & 5.24055 & 14.00 & 20.00 & 23.0 & 27.00 & 60.00\\
\hline
numeric & momheight & 31 & 0.99340 & NA & NA & NA & NA & NA & 150.50407 & 5.22667 & 120.65 & 147.05 & 150.6 & 154.06 & 168.00\\
\hline
numeric & Nlt18 & 0 & 1.00000 & NA & NA & NA & NA & NA & 1.60469 & 1.24726 & 0.00 & 1.00 & 1.0 & 2.00 & 10.00\\
\hline
numeric & Ncomp & 0 & 1.00000 & NA & NA & NA & NA & NA & 11.04324 & 6.35044 & 2.00 & 6.00 & 10.0 & 14.00 & 52.00\\
\hline
numeric & watmin & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.94867 & 9.48125 & 0.00 & 0.00 & 0.0 & 1.00 & 600.00\\
\hline
numeric & elec & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.59510 & 0.49092 & 0.00 & 0.00 & 1.0 & 1.00 & 1.00\\
\hline
numeric & floor & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.10671 & 0.30878 & 0.00 & 0.00 & 0.0 & 0.00 & 1.00\\
\hline
numeric & walls & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.71502 & 0.45145 & 0.00 & 0.00 & 1.0 & 1.00 & 1.00\\
\hline
numeric & roof & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.98530 & 0.12035 & 0.00 & 1.00 & 1.0 & 1.00 & 1.00\\
\hline
numeric & asset\_wardrobe & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.16720 & 0.37319 & 0.00 & 0.00 & 0.0 & 0.00 & 1.00\\
\hline
numeric & asset\_table & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.73440 & 0.44170 & 0.00 & 0.00 & 1.0 & 1.00 & 1.00\\
\hline
numeric & asset\_chair & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.73440 & 0.44170 & 0.00 & 0.00 & 1.0 & 1.00 & 1.00\\
\hline
numeric & asset\_khat & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.61321 & 0.48707 & 0.00 & 0.00 & 1.0 & 1.00 & 1.00\\
\hline
numeric & asset\_chouki & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.78126 & 0.41344 & 0.00 & 1.00 & 1.0 & 1.00 & 1.00\\
\hline
numeric & asset\_tv & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.30394 & 0.46001 & 0.00 & 0.00 & 0.0 & 1.00 & 1.00\\
\hline
numeric & asset\_refrig & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.07945 & 0.27046 & 0.00 & 0.00 & 0.0 & 0.00 & 1.00\\
\hline
numeric & asset\_bike & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.31906 & 0.46616 & 0.00 & 0.00 & 0.0 & 1.00 & 1.00\\
\hline
numeric & asset\_moto & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.06603 & 0.24836 & 0.00 & 0.00 & 0.0 & 0.00 & 1.00\\
\hline
numeric & asset\_sewmach & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.06475 & 0.24611 & 0.00 & 0.00 & 0.0 & 0.00 & 1.00\\
\hline
numeric & asset\_mobile & 0 & 1.00000 & NA & NA & NA & NA & NA & 0.85857 & 0.34850 & 0.00 & 1.00 & 1.0 & 1.00 & 1.00\\
\hline
\end{tabular}

A convenient summary of the relevant variables is given just above, complete
with a small visualization describing the marginal characteristics of each
covariate. Note that the \emph{asset} variables reflect socio-economic status of the
study participants. Notice also the uniform distribution of the treatment groups
(with twice as many controls); this is, of course, by design.

\hypertarget{origami}{%
\chapter{Cross-validation}\label{origami}}

\emph{Ivana Malenica}

Based on the \href{https://github.com/tlverse/origami}{\passthrough{\lstinline!origami!} \passthrough{\lstinline!R!} package}
by \emph{Jeremy Coyle, Nima Hejazi, Ivana Malenica and Rachael Phillips}.

Updated: 2021-09-21

\begin{VT1}
\VH{Learning Objectives}



By the end of this chapter you will be able to:

1. Differentiate between training, validation and test sets.

2. Understand the concept of a loss function, risk and cross-validation.

3. Select a loss function that is appropriate for the functional parameter to be
   estimated.

4. Understand and contrast different cross-validation schemes for i.i.d. data.

5. Understand and contrast different cross-validation schemes for time dependent
   data.

6. Setup the proper fold structure, build custom fold-based function, and
   cross-validate the proposed function using the `origami` `R` package.

7. Setup the proper cross-validation structure for the use by the Super Learner
   using the the `origami` `R` package.

\end{VT1}

\hypertarget{introduction-1}{%
\section{Introduction}\label{introduction-1}}

In this chapter, we start elaborating on the estimation step outlined in the
\protect\hyperlink{intro}{introductory chapter}, which discussed the \protect\hyperlink{roadmap}{\emph{Roadmap for Targeted
Learning}}. In order to generate an initial estimate of our target
parameter -- which is the focus of the following \protect\hyperlink{sl3}{chapter on Super
Learning}, we first need to translate, and incorporate, our knowledge
about the data generating process into the estimation procedure, and decide how
to evaluate our estimation performance.

The performance, or error, of any algorithm used in the estimation procedure
directly relates to its generalizability on the independent data. The proper
assessment of the performance of proposed algorithms is extremely important; it
guides the choice of the final learning method, and it gives us a quantitative
assessment of how good the chosen algorithm is doing. In order to assess the
performance of an algorithm, we introduce the concept of a \textbf{loss} function,
which helps us define the \textbf{risk}, also referred to as the \textbf{expected
prediction error}.

\begin{shortbox}
\Boxhead{Constructing a library that is consistent with the data-generating distribution}
Our goal, as further specified in the next chapter, will be
to estimate the true risk of the proposed statistical learning method. Our
goal(s) consist of:

1. Estimating the performance of different algorithms in order to choose the
   best one.
2. Having chosen a winner, estimate the true risk of the proposed
   statistical learning method.
\end{shortbox}

In the following, we propose a method to do so using the observed data and
\textbf{cross-validation} procedure using the \passthrough{\lstinline!origami!} package \citep{coyle2018origami}.

\hypertarget{background}{%
\section{Background}\label{background}}

Ideally, in a data-rich scenario, we would split our dataset into three parts:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  training set,
\item
  validation set,
\item
  test set.
\end{enumerate}

The training set is used to fit algorithm(s) of interest; we evaluate the
performance of the fit(s) on a validation set, which can be used to estimate
prediction error (e.g., for tuning and model selection). The final error of the
chosen algorithm(s) is obtained by using the test set, which is kept separately,
and doesn't see the data before the final evaluation. One might wonder, with
training data readily available, why not use the training error to evaluate the
proposed algorithm's performance? Unfortunately, the training error is not a
good estimate of the true risk; it consistently decreases with model complexity,
resulting in a possible overfit to the training data and low generalizability.

Since data are often scarce, separating it into training, validation and test
set is usually not possible. In the absence of a large data set and a designated
test set, we must resort to methods that estimate the true risk by efficient
sample re-use. Re-sampling methods, in great generality, involve repeatedly
sampling from the training set and fitting proposed algorithms on the new
samples. While often computationally intensive, re-sampling methods are
particularly useful for model selection and estimation of the true risk. In
addition, they might provide more insight on variability and robustness of the
algorithm fit then fitting an algorithm only once on all the training data.

\hypertarget{introducing-cross-validation}{%
\subsection{Introducing: cross-validation}\label{introducing-cross-validation}}

In this chapter, we focus on \textbf{cross-validation} -- an essential tool for
evaluating how any given algorithm extends from a sample to the target
population from which the sample is derived. It has seen widespread application
in all facets of statistics, perhaps most notably statistical machine learning.
The cross-validation procedure can be used for model selection, as well as for
estimation of the true risk associated with any statistical learning method in
order to evaluate its performance. It particular, cross-validation directly
estimates the true risk when the estimate is applied to an independent sample
from the joint distribution of the predictors and outcome. When used for model
selection, cross-validation has powerful optimality properties. The asymptotic
optimality results state that the cross-validated selector performs (in terms of
risk) asymptotically as well as an optimal oracle selector based on the true,
unknown data generating distribution. For further details on the theoretical
results, we suggest \citet{vdl2003unified}, \citet{vdl2004asymptotic}, \citet{dudoit2005asymptotics} and
\citet{vaart2006oracle}.

In great generality, cross-validation works by partitioning a sample into
complementary subsets, applying a particular algorithm(s) on a subset (the
training set), and evaluating the method of choice on the complementary subset
(the validation/test set). This procedure is repeated across multiple partitions
of the data. A variety of different partitioning schemes exist, depending on the
problem of interest, data size, prevalence of the outcome, and dependence
structure. The \passthrough{\lstinline!origami!} package provides a suite of tools that generalize the
application of cross-validation to arbitrary data analytic procedures. In the
the following, we describe different types of cross-validation schemes readily
available in \passthrough{\lstinline!origami!}, introduce the general structure of the \passthrough{\lstinline!origami!}
package, and show their use in applied settings.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{estimation-roadmap-how-does-it-all-fit-together}{%
\section{Estimation Roadmap: how does it all fit together?}\label{estimation-roadmap-how-does-it-all-fit-together}}

Similarly to how we defined the \protect\hyperlink{roadmap}{\emph{Roadmap for Targeted Learning}}, we
can define the \textbf{Estimation Roadmap} to guide the estimation process. In
particular, we have developed a unified loss-based cross-validation methodology
for estimator construction, selection, and performance assessment in a series of
articles (e.g., see \citet{vdl2003unified}, \citet{vdl2004asymptotic}, \citet{dudoit2005asymptotics},
\citet{vaart2006oracle}, and \citet{vdl2007super}) that follow three main steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{The loss funtion}:
  Define the target parameter as the minimizer of the expected loss (risk) for a
  full data loss function chosen to represent the desired performance measure.
  Map the full data loss function into an observed data loss function, having the
  same expected value and leading to an efficient estimator of risk.
\item
  \textbf{The algorithms}:
  Construct a finite collection of candidate estimators for the parameter of
  interest.
\item
  \textbf{The cross-validation scheme}:
  Apply appropriate cross-validation to select an optimal estimator among the
  candidates, and assess the overall performance of the resulting estimator.
\end{enumerate}

Step 1 of the Estimation Roadmap allows us to unify a broad range of problems
that are traditionally treated separately in the statistical literature,
including density estimation, prediction of polychotomous and continuous
outcomes. For example, if we are interested in estimating the full joint
conditional density, we could use the negative log-likelihood loss. If instead
we are interested in the conditional mean with continuous outcome, one could use
the squared error loss; had the outcome been binary, one could resort to the
indicator (0-1) loss. The unified loss-based framework also reconciles censored
and full data estimation methods, by generalizing any loss based learning for
full data into loss based learning for general censored data.

\hypertarget{example-cross-validation-and-prediction}{%
\section{Example: cross-validation and prediction}\label{example-cross-validation-and-prediction}}

Now that we introduced the Estimation Roadmap, we can define our objective with
more mathematical notation, using prediction as an example. Let the observed
data be defined as \(X = (W,Y)\), where a unit specific data can be written as
\(X_i = (W_i,Y_i)\), for \(i = 1, \ldots, n\). For each of the \(n\) samples, we
denote \(Y_i\) as the outcome of interest (polychotomous or continuous), and \(W_i\)
as a \(p\)-dimensional set of covariates. Let \(\psi_0(W)\) denote the target
parameter of interest we want to estimate; for this example, we are interested
in estimating the conditional expectation of the outcome given the covariates,
\(\psi_0(W) = E(Y \mid W)\). Following the Estimation Roadmap, we chose the
appropriate loss function, \(L\), such that \(\psi_0(W) = \text{argmin}_{\psi} E[L(X,\psi(W))]\). But how do we know how each \(\psi\) is doing? In order to pick
the optimal estimator among the candidates, and assess the overall performance
of the resulting estimator, we use cross-validation -- dividing the available data
into the training set and validation set. Observations in the training set are
used to fit (or train) the estimator, while the validation set is used to assess
the risk of (or validate) it.

To derive a general representation for cross-validation, we define a \textbf{split
vector}, \(B_n = (B_n(i): i = 1, \ldots, n) \in \{0,1\}^n\). Note that split
vector is independent of the empirical distribution, \(P_n\). A realization of
\(B_n\) defines a random split of the data into a training and validation set such
that if

\[B_n(i) = 0, \ \ \text{i sample is in the training set}\]
\[B_n(i) = 1, \ \ \text{i sample is in the validation set.}\]
We can further define \(P_{n,B_n}^0\) and \(P_{n,B_n}^1\) as the empirical
distributions of the training and validation sets, respectively. Then \(n_0 = \sum_i (1-B_n(i))\) and \(n_1 = \sum_i B_n(i)\) denote the number of samples in each
set. The particular distribution of the split vector \(B_n\) defines the type of
cross-validation scheme, tailored to the problem and data set in hand.

\hypertarget{cross-validation-schemes-in-origami}{%
\section{\texorpdfstring{Cross-validation schemes in \texttt{origami}}{Cross-validation schemes in origami}}\label{cross-validation-schemes-in-origami}}

As we specified earlier, the particular distribution of the split vector \(B_n\)
defines the type of the cross-validation method. In the following, we describe
different types of cross-validation schemes available in \passthrough{\lstinline!origami!} package, and
show their use in the sequel.

\hypertarget{wash-benefits-study-example}{%
\subsection*{WASH Benefits Study Example}\label{wash-benefits-study-example}}


In order to illustrate different cross-validation schemes, we will be using the
WASH data. Detailed information on the WASH Benefits Example Dataset can be
found in \protect\hypertarget{data}{}{Chapter 3}. In particular, we are interested in predicting
weight-for-height z-score \passthrough{\lstinline!whz!} using the available covariate data. For this
illustration, we will start by treating the data as independent and identically
distributed (i.i.d.) random draws. To see what each cross-validation scheme is
doing, we will subset the data to only \(n=30\). Note that each row represents an
i.i.d. sample, indexed by the row number.

\begin{lstlisting}[language=R]
library(data.table)
library(origami)
library(knitr)
library(kableExtra)

# load data set and take a peek
washb_data <- fread(
  paste0(
    "https://raw.githubusercontent.com/tlverse/tlverse-data/master/",
    "wash-benefits/washb_data.csv"
  ),
  stringsAsFactors = TRUE
)
\end{lstlisting}

\begin{tabular}{r|l|l|r|r|l|r|l|r|l|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r}
\hline
whz & tr & fracode & month & aged & sex & momage & momedu & momheight & hfiacat & Nlt18 & Ncomp & watmin & elec & floor & walls & roof & asset\_wardrobe & asset\_table & asset\_chair & asset\_khat & asset\_chouki & asset\_tv & asset\_refrig & asset\_bike & asset\_moto & asset\_sewmach & asset\_mobile\\
\hline
0.00 & Control & N05265 & 9 & 268 & male & 30 & Primary (1-5y) & 146.40 & Food Secure & 3 & 11 & 0 & 1 & 0 & 1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 1\\
\hline
-1.16 & Control & N05265 & 9 & 286 & male & 25 & Primary (1-5y) & 148.75 & Moderately Food Insecure & 2 & 4 & 0 & 1 & 0 & 1 & 1 & 0 & 1 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
-1.05 & Control & N08002 & 9 & 264 & male & 25 & Primary (1-5y) & 152.15 & Food Secure & 1 & 10 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
-1.26 & Control & N08002 & 9 & 252 & female & 28 & Primary (1-5y) & 140.25 & Food Secure & 3 & 5 & 0 & 1 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 1\\
\hline
-0.59 & Control & N06531 & 9 & 336 & female & 19 & Secondary (>5y) & 150.95 & Food Secure & 2 & 7 & 0 & 1 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
-0.51 & Control & N06531 & 9 & 304 & male & 20 & Secondary (>5y) & 154.20 & Severely Food Insecure & 0 & 3 & 1 & 1 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
\end{tabular}

Above is a look at the first 30 of the data.

\hypertarget{cross-validation-for-i.i.d.-data}{%
\subsection{Cross-validation for i.i.d. data}\label{cross-validation-for-i.i.d.-data}}

\hypertarget{re-substitution}{%
\subsubsection{Re-substitution}\label{re-substitution}}

The re-substitution method is the simplest strategy for estimating the risk
associated with fitting a proposed algorithm on a set of observations. Here, all
observed data is used for both training and validation set.

We illustrate the usage of the re-substitution method with \passthrough{\lstinline!origami!} package
below; we will use the function \passthrough{\lstinline!folds\_resubstitution(n)!}. In order to setup
\passthrough{\lstinline!folds\_resubstitution(n)!}, we just need the total number of samples we want to
allocate to training and validation sets; remember that each row of data is a
unique i.i.d. sample. Notice the structure of the \passthrough{\lstinline!origami!} output:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{v:} the cross-validation fold
\item
  \textbf{training\_set:} the indexes of the samples in the training set
\item
  \textbf{validation\_set:} the indexes of the samples in the training set.
\end{enumerate}

This structure of the \passthrough{\lstinline!origami!} output (aka, fold(s)) will persist for each of the
cross-validation schemes we present in this chapter. Below, we show the fold
generated by the re-substitution method:

\begin{lstlisting}[language=R]
folds_resubstitution(nrow(washb_data))
[[1]]
$v
[1] 1

$training_set
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
[26] 26 27 28 29 30

$validation_set
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
[26] 26 27 28 29 30

attr(,"class")
[1] "fold"
\end{lstlisting}

\hypertarget{holdout-method}{%
\subsubsection{Holdout method}\label{holdout-method}}

The holdout method, or the validation set approach, consists of randomly
dividing the available data into the training set and validation set (holdout
set). The model is then fitted on the training set, and further evaluated on
the observations in the validation set. Typically, the data is split into
\(60/40\), \(70/30\), \(80/20\) or \(90/10\) splits.

The holdout method is intuitive, conceptually easy, and computationally not too
demanding. However, if we repeat the process of randomly splitting the data into
the training and validation set, we might get a very different cross-validated
emprical risk. In particular, the emprical mean of the loss over the validation
sets might be highly variable, depending on which samples were included in the training/validation split. Overall, the cross-validated emprical risk for the
holdout method is more variabiable, since in includes variability of the random
split as well - which is not what we want. For classification problems, there is a
possibility of an uneven distribution of different classes in the training and validation
set unless data is stratified. Finally, note that we are not using all of the
data to train and evaluate the performance of the proposed algorithm, which might
result in bias.

\hypertarget{leave-one-out}{%
\subsubsection{Leave-one-out}\label{leave-one-out}}

The leave-one-out cross-validation scheme is closely related to the holdout
method. In particular, it also involves splitting the data into the training and
validation set; however, instead of partitioning the observed data into sets of
similar size, a single observation is used as a validation set. With that,
majority of the units are employed for training (fitting) the proposed
algorithm. Since only one unit (for example \(x_1 = (w_1, y_1)\)) is not used in
the fitting process, leave-one-out cross-validation results in a possibly less
biased estimate of the true risk; typically, leave-one-out approach will not
overestimate the risk as much as the holdout method. On the other hand, since
the estimate of risk is based on a single sample, it is typically a highly
variable estimate.

We can repeat the process of spiting the data into training and validation set
until all samples are part of the validation set at some point. For example,
next iteration of the cross-validation might have \(x_2 = (w_2,y_2)\) as the
validation set and all the rest of \(n-1\) samples as the training set. Repeating
this approach \(n\) times results in, for example, \(n\) squared errors \(MSE_1, MSE_2, \ldots, MSE_n\). The estimate of the true risk is the average over the
\(n\) squared errors. While the leave-one-out cross-validation results in a less
biased (albeit, more variable) estimate of risk than the holdout method, it
could be expensive to implement if \(n\) is large.

We illustrate the usage of the leave-one-out cross-validation with \passthrough{\lstinline!origami!}
package below; we will use the function \passthrough{\lstinline!folds\_loo(n)!}. In order to setup
\passthrough{\lstinline!folds\_loo(n)!}, similarly to the re-substitution method, we just need the total
number of samples we want to cross-validate. We show the first two folds
generated by the leave-one-out cross-validation below.

\begin{lstlisting}[language=R]
folds <- folds_loo(nrow(washb_data))
folds[[1]]
$v
[1] 1

$training_set
 [1]  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26
[26] 27 28 29 30

$validation_set
[1] 1

attr(,"class")
[1] "fold"
folds[[2]]
$v
[1] 2

$training_set
 [1]  1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26
[26] 27 28 29 30

$validation_set
[1] 2

attr(,"class")
[1] "fold"
\end{lstlisting}

\hypertarget{v-fold}{%
\subsubsection{V-fold}\label{v-fold}}

An alternative to leave-one-out is V-fold cross-validation. This
cross-validation scheme randomly divides the data into \(v\) sets (folds) of equal
size; for each fold, the number of samples in the validation set are the same.
For V-fold cross-validation, one of the folds is treated as a validation set,
whereas the proposed algorithm is fit on the remaining \(v-1\) folds in the
training set. The loss, for example MSE, is computed on the samples in the
validation set. With the proposed algorithm trained and its performance
evaluated on the first fold, we repeat this process \(v\) times; each time, a
different group of samples is treated as a validation set. Note that with V-fold
cross-validation we effectively use all of the data to train and evaluate the
proposed algorithm without overfitting to the training data. In the end, the
V-fold cross-validation results in \(v\) estimates of validation error. The final
V-fold CV estimate is computed as an average over all the validation losses.

For a dataset with \(n\) samples, V-fold cross-validation with \(v=n\) is just
leave-one-out; similarly, if we set \(n=1\), we can get the holdout method's
estimate of algorithm's performance. Despite the obvious computational
advantages, V-fold cross-validation often gives more accurate estimates of the
true risk. The reason for this comes from the bias-variance trade-off that comes
from employing both methods; while leave-one-out might be less biased, it has
higher variance. This difference becomes more obvious as \(v<<n\) (but not too
small, as then we increase bias). With V-fold cross-validation, we end up
averaging output from \(v\) fits that are typically less correlated than the
outputs from leave-one-out fits. Since the mean of many highly correlated
quantities has higher variance, leave-one-out estimate of the risk will
have higher variance than the estimate based on V-fold cross-validation.

Let's see V-fold cross-validation with \passthrough{\lstinline!origami!} in action! In the next chapter
we will study the Super Learner --- an actual algorithm that we fit and evaluate
its performance. The Super Learner relies on V-fold cross-validation as default cross-validation scheme. In order
to set up V-fold CV, we need to call function \passthrough{\lstinline!folds\_vfold(n, V)!}. Arguments
for \passthrough{\lstinline!folds\_vfold(n, V)!} require the total number of samples to be
cross-validated, and the number of folds we want to get.

At \(V=2\), we get 2 folds with \(n/2\) number of samples in both training and
validation set.

\begin{lstlisting}[language=R]
folds <- folds_vfold(nrow(washb_data), V = 2)
folds[[1]]
$v
[1] 1

$training_set
 [1]  2  3  4  6  7  8 11 12 14 15 19 22 23 24 28

$validation_set
 [1]  1  5  9 10 13 16 17 18 20 21 25 26 27 29 30

attr(,"class")
[1] "fold"
folds[[2]]
$v
[1] 2

$training_set
 [1]  1  5  9 10 13 16 17 18 20 21 25 26 27 29 30

$validation_set
 [1]  2  3  4  6  7  8 11 12 14 15 19 22 23 24 28

attr(,"class")
[1] "fold"
\end{lstlisting}

\hypertarget{monte-carlo}{%
\subsubsection{Monte Carlo}\label{monte-carlo}}

With Monte Carlo cross-validation, we randomly select some fraction of the data
(without replacement) to form the training set; we assign the rest of the
samples to the validation set. With that, the data is repeatedly and randomly
divided into two sets, a training set of \(n_0 = n \cdot (1-p)\) observations and
a validation set of \(n_1 = n \cdot p\) observations. This process is then
repeated multiple times, generating (at random) new training and validation
partitions each time.

Since the partitions are independent across folds, the same sample can appear in
the validation set multiple times -- note that this is a stark difference
between Monte Carlo and V-fold cross-validation. For a given \(p\), Monte Carlo
cross-validation would be optimal if done infinite times, but this is not
computationally feasible. With Monte Carlo
cross-validation, one is able to explore many more available partitions than
with V-fold cross-validation -- resulting in a possibly less variable estimate
of the risk, at a cost of an increase in bias. By having many overlapping splits,
we often also need more splits (and thus more computational time) to achieve
V-fold performance with only \(V\) splits.

We illustrate the usage of the Monte Carlo cross-validation with \passthrough{\lstinline!origami!}
package below using the function \passthrough{\lstinline!folds\_montecarlo(n, V, pvalidation)!}. In order
to setup \passthrough{\lstinline!folds\_montecarlo(n, V, pvalidation)!}, we need:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the total number of samples we want to cross-validate;
\item
  the number of folds;
\item
  the proportion of observations to be placed in the validation set.
\end{enumerate}

At \(V=2\) and \(pvalidation=0.2\), we obtain 2 folds with approximately \(6\) samples
in validation set per fold.

\begin{lstlisting}[language=R]
folds <- folds_montecarlo(nrow(washb_data), V = 2, pvalidation = 0.2)
folds[[1]]
$v
[1] 1

$training_set
 [1] 19 27 16 29 23 12  1  3 18 11  5  7  8  6  9 22 10 25 20 28 15  2 24 26

$validation_set
[1]  4 13 14 17 21 30

attr(,"class")
[1] "fold"
folds[[2]]
$v
[1] 2

$training_set
 [1] 19 15 28 25 29 11 20 17 14  4  9 12 30  8 27 18 16 10 13  6 24  3 26  1

$validation_set
[1]  2  5  7 21 22 23

attr(,"class")
[1] "fold"
\end{lstlisting}

\hypertarget{bootstrap}{%
\subsubsection{Bootstrap}\label{bootstrap}}

The bootstrap cross-validation also consists of randomly selecting samples, with
replacement, for the training set. The rest of the samples not picked for the
training set are allocated to the validation set. This process is then repeated
multiple times, generating (at random) new training and validation partitions
each time. In contract to the Monte Carlo cross-validation, the total number of
samples in a training and validation size across folds is not constant. We also
sample with replacement, hence the same samples can be in multiple training
sets. The proportion of observations in the validation sets is a random
variable, with expectation \(\sim 0.368\).

We illustrate the usage of the bootstrap cross-validation with \passthrough{\lstinline!origami!} package
below using the function \passthrough{\lstinline!folds\_bootstrap(n, V)!}. In order to setup
\passthrough{\lstinline!folds\_bootstrap(n, V)!}, we need:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the total number of samples we want to cross-validate;
\item
  the number of folds.
\end{enumerate}

At \(V=2\), we obtain \(2\) folds with different number of samples in the validation
set across folds.

\begin{lstlisting}[language=R]
folds <- folds_bootstrap(nrow(washb_data), V = 2)
folds[[1]]
$v
[1] 1

$training_set
 [1]  2  5 30  1 29 16 10 11  8 25 28  2 11  2 16 28 15 28  1 27  9 19 20 30 18
[26] 11 13  2 18 12

$validation_set
 [1]  3  4  6  7 14 17 21 22 23 24 26

attr(,"class")
[1] "fold"
folds[[2]]
$v
[1] 2

$training_set
 [1] 12 16 10 29 22 15 27  9 27 16 12 28 10 28 26  1 14  6 23 14 21 16  5 20  8
[26] 23 25  8 27  5

$validation_set
 [1]  2  3  4  7 11 13 17 18 19 24 30

attr(,"class")
[1] "fold"
\end{lstlisting}

\hypertarget{cross-validation-for-dependent-data}{%
\subsection{Cross-validation for dependent data}\label{cross-validation-for-dependent-data}}

The \passthrough{\lstinline!origami!} package also supports numerous cross-validation schemes for
time-series data, for both single and multiple time-series with arbitrary time
and network dependence.

\hypertarget{airpassenger-example}{%
\subsection*{AirPassenger Example}\label{airpassenger-example}}


In order to illustrate different cross-validation schemes for time-series, we
will be using the AirPassenger data; this is a widely used, freely available
dataset. The AirPassenger dataset in \passthrough{\lstinline!R!} provides monthly totals of
international airline passengers from 1949 to 1960. This dataset is already of a
time series class therefore no further class or date manipulation is required.

\begin{shortbox}
\Boxhead{Constructing a library that is consistent with the data-generating distribution}
**Goal:** we want to forecast the number of airline passengers at time $h$
horizon using the historical data from 1949 to 1960.
\end{shortbox}

\begin{lstlisting}[language=R]
library(ggfortify)

data(AirPassengers)
AP <- AirPassengers

autoplot(AP) +
  labs(
    x = "Date",
    y = "Passenger numbers (1000's)",
    title = "Air Passengers from 1949 to 1961"
  )

t <- length(AP)
\end{lstlisting}

\begin{center}\includegraphics[width=0.8\linewidth]{05-origami_files/figure-latex/plot_airpass-1} \end{center}

\hypertarget{rolling-origin}{%
\subsubsection{Rolling origin}\label{rolling-origin}}

Rolling origin cross-validation scheme lends itself to ``online'' algorithms,
where large streams of data have to be fit continually, and the final fit is
constantly updated with more data acquired. In general, the rolling origin
scheme defines an initial training set, and with each iteration the size of the
training set grows by \(m\) observations until we reach time \(t\) for a particular
fold. The time points included in the training set are always behind the
validation set time points; in addition, there might be a gap between training
and validation times of size \(h\).

To further illustrate rolling origin cross-validation, we show below an example
with 3 folds. Here, the first window size is 15 time points, on which we first
train the proposed algorithm. We then evaluate its performance on 10 time
points, with a gap of size 5 between the training and validation time points.
For the following fold, we train the algorithm on a longer stream of data, 25
time points, including the original 15 we started with. We then evaluate its
performance on 10 time points in the future.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{img/png/rolling_origin} 

}

\caption{Rolling origin CV}\label{fig:unnamed-chunk-1}
\end{figure}

We illustrate the usage of the rolling origin cross-validation with \passthrough{\lstinline!origami!}
package below using the function \passthrough{\lstinline!folds\_rolling\_origin(n, first\_window, validation\_size, gap, batch)!}. In order to setup \passthrough{\lstinline!folds\_rolling\_origin(n, first\_window, validation\_size, gap, batch)!}, we need:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the total number of time points we want to cross-validate;
\item
  the size of the first training set;
\item
  the size of the validation set;
\item
  the gap between training and validation set;
\item
  the size of the update on the training set per each iteration of CV.
\end{enumerate}

Our time-series has \(t=144\) time points. Setting the \passthrough{\lstinline!first\_window!} to \(50\),
\passthrough{\lstinline!validation\_size!} to 10, \passthrough{\lstinline!gap!} to 5 and \passthrough{\lstinline!batch!} to 20, we get 4 time-series
folds; we show the first two below.

\begin{lstlisting}[language=R]
folds <- folds_rolling_origin(
  t,
  first_window = 50, validation_size = 10, gap = 5, batch = 20
)
folds[[1]]
$v
[1] 1

$training_set
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
[26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50

$validation_set
 [1] 56 57 58 59 60 61 62 63 64 65

attr(,"class")
[1] "fold"
folds[[2]]
$v
[1] 2

$training_set
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
[26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
[51] 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70

$validation_set
 [1] 76 77 78 79 80 81 82 83 84 85

attr(,"class")
[1] "fold"
\end{lstlisting}

\hypertarget{rolling-window}{%
\subsubsection{Rolling window}\label{rolling-window}}

Instead of adding more time points to the training set per each iteration, the
rolling window cross-validation scheme ``rolls'' the training sample forward by
\(m\) time units. The rolling window scheme might be considered in parametric
settings when one wishes to guard against moment or parameter drift that is
difficult to model explicitly; it is also more efficient for computationally
demanding settings such as streaming data, in which large amounts of training
data cannot be stored. In contrast to rolling origin CV, the training sample for
each iteration of the rolling window scheme is always the same.

To illustrate the rolling window cross-validation with 3 time-series folds
below. The first window size is 15 time points, on which we first train the
proposed algorithm. As in the previous illustration, we evaluate its performance
on 10 time points, with a gap of size 5 between the training and validation time
points. However, for the next fold, we train the algorithm on time points
further away from the origin (here, 10 time points). Note that the size of the
training set in the new fold is the same as in the first fold (15 time points).
This setup keeps the training sets comparable over time (and fold) as compared
to the rolling origin CV. We then evaluate the performance of the proposed
algorithm on 10 time points in the future.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{img/png/rolling_window} 

}

\caption{Rolling window CV}\label{fig:unnamed-chunk-2}
\end{figure}

We illustrate the usage of the rolling window cross-validation with \passthrough{\lstinline!origami!}
package below using the function \passthrough{\lstinline!folds\_rolling\_window(n, window\_size, validation\_size, gap, batch)!}. In order to setup \passthrough{\lstinline!folds\_rolling\_window(n, window\_size, validation\_size, gap, batch)!}, we need:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the total number of time points we want to cross-validate;
\item
  the size of the training sets;
\item
  the size of the validation set;
\item
  the gap between training and validation set;
\item
  the size of the update on the training set per each iteration of CV.
\end{enumerate}

Setting the \passthrough{\lstinline!window\_size!} to \(50\), \passthrough{\lstinline!validation\_size!} to 10, \passthrough{\lstinline!gap!} to 5 and
\passthrough{\lstinline!batch!} to 20, we also get 4 time-series folds; we show the first two below.

\begin{lstlisting}[language=R]
folds <- folds_rolling_window(
  t,
  window_size = 50, validation_size = 10, gap = 5, batch = 20
)
folds[[1]]
$v
[1] 1

$training_set
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
[26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50

$validation_set
 [1] 56 57 58 59 60 61 62 63 64 65

attr(,"class")
[1] "fold"
folds[[2]]
$v
[1] 2

$training_set
 [1] 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45
[26] 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70

$validation_set
 [1] 76 77 78 79 80 81 82 83 84 85

attr(,"class")
[1] "fold"
\end{lstlisting}

\hypertarget{rolling-origin-with-v-fold}{%
\subsubsection{Rolling origin with V-fold}\label{rolling-origin-with-v-fold}}

A variant of rolling origin scheme which accounts for sample dependence is the
rolling-origin-\(V\)-fold cross-validation. In contrast to the canonical rolling
origin CV, samples in the training and validation set are not the same, as the
variant encompasses \(V\)-fold CV in addition to the time-series setup. The
predictions are evaluated on the future times of time-series units not seen
during the training step, allowing for dependence in both samples and time. One
can use the rolling-origin-\(v\)-fold cross-validation with \passthrough{\lstinline!origami!} package
using the function \passthrough{\lstinline!folds\_vfold\_rolling\_origin\_pooled(n, t, id, time, V, first\_window, validation\_size, gap, batch)!}. In the figure below, we show \(V=2\)
\(V\)-folds, and 2 time-series CV folds.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{img/png/rolling_origin_v_fold} 

}

\caption{Rolling origin V-fold CV}\label{fig:unnamed-chunk-3}
\end{figure}

\hypertarget{rolling-window-with-v-fold}{%
\subsubsection{Rolling window with v-fold}\label{rolling-window-with-v-fold}}

Analogous to the previous section, we can extend rolling window CV to support
multiple time-series with arbitrary sample dependence. One can use the
rolling-window-\(V\)-fold cross-validation with \passthrough{\lstinline!origami!} package using the
function \passthrough{\lstinline!folds\_vfold\_rolling\_window\_pooled(n, t, id, time, V, window\_size, validation\_size, gap, batch)!}. In the figure below, we show \(V=2\) \(V\)-folds, and
2 time-series CV folds.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{img/png/rolling_window_v_fold} 

}

\caption{Rolling window V-fold CV}\label{fig:unnamed-chunk-4}
\end{figure}

\hypertarget{general-workflow-of-origami}{%
\section{\texorpdfstring{General workflow of \texttt{origami}}{General workflow of origami}}\label{general-workflow-of-origami}}

Before we dive into more details, let's take a moment to review some of the
basic functionality in \passthrough{\lstinline!origami!} R package. The main function in the \passthrough{\lstinline!origami!}
is \passthrough{\lstinline!cross\_validate!}. To start off, the user must define the fold structure and a function
that operates on each fold. Once these are passed to \passthrough{\lstinline!cross\_validate!}, \passthrough{\lstinline!cross\_validate!}
will apply the same specified function to each fold, and combine the fold-specific results in a meaningful way. We will see this in action in later sections; for
now, we provide specific details on each each step of this process below.

\hypertarget{define-folds}{%
\subsection{(1) Define folds}\label{define-folds}}

The \passthrough{\lstinline!folds!} object passed to \passthrough{\lstinline!cross\_validate!} is a list of folds; such lists can
be generated using the \passthrough{\lstinline!make\_folds!} function. Each fold consists of a list with
a \passthrough{\lstinline!training!} index vector, a \passthrough{\lstinline!validation!} index vector, and a \passthrough{\lstinline!fold\_index!} (its
order in the list of folds). This function supports a variety of
cross-validation schemes we describe in the following section. The \passthrough{\lstinline!make\_folds!}
can balance across levels of a variable (\passthrough{\lstinline!strata\_ids!}), and it can also keep
all observations from the same independent unit together (\passthrough{\lstinline!cluster!}).

\hypertarget{define-fold-function}{%
\subsection{(2) Define fold function}\label{define-fold-function}}

The \passthrough{\lstinline!cv\_fun!} argument to \passthrough{\lstinline!cross\_validate!} is a function that will perform some
operation on each fold. The first argument to this function must be \passthrough{\lstinline!fold!},
which will receive an individual fold object to operate on. Additional arguments
can be passed to \passthrough{\lstinline!cv\_fun!} using the \passthrough{\lstinline!...!} argument to \passthrough{\lstinline!cross\_validate!}. Within
this function, the convenience functions \passthrough{\lstinline!training!}, \passthrough{\lstinline!validation!} and
\passthrough{\lstinline!fold\_index!} can return the various components of a fold object. If \passthrough{\lstinline!training!}
or \passthrough{\lstinline!validation!} is passed an object, it will index it in a sensible way.
For instance, if it is a vector, it will index the vector directly; if it is a
\passthrough{\lstinline!data.frame!} or \passthrough{\lstinline!matrix!}, it will index rows. This allows the user to easily
partition data into training and validation sets. The fold function must return
a named list of results containing whatever fold-specific outputs are generated.

\hypertarget{apply-cross_validate}{%
\subsection{\texorpdfstring{(3) Apply \texttt{cross\_validate}}{(3) Apply cross\_validate}}\label{apply-cross_validate}}

After defining folds, \passthrough{\lstinline!cross\_validate!} can be used to map the \passthrough{\lstinline!cv\_fun!} across
the \passthrough{\lstinline!folds!} using \passthrough{\lstinline!future\_lapply!}. This means that it can be easily parallelized
by specifying a parallelization scheme (i.e., a \passthrough{\lstinline!plan!} from the \href{https://Cran.R-project.org/package=future}{future
parallelization framework for \passthrough{\lstinline!R!}}
\citep{bengtsson2020unifying}). The application of \passthrough{\lstinline!cross\_validate!} generates a list
of results. As described above, each call to \passthrough{\lstinline!cv\_fun!} itself returns a list of
results, with different elements for each type of result we care about. The main
loop generates a list of these individual lists of results (a sort of
``meta-list''). This ``meta-list'' is then inverted such that there is one element
per result type (this too is a list of the results for each fold). By default,
\passthrough{\lstinline!combine\_results!} is used to combine these results type lists in a sensible
manner. How results are combined is determined automatically by examining the
data types of the results from the first fold. This can be modified by
specifying a list of arguments to \passthrough{\lstinline!.combine\_control!}.

\hypertarget{cross-validation-in-action}{%
\section{Cross-validation in action}\label{cross-validation-in-action}}

Let's see \passthrough{\lstinline!origami!} in action! In the following chapter we will learn how to use
cross-validation with the Super Learner, and how we can utilize the power of
cross-validation to build optimal ensembles of algorithms, not just its use on a
single statistical learning method.

\hypertarget{cross-validation-with-linear-regression}{%
\subsection{Cross-validation with linear regression}\label{cross-validation-with-linear-regression}}

First, we will load the relevant \passthrough{\lstinline!R!} packages, set a seed, and load the full
WASH data once again. In order to illustrate cross-validation with \passthrough{\lstinline!origami!} and
linear regression, we will focus on predicting the weight-for-height Z-score
\passthrough{\lstinline!whz!} using all of the available covariate data. As stated previously, we will
assume the data is independent and identically distributed, ignoring the cluster
structure imposed by the clinical trial design. For the sake of illustration, we
will work with a subset of data, and remove all samples with missing data from
the dataset; we will learn in the next chapter how to deal with missingness.

\begin{lstlisting}[language=R]
library(stringr)
library(dplyr)
library(tidyr)

# load data set and take a peek
washb_data <- fread(
  paste0(
    "https://raw.githubusercontent.com/tlverse/tlverse-data/master/",
    "wash-benefits/washb_data.csv"
  ),
  stringsAsFactors = TRUE
)

# Remove missing data, then pick just the first 500 rows
washb_data <- washb_data %>%
  drop_na() %>%
  slice(1:500)

outcome <- "whz"
covars <- colnames(washb_data)[-which(names(washb_data) == outcome)]
\end{lstlisting}

Here's a look at the data:

\begin{tabular}{r|l|l|r|r|l|r|l|r|l|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r}
\hline
whz & tr & fracode & month & aged & sex & momage & momedu & momheight & hfiacat & Nlt18 & Ncomp & watmin & elec & floor & walls & roof & asset\_wardrobe & asset\_table & asset\_chair & asset\_khat & asset\_chouki & asset\_tv & asset\_refrig & asset\_bike & asset\_moto & asset\_sewmach & asset\_mobile\\
\hline
0.00 & Control & N05265 & 9 & 268 & male & 30 & Primary (1-5y) & 146.40 & Food Secure & 3 & 11 & 0 & 1 & 0 & 1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 1\\
\hline
-1.16 & Control & N05265 & 9 & 286 & male & 25 & Primary (1-5y) & 148.75 & Moderately Food Insecure & 2 & 4 & 0 & 1 & 0 & 1 & 1 & 0 & 1 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
-1.05 & Control & N08002 & 9 & 264 & male & 25 & Primary (1-5y) & 152.15 & Food Secure & 1 & 10 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
-1.26 & Control & N08002 & 9 & 252 & female & 28 & Primary (1-5y) & 140.25 & Food Secure & 3 & 5 & 0 & 1 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 1\\
\hline
-0.59 & Control & N06531 & 9 & 336 & female & 19 & Secondary (>5y) & 150.95 & Food Secure & 2 & 7 & 0 & 1 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
-0.51 & Control & N06531 & 9 & 304 & male & 20 & Secondary (>5y) & 154.20 & Severely Food Insecure & 0 & 3 & 1 & 1 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
\end{tabular}

We can see the covariates used in the prediction:

\begin{lstlisting}[language=R]
outcome
[1] "whz"
covars
 [1] "tr"             "fracode"        "month"          "aged"          
 [5] "sex"            "momage"         "momedu"         "momheight"     
 [9] "hfiacat"        "Nlt18"          "Ncomp"          "watmin"        
[13] "elec"           "floor"          "walls"          "roof"          
[17] "asset_wardrobe" "asset_table"    "asset_chair"    "asset_khat"    
[21] "asset_chouki"   "asset_tv"       "asset_refrig"   "asset_bike"    
[25] "asset_moto"     "asset_sewmach"  "asset_mobile"  
\end{lstlisting}

Next, we fit a linear model on the full data, with the goal of predicting the
weight-for-height Z-score \passthrough{\lstinline!whz!} using all of the available covariate data. Let's
try it out:

\begin{lstlisting}[language=R]
lm_mod <- lm(whz ~ ., data = washb_data)
summary(lm_mod)

Call:
lm(formula = whz ~ ., data = washb_data)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.8890 -0.6799 -0.0169  0.6595  3.1005 

Coefficients:
                                Estimate Std. Error t value Pr(>|t|)   
(Intercept)                     -1.89006    1.72022   -1.10   0.2725   
trHandwashing                   -0.25276    0.17032   -1.48   0.1385   
trNutrition                     -0.09695    0.15696   -0.62   0.5371   
trNutrition + WSH               -0.09587    0.16528   -0.58   0.5622   
trSanitation                    -0.27702    0.15846   -1.75   0.0811 . 
trWSH                           -0.02846    0.15967   -0.18   0.8586   
trWater                         -0.07148    0.15813   -0.45   0.6515   
fracodeN05160                    0.62355    0.30719    2.03   0.0430 * 
fracodeN05265                    0.38762    0.31011    1.25   0.2120   
fracodeN05359                    0.10187    0.31329    0.33   0.7452   
fracodeN06229                    0.30933    0.29766    1.04   0.2993   
fracodeN06453                    0.08066    0.30006    0.27   0.7882   
fracodeN06458                    0.43707    0.29970    1.46   0.1454   
fracodeN06473                    0.45406    0.30912    1.47   0.1426   
fracodeN06479                    0.60994    0.31463    1.94   0.0532 . 
fracodeN06489                    0.25923    0.31901    0.81   0.4169   
fracodeN06500                    0.07539    0.35794    0.21   0.8333   
fracodeN06502                    0.36748    0.30504    1.20   0.2290   
fracodeN06505                    0.20038    0.31560    0.63   0.5258   
fracodeN06516                    0.55455    0.29807    1.86   0.0635 . 
fracodeN06524                    0.49429    0.31423    1.57   0.1164   
fracodeN06528                    0.75966    0.31060    2.45   0.0148 * 
fracodeN06531                    0.36856    0.30155    1.22   0.2223   
fracodeN06862                    0.56932    0.29293    1.94   0.0526 . 
fracodeN08002                    0.36779    0.26846    1.37   0.1714   
month                            0.17161    0.10865    1.58   0.1149   
aged                            -0.00336    0.00112   -3.00   0.0029 **
sexmale                          0.12352    0.09203    1.34   0.1802   
momage                          -0.01379    0.00973   -1.42   0.1570   
momeduPrimary (1-5y)            -0.13214    0.15225   -0.87   0.3859   
momeduSecondary (>5y)            0.12632    0.16041    0.79   0.4314   
momheight                        0.00512    0.00919    0.56   0.5776   
hfiacatMildly Food Insecure      0.05804    0.19341    0.30   0.7643   
hfiacatModerately Food Insecure -0.01362    0.12887   -0.11   0.9159   
hfiacatSeverely Food Insecure   -0.13447    0.25418   -0.53   0.5970   
Nlt18                           -0.02557    0.04060   -0.63   0.5291   
Ncomp                            0.00179    0.00762    0.23   0.8145   
watmin                           0.01347    0.00861    1.57   0.1182   
elec                             0.08906    0.10700    0.83   0.4057   
floor                           -0.17763    0.17734   -1.00   0.3171   
walls                           -0.03001    0.21445   -0.14   0.8888   
roof                            -0.03716    0.49214   -0.08   0.9399   
asset_wardrobe                  -0.05754    0.13736   -0.42   0.6755   
asset_table                     -0.22079    0.12276   -1.80   0.0728 . 
asset_chair                      0.28012    0.13750    2.04   0.0422 * 
asset_khat                       0.02306    0.11766    0.20   0.8447   
asset_chouki                    -0.13943    0.14084   -0.99   0.3227   
asset_tv                         0.17723    0.12972    1.37   0.1726   
asset_refrig                     0.12613    0.23162    0.54   0.5863   
asset_bike                      -0.02568    0.10083   -0.25   0.7990   
asset_moto                      -0.32094    0.19944   -1.61   0.1083   
asset_sewmach                    0.05090    0.17795    0.29   0.7750   
asset_mobile                     0.01420    0.14972    0.09   0.9245   
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.984 on 447 degrees of freedom
Multiple R-squared:  0.129, Adjusted R-squared:  0.0277 
F-statistic: 1.27 on 52 and 447 DF,  p-value: 0.104
\end{lstlisting}

We can assess how well the model fits the data by comparing the predictions of
the linear model to the true outcomes observed in the data set. This is the well
known (and standard) mean squared error. We can extract that from the \passthrough{\lstinline!lm!} model
object as follows:

\begin{lstlisting}[language=R]
(err <- mean(resid(lm_mod)^2))
[1] 0.86568
\end{lstlisting}

The mean squared error is 0.86568. There is an important problem that arises
when we assess the model in this way - that is, we have trained our linear
regression model on the full data set and assessed the error on the full data
set, using up all of our data. We, of course, are generally not interested in
how well the model explains variation in the observed data; rather, we are
interested in how the explanation provided by the model generalizes to a target
population from which the sample is presumably derived. Having used all of our
available data, we cannot honestly evaluate how well the model fits (and thus
explains) variation at the population level.

To resolve this issue, cross-validation allows for a particular procedure (e.g.,
linear regression) to be implemented over subsets of the data, evaluating how
well the procedure fits on a testing (``validation'') set, thereby providing an
honest evaluation of the error.

We can easily add cross-validation to our linear regression procedure using
\passthrough{\lstinline!origami!}. First, let us define a new function to perform linear regression on a
specific partition of the data (called a ``fold''):

\begin{lstlisting}[language=R]
cv_lm <- function(fold, data, reg_form) {
  # get name and index of outcome variable from regression formula
  out_var <- as.character(unlist(str_split(reg_form, " "))[1])
  out_var_ind <- as.numeric(which(colnames(data) == out_var))

  # split up data into training and validation sets
  train_data <- training(data)
  valid_data <- validation(data)

  # fit linear model on training set and predict on validation set
  mod <- lm(as.formula(reg_form), data = train_data)
  preds <- predict(mod, newdata = valid_data)
  valid_data <- as.data.frame(valid_data)

  # capture results to be returned as output
  out <- list(
    coef = data.frame(t(coef(mod))),
    SE = (preds - valid_data[, out_var_ind])^2
  )
  return(out)
}
\end{lstlisting}

Our \passthrough{\lstinline!cv\_lm!} function is rather simple: we merely split the available data into a
training and validation sets (using the eponymous functions provided in
\passthrough{\lstinline!origami!}) fit the linear model on the training set, and evaluate the model on
the validation set. This is a simple example of what \passthrough{\lstinline!origami!} considers to be
\passthrough{\lstinline!cv\_fun!} --- functions for using cross-validation to perform a particular routine
over an input data set. Having defined such a function, we can simply generate a
set of partitions using \passthrough{\lstinline!origami!}'s \passthrough{\lstinline!make\_folds!} function, and apply our \passthrough{\lstinline!cv\_lm!}
function over the resultant \passthrough{\lstinline!folds!} object. Below, we replicate the
re-substitution estimate of the error -- we did this ``by hand'' above -- using
the functions \passthrough{\lstinline!make\_folds!} and \passthrough{\lstinline!cv\_lm!}.

\begin{lstlisting}[language=R]
# re-substitution estimate
resub <- make_folds(washb_data, fold_fun = folds_resubstitution)[[1]]
resub_results <- cv_lm(fold = resub, data = washb_data, reg_form = "whz ~ .")
mean(resub_results$SE, na.rm = TRUE)
[1] 0.86568
\end{lstlisting}

This (nearly) matches the estimate of the error that we obtained above.

We can more honestly evaluate the error by V-fold cross-validation, which
partitions the data into \(v\) subsets, fitting the model on \(v - 1\) of the
subsets and evaluating on the subset that was held out for testing. This is
repeated such that each subset is used for validation. We can easily apply our
\passthrough{\lstinline!cv\_lm!} function using \passthrough{\lstinline!origami!}'s \passthrough{\lstinline!cross\_validate!} (n.b., by default this
performs 10-fold cross-validation):

\begin{lstlisting}[language=R]
# cross-validated estimate
folds <- make_folds(washb_data)
cvlm_results <- cross_validate(
  cv_fun = cv_lm, folds = folds, data = washb_data, reg_form = "whz ~ .",
  use_future = FALSE
)
mean(cvlm_results$SE, na.rm = TRUE)
[1] 1.35
\end{lstlisting}

Having performed 10-fold cross-validation, we quickly notice that our previous
estimate of the model error (by resubstitution) was a bit optimistic. The honest
estimate of the error is larger!

\hypertarget{cross-validation-with-random-forests}{%
\subsection{Cross-validation with random forests}\label{cross-validation-with-random-forests}}

To examine \passthrough{\lstinline!origami!} further, let us return to our example analysis using the
WASH data set. Here, we will write a new \passthrough{\lstinline!cv\_fun!} type object. As an example, we
will use Breiman's \passthrough{\lstinline!randomForest!} \citep{breiman2001random}:

\begin{lstlisting}[language=R]
# make sure to load the package!
library(randomForest)

cv_rf <- function(fold, data, reg_form) {
  # get name and index of outcome variable from regression formula
  out_var <- as.character(unlist(str_split(reg_form, " "))[1])
  out_var_ind <- as.numeric(which(colnames(data) == out_var))

  # define training and validation sets based on input object of class "folds"
  train_data <- training(data)
  valid_data <- validation(data)

  # fit Random Forest regression on training set and predict on holdout set
  mod <- randomForest(formula = as.formula(reg_form), data = train_data)
  preds <- predict(mod, newdata = valid_data)
  valid_data <- as.data.frame(valid_data)

  # define output object to be returned as list (for flexibility)
  out <- list(
    coef = data.frame(mod$coefs),
    SE = ((preds - valid_data[, out_var_ind])^2)
  )
  return(out)
}
\end{lstlisting}

Above, in writing our \passthrough{\lstinline!cv\_rf!} function to cross-validate \passthrough{\lstinline!randomForest!}, we used
our previous function \passthrough{\lstinline!cv\_lm!} as an example. For now, individual \passthrough{\lstinline!cv\_fun!} must
be written by hand; however, in future releases, a wrapper may be available to
support auto-generating \passthrough{\lstinline!cv\_fun!}s to be used with \passthrough{\lstinline!origami!}.

Below, we use \passthrough{\lstinline!cross\_validate!} to apply our new \passthrough{\lstinline!cv\_rf!} function over the \passthrough{\lstinline!folds!}
object generated by \passthrough{\lstinline!make\_folds!}.

\begin{lstlisting}[language=R]
# now, let's cross-validate...
folds <- make_folds(washb_data)
cvrf_results <- cross_validate(
  cv_fun = cv_rf, folds = folds, 
  data = washb_data, reg_form = "whz ~ .",
  use_future = FALSE
)
mean(cvrf_results$SE)
[1] 1.0271
\end{lstlisting}

Using 10-fold cross-validation (the default), we obtain an honest estimate of
the prediction error of random forests. From this, we gather that the use of
\passthrough{\lstinline!origami!}'s \passthrough{\lstinline!cross\_validate!} procedure can be generalized to arbitrary estimation
techniques, given availability of an appropriate \passthrough{\lstinline!cv\_fun!} function.

\hypertarget{cross-validation-with-arima}{%
\subsection{Cross-validation with arima}\label{cross-validation-with-arima}}

Cross-validation can also be used for forecast model selection in a time series
setting. Here, the partitioning scheme mirrors the application of the
forecasting model: we'll train the data on past observations (either all
available or a recent subset), and then use the model fit to predict the next
few observations. We consider the \passthrough{\lstinline!AirPassengers!} dataset again, a monthly time
series of passenger air traffic in thousands of people.

\begin{lstlisting}[language=R]
data(AirPassengers)
print(AirPassengers)
     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
1949 112 118 132 129 121 135 148 148 136 119 104 118
1950 115 126 141 135 125 149 170 170 158 133 114 140
1951 145 150 178 163 172 178 199 199 184 162 146 166
1952 171 180 193 181 183 218 230 242 209 191 172 194
1953 196 196 236 235 229 243 264 272 237 211 180 201
1954 204 188 235 227 234 264 302 293 259 229 203 229
1955 242 233 267 269 270 315 364 347 312 274 237 278
1956 284 277 317 313 318 374 413 405 355 306 271 306
1957 315 301 356 348 355 422 465 467 404 347 305 336
1958 340 318 362 348 363 435 491 505 404 359 310 337
1959 360 342 406 396 420 472 548 559 463 407 362 405
1960 417 391 419 461 472 535 622 606 508 461 390 432
\end{lstlisting}

Suppose we want to pick between two forecasting models with different \passthrough{\lstinline!arima!}
configurations. We can do that by evaluating their forecasting performance.
First, we set up the appropriate cross-validation scheme for time-series.

\begin{lstlisting}[language=R]
folds <- make_folds(AirPassengers,
  fold_fun = folds_rolling_origin,
  first_window = 36, validation_size = 24, batch = 10
)

# How many folds where generated?
length(folds)
[1] 9

# Examine the first 2 folds.
folds[[1]]
$v
[1] 1

$training_set
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
[26] 26 27 28 29 30 31 32 33 34 35 36

$validation_set
 [1] 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60

attr(,"class")
[1] "fold"
folds[[2]]
$v
[1] 2

$training_set
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
[26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46

$validation_set
 [1] 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70

attr(,"class")
[1] "fold"
\end{lstlisting}

By default, \passthrough{\lstinline!folds\_rolling\_origin!} will increase the size of the training set by
one time point each fold. Had we followed the default option, we would have 85
folds to train! Luckily, we can pass the \passthrough{\lstinline!batch!} as option to
\passthrough{\lstinline!folds\_rolling\_origin!} that tells it to increase the size of the training set by
10 points each iteration. Since we want to forecast the immediate next point,
\passthrough{\lstinline!gap!} argument remains the default (0).

\begin{lstlisting}[language=R]
# make sure to load the package!
library(forecast)

# function to calculate cross-validated squared error
cv_forecasts <- function(fold, data) {
  # Get training and validation data
  train_data <- training(data)
  valid_data <- validation(data)
  valid_size <- length(valid_data)

  train_ts <- ts(log10(train_data), frequency = 12)

  # First arima model
  arima_fit <- arima(train_ts, c(0, 1, 1),
    seasonal = list(
      order = c(0, 1, 1),
      period = 12
    )
  )
  raw_arima_pred <- predict(arima_fit, n.ahead = valid_size)
  arima_pred <- 10^raw_arima_pred$pred
  arima_MSE <- mean((arima_pred - valid_data)^2)

  # Second arima model
  arima_fit2 <- arima(train_ts, c(5, 1, 1),
    seasonal = list(
      order = c(0, 1, 1),
      period = 12
    )
  )
  raw_arima_pred2 <- predict(arima_fit2, n.ahead = valid_size)
  arima_pred2 <- 10^raw_arima_pred2$pred
  arima_MSE2 <- mean((arima_pred2 - valid_data)^2)

  out <- list(mse = data.frame(
    fold = fold_index(),
    arima = arima_MSE, arima2 = arima_MSE2
  ))
  return(out)
}

mses <- cross_validate(
  cv_fun = cv_forecasts, folds = folds, data = AirPassengers,
  use_future = FALSE
)
mses$mse
  fold   arima  arima2
1    1   68.21  137.28
2    2  319.68  313.15
3    3  578.35  713.36
4    4  428.69  505.31
5    5  407.33  371.27
6    6  281.82  250.99
7    7  827.56  910.12
8    8 2099.59 2213.15
9    9  398.37  293.38
colMeans(mses$mse[, c("arima", "arima2")])
 arima arima2 
601.07 634.22 
\end{lstlisting}

The arima model with no AR component seems to be a better fit for this data.

\hypertarget{exercises}{%
\section{Exercises}\label{exercises}}

\hypertarget{review-of-key-concepts}{%
\subsection{Review of Key Concepts}\label{review-of-key-concepts}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Compare and contrast V-fold cross-validation with resubstitution
  cross-validation. What are some of the differences between the two methods?
  How are they similar? Describe a scenario when you would use one over the
  other.
\item
  What are the advantages and disadvantages of \(v\)-fold CV relative to:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    holdout CV?
  \item
    leave-one-out CV?
  \end{enumerate}
\item
  Why can't we use V-fold cross-validation for time-series data?
\item
  Would you use rolling window or origin for non-stationary time-series? Why?
\end{enumerate}

\hypertarget{the-ideas-in-action}{%
\subsection{The Ideas in Action}\label{the-ideas-in-action}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Let \(Y\) be a binary variable with \(P(Y=1 \mid W) = 0.01\). What kind of
  cross-validation scheme should be used for a rare outcome? How can we do this
  with the \passthrough{\lstinline!origami!} package?
\item
  Consider the WASH benefits dataset presented in this chapter. How can we
  include cluster information into cross-validation? How can we do this with
  the \passthrough{\lstinline!origami!} package?
\end{enumerate}

\hypertarget{advanced-topics}{%
\subsection{Advanced Topics}\label{advanced-topics}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Think about a dataset with arbitrary spatial dependence, where we know
  the extent of dependence, and groups formed by such dependence are clear
  with no spillover effects. What kind of cross-validation can we use?
\item
  Continuing on the last problem, what kind of procedure, and cross-validation
  method, can we use if the spatial dependence is not clearly defined as in the
  previous problem?
\item
  Consider a classification problem with a large number of predictors. A
  statistician proposes the following analysis:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    First screen the predictors, leaving only covariates with a strong
    correlation with the class labels.
  \item
    Fit some algorithm using only the subset of highly correlated covariates.
  \item
    Use cross-validation to estimate the tuning parameters and the performance
    of the proposed algorithm.
  \end{enumerate}

  Is this a correct application of cross-validation? Why?
\end{enumerate}

\hypertarget{sl3}{%
\chapter{Super (Machine) Learning}\label{sl3}}

\emph{Rachael Phillips}

Based on the \href{https://github.com/tlverse/sl3}{\passthrough{\lstinline!sl3!} \passthrough{\lstinline!R!} package} by \emph{Jeremy
Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips, and Oleg Sofrygin}.

Updated: 2021-09-21

\hypertarget{learning-objectives}{%
\section*{Learning Objectives}\label{learning-objectives}}


By the end of this chapter you will be able to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Select an objective function that (i) aligns with the intention of the
  analysis and (ii) is optimized by the target parameter.
\item
  Assemble a diverse library of learners to be considered in the Super Learner
  ensemble. In particular, you should be able to:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    Customize a learner by modifying it's tuning parameters.
  \item
    Create several different versions of the same learner at once by
    specifying a grid of tuning parameters.
  \item
    Curate covariate screening pipelines in order to pass a screener's
    output, a subset of covariates, as input for another learner that will
    use the subset of covariates selected by the screener to model the data.
  \end{enumerate}
\item
  Specify the learner for ensembling (the metalearner) such that it corresponds
  to your objective function.
\item
  Fit the Super Learner ensemble with nested cross-validation to obtain an
  estimate of the performance of the ensemble itself on out-of-sample data.
\item
  Obtain \passthrough{\lstinline!sl3!} variable importance metrics.
\item
  Interpret the fit for discrete and continuous Super Learners' from the
  cross-validated risk table and the coefficients.
\item
  Justify the base library of machine learning algorithms and the ensembling
  learner in terms of the prediction problem, statistical model \(\M\), data
  sparsity, and the dimensionality of the covariates.
\end{enumerate}

\hypertarget{motivation}{%
\section*{Motivation}\label{motivation}}


\begin{itemize}
\tightlist
\item
  A common task in data analysis is prediction -- using the observed data (input
  variables and outcomes) to learn a function that can map new input variables
  into a predicted outcome.
\item
  For some data, algorithms that learn complex relationships between variables
  are necessary to adequately model the data. For other data, main terms
  regression models might fit the data quite well.
\item
  It is generally impossible to know a priori which algorithm will be the best
  for a given data set and prediction problem. It's like picking the winner of
  \emph{The Great British Bake Off} at the start of the first week!
\item
  The Super Learner solves this issue of algorithm selection by creating an
  ensemble of many algorithms, from the simplest (intercept-only) to most
  complex (neural nets, tree-based methods, support vector machines, etc.).
\item
  Super Learner works by using cross-validation in a manner that theoretically
  (in large samples) guarantees the resulting fit will be as good as possible,
  given the algorithms provided.
\end{itemize}

\hypertarget{introduction-2}{%
\section{Introduction}\label{introduction-2}}

In \protect\hyperlink{intro}{Chapter 1}, we introduced the \protect\hyperlink{roadmap}{\emph{Roadmap for Targeted
Learning}} as a general template to translate real-world data
applications into formal statistical estimation problems. The first steps of
this roadmap define the \emph{statistical estimation problem}, which establish

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{The data \$O\$ as a random variable, or equivalently, a realization of a}
  \textbf{particular experiment/study, which has probability distribution \(P_0\).}
  This is written \(O \sim P_0\), and \(P_0\) is also commonly referred to as the
  data-generating process (DGP) and also the data-generating distribution
  (DGD). The data structure \(O\) is comprised of variables, such as a
  vector of covariates \(W\), a treatment or exposure \(A\), and an outcome \(Y\),
  \(O=(W,A,Y) \sim P_0\). We often observe the random variable \(O\) \(n\) times, by
  repeating the common experiment \(n\) times. For example, \(O_1,\ldots, O_n\)
  random variables could be the result of a random sample of \(n\) subjects from
  a population, collecting baseline characteristics \(W\), randomly assigning
  treatment \(A\), and then later measuring an outcome \(Y\).
\item
  \textbf{A statistical model \(\M\) as a set of possible probability distributions}
  \textbf{that could have given rise to the data.} It's essential for \(\M\) to only
  constrained by factual subject-matter knowledge in order to guarantee \(P_0\)
  resides in the statistical model, written \(P_0 \in \M\). Continuing
  the example from step 1, the following restrictions could be placed on the
  statistical model: the \(O_1, \ldots, O_n\) observations in the data are
  independent and identically distributed (i.i.d.), the assignment of
  treatment \(A\) was random and not based on covariates \(W\).
\item
  \textbf{A translation of the scientific question of interest into a function of}
  \textbf{\(P_0\), the target statistical estimand \(\Psi(P_0)\).} For example, we might
  be interested in the average difference in mean outcomes under treatment
  \(A=1\) versus placebo \(A=0\):
  \(\Psi(P_0)=E_{P_0}\Big[E_{P_0}(Y|A=1,W)−E_{P_0}(Y|A=0,W)\Big]\). Note
  that, if the scientific question is causal, then it's translation will
  produce a target \emph{causal} estimand; another layer of translation,
  identifiability, is required to express the target causal estimand as a
  function of the observed data distribution \(P_0\). See \protect\hyperlink{causal}{causal target
  parameters} for more information on causal quantities, causal models
  and identifiability.
\end{enumerate}

Once the statistical estimation problem has been established, then the estimator
can be constructed. Estimators (also referred to as algorithms and learners)
are functions that take as input the observed data, and return as output an
estimate of \(P_0\) or some feature of \(P_0\) (such as a component of the target
estimand). We will use the Super Learner (SL) algorithm to estimate a
prediction function, and then we will use the SL estimator of the prediction
function to predict outcomes from new input (e.g., covariate/predictor) data.
Occasionally, the prediction function itself is the target estimand; more
commonly, the prediction function is a component of a target estimand.

Consider an example where we need to estimate the prediction function for
\(E_{P_0}(Y|A,W)\) (the conditional mean outcome, given treatment \(A\) and
baseline covariates \(W\)), so we can predict what the outcomes would have been
under a hypothetical scenario where all subjects received treatment \(A=1\). In
order for this estimator to output predictions that correspond to outcomes in
a world where all subjects received treatment \(A=1\), we would need to supply
the estimator with input data that reflects it; specifically, the baseline
covariate information \(W\) would remain the same treatment as it is in the
observed data, but the treatment \(A\) would be set to 1 for all individuals,
regardless of whether or not they actually received it. This learning paradigm
corresponds to estimation of a component of the target statistical estimand
mentioned in step 3 above, the \(E_{P_0}(Y|A=1,W)\) component of \(\Psi(P_0)\).

There are various strategies that estimators can employ to model relationships
from the observed data, and there is no ``one fits all'' algorithm in the realm
of real-world data science. However, the statistical performance of algorithms'
(e.g., mean squared error) can be used to compare them. Therefore, algorithm
selection should be driven criteria that have been (i) proven to optimize
relevant statistical properties (e.g., provide theoretical guarantees) and (ii)
shown to be reliable in practice (e.g., with complex real-world data). The SL
is an algorithm that is equipped with such a standard, the cross-validation
criterion, which ensures in large samples that the SL will perform atleast as
well as the unknown best-performing candidate algorithm \citep{vdl2003unified, vaart2006oracle, vdl2007super}. Also, as an ensemble machine learning
algorithm, SL leverages information learned from a variety of candidate
algorithms by creating a weighted combination of
them (i.e., metalearning). In summary, SL represents a practical approach for
principled machine learning. It has been shown to be adaptive and robust, even
in small samples \citep{polley2010super}.

\hypertarget{candidate-learners-and-ensembling}{%
\subsection{Candidate Learners and Ensembling}\label{candidate-learners-and-ensembling}}

The set of algorithms considering by the SL (also referred to as ``library'')
should consist of those that align with what's known about the DGP and what is
not known about the DGP. In other words, the learners in the library should
be tailored to respect the statistical model \(\mathcal{M}\), both in terms of

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the restrictions placed on \(\mathcal{M}\), so the candidate algorithms
  represent functions that align with the knowledge about the DGP, and
\item
  the vastness of \(\mathcal{M}\), so the library is able to adapt to a
  diversity of possible forms for the DGP, which can be acheived by including
  a variety of learning strategies (e.g., that range from parametric regression
  models to multi-step algorithms involving screening covariates,
  penalizations, optimizing tuning parameters, etc.)
\end{enumerate}

\hypertarget{example-respecting-known-bounds-on-the-outcome}{%
\subsubsection{Example: Respecting known bounds on the outcome}\label{example-respecting-known-bounds-on-the-outcome}}

Suppose it is known that the outcome cannot take certain values,
(e.g., the outcome is always a positive real number). The statistical model
should be constrained to reflect these outcome bounds, and in order for the
learners in the library to respect the statistical model, the learners should
be constructed such that their predictions do not fall outside of the outcome
bounds. For learners that allow link functions (e.g., generalized elastic-net
regression models), different link functions can be chosen to match known
outcome bounds. If a learner does not support link functions, or some other
bounding criteria during model fitting, then there is a possibility that the
learner will yield predictions that fall outside of known outcome bounds. In
this scenario, the predictions that are not within known bounds could be
truncated, which might be fine for learners that seldomly produce predictions
that violate known outcome bounds.

In general, the use of link function(s) is more sensible, since it formulates a
model for the function that respects the statistical model, and then optimizes
the fit in that model. The truncation option optimizes in a model that's too
big, losing information, and then corrects ad hoc. However, it might be
limiting to only include learners that support some desired link function
(e.g., a library of several logistic regression models), since a diversity of
possible DGPs might not be captured by this library.

Recall that SL is a weighted combination of this library of candidate
algorithms, and not all weighted combinations are created equally. In order to
ensure that the SL has the same bounds on the predictions as the candidates in
the library, SL's weighted combination should be a convex combination
(i.e., weights are non-negative and sum to one). The most simple example of a
convex combination would be the so-called ``discrete SL'' or
``cross-validated selector'', which uses a metalearner that assigns a weight of
one to the \emph{best} candidate algorithm in the library, and a weight of zero to
all others (where \emph{best} is described in step 4(a) in the \protect\hyperlink{sl3-theory}{step-by-step
overview} below). More flexible metalearners,
like the default metalearner in \passthrough{\lstinline!sl3!}, are those that allow multiple algorithms
to have nonzero weights and still enforce a convex combination.

\hypertarget{sl3-steps}{%
\subsection{Fitting the Super Learner}\label{sl3-steps}}

\hypertarget{cross-validation}{%
\subsubsection{Cross-validation}\label{cross-validation}}

\begin{itemize}
\tightlist
\item
  There are many different cross-validation schemes, which are designed to
  accommodate different study designs, data structures, and prediction
  problems. See \protect\hyperlink{causal}{cross-validation} for more detail.
\end{itemize}

\begin{center}\includegraphics[width=0.8\linewidth]{img/png/vs} \end{center}

The figure above shows an example of \(V\)-fold cross-validation with \(V=10\)
folds, and this is the default cross-validation structure in the \passthrough{\lstinline!sl3!} \passthrough{\lstinline!R!}
package. The darker boxes represent the so-called ``validation data'' and the
lighter boxes represent the so-called ``training data''. The following details
are important to notice:

\begin{itemize}
\tightlist
\item
  Across all folds, there are \(V\) (10) copies of the dataset. The only
  difference between each copy is the coloring, which distinguishes the subset
  of the data that's considered as the training data from the subset that's
  considered as the validation data.
\item
  Within each fold 1/\(V\) (1/10) of the data is the validation data.
\item
  Across all folds, all of the data will be considered as validation data and
  no observation will be included twice as validation data. Therefore, the
  total number of validation data observations across all of the folds is
  equal to the total number of observations in the data.
\end{itemize}

\hypertarget{step-by-step-procedure-with-v-fold-cross-validation}{%
\subsubsection{Step-by-step procedure with V-fold Cross-validation}\label{step-by-step-procedure-with-v-fold-cross-validation}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Fit each learner (say there are \(K\) learners) on the whole dataset. We refer
  to these learners that are trained on the whole dataset as ``full-fit''
  learners.
\item
  Break up the data evenly into \(V\) disjoint subsets. Separately, create
  \(V\) copies of the data. For each copy \(v\), where \(v=1,\ldots,V\), create the
  \(V\) folds by labelling the portion of the data that was included in subset
  \(v\) as the validation sample, and the labelling what's remaining of the data
  as the training sample.
\item
  For each fold \(v\), \(v=1,\ldots,V\), fit each learner (say there are \(K\)
  learners) on the training sample and predict the validation sample outcomes
  by providing each fitted learner with the validation sample covariates as
  input. Notice that each learner will be fit \(V\) times. We refer to these
  learners that are trained across the \(V\) cross-validation folds as
  ``cross-validated fit'' learners.
\item
  Combine the validation sample predictions from all folds and all learners to
  create the so-called \(K\) column matrix of ``cross-validated predictions''.
  This matrix is also commonly referred to as the \(Z\) matrix. Notice that it
  contains, for each learner, out-of-sample predictions for all of the
  observations in the data.
\item
  Train the metalearner (e.g., a non-negative least squares regression) on
  data with predictors and outcomes being the \(Z\) matrix and the observed data
  outcomes, respectively. The metalearner --- just like any ordinary ML
  algorithm --- estimates the parameters of it's model using the training data
  and afterwards, the fitted model can be used to obtain predicted outcomes
  from new input data. What's special about the metalearner is that it's
  estimated model parameters (e.g., regression coefficients) correspond to
  it's predictors, which are the variables in the \(Z\) matrix, the \(K\) learners'
  predictions. Once the metalearner is fit, it can be used to obtain predicted
  outcomes from new input data; that is, new \(K\) learners predictions' can be
  supplied to the fitted metalearner in order to obtain predicted outcomes.
\item
  The fitted metalearner and the full-fit learners define the weighted
  combination of the \(K\) learners, finalizing the Super Learner (SL) fit. To
  obtain SL predictions the full-fit learners' predictions are first obtained
  and then fed as input to the fitted metalearner; the metalearner's output
  is the SL predictions.
\end{enumerate}

\begin{center}\includegraphics[width=0.8\linewidth]{img/png/SLKaiserNew} \end{center}

\hypertarget{sl3-theory}{%
\subsection{Theoretical foundations}\label{sl3-theory}}

This section is under construction.

For more detail on Super Learner algorithm we refer the reader to
\citet{polley2010super} and \citet{vdl2007super}. The optimality results for the
cross-validation selector among a family of algorithms were established in
\citet{vdl2003unified} and extended in \citet{vaart2006oracle}.

\hypertarget{sl3-microwave-dinner-implementation}{%
\section*{\texorpdfstring{\texttt{sl3} ``Microwave Dinner'' Implementation}{sl3 ``Microwave Dinner'' Implementation}}\label{sl3-microwave-dinner-implementation}}


We begin by illustrating the core functionality of the SL algorithm as
implemented in \passthrough{\lstinline!sl3!}.

The \passthrough{\lstinline!sl3!} implementation consists of the following steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{-1}
\tightlist
\item
  Load the necessary libraries and data
\item
  Define the machine learning task
\item
  Make an SL by creating library of base learners and a metalearner
\item
  Train the SL on the machine learning task
\item
  Obtain predicted values
\end{enumerate}

\hypertarget{wash-benefits-study-example-1}{%
\subsection*{WASH Benefits Study Example}\label{wash-benefits-study-example-1}}


Using the WASH Benefits Bangladesh data, we are interested in predicting
weight-for-height z-score \passthrough{\lstinline!whz!} using the available covariate data. More
information on this dataset, and all other data that we will work with, are
described in \href{ihttps://tlverse.org/tlverse-handbook/data.html}{this chapter of the \passthrough{\lstinline!tlverse!}
handbook}. Let's begin!

\hypertarget{load-the-necessary-libraries-and-data}{%
\subsection*{0. Load the necessary libraries and data}\label{load-the-necessary-libraries-and-data}}


First, we will load the relevant \passthrough{\lstinline!R!} packages, set a seed, and load the data.

\begin{lstlisting}[language=R]
library(data.table)
library(dplyr)
library(readr)
library(ggplot2)
library(SuperLearner)
library(origami)
library(sl3)
library(knitr)
library(kableExtra)

# load data set and take a peek
washb_data <- fread(
  paste0(
    "https://raw.githubusercontent.com/tlverse/tlverse-data/master/",
    "wash-benefits/washb_data.csv"
  ),
  stringsAsFactors = TRUE
)
head(washb_data) %>%
  kable() %>%
  kableExtra:::kable_styling(fixed_thead = T) %>%
  scroll_box(width = "100%", height = "300px")
\end{lstlisting}

\begin{table}
\centering
\begin{tabular}{r|l|l|r|r|l|r|l|r|l|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r}
\hline
whz & tr & fracode & month & aged & sex & momage & momedu & momheight & hfiacat & Nlt18 & Ncomp & watmin & elec & floor & walls & roof & asset\_wardrobe & asset\_table & asset\_chair & asset\_khat & asset\_chouki & asset\_tv & asset\_refrig & asset\_bike & asset\_moto & asset\_sewmach & asset\_mobile\\
\hline
0.00 & Control & N05265 & 9 & 268 & male & 30 & Primary (1-5y) & 146.40 & Food Secure & 3 & 11 & 0 & 1 & 0 & 1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 1\\
\hline
-1.16 & Control & N05265 & 9 & 286 & male & 25 & Primary (1-5y) & 148.75 & Moderately Food Insecure & 2 & 4 & 0 & 1 & 0 & 1 & 1 & 0 & 1 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
-1.05 & Control & N08002 & 9 & 264 & male & 25 & Primary (1-5y) & 152.15 & Food Secure & 1 & 10 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
-1.26 & Control & N08002 & 9 & 252 & female & 28 & Primary (1-5y) & 140.25 & Food Secure & 3 & 5 & 0 & 1 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 1\\
\hline
-0.59 & Control & N06531 & 9 & 336 & female & 19 & Secondary (>5y) & 150.95 & Food Secure & 2 & 7 & 0 & 1 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
-0.51 & Control & N06531 & 9 & 304 & male & 20 & Secondary (>5y) & 154.20 & Severely Food Insecure & 0 & 3 & 1 & 1 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1\\
\hline
\end{tabular}
\end{table}

\hypertarget{define-the-machine-learning-task}{%
\subsection*{1. Define the machine learning task}\label{define-the-machine-learning-task}}


To define the machine learning \passthrough{\lstinline!task!} (predict weight-for-height Z-score
\passthrough{\lstinline!whz!} using the available covariate data), we need to create an \passthrough{\lstinline!sl3\_Task!}
object.

The \passthrough{\lstinline!sl3\_Task!} keeps track of the roles the variables play in the machine
learning problem, the data, and any metadata (e.g., observational-level
weights, IDs, offset).

Also, if we had missing outcomes, we would need to set \passthrough{\lstinline!drop\_missing\_outcome = TRUE!} when we create the task. In the next analysis, with the \protect\hyperlink{ist}{IST stroke trial
data}, we do have a missing outcome. In the following chapter, we need to
estimate this missingness mechanism; which is the conditional probably that
the outcome is observed, given the history (i.e., variables that were measured
before the missingness). Estimating the missingness mechanism requires learning
a prediction function that outputs the predicted probability that a unit
is missing, given their history.

\begin{lstlisting}[language=R]
# specify the outcome and covariates
outcome <- "whz"
covars <- colnames(washb_data)[-which(names(washb_data) == outcome)]

# create the sl3 task
washb_task <- make_sl3_Task(
  data = washb_data,
  covariates = covars,
  outcome = outcome
)
Warning in process_data(data, nodes, column_names = column_names, flag = flag, :
Missing covariate data detected: imputing covariates.
\end{lstlisting}

\emph{This warning is important.} The task just imputed missing covariates for us.
Specifically, for each covariate column with missing values, \passthrough{\lstinline!sl3!} uses the
median to impute missing continuous covariates, and the mode to impute binary
and categorical covariates.

Also, for each covariate column with missing values, \passthrough{\lstinline!sl3!} adds an additional
column indicating whether or not the value was imputed, which is particularly
handy when the missingness in the data might be informative.

Also, notice that we did not specify the number of folds, or the loss function
in the task. The default cross-validation scheme is V-fold, with \(V=10\) number
of folds.

Let's visualize our \passthrough{\lstinline!washb\_task!}:

\begin{lstlisting}[language=R]
washb_task
A sl3 Task with 4695 obs and these nodes:
$covariates
 [1] "tr"              "fracode"         "month"           "aged"           
 [5] "sex"             "momage"          "momedu"          "momheight"      
 [9] "hfiacat"         "Nlt18"           "Ncomp"           "watmin"         
[13] "elec"            "floor"           "walls"           "roof"           
[17] "asset_wardrobe"  "asset_table"     "asset_chair"     "asset_khat"     
[21] "asset_chouki"    "asset_tv"        "asset_refrig"    "asset_bike"     
[25] "asset_moto"      "asset_sewmach"   "asset_mobile"    "delta_momage"   
[29] "delta_momheight"

$outcome
[1] "whz"

$id
NULL

$weights
NULL

$offset
NULL

$time
NULL
\end{lstlisting}

We can't see when we print the task, but the default cross-validation fold
structure (\(V\)-fold cross-validation with \(V\)=10 folds) was created when we
defined the task.

\begin{lstlisting}[language=R]
length(washb_task$folds) # how many folds?
[1] 10

head(washb_task$folds[[1]]$training_set) # row indexes for fold 1 training
[1] 1 2 3 4 5 6
head(washb_task$folds[[1]]$validation_set) # row indexes for fold 1 validation
[1] 12 21 29 41 43 53

any(
  washb_task$folds[[1]]$training_set %in% washb_task$folds[[1]]$validation_set
)
[1] FALSE
\end{lstlisting}

Tip: If you type \passthrough{\lstinline!washb\_task$!} and then press the tab button (you will
need to press tab twice if you're not in RStudio), you can view all of the
active and public fields and methods that can be accessed from the \passthrough{\lstinline!washb\_task!}
object.

\hypertarget{make-a-super-learner}{%
\subsection*{2. Make a Super Learner}\label{make-a-super-learner}}


Now that we have defined our machine learning problem with the \passthrough{\lstinline!sl3\_Task!}, we
are ready to make the Super Learner (SL). This requires specification of

\begin{itemize}
\tightlist
\item
  A set of candidate machine learning algorithms, also commonly referred to as
  a library of learners. The set should include a diversity of algorithms
  that are believed to be consistent with the true data-generating distribution.
\item
  A metalearner, to ensemble the base learners.
\end{itemize}

We might also incorporate

\begin{itemize}
\tightlist
\item
  Feature selection, to pass only a subset of the predictors to the algorithm.
\item
  Hyperparameter specification, to tune base learners.
\end{itemize}

Learners have properties that indicate what features they support. We may use
\passthrough{\lstinline!sl3\_list\_properties()!} to get a list of all properties supported by at least
one learner.

\begin{lstlisting}[language=R]
sl3_list_properties()
 [1] "binomial"      "categorical"   "continuous"    "cv"           
 [5] "density"       "h2o"           "ids"           "importance"   
 [9] "offset"        "preprocessing" "sampling"      "screener"     
[13] "timeseries"    "weights"       "wrapper"      
\end{lstlisting}

Since we have a continuous outcome, we may identify the learners that support
this outcome type with \passthrough{\lstinline!sl3\_list\_learners()!}.

\begin{lstlisting}[language=R]
sl3_list_learners("continuous")
 [1] "Lrnr_arima"                     "Lrnr_bartMachine"              
 [3] "Lrnr_bayesglm"                  "Lrnr_bilstm"                   
 [5] "Lrnr_bound"                     "Lrnr_caret"                    
 [7] "Lrnr_cv_selector"               "Lrnr_dbarts"                   
 [9] "Lrnr_earth"                     "Lrnr_expSmooth"                
[11] "Lrnr_gam"                       "Lrnr_gbm"                      
[13] "Lrnr_glm"                       "Lrnr_glm_fast"                 
[15] "Lrnr_glmnet"                    "Lrnr_grf"                      
[17] "Lrnr_gru_keras"                 "Lrnr_gts"                      
[19] "Lrnr_h2o_glm"                   "Lrnr_h2o_grid"                 
[21] "Lrnr_hal9001"                   "Lrnr_HarmonicReg"              
[23] "Lrnr_hts"                       "Lrnr_lightgbm"                 
[25] "Lrnr_lstm_keras"                "Lrnr_mean"                     
[27] "Lrnr_multiple_ts"               "Lrnr_nnet"                     
[29] "Lrnr_nnls"                      "Lrnr_optim"                    
[31] "Lrnr_pkg_SuperLearner"          "Lrnr_pkg_SuperLearner_method"  
[33] "Lrnr_pkg_SuperLearner_screener" "Lrnr_polspline"                
[35] "Lrnr_randomForest"              "Lrnr_ranger"                   
[37] "Lrnr_rpart"                     "Lrnr_rugarch"                  
[39] "Lrnr_screener_correlation"      "Lrnr_solnp"                    
[41] "Lrnr_stratified"                "Lrnr_svm"                      
[43] "Lrnr_tsDyn"                     "Lrnr_xgboost"                  
\end{lstlisting}

Now that we have an idea of some learners, we can construct them using the
\passthrough{\lstinline!make\_learner!} function or the \passthrough{\lstinline!new!} method.

\begin{lstlisting}[language=R]
# choose base learners
lrn_glm <- make_learner(Lrnr_glm)
lrn_mean <- Lrnr_mean$new()
\end{lstlisting}

We can customize learner hyperparameters to incorporate a diversity of different
settings. Documentation for the learners and their hyperparameters can be found
in the \href{https://tlverse.org/sl3/reference/index.html\#section-sl-learners}{\passthrough{\lstinline!sl3!} Learners
Reference}.

\begin{lstlisting}[language=R]
lrn_lasso <- make_learner(Lrnr_glmnet) # alpha default is 1
lrn_ridge <- Lrnr_glmnet$new(alpha = 0)
lrn_enet.5 <- make_learner(Lrnr_glmnet, alpha = 0.5)

lrn_polspline <- Lrnr_polspline$new()

lrn_ranger100 <- make_learner(Lrnr_ranger, num.trees = 100)

lrn_hal_faster <- Lrnr_hal9001$new(max_degree = 2, reduce_basis = 0.05)

xgb_fast <- Lrnr_xgboost$new() # default with nrounds = 20 is pretty fast
xgb_50 <- Lrnr_xgboost$new(nrounds = 50)
\end{lstlisting}

We can use \passthrough{\lstinline!Lrnr\_define\_interactions!} to define interaction terms among
covariates. The interactions should be supplied as list of character vectors,
where each vector specifies an interaction. For example, we specify
interactions below between (1) \passthrough{\lstinline!tr!} (whether or not the subject received the
WASH intervention) and \passthrough{\lstinline!elec!} (whether or not the subject had electricity); and
between (2) \passthrough{\lstinline!tr!} and \passthrough{\lstinline!hfiacat!} (the subject's level of food security).

\begin{lstlisting}[language=R]
interactions <- list(c("elec", "tr"), c("tr", "hfiacat"))
# main terms as well as the interactions above will be included
lrn_interaction <- make_learner(Lrnr_define_interactions, interactions)
\end{lstlisting}

What we just defined above is incomplete. In order to fit learners with these
interactions, we need to create a \passthrough{\lstinline!Pipeline!}. A \passthrough{\lstinline!Pipeline!} is a set of learners
to be fit sequentially, where the fit from one learner is used to define the
task for the next learner. We need to create a \passthrough{\lstinline!Pipeline!} with the interaction
defining learner and another learner that incorporate these terms when fitting
a model. Let's create a learner pipeline that will fit a linear model with the
combination of main terms and interactions terms, as specified in
\passthrough{\lstinline!lrn\_interaction!}.

\begin{lstlisting}[language=R]
# we already instantiated a linear model learner, no need to do that again
lrn_glm_interaction <- make_learner(Pipeline, lrn_interaction, lrn_glm)
lrn_glm_interaction
[1] "Lrnr_define_interactions_TRUE"
[1] "Lrnr_glm_TRUE"
\end{lstlisting}

We can also include learners from the \passthrough{\lstinline!SuperLearner!} \passthrough{\lstinline!R!} package.

\begin{lstlisting}[language=R]
lrn_bayesglm <- Lrnr_pkg_SuperLearner$new("SL.bayesglm")
\end{lstlisting}

Here is a fun trick to create customized learners over a grid of parameters.

\begin{lstlisting}[language=R]
# I like to crock pot my SLs
grid_params <- list(
  cost = c(0.01, 0.1, 1, 10, 100, 1000),
  gamma = c(0.001, 0.01, 0.1, 1),
  kernel = c("polynomial", "radial", "sigmoid"),
  degree = c(1, 2, 3)
)
grid <- expand.grid(grid_params, KEEP.OUT.ATTRS = FALSE)
svm_learners <- apply(grid, MARGIN = 1, function(tuning_params) {
  do.call(Lrnr_svm$new, as.list(tuning_params))
})
\end{lstlisting}

\begin{lstlisting}[language=R]
grid_params <- list(
  max_depth = c(2, 4, 6),
  eta = c(0.001, 0.1, 0.3),
  nrounds = 100
)
grid <- expand.grid(grid_params, KEEP.OUT.ATTRS = FALSE)
grid
  max_depth   eta nrounds
1         2 0.001     100
2         4 0.001     100
3         6 0.001     100
4         2 0.100     100
5         4 0.100     100
6         6 0.100     100
7         2 0.300     100
8         4 0.300     100
9         6 0.300     100

xgb_learners <- apply(grid, MARGIN = 1, function(tuning_params) {
  do.call(Lrnr_xgboost$new, as.list(tuning_params))
})
xgb_learners
[[1]]
[1] "Lrnr_xgboost_100_1_2_0.001"

[[2]]
[1] "Lrnr_xgboost_100_1_4_0.001"

[[3]]
[1] "Lrnr_xgboost_100_1_6_0.001"

[[4]]
[1] "Lrnr_xgboost_100_1_2_0.1"

[[5]]
[1] "Lrnr_xgboost_100_1_4_0.1"

[[6]]
[1] "Lrnr_xgboost_100_1_6_0.1"

[[7]]
[1] "Lrnr_xgboost_100_1_2_0.3"

[[8]]
[1] "Lrnr_xgboost_100_1_4_0.3"

[[9]]
[1] "Lrnr_xgboost_100_1_6_0.3"
\end{lstlisting}

Did you see \passthrough{\lstinline!Lrnr\_caret!} when we called \passthrough{\lstinline!sl3\_list\_learners(c("binomial"))!}? All
we need to specify to use this popular algorithm as a candidate in our SL is
the \passthrough{\lstinline!algorithm!} we want to tune, which is passed as \passthrough{\lstinline!method!} to \passthrough{\lstinline!caret::train()!}.

\begin{lstlisting}[language=R]
# Unlike xgboost, I have no idea how to tune a neural net or BART machine, so
# I let caret take the reins
lrnr_caret_nnet <- make_learner(Lrnr_caret, algorithm = "nnet")
lrnr_caret_bartMachine <- make_learner(Lrnr_caret,
  algorithm = "bartMachine",
  method = "boot", metric = "Accuracy",
  tuneLength = 10
)
\end{lstlisting}

In order to assemble the library of learners, we need to \passthrough{\lstinline!Stack!} them
together.

A \passthrough{\lstinline!Stack!} is a special learner and it has the same interface as all other
learners. What makes a stack special is that it combines multiple learners by
training them simultaneously, so that their predictions can be either combined
or compared.

\begin{lstlisting}[language=R]
stack <- make_learner(
  Stack, lrn_glm, lrn_polspline, lrn_enet.5, lrn_ridge, lrn_lasso, xgb_50
)
stack
[1] "Lrnr_glm_TRUE"                                  
[2] "Lrnr_polspline_5"                               
[3] "Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE_FALSE"
[4] "Lrnr_glmnet_NULL_deviance_10_0_100_TRUE_FALSE"  
[5] "Lrnr_glmnet_NULL_deviance_10_1_100_TRUE_FALSE"  
[6] "Lrnr_xgboost_50_1"                              
\end{lstlisting}

We can also stack the learners by first creating a vector, and then
instantiating the stack. I prefer this method, since it easily allows us to
modify the names of the learners.

\begin{lstlisting}[language=R]
# named vector of learners first
learners <- c(
  lrn_glm, lrn_polspline, lrn_enet.5, lrn_ridge, lrn_lasso, xgb_50
)
names(learners) <- c(
  "glm", "polspline", "enet.5", "ridge", "lasso", "xgboost50"
)
# next make the stack
stack <- make_learner(Stack, learners)
# now the names are pretty
stack
[1] "glm"       "polspline" "enet.5"    "ridge"     "lasso"     "xgboost50"
\end{lstlisting}

We're jumping ahead a bit, but let's check something out quickly. It's
straightforward, and just one more step, to set up this stack such that
all of the learners will train in a cross-validated manner.

\begin{lstlisting}[language=R]
cv_stack <- Lrnr_cv$new(stack)
cv_stack
[1] "Lrnr_cv"
[1] "glm"       "polspline" "enet.5"    "ridge"     "lasso"     "xgboost50"
\end{lstlisting}

\hypertarget{screening-algorithms-for-feature-selection}{%
\subsubsection*{Screening Algorithms for Feature Selection}\label{screening-algorithms-for-feature-selection}}


We can optionally select a subset of available covariates and pass only
those variables to the modeling algorithm. The current set of learners that
can be used for prescreening covariates is included below.

\begin{itemize}
\tightlist
\item
  \passthrough{\lstinline!Lrnr\_screener\_importance!} selects \passthrough{\lstinline!num\_screen!} (default = 5) covariates
  based on the variable importance ranking provided by the \passthrough{\lstinline!learner!}. Any
  learner with an importance method can be used in \passthrough{\lstinline!Lrnr\_screener\_importance!};
  and this currently includes \passthrough{\lstinline!Lrnr\_ranger!}, \passthrough{\lstinline!Lrnr\_randomForest!}, and
  \passthrough{\lstinline!Lrnr\_xgboost!}.
\item
  \passthrough{\lstinline!Lrnr\_screener\_coefs!}, which provides screening of covariates based on the
  magnitude of their estimated coefficients in a (possibly regularized) GLM.
  The \passthrough{\lstinline!threshold!} (default = 1e-3) defines the minimum absolute size of the
  coefficients, and thus covariates, to be kept. Also, a \passthrough{\lstinline!max\_retain!} argument
  can be optionally provided to restrict the number of selected covariates to be
  no more than \passthrough{\lstinline!max\_retain!}.
\item
  \passthrough{\lstinline!Lrnr\_screener\_correlation!} provides covariate screening procedures by
  running a test of correlation (Pearson default), and then selecting the (1)
  top ranked variables (default), or (2) the variables with a pvalue lower than
  some pre-specified threshold.
\item
  \passthrough{\lstinline!Lrnr\_screener\_augment!} augments a set of screened covariates with additional
  covariates that should be included by default, even if the screener did not
  select them. An example of how to use this screener is included below.
\end{itemize}

Let's consider screening covariates based on their \passthrough{\lstinline!randomForest!} variable
importance ranking (ordered by mean decrease in accuracy). To select the top
5 most important covariates according to this ranking, we can combine
\passthrough{\lstinline!Lrnr\_screener\_importance!} with \passthrough{\lstinline!Lrnr\_ranger!} (limiting the number of trees by
setting \passthrough{\lstinline!ntree = 20!}).

Hang on! Before you think it -- we will confess: Bob Ross and us both know that
20 trees makes for a lonely forest, and we shouldn't consider it, but these are
the sacrifices we make for this chapter to be built in time!

\begin{lstlisting}[language=R]
miniforest <- Lrnr_ranger$new(
  num.trees = 20, write.forest = FALSE,
  importance = "impurity_corrected"
)

# learner must already be instantiated, we did this when we created miniforest
screen_rf <- Lrnr_screener_importance$new(learner = miniforest, num_screen = 5)
screen_rf
[1] "Lrnr_screener_importance_5"

# which covariates are selected on the full data?
screen_rf$train(washb_task)
[1] "Lrnr_screener_importance_5"
$selected
[1] "aged"        "month"       "momedu"      "asset_tv"    "asset_chair"
\end{lstlisting}

An example of how to format \passthrough{\lstinline!Lrnr\_screener\_augment!} is included below for
clarity.

\begin{lstlisting}[language=R]
keepme <- c("aged", "momage")
# screener must already be instantiated, we did this when we created screen_rf
screen_augment_rf <- Lrnr_screener_augment$new(
  screener = screen_rf, default_covariates = keepme
)
screen_augment_rf
[1] "Lrnr_screener_augment_c(\"aged\", \"momage\")"
\end{lstlisting}

Selecting covariates with non-zero lasso coefficients is quite common. Let's
construct \passthrough{\lstinline!Lrnr\_screener\_coefs!} screener that does just that, and test it
out.

\begin{lstlisting}[language=R]
# we already instantiated a lasso learner above, no need to do it again
screen_lasso <- Lrnr_screener_coefs$new(learner = lrn_lasso, threshold = 0)
screen_lasso
[1] "Lrnr_screener_coefs_0_NULL_2"
\end{lstlisting}

To pipe only the selected covariates to the modeling algorithm, we need to
make a \passthrough{\lstinline!Pipeline!}, similar to the one we built for the regression model with
interaction terms.

\begin{lstlisting}[language=R]
screen_rf_pipe <- make_learner(Pipeline, screen_rf, stack)
screen_lasso_pipe <- make_learner(Pipeline, screen_lasso, stack)
\end{lstlisting}

Now, these learners will be preceded by a screening step.

We also consider the original \passthrough{\lstinline!stack!}, to compare how the feature selection
methods perform in comparison to the methods without feature selection.

Analogous to what we have seen before, we have to stack the pipeline and
original \passthrough{\lstinline!stack!} together, so we may use them as base learners in our super
learner.

\begin{lstlisting}[language=R]
# pretty names again
learners2 <- c(learners, screen_rf_pipe, screen_lasso_pipe)
names(learners2) <- c(names(learners), "randomforest_screen", "lasso_screen")

fancy_stack <- make_learner(Stack, learners2)
fancy_stack
[1] "glm"                 "polspline"           "enet.5"             
[4] "ridge"               "lasso"               "xgboost50"          
[7] "randomforest_screen" "lasso_screen"       
\end{lstlisting}

We will use the \href{https://tlverse.org/sl3/reference/default_metalearner.html}{default
metalearner},
which uses
\href{https://tlverse.org/sl3/reference/Lrnr_solnp.html}{\passthrough{\lstinline!Lrnr\_solnp!}} to
provide fitting procedures for a pairing of \href{https://tlverse.org/sl3/reference/loss_functions.html}{loss
function} and
\href{https://tlverse.org/sl3/reference/metalearners.html}{metalearner
function}. This
default metalearner selects a loss and metalearner pairing based on the outcome
type. Note that any learner can be used as a metalearner.

Now that we have made a diverse stack of base learners, we are ready to make the
SL. The SL algorithm fits a metalearner on the validation set
predictions/losses across all folds.

\begin{lstlisting}[language=R]
sl <- make_learner(Lrnr_sl, learners = fancy_stack)
\end{lstlisting}

We can also use \passthrough{\lstinline!Lrnr\_cv!} to build a SL, cross-validate a stack of
learners to compare performance of the learners in the stack, or cross-validate
any single learner (see ``Cross-validation'' section of this \href{https://tlverse.org/sl3/articles/intro_sl3.html}{\passthrough{\lstinline!sl3!}
introductory tutorial}).

Furthermore, we can \href{https://tlverse.org/sl3/articles/custom_lrnrs.html}{Define New \passthrough{\lstinline!sl3!}
Learners} which can be used
in all the places you could otherwise use any other \passthrough{\lstinline!sl3!} learners, including
\passthrough{\lstinline!Pipelines!}, \passthrough{\lstinline!Stacks!}, and the SL.

Recall that the discrete SL, or cross-validated selector, is a metalearner that
assigns a weight of 1 to the learner with the lowest cross-validated empirical
risk, and weight of 0 to all other learners. This metalearner specification can
be invoked with \passthrough{\lstinline!Lrnr\_cv\_selector!}.

\begin{lstlisting}[language=R]
discrete_sl_metalrn <- Lrnr_cv_selector$new()
discrete_sl <- Lrnr_sl$new(
  learners = fancy_stack,
  metalearner = discrete_sl_metalrn
)
\end{lstlisting}

\hypertarget{train-the-super-learner-on-the-machine-learning-task}{%
\subsection*{3. Train the Super Learner on the machine learning task}\label{train-the-super-learner-on-the-machine-learning-task}}


The SL algorithm fits a metalearner on the validation-set predictions in a
cross-validated manner, thereby avoiding overfitting.

Now we are ready to \passthrough{\lstinline!train!} our SL on our \passthrough{\lstinline!sl3\_task!} object, \passthrough{\lstinline!washb\_task!}.

\begin{lstlisting}[language=R]
set.seed(4197)
sl_fit <- sl$train(washb_task)
\end{lstlisting}

\hypertarget{obtain-predicted-values}{%
\subsection*{4. Obtain predicted values}\label{obtain-predicted-values}}


Now that we have fit the SL, we are ready to calculate the predicted outcome
for each subject.

\begin{lstlisting}[language=R]
# we did it! now we have SL predictions
sl_preds <- sl_fit$predict()
head(sl_preds)
[1] -0.64698 -0.76514 -0.64312 -0.68991 -0.68068 -0.66422
\end{lstlisting}

We can also obtain a summary of the results.

\begin{lstlisting}[language=R]
sl_fit$cv_risk(loss_fun = loss_squared_error)
                          learner coefficients   risk       se  fold_sd
 1:                           glm     0.055565 1.0202 0.023955 0.067500
 2:                     polspline     0.055551 1.0208 0.023577 0.067921
 3:                        enet.5     0.055558 1.0131 0.023598 0.065732
 4:                         ridge     0.055564 1.0153 0.023739 0.065299
 5:                         lasso     0.055558 1.0130 0.023592 0.065840
 6:                     xgboost50     0.055583 1.1136 0.025262 0.077580
 7:       randomforest_screen_glm     0.055556 1.0173 0.023830 0.069913
 8: randomforest_screen_polspline     0.055573 1.0135 0.023814 0.069240
 9:    randomforest_screen_enet.5     0.055555 1.0177 0.023842 0.070142
10:     randomforest_screen_ridge     0.055555 1.0176 0.023855 0.069787
11:     randomforest_screen_lasso     0.055555 1.0177 0.023840 0.070155
12: randomforest_screen_xgboost50     0.055546 1.1277 0.026043 0.078673
13:              lasso_screen_glm     0.055553 1.0164 0.023542 0.065018
14:        lasso_screen_polspline     0.055553 1.0177 0.023520 0.065566
15:           lasso_screen_enet.5     0.055553 1.0163 0.023544 0.065017
16:            lasso_screen_ridge     0.055552 1.0166 0.023553 0.064869
17:            lasso_screen_lasso     0.055553 1.0163 0.023544 0.065020
18:        lasso_screen_xgboost50     0.055516 1.1256 0.025939 0.084270
19:                  SuperLearner           NA 1.0100 0.023524 0.068184
    fold_min_risk fold_max_risk
 1:       0.89442        1.1200
 2:       0.89892        1.1255
 3:       0.88839        1.1058
 4:       0.88559        1.1063
 5:       0.88842        1.1060
 6:       0.96019        1.2337
 7:       0.88579        1.1119
 8:       0.89370        1.1190
 9:       0.88593        1.1137
10:       0.88620        1.1128
11:       0.88593        1.1136
12:       1.00223        1.2465
13:       0.90204        1.1156
14:       0.89742        1.1162
15:       0.90184        1.1154
16:       0.90120        1.1146
17:       0.90183        1.1154
18:       0.96251        1.2327
19:       0.88036        1.1041
\end{lstlisting}

\hypertarget{cross-validated-super-learner}{%
\section*{Cross-validated Super Learner}\label{cross-validated-super-learner}}


We can cross-validate the SL to see how well the SL performs on unseen data, and
obtain an estimate of the cross-validated risk of the SL.

This estimation procedure requires an outer/external layer of
cross-validation, also called nested cross-validation, which involves setting
aside a separate holdout sample that we don't use to fit the SL. This external
cross-validation procedure may also incorporate 10 folds, which is the default
in \passthrough{\lstinline!sl3!}. However, we will incorporate 2 outer/external folds of
cross-validation for computational efficiency.

We also need to specify a loss function to evaluate SL. Documentation for the
available loss functions can be found in the \href{https://tlverse.org/sl3/reference/loss_functions.html}{\passthrough{\lstinline!sl3!} Loss Function
Reference}.

\begin{lstlisting}[language=R]
washb_task_new <- make_sl3_Task(
  data = washb_data,
  covariates = covars,
  outcome = outcome,
  folds = origami::make_folds(washb_data, fold_fun = folds_vfold, V = 2)
)
CVsl <- CV_lrnr_sl(
  lrnr_sl = sl_fit, task = washb_task_new, loss_fun = loss_squared_error
)
CVsl %>%
  kable(digits = 4) %>%
  kableExtra:::kable_styling(fixed_thead = T) %>%
  scroll_box(width = "100%", height = "300px")
\end{lstlisting}

\begin{table}
\centering
\begin{tabular}{l|r|r|r|r|r|r}
\hline
learner & coefficients & risk & se & fold\_sd & fold\_min\_risk & fold\_max\_risk\\
\hline
glm & 0.0556 & 1.0340 & 0.0255 & 0.0195 & 1.0203 & 1.0478\\
\hline
polspline & 0.0556 & 1.0231 & 0.0236 & 0.0005 & 1.0227 & 1.0235\\
\hline
enet.5 & 0.0556 & 1.0140 & 0.0236 & 0.0081 & 1.0083 & 1.0197\\
\hline
ridge & 0.0556 & 1.0192 & 0.0239 & 0.0118 & 1.0108 & 1.0275\\
\hline
lasso & 0.0556 & 1.0141 & 0.0236 & 0.0081 & 1.0084 & 1.0198\\
\hline
xgboost50 & 0.0556 & 1.1647 & 0.0259 & 0.0025 & 1.1629 & 1.1665\\
\hline
randomforest\_screen\_glm & 0.0556 & 1.0204 & 0.0239 & 0.0121 & 1.0118 & 1.0289\\
\hline
randomforest\_screen\_polspline & 0.0556 & 1.0161 & 0.0240 & 0.0015 & 1.0151 & 1.0172\\
\hline
randomforest\_screen\_enet.5 & 0.0556 & 1.0204 & 0.0239 & 0.0121 & 1.0118 & 1.0289\\
\hline
randomforest\_screen\_ridge & 0.0556 & 1.0204 & 0.0240 & 0.0128 & 1.0114 & 1.0295\\
\hline
randomforest\_screen\_lasso & 0.0556 & 1.0204 & 0.0239 & 0.0120 & 1.0119 & 1.0289\\
\hline
randomforest\_screen\_xgboost50 & 0.0555 & 1.2000 & 0.0273 & 0.0122 & 1.1914 & 1.2087\\
\hline
lasso\_screen\_glm & 0.0555 & 1.0233 & 0.0238 & 0.0001 & 1.0232 & 1.0234\\
\hline
lasso\_screen\_polspline & 0.0555 & 1.0247 & 0.0238 & 0.0018 & 1.0235 & 1.0260\\
\hline
lasso\_screen\_enet.5 & 0.0555 & 1.0233 & 0.0238 & 0.0001 & 1.0232 & 1.0233\\
\hline
lasso\_screen\_ridge & 0.0555 & 1.0233 & 0.0238 & 0.0002 & 1.0231 & 1.0235\\
\hline
lasso\_screen\_lasso & 0.0555 & 1.0233 & 0.0238 & 0.0001 & 1.0232 & 1.0233\\
\hline
lasso\_screen\_xgboost50 & 0.0556 & 1.1265 & 0.0253 & 0.0263 & 1.1079 & 1.1451\\
\hline
SuperLearner & NA & 1.0125 & 0.0236 & 0.0024 & 1.0108 & 1.0142\\
\hline
\end{tabular}
\end{table}

\hypertarget{variable-importance-measures-with-sl3}{%
\section*{\texorpdfstring{Variable Importance Measures with \texttt{sl3}}{Variable Importance Measures with sl3}}\label{variable-importance-measures-with-sl3}}


Variable importance can be interesting and informative. It can also be
contradictory and confusing. Nevertheless, we like it, and so do our
collaborators, so we created a variable importance function in \passthrough{\lstinline!sl3!}! The \passthrough{\lstinline!sl3!}
\passthrough{\lstinline!importance!} function returns a table with variables listed in decreasing order
of importance (i.e., most important on the first row).

The measure of importance in \passthrough{\lstinline!sl3!} is based on a risk ratio, or risk difference,
between the learner fit with a removed, or permuted, covariate and the learner
fit with the true covariate, across all covariates. In this manner, the larger
the risk difference, the more important the variable is in the prediction.

The intuition of this measure is that it calculates the risk (in terms of the
average loss in predictive accuracy) of losing one covariate, while keeping
everything else fixed, and compares it to the risk if the covariate was not
lost. If this risk ratio is one, or risk difference is zero, then losing that
covariate had no impact, and is thus not important by this measure. We do this
across all of the covariates. As stated above, we can remove the covariate and
refit the SL without it, or we just permute the covariate (faster)
and hope for the shuffling to distort any meaningful information that was
present in the covariate. This idea of permuting instead of removing saves a lot
of time, and is also incorporated in the \passthrough{\lstinline!randomForest!} variable importance
measures. However, the permutation approach is risky, so the importance function
default is to remove and refit.

Let's explore the \passthrough{\lstinline!sl3!} variable importance measurements for the \passthrough{\lstinline!washb!} data.

\begin{lstlisting}[language=R]
washb_varimp <- importance(sl_fit, loss = loss_squared_error, type = "permute")
washb_varimp %>%
  kable(digits = 4) %>%
  kableExtra:::kable_styling(fixed_thead = TRUE) %>%
  scroll_box(width = "100%", height = "300px")
\end{lstlisting}

\begin{table}
\centering
\begin{tabular}{l|r}
\hline
X & risk\_ratio\\
\hline
aged & 1.0413\\
\hline
momedu & 1.0139\\
\hline
asset\_refrig & 1.0083\\
\hline
asset\_chair & 1.0046\\
\hline
month & 1.0032\\
\hline
momheight & 1.0027\\
\hline
elec & 1.0020\\
\hline
Nlt18 & 1.0012\\
\hline
tr & 1.0011\\
\hline
momage & 1.0006\\
\hline
asset\_chouki & 1.0003\\
\hline
asset\_mobile & 1.0003\\
\hline
floor & 1.0002\\
\hline
delta\_momheight & 1.0001\\
\hline
asset\_table & 1.0000\\
\hline
Ncomp & 1.0000\\
\hline
sex & 1.0000\\
\hline
asset\_moto & 1.0000\\
\hline
watmin & 1.0000\\
\hline
walls & 1.0000\\
\hline
delta\_momage & 1.0000\\
\hline
roof & 0.9999\\
\hline
asset\_tv & 0.9999\\
\hline
hfiacat & 0.9999\\
\hline
fracode & 0.9998\\
\hline
asset\_wardrobe & 0.9998\\
\hline
asset\_bike & 0.9998\\
\hline
asset\_sewmach & 0.9998\\
\hline
asset\_khat & 0.9997\\
\hline
\end{tabular}
\end{table}

\begin{lstlisting}[language=R]
# plot variable importance
importance_plot(
  washb_varimp,
  main = "sl3 Variable Importance for WASH Benefits Example Data"
)
\end{lstlisting}

\begin{center}\includegraphics[width=1\linewidth]{06-sl3_files/figure-latex/varimp-plot-1} \end{center}

\hypertarget{sl3-exercises}{%
\section{Exercises}\label{sl3-exercises}}

\hypertarget{sl3ex1}{%
\subsection{\texorpdfstring{Predicting Myocardial Infarction with \texttt{sl3}}{Predicting Myocardial Infarction with sl3}}\label{sl3ex1}}

Follow the steps below to predict myocardial infarction (\passthrough{\lstinline!mi!}) using the
available covariate data. We thank Prof.~David Benkeser at Emory University for
making the this Cardiovascular Health Study (CHS) data accessible.

\begin{lstlisting}[language=R]
# load the data set
db_data <- url(
  paste0(
    "https://raw.githubusercontent.com/benkeser/sllecture/master/",
    "chspred.csv"
  )
)
chspred <- read_csv(file = db_data, col_names = TRUE)
\end{lstlisting}

Let's take a quick peek at the data:

\begin{tabular}{r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r}
\hline
waist & alcoh & hdl & beta & smoke & ace & ldl & bmi & aspirin & gend & age & estrgn & glu & ins & cysgfr & dm & fetuina & whr & hsed & race & logcystat & logtrig & logcrp & logcre & health & logkcal & sysbp & mi\\
\hline
110.164 & 0.0000 & 66.497 & 0 & 0 & 1 & 114.216 & 27.997 & 0 & 0 & 73.518 & 0 & 159.931 & 70.3343 & 75.008 & 1 & 0.17516 & 1.16898 & 1 & 1 & -0.34202 & 5.4063 & 2.01260 & -0.67385 & 0 & 4.3926 & 177.135 & 0\\
\hline
89.976 & 0.0000 & 50.065 & 0 & 0 & 0 & 103.777 & 20.893 & 0 & 0 & 61.772 & 0 & 153.389 & 33.9695 & 82.743 & 1 & 0.57165 & 0.90114 & 0 & 0 & -0.08465 & 4.8592 & 3.29328 & -0.55509 & 1 & 6.2071 & 136.374 & 0\\
\hline
106.194 & 8.4174 & 40.506 & 0 & 0 & 0 & 165.716 & 28.455 & 1 & 1 & 72.931 & 0 & 121.715 & -17.3017 & 74.699 & 0 & 0.35168 & 1.17971 & 0 & 1 & -0.44511 & 4.5088 & 0.30132 & -0.01152 & 0 & 6.7320 & 135.199 & 0\\
\hline
90.057 & 0.0000 & 36.175 & 0 & 0 & 0 & 45.203 & 23.961 & 0 & 0 & 79.119 & 0 & 53.969 & 11.7315 & 95.782 & 0 & 0.54391 & 1.13599 & 0 & 0 & -0.48072 & 5.1832 & 3.02426 & -0.57507 & 1 & 7.3972 & 139.018 & 0\\
\hline
78.614 & 2.9790 & 71.064 & 0 & 1 & 0 & 131.312 & 10.966 & 0 & 1 & 69.018 & 0 & 94.315 & 9.7112 & 72.711 & 0 & 0.49159 & 1.10276 & 1 & 0 & 0.31206 & 4.2190 & -0.70568 & 0.00534 & 1 & 8.2779 & 88.047 & 0\\
\hline
91.659 & 0.0000 & 59.496 & 0 & 0 & 0 & 171.187 & 29.132 & 0 & 1 & 81.835 & 0 & 212.907 & -28.2269 & 69.218 & 1 & 0.46215 & 0.95291 & 1 & 0 & -0.28716 & 5.1773 & 0.97046 & 0.21268 & 1 & 5.9942 & 69.594 & 0\\
\hline
\end{tabular}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create an \passthrough{\lstinline!sl3!} task, setting myocardial infarction \passthrough{\lstinline!mi!} as the outcome and
  using all available covariate data.
\item
  Make a library of seven relatively fast base learning algorithms (i.e., do
  not consider BART or HAL). Customize hyperparameters for one of your
  learners. Feel free to use learners from \passthrough{\lstinline!sl3!} or \passthrough{\lstinline!SuperLearner!}. You may
  use the same base learning library that is presented above.
\item
  Incorporate at least one pipeline with feature selection. Any screener and
  learner(s) can be used.
\item
  Fit the metalearning step with the default metalearner.
\item
  With the metalearner and base learners, make the Super Learner (SL) and
  train it on the task.
\item
  Print the SL fit results by adding \passthrough{\lstinline!$cv\_risk(loss\_squared\_error)!} to your
  fit object. The squared error loss is specified here, since that's what is
  used by the default metalearner.
\item
  Cross-validate your SL fit to see how well it performs on unseen data.
  Specify the \passthrough{\lstinline!loss\_squared\_error!} loss function to evaluate the SL as it's
  the same loss that was used by the default metalearner. Print the result.
\item
  Use the \passthrough{\lstinline!importance()!} function to identify the ``most important'' predictor of
  myocardial infarction, according to \passthrough{\lstinline!sl3!} importance metrics. Print the
  result.
\end{enumerate}

\hypertarget{concluding-remarks}{%
\section{Concluding Remarks}\label{concluding-remarks}}

\begin{itemize}
\item
  Super Learner (SL) is a general approach that can be applied to a diversity of
  estimation and prediction problems which can be defined by a loss function.
\item
  It would be straightforward to plug in the estimator returned by SL into the
  target parameter mapping.

  \begin{itemize}
  \tightlist
  \item
    For example, suppose we are after the average treatment effect (ATE) of a
    binary treatment intervention:
    \(\Psi_0 = E_{0,W}[E_0(Y|A=1,W) - E_0(Y|A=0,W)]\).
  \item
    We could use the SL that was trained on the original data (let's call
    this \passthrough{\lstinline!sl\_fit!}) to predict the outcome for all subjects under each
    intervention. All we would need to do is take the average difference
    between the counterfactual outcomes under each intervention of interest.
  \item
    Considering \(\Psi_0\) above, we would first need two \(n\)-length vectors of
    predicted outcomes under each intervention. One vector would represent
    the predicted outcomes under an intervention that sets all subjects to
    receive \(A=1\), \(Y_i|A_i=1,W_i\) for all \(i=1,\ldots,n\). The other vector
    would represent the predicted outcomes under an intervention that sets
    all subjects to receive \(A=0\), \(Y_i|A_i=0,W_i\) for all \(i=1,\ldots,n\).
  \item
    After obtaining these vectors of counterfactual predicted outcomes, all
    we would need to do is average and then take the difference in order to
    ``plug-in'' the SL estimator into the target parameter mapping.
  \item
    In \passthrough{\lstinline!sl3!} and with our current ATE example, this could be achieved with
    \passthrough{\lstinline!mean(sl\_fit$predict(A1\_task)) - mean(sl\_fit$predict(A0\_task))!};
    where \passthrough{\lstinline!A1\_task$data!} would contain all 1's (or the level that pertains to
    receiving the treatment) for the treatment column in the data (keeping
    all else the same), and \passthrough{\lstinline!A0\_task$data!} would contain all 0's (or the
    level that pertains to not receiving the treatment) for the treatment
    column in the data.
  \end{itemize}
\item
  It's a worthwhile exercise to obtain the predicted counterfactual outcomes
  and create these counterfactual \passthrough{\lstinline!sl3!} tasks. It's too biased; however, to
  plug the SL fit into the target parameter mapping, (e.g., calling the result
  of \passthrough{\lstinline!mean(sl\_fit$predict(A1\_task)) - mean(sl\_fit$predict(A0\_task))!} the
  estimated ATE. We would end up with an estimator for the ATE that was
  optimized for estimation of the prediction function, and not the ATE!
\item
  At the end of the ``analysis day'', we want an estimator that is optimized for
  our target estimand of interest. We ultimately care about doing a good job
  estimating \(\psi_0\). The SL is an essential step to help us get there. In
  fact, we will use the counterfactual predicted outcomes that were explained
  at length above. However, SL is not the end of the estimation procedure.
  Specifically, the Super Learner would not be an asymptotically linear
  estimator of the target estimand; and it is not an efficient substitution
  estimator. This begs the question, why is it so important for an estimator to
  possess these properties?

  \begin{itemize}
  \item
    An asymptotically linear estimator converges to the estimand a
    \(\frac{1}{\sqrt{n}}\) rate, thereby permitting formal statistical inference
    (i.e., confidence intervals and \(p\)-values) {[}ADD REF{]}.
  \item
    Substitution, or plug-in, estimators of the estimand are desirable because
    they respect both the local and global constraints of the statistical model
    (e.g., bounds), and have they have better finite-sample properties{[}ADD REF{]}.
  \item
    An efficient estimator is optimal in the sense that it has the lowest
    possible variance, and is thus the most precise. An estimator is efficient
    if and only if is asymptotically linear with influence curve equal to the
    canonical gradient {[}ADD REF{]}.

    \begin{itemize}
    \tightlist
    \item
      The canonical gradient is a mathematical object that is specific to
      the target estimand, and it provides information on the level of
      difficulty of the estimation problem {[}ADD REF{]}. Various canonical
      gradient are shown in the chapters that follow.
    \item
      Practitioner's do not need to know how to calculate a canonical
      gradient in order to understand efficiency and use Targeted Maximum
      Likelihood Estimation (TMLE). Metaphorically, you do not need to be
      Yoda in order to be a Jedi.
    \end{itemize}
  \end{itemize}
\item
  TMLE is a general strategy that succeeds in constructing efficient and
  asymptotically linear plug-in estimators.
\item
  SL is fantastic for pure prediction, and for obtaining an initial
  estimate in the first step of TMLE, but we need the second step of TMLE to
  have the desirable statistical properties mentioned above.
\item
  In the chapters that follow, we focus on the targeted maximum likelihood
  estimator and the targeted minimum loss-based estimator, both referred to as
  TMLE.
\end{itemize}

\hypertarget{appendix}{%
\section{Appendix}\label{appendix}}

\hypertarget{sl3ex1-sol}{%
\subsection{Exercise 1 Solution}\label{sl3ex1-sol}}

Here is a potential solution to the \protect\hyperlink{sl3ex1}{\passthrough{\lstinline!sl3!} Exercise 1 -- Predicting Myocardial
Infarction with \passthrough{\lstinline!sl3!}}.

\begin{lstlisting}[language=R]
db_data <- url(
  "https://raw.githubusercontent.com/benkeser/sllecture/master/chspred.csv"
)
chspred <- read_csv(file = db_data, col_names = TRUE)

# make task
chspred_task <- make_sl3_Task(
  data = chspred,
  covariates = head(colnames(chspred), -1),
  outcome = "mi"
)

# make learners
glm_learner <- Lrnr_glm$new()
lasso_learner <- Lrnr_glmnet$new(alpha = 1)
ridge_learner <- Lrnr_glmnet$new(alpha = 0)
enet_learner <- Lrnr_glmnet$new(alpha = 0.5)
# curated_glm_learner uses formula = "mi ~ smoke + beta + waist"
curated_glm_learner <- Lrnr_glm_fast$new(covariates = c("smoke, beta, waist"))
mean_learner <- Lrnr_mean$new() # That is one mean learner!
glm_fast_learner <- Lrnr_glm_fast$new()
ranger_learner <- Lrnr_ranger$new()
svm_learner <- Lrnr_svm$new()
xgb_learner <- Lrnr_xgboost$new()

# screening
screen_cor <- make_learner(Lrnr_screener_correlation)
glm_pipeline <- make_learner(Pipeline, screen_cor, glm_learner)

# stack learners together
stack <- make_learner(
  Stack,
  glm_pipeline, glm_learner,
  lasso_learner, ridge_learner, enet_learner,
  curated_glm_learner, mean_learner, glm_fast_learner,
  ranger_learner, svm_learner, xgb_learner
)

# make and train SL
sl <- Lrnr_sl$new(
  learners = stack
)
sl_fit <- sl$train(chspred_task)
sl_fit$cv_risk(loss_squared_error)

CVsl <- CV_lrnr_sl(sl_fit, chspred_task, loss_squared_error)
CVsl

varimp <- importance(sl_fit)
importance_plot(varimp) 
\end{lstlisting}

\hypertarget{sl3ex2-sol}{%
\subsection{Exercise 2 Solution}\label{sl3ex2-sol}}

Here is a potential solution to \protect\hyperlink{sl3ex2}{\passthrough{\lstinline!sl3!} Exercise 2 -- Predicting Recurrent
Ischemic Stroke in an RCT with \passthrough{\lstinline!sl3!}}.

\begin{lstlisting}[language=R]
library(ROCR) # for AUC calculation

ist_data <- paste0(
  "https://raw.githubusercontent.com/tlverse/",
  "tlverse-handbook/master/data/ist_sample.csv"
) %>% fread()

# stack
ist_task <- make_sl3_Task(
  data = ist_data,
  outcome = "DRSISC",
  covariates = colnames(ist_data)[-which(names(ist_data) == "DRSISC")],
  drop_missing_outcome = TRUE
)

# learner library
lrn_glm <- Lrnr_glm$new()
lrn_lasso <- Lrnr_glmnet$new(alpha = 1)
lrn_ridge <- Lrnr_glmnet$new(alpha = 0)
lrn_enet <- Lrnr_glmnet$new(alpha = 0.5)
lrn_mean <- Lrnr_mean$new()
lrn_ranger <- Lrnr_ranger$new()
lrn_svm <- Lrnr_svm$new()
# xgboost grid
grid_params <- list(
  max_depth = c(2, 5, 8),
  eta = c(0.01, 0.15, 0.3)
)
grid <- expand.grid(grid_params, KEEP.OUT.ATTRS = FALSE)
params_default <- list(nthread = getOption("sl.cores.learners", 1))
xgb_learners <- apply(grid, MARGIN = 1, function(params_tune) {
  do.call(Lrnr_xgboost$new, c(params_default, as.list(params_tune)))
})
learners <- unlist(list(
  xgb_learners, lrn_ridge, lrn_mean, lrn_lasso,
  lrn_glm, lrn_enet, lrn_ranger, lrn_svm
),
recursive = TRUE
)

# SL
sl <- Lrnr_sl$new(learners)
sl_fit <- sl$train(ist_task)

# AUC
preds <- sl_fit$predict()
obs <- c(na.omit(ist_data$DRSISC))
AUC <- performance(prediction(sl_preds, obs), measure = "auc")@y.values[[1]]
plot(performance(prediction(sl_preds, obs), "tpr", "fpr"))

# CVsl
ist_task_CVsl <- make_sl3_Task(
  data = ist_data,
  outcome = "DRSISC",
  covariates = colnames(ist_data)[-which(names(ist_data) == "DRSISC")],
  drop_missing_outcome = TRUE,
  folds = origami::make_folds(
    n = sum(!is.na(ist_data$DRSISC)),
    fold_fun = folds_vfold,
    V = 5
  )
)
CVsl <- CV_lrnr_sl(sl_fit, ist_task_CVsl, loss_loglik_binomial)
CVsl

# sl3 variable importance plot
ist_varimp <- importance(sl_fit, type = "permute")
ist_varimp %>%
  importance_plot(
    main = "Variable Importance for Predicting Recurrent Ischemic Stroke"
  )
\end{lstlisting}

\hypertarget{tmle3}{%
\chapter{The TMLE Framework}\label{tmle3}}

\emph{Jeremy Coyle}

Based on the \href{https://github.com/tlverse/tmle3}{\passthrough{\lstinline!tmle3!} \passthrough{\lstinline!R!} package}.

\hypertarget{learn-tmle}{%
\section{Learning Objectives}\label{learn-tmle}}

By the end of this chapter, you will be able to

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Understand why we use TMLE for effect estimation.
\item
  Use \passthrough{\lstinline!tmle3!} to estimate an Average Treatment Effect (ATE).
\item
  Understand how to use \passthrough{\lstinline!tmle3!} ``Specs'' objects.
\item
  Fit \passthrough{\lstinline!tmle3!} for a custom set of target parameters.
\item
  Use the delta method to estimate transformations of target parameters.
\end{enumerate}

\hypertarget{tmle-intro}{%
\section{Introduction}\label{tmle-intro}}

In the previous chapter on \passthrough{\lstinline!sl3!} we learned how to estimate a regression
function like \(\mathbb{E}[Y \mid X]\) from data. That's an important first step
in learning from data, but how can we use this predictive model to estimate
statistical and causal effects?

Going back to \protect\hyperlink{intro}{the roadmap for targeted learning}, suppose we'd like to
estimate the effect of a treatment variable \(A\) on an outcome \(Y\). As discussed,
one potential parameter that characterizes that effect is the Average Treatment
Effect (ATE), defined as \(\psi_0 = \mathbb{E}_W[\mathbb{E}[Y \mid A=1,W] - \mathbb{E}[Y \mid A=0,W]]\) and interpreted as the difference in mean outcome
under when treatment \(A=1\) and \(A=0\), averaging over the distribution of
covariates \(W\). We'll illustrate several potential estimators for this
parameter, and motivate the use of the TMLE (targeted maximum likelihood
estimation; targeted minimum loss-based estimation) framework, using the
following example data:

\begin{center}\includegraphics[width=0.8\linewidth]{img/png/schematic_1_truedgd} \end{center}

The small ticks on the right indicate the mean outcomes (averaging over \(W\))
under \(A=1\) and \(A=0\) respectively, so their difference is the quantity we'd
like to estimate.

While we hope to motivate the application of TMLE in this chapter, we refer the
interested reader to the two Targeted Learning books and associated works for
full technical details.

\hypertarget{substitution-est}{%
\section{Substitution Estimators}\label{substitution-est}}

We can use \passthrough{\lstinline!sl3!} to fit a Super Learner or other regression model to estimate
the outcome regression function \(\mathbb{E}_0[Y \mid A,W]\), which we often refer
to as \(\overline{Q}_0(A,W)\) and whose estimate we denote \(\overline{Q}_n(A,W)\).
To construct an estimate of the ATE \(\psi_n\), we need only ``plug-in'' the
estimates of \(\overline{Q}_n(A,W)\), evaluated at the two intervention contrasts,
to the corresponding ATE ``plug-in'' formula:
\(\psi_n = \frac{1}{n}\sum(\overline{Q}_n(1,W)-\overline{Q}_n(0,W))\). This kind
of estimator is called a \emph{plug-in} or \emph{substitution} estimator, since accurate
estimates \(\psi_n\) of the parameter \(\psi_0\) may be obtained by substituting
estimates \(\overline{Q}_n(A,W)\) for the relevant regression functions
\(\overline{Q}_0(A,W)\) themselves.

Applying \passthrough{\lstinline!sl3!} to estimate the outcome regression in our example, we can see
that the ensemble machine learning predictions fit the data quite well:

\begin{center}\includegraphics[width=0.8\linewidth]{img/png/schematic_2b_sllik} \end{center}

The solid lines indicate the \passthrough{\lstinline!sl3!} estimate of the regression function, with the
dotted lines indicating the \passthrough{\lstinline!tmle3!} updates \protect\hyperlink{tmle-updates}{(described below)}.

While substitution estimators are intuitive, naively using this approach with a
Super Learner estimate of \(\overline{Q}_0(A,W)\) has several limitations. First,
Super Learner is selecting learner weights to minimize risk across the entire
regression function, instead of ``targeting'' the ATE parameter we hope to
estimate, leading to biased estimation. That is, \passthrough{\lstinline!sl3!} is trying to do well on
the full regression curve on the left, instead of focusing on the small ticks on
the right. What's more, the sampling distribution of this approach is not
asymptotically linear, and therefore inference is not possible.

We can see these limitations illustrated in the estimates generated for the
example data:

\begin{center}\includegraphics[width=0.8\linewidth]{img/png/schematic_3_effects} \end{center}

We see that Super Learner, estimates the true parameter value (indicated by the
dashed vertical line) more accurately than GLM. However, it is still less
accurate than TMLE, and valid inference is not possible. In contrast, TMLE
achieves a less biased estimator and valid inference.

\hypertarget{tmle}{%
\section{Targeted Maximum Likelihood Estimation}\label{tmle}}

TMLE takes an initial estimate \(\overline{Q}_n(A,W)\) as well as an estimate of
the propensity score \(g_n(A \mid W) = \mathbb{P}(A = 1 \mid W)\) and produces an
updated estimate \(\overline{Q}^{\star}_n(A,W)\) that is ``targeted'' to the
parameter of interest. TMLE keeps the benefits of substitution estimators (it is
one), but augments the original, potentially erratic estimates to \emph{correct for
bias} while also resulting in an \emph{asymptotically linear} (and thus normally
distributed) estimator that accommodates inference via asymptotically consistent
Wald-style confidence intervals.

\hypertarget{tmle-updates}{%
\subsection{TMLE Updates}\label{tmle-updates}}

There are different types of TMLEs (and, sometimes, multiple for the same set of
target parameters) -- below, we give an example of the algorithm for TML
estimation of the ATE. \(\overline{Q}^{\star}_n(A,W)\) is the TMLE-augmented
estimate \(f(\overline{Q}^{\star}_n(A,W)) = f(\overline{Q}_n(A,W)) + \epsilon \cdot H_n(A,W)\), where \(f(\cdot)\) is the appropriate link function (e.g.,
\(\text{logit}(x) = \log(x / (1 - x))\)), and an estimate \(\epsilon_n\) of the
coefficient \(\epsilon\) of the ``clever covariate'' \(H_n(A,W)\) is computed. The
form of the covariate \(H_n(A,W)\) differs across target parameters; in this case
of the ATE, it is \(H_n(A,W) = \frac{A}{g_n(A \mid W)} - \frac{1-A}{1-g_n(A, W)}\), with \(g_n(A,W) = \mathbb{P}(A=1 \mid W)\) being the estimated propensity
score, so the estimator depends both on the initial fit (by \passthrough{\lstinline!sl3!}) of the
outcome regression (\(\overline{Q}_n\)) and of the propensity score (\(g_n\)).

There are several robust augmentations that are used across the \passthrough{\lstinline!tlverse!},
including the use of an additional layer of cross-validation to avoid
over-fitting bias (i.e., CV-TMLE) as well as approaches for more consistently
estimating several parameters simultaneously (e.g., the points on a survival
curve).

\hypertarget{tmle-infer}{%
\subsection{Statistical Inference}\label{tmle-infer}}

Since TMLE yields an \textbf{asymptotically linear} estimator, obtaining statistical
inference is very convenient. Each TML estimator has a corresponding
\textbf{(efficient) influence function} (often, ``EIF'', for short) that describes the
asymptotic distribution of the estimator. By using the estimated EIF, Wald-style
inference (asymptotically correct confidence intervals) can be constructed
simply by plugging into the form of the EIF our initial estimates
\(\overline{Q}_n\) and \(g_n\), then computing the sample standard error.

The following sections describe both a simple and more detailed way of
specifying and estimating a TMLE in the \passthrough{\lstinline!tlverse!}. In designing \passthrough{\lstinline!tmle3!}, we
sought to replicate as closely as possible the very general estimation framework
of TMLE, and so each theoretical object relevant to TMLE is encoded in a
corresponding software object/method. First, we will present the simple
application of \passthrough{\lstinline!tmle3!} to the WASH Benefits example, and then go on to describe
the underlying objects in greater detail.

\hypertarget{easy-bake-example-tmle3-for-ate}{%
\section{\texorpdfstring{Easy-Bake Example: \texttt{tmle3} for ATE}{Easy-Bake Example: tmle3 for ATE}}\label{easy-bake-example-tmle3-for-ate}}

We'll illustrate the most basic use of TMLE using the WASH Benefits data
introduced earlier and estimating an average treatment effect.

\hypertarget{load-the-data}{%
\subsection{Load the Data}\label{load-the-data}}

We'll use the same WASH Benefits data as the earlier chapters:

\begin{lstlisting}[language=R]
library(data.table)
library(dplyr)
library(tmle3)
library(sl3)
washb_data <- fread(
  paste0(
    "https://raw.githubusercontent.com/tlverse/tlverse-data/master/",
    "wash-benefits/washb_data.csv"
  ),
  stringsAsFactors = TRUE
)
\end{lstlisting}

\hypertarget{define-the-variable-roles}{%
\subsection{Define the variable roles}\label{define-the-variable-roles}}

We'll use the common \(W\) (covariates), \(A\) (treatment/intervention), \(Y\)
(outcome) data structure. \passthrough{\lstinline!tmle3!} needs to know what variables in the dataset
correspond to each of these roles. We use a list of character vectors to tell
it. We call this a ``Node List'' as it corresponds to the nodes in a Directed
Acyclic Graph (DAG), a way of displaying causal relationships between variables.

\begin{lstlisting}[language=R]
node_list <- list(
  W = c(
    "month", "aged", "sex", "momage", "momedu",
    "momheight", "hfiacat", "Nlt18", "Ncomp", "watmin",
    "elec", "floor", "walls", "roof", "asset_wardrobe",
    "asset_table", "asset_chair", "asset_khat",
    "asset_chouki", "asset_tv", "asset_refrig",
    "asset_bike", "asset_moto", "asset_sewmach",
    "asset_mobile"
  ),
  A = "tr",
  Y = "whz"
)
\end{lstlisting}

\hypertarget{handle-missingness}{%
\subsection{Handle Missingness}\label{handle-missingness}}

Currently, missingness in \passthrough{\lstinline!tmle3!} is handled in a fairly simple way:

\begin{itemize}
\tightlist
\item
  Missing covariates are median- (for continuous) or mode- (for discrete)
  imputed, and additional covariates indicating imputation are generated, just
  as described in \protect\hyperlink{sl3}{the \passthrough{\lstinline!sl3!} chapter}.
\item
  Missing treatment variables are excluded -- such observations are dropped.
\item
  Missing outcomes are efficiently handled by the automatic calculation (and
  incorporation into estimators) of \emph{inverse probability of censoring weights}
  (IPCW); this is also known as IPCW-TMLE and may be thought of as a joint
  intervention to remove missingness and is analogous to the procedure used with
  classical inverse probability weighted estimators.
\end{itemize}

These steps are implemented in the \passthrough{\lstinline!process\_missing!} function in \passthrough{\lstinline!tmle3!}:

\begin{lstlisting}[language=R]
processed <- process_missing(washb_data, node_list)
washb_data <- processed$data
node_list <- processed$node_list
\end{lstlisting}

\hypertarget{create-a-spec-object}{%
\subsection{Create a ``Spec'' Object}\label{create-a-spec-object}}

\passthrough{\lstinline!tmle3!} is general, and allows most components of the TMLE procedure to be
specified in a modular way. However, most users will not be interested in
manually specifying all of these components. Therefore, \passthrough{\lstinline!tmle3!} implements a
\passthrough{\lstinline!tmle3\_Spec!} object that bundles a set of components into a \emph{specification}
(``Spec'') that, with minimal additional detail, can be run to fit a TMLE.

We'll start with using one of the specs, and then work our way down into the
internals of \passthrough{\lstinline!tmle3!}.

\begin{lstlisting}[language=R]
ate_spec <- tmle_ATE(
  treatment_level = "Nutrition + WSH",
  control_level = "Control"
)
\end{lstlisting}

\hypertarget{define-the-learners}{%
\subsection{Define the learners}\label{define-the-learners}}

Currently, the only other thing a user must define are the \passthrough{\lstinline!sl3!} learners used
to estimate the relevant factors of the likelihood: Q and g.

This takes the form of a list of \passthrough{\lstinline!sl3!} learners, one for each likelihood factor
to be estimated with \passthrough{\lstinline!sl3!}:

\begin{lstlisting}[language=R]
# choose base learners
lrnr_mean <- make_learner(Lrnr_mean)
lrnr_rf <- make_learner(Lrnr_ranger)

# define metalearners appropriate to data types
ls_metalearner <- make_learner(Lrnr_nnls)
mn_metalearner <- make_learner(
  Lrnr_solnp, metalearner_linear_multinomial,
  loss_loglik_multinomial
)
sl_Y <- Lrnr_sl$new(
  learners = list(lrnr_mean, lrnr_rf),
  metalearner = ls_metalearner
)
sl_A <- Lrnr_sl$new(
  learners = list(lrnr_mean, lrnr_rf),
  metalearner = mn_metalearner
)
learner_list <- list(A = sl_A, Y = sl_Y)
\end{lstlisting}

Here, we use a Super Learner as defined in the previous chapter. In the future,
we plan to include reasonable defaults learners.

\hypertarget{fit-the-tmle}{%
\subsection{Fit the TMLE}\label{fit-the-tmle}}

We now have everything we need to fit the tmle using \passthrough{\lstinline!tmle3!}:

\begin{lstlisting}[language=R]
tmle_fit <- tmle3(ate_spec, washb_data, node_list, learner_list)
print(tmle_fit)
A tmle3_Fit that took 1 step(s)
   type                                    param  init_est tmle_est       se
1:  ATE ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] -0.005231  0.00812 0.050679
       lower   upper psi_transformed lower_transformed upper_transformed
1: -0.091208 0.10745         0.00812         -0.091208           0.10745
\end{lstlisting}

\hypertarget{evaluate-the-estimates}{%
\subsection{Evaluate the Estimates}\label{evaluate-the-estimates}}

We can see the summary results by printing the fit object. Alternatively, we
can extra results from the summary by indexing into it:

\begin{lstlisting}[language=R]
estimates <- tmle_fit$summary$psi_transformed
print(estimates)
[1] 0.00812
\end{lstlisting}

\hypertarget{tmle3-components}{%
\section{\texorpdfstring{\texttt{tmle3} Components}{tmle3 Components}}\label{tmle3-components}}

Now that we've successfully used a spec to obtain a TML estimate, let's look
under the hood at the components. The spec has a number of functions that
generate the objects necessary to define and fit a TMLE.

\hypertarget{tmle3_task}{%
\subsection{\texorpdfstring{\texttt{tmle3\_task}}{tmle3\_task}}\label{tmle3_task}}

First is, a \passthrough{\lstinline!tmle3\_Task!}, analogous to an \passthrough{\lstinline!sl3\_Task!}, containing the data we're
fitting the TMLE to, as well as an NPSEM generated from the \passthrough{\lstinline!node\_list!}
defined above, describing the variables and their relationships.

\begin{lstlisting}[language=R]
tmle_task <- ate_spec$make_tmle_task(washb_data, node_list)
\end{lstlisting}

\begin{lstlisting}[language=R]
tmle_task$npsem
$W
tmle3_Node: W
    Variables: month, aged, sex, momedu, hfiacat, Nlt18, Ncomp, watmin, elec, floor, walls, roof, asset_wardrobe, asset_table, asset_chair, asset_khat, asset_chouki, asset_tv, asset_refrig, asset_bike, asset_moto, asset_sewmach, asset_mobile, momage, momheight, delta_momage, delta_momheight
    Parents: 

$A
tmle3_Node: A
    Variables: tr
    Parents: W

$Y
tmle3_Node: Y
    Variables: whz
    Parents: A, W
\end{lstlisting}

\hypertarget{initial-likelihood}{%
\subsection{Initial Likelihood}\label{initial-likelihood}}

Next, is an object representing the likelihood, factorized according to the
NPSEM described above:

\begin{lstlisting}[language=R]
initial_likelihood <- ate_spec$make_initial_likelihood(
  tmle_task,
  learner_list
)
print(initial_likelihood)
W: Lf_emp
A: LF_fit
Y: LF_fit
\end{lstlisting}

These components of the likelihood indicate how the factors were estimated: the
marginal distribution of \(W\) was estimated using NP-MLE, and the conditional
distributions of \(A\) and \(Y\) were estimated using \passthrough{\lstinline!sl3!} fits (as defined with
the \passthrough{\lstinline!learner\_list!}) above.

We can use this in tandem with the \passthrough{\lstinline!tmle\_task!} object to obtain likelihood
estimates for each observation:

\begin{lstlisting}[language=R]
initial_likelihood$get_likelihoods(tmle_task)
               W       A        Y
   1: 0.00021299 0.34925 -0.35834
   2: 0.00021299 0.36117 -0.93261
   3: 0.00021299 0.34740 -0.80873
   4: 0.00021299 0.34248 -0.94020
   5: 0.00021299 0.34134 -0.57866
  ---                            
4691: 0.00021299 0.23375 -0.58997
4692: 0.00021299 0.23366 -0.22769
4693: 0.00021299 0.22660 -0.74235
4694: 0.00021299 0.28944 -0.91796
4695: 0.00021299 0.19533 -1.03878
\end{lstlisting}

\hypertarget{targeted-likelihood-updater}{%
\subsection{Targeted Likelihood (updater)}\label{targeted-likelihood-updater}}

We also need to define a ``Targeted Likelihood'' object. This is a special type
of likelihood that is able to be updated using an \passthrough{\lstinline!tmle3\_Update!} object. This
object defines the update strategy (e.g., submodel, loss function, CV-TMLE or
not).

\begin{lstlisting}[language=R]
targeted_likelihood <- Targeted_Likelihood$new(initial_likelihood)
\end{lstlisting}

When constructing the targeted likelihood, you can specify different update
options. See the documentation for \passthrough{\lstinline!tmle3\_Update!} for details of the different
options. For example, you can disable CV-TMLE (the default in \passthrough{\lstinline!tmle3!}) as
follows:

\begin{lstlisting}[language=R]
targeted_likelihood_no_cv <-
  Targeted_Likelihood$new(initial_likelihood,
    updater = list(cvtmle = FALSE)
  )
\end{lstlisting}

\hypertarget{parameter-mapping}{%
\subsection{Parameter Mapping}\label{parameter-mapping}}

Finally, we need to define the parameters of interest. Here, the spec defines a
single parameter, the ATE. In the next section, we'll see how to add additional
parameters.

\begin{lstlisting}[language=R]
tmle_params <- ate_spec$make_params(tmle_task, targeted_likelihood)
print(tmle_params)
[[1]]
Param_ATE: ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}]
\end{lstlisting}

\hypertarget{putting-it-all-together}{%
\subsection{Putting it all together}\label{putting-it-all-together}}

Having used the spec to manually generate all these components, we can now
manually fit a \passthrough{\lstinline!tmle3!}:

\begin{lstlisting}[language=R]
tmle_fit_manual <- fit_tmle3(
  tmle_task, targeted_likelihood, tmle_params,
  targeted_likelihood$updater
)
print(tmle_fit_manual)
A tmle3_Fit that took 1 step(s)
   type                                    param   init_est tmle_est       se
1:  ATE ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] -0.0045451  0.01174 0.050807
      lower   upper psi_transformed lower_transformed upper_transformed
1: -0.08784 0.11132         0.01174          -0.08784           0.11132
\end{lstlisting}

The result is equivalent to fitting using the \passthrough{\lstinline!tmle3!} function as above.

\hypertarget{fitting-tmle3-with-multiple-parameters}{%
\section{\texorpdfstring{Fitting \texttt{tmle3} with multiple parameters}{Fitting tmle3 with multiple parameters}}\label{fitting-tmle3-with-multiple-parameters}}

Above, we fit a \passthrough{\lstinline!tmle3!} with just one parameter. \passthrough{\lstinline!tmle3!} also supports fitting
multiple parameters simultaneously. To illustrate this, we'll use the
\passthrough{\lstinline!tmle\_TSM\_all!} spec:

\begin{lstlisting}[language=R]
tsm_spec <- tmle_TSM_all()
targeted_likelihood <- Targeted_Likelihood$new(initial_likelihood)
all_tsm_params <- tsm_spec$make_params(tmle_task, targeted_likelihood)
print(all_tsm_params)
[[1]]
Param_TSM: E[Y_{A=Control}]

[[2]]
Param_TSM: E[Y_{A=Handwashing}]

[[3]]
Param_TSM: E[Y_{A=Nutrition}]

[[4]]
Param_TSM: E[Y_{A=Nutrition + WSH}]

[[5]]
Param_TSM: E[Y_{A=Sanitation}]

[[6]]
Param_TSM: E[Y_{A=WSH}]

[[7]]
Param_TSM: E[Y_{A=Water}]
\end{lstlisting}

This spec generates a Treatment Specific Mean (TSM) for each level of the
exposure variable. Note that we must first generate a new targeted likelihood,
as the old one was targeted to the ATE. However, we can recycle the initial
likelihood we fit above, saving us a super learner step.

\hypertarget{delta-method}{%
\subsection{Delta Method}\label{delta-method}}

We can also define parameters based on Delta Method Transformations of other
parameters. For instance, we can estimate a ATE using the delta method and two
of the above TSM parameters:

\begin{lstlisting}[language=R]
ate_param <- define_param(
  Param_delta, targeted_likelihood,
  delta_param_ATE,
  list(all_tsm_params[[1]], all_tsm_params[[4]])
)
print(ate_param)
Param_delta: E[Y_{A=Nutrition + WSH}] - E[Y_{A=Control}]
\end{lstlisting}

This can similarly be used to estimate other derived parameters like Relative
Risks, and Population Attributable Risks

\hypertarget{fit}{%
\subsection{Fit}\label{fit}}

We can now fit a TMLE simultaneously for all TSM parameters, as well as the
above defined ATE parameter

\begin{lstlisting}[language=R]
all_params <- c(all_tsm_params, ate_param)

tmle_fit_multiparam <- fit_tmle3(
  tmle_task, targeted_likelihood, all_params,
  targeted_likelihood$updater
)

print(tmle_fit_multiparam)
A tmle3_Fit that took 1 step(s)
   type                                       param   init_est  tmle_est
1:  TSM                            E[Y_{A=Control}] -0.5959678 -0.620830
2:  TSM                        E[Y_{A=Handwashing}] -0.6188184 -0.660230
3:  TSM                          E[Y_{A=Nutrition}] -0.6111402 -0.606586
4:  TSM                    E[Y_{A=Nutrition + WSH}] -0.6005128 -0.608949
5:  TSM                         E[Y_{A=Sanitation}] -0.5857464 -0.578472
6:  TSM                                E[Y_{A=WSH}] -0.5205610 -0.448252
7:  TSM                              E[Y_{A=Water}] -0.5657364 -0.537709
8:  ATE E[Y_{A=Nutrition + WSH}] - E[Y_{A=Control}] -0.0045451  0.011881
         se     lower    upper psi_transformed lower_transformed
1: 0.029901 -0.679435 -0.56223       -0.620830         -0.679435
2: 0.041719 -0.741998 -0.57846       -0.660230         -0.741998
3: 0.042047 -0.688996 -0.52418       -0.606586         -0.688996
4: 0.041285 -0.689867 -0.52803       -0.608949         -0.689867
5: 0.042396 -0.661566 -0.49538       -0.578472         -0.661566
6: 0.045506 -0.537442 -0.35906       -0.448252         -0.537442
7: 0.039253 -0.614644 -0.46077       -0.537709         -0.614644
8: 0.050801 -0.087688  0.11145        0.011881         -0.087688
   upper_transformed
1:          -0.56223
2:          -0.57846
3:          -0.52418
4:          -0.52803
5:          -0.49538
6:          -0.35906
7:          -0.46077
8:           0.11145
\end{lstlisting}

\hypertarget{exercises-1}{%
\section{Exercises}\label{exercises-1}}

\hypertarget{tmle3-ex1}{%
\subsection{\texorpdfstring{Estimation of the ATE with \texttt{tmle3}}{Estimation of the ATE with tmle3}}\label{tmle3-ex1}}

Follow the steps below to estimate an average treatment effect using data from
the Collaborative Perinatal Project (CPP), available in the \passthrough{\lstinline!sl3!} package. To
simplify this example, we define a binary intervention variable, \passthrough{\lstinline!parity01!} --
an indicator of having one or more children before the current child and a
binary outcome, \passthrough{\lstinline!haz01!} -- an indicator of having an above average height for
age.

\begin{lstlisting}[language=R]
# load the data set
data(cpp)
cpp <- cpp %>%
  as_tibble() %>%
  dplyr::filter(!is.na(haz)) %>%
  mutate(
    parity01 = as.numeric(parity > 0),
    haz01 = as.numeric(haz > 0)
  )
\end{lstlisting}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Define the variable roles \((W,A,Y)\) by creating a list of these nodes.
  Include the following baseline covariates in \(W\): \passthrough{\lstinline!apgar1!}, \passthrough{\lstinline!apgar5!},
  \passthrough{\lstinline!gagebrth!}, \passthrough{\lstinline!mage!}, \passthrough{\lstinline!meducyrs!}, \passthrough{\lstinline!sexn!}. Both \(A\) and \(Y\) are specified
  above. The missingness in the data (specifically, the missingness in the
  columns that are specified in the node list) will need to be taking care of.
  The \passthrough{\lstinline!process\_missing!} function can be used to accomplish this, like the
  \passthrough{\lstinline!washb\_data!} example above.
\item
  Define a \passthrough{\lstinline!tmle3\_Spec!} object for the ATE, \passthrough{\lstinline!tmle\_ATE()!}.
\item
  Using the same base learning libraries defined above, specify \passthrough{\lstinline!sl3!} base
  learners for estimation of \(\overline{Q}_0 = \mathbb{E}_0(Y \mid A, W)\) and
  \(g_0 = \mathbb{P}(A = 1 \mid W)\).
\item
  Define the metalearner like below.
\end{enumerate}

\begin{lstlisting}[language=R]
metalearner <- make_learner(
  Lrnr_solnp,
  loss_function = loss_loglik_binomial,
  learner_function = metalearner_logistic_binomial
)
\end{lstlisting}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Define one super learner for estimating \(\overline{Q}_0\) and another for
  estimating \(g_0\). Use the metalearner above for both super learners.
\item
  Create a list of the two super learners defined in the step above and call
  this object \passthrough{\lstinline!learner\_list!}. The list names should be \passthrough{\lstinline!A!} (defining the super
  learner for estimation of \(g_0\)) and \passthrough{\lstinline!Y!} (defining the super learner for
  estimation of \(\overline{Q}_0\)).
\item
  Fit the TMLE with the \passthrough{\lstinline!tmle3!} function by specifying (1) the \passthrough{\lstinline!tmle3\_Spec!},
  which we defined in Step 2; (2) the data; (3) the list of nodes, which we
  specified in Step 1; and (4) the list of super learners for estimation of
  \(g_0\) and \(\overline{Q}_0\), which we defined in Step 6. \emph{Note}: Like before,
  you will need to explicitly make a copy of the data (to work around
  \passthrough{\lstinline!data.table!} optimizations), e.g., (\passthrough{\lstinline!cpp2 <- data.table::copy(cpp)!}), then
  use the \passthrough{\lstinline!cpp2!} data going forward.
\end{enumerate}

\hypertarget{tmle3-ex2}{%
\subsection{\texorpdfstring{Estimation of Strata-Specific ATEs with \texttt{tmle3}}{Estimation of Strata-Specific ATEs with tmle3}}\label{tmle3-ex2}}

For this exercise, we will work with a random sample of 5,000 patients who
participated in the International Stroke Trial (IST). This data is described in
the \protect\hyperlink{ist}{Chapter 3.2 of the \passthrough{\lstinline!tlverse!} handbook}. We included the data below
and a summarized description that is relevant for this exercise.

The outcome, \(Y\), indicates recurrent ischemic stroke within 14 days after
randomization (\passthrough{\lstinline!DRSISC!}); the treatment of interest, \(A\), is the randomized
aspirin vs.~no aspirin treatment allocation (\passthrough{\lstinline!RXASP!} in \passthrough{\lstinline!ist!}); and the
adjustment set, \(W\), consists simply of other variables measured at baseline. In
this data, the outcome is occasionally missing, but there is no need to create a
variable indicating this missingness (such as \(\Delta\)) for analyses in the
\passthrough{\lstinline!tlverse!}, since the missingness is automatically detected when \passthrough{\lstinline!NA!} are present
in the outcome. Covariates with missing values (\passthrough{\lstinline!RATRIAL!}, \passthrough{\lstinline!RASP3!} and \passthrough{\lstinline!RHEP24!})
have already been imputed. Additional covariates were created
(\passthrough{\lstinline!MISSING\_RATRIAL\_RASP3!} and \passthrough{\lstinline!MISSING\_RHEP24!}), which indicate whether or not
the covariate was imputed. The missingness was identical for \passthrough{\lstinline!RATRIAL!} and
\passthrough{\lstinline!RASP3!}, which is why only one covariate indicating imputation for these two
covariates was created.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Estimate the average effect of randomized aspirin treatment (\passthrough{\lstinline!RXASP!} = 1) on
  recurrent ischemic stroke. Even though the missingness mechanism on \(Y\),
  \(\Delta\), does not need to be specified in the node list, it does still need
  to be accounted for in the TMLE. In other words, for this estimation problem,
  \(\Delta\) is a relevant factor of the likelihood. Thus, when defining the
  list of \passthrough{\lstinline!sl3!} learners for each likelihood factor, be sure to include a list
  of learners for estimation of \(\Delta\), say \passthrough{\lstinline!sl\_Delta!}, and specify this in
  the learner list, like so
  \passthrough{\lstinline!learner\_list <- list(A = sl\_A, delta\_Y = sl\_Delta, Y = sl\_Y)!}.
\item
  Recall that this RCT was conducted internationally. Suppose there is concern
  that the dose of aspirin may have varied across geographical regions, and an
  average across all geographical regions may not be warranted. Calculate the
  strata specific ATEs according to geographical region (\passthrough{\lstinline!REGION!}).
\end{enumerate}

\begin{lstlisting}[language=R]
ist_data <- fread(
  paste0(
    "https://raw.githubusercontent.com/tlverse/deming2019-workshop/",
    "master/data/ist_sample.csv"
  )
)
\end{lstlisting}

\hypertarget{summary}{%
\section{Summary}\label{summary}}

\passthrough{\lstinline!tmle3!} is a general purpose framework for generating TML estimates. The easiest
way to use it is to use a predefined spec, allowing you to just fill in the
blanks for the data, variable roles, and \passthrough{\lstinline!sl3!} learners. However, digging under
the hood allows users to specify a wide range of TMLEs. In the next sections,
we'll see how this framework can be used to estimate advanced parameters such as
optimal treatments and stochastic shift interventions.

\hypertarget{optimal-individualized-treatment-regimes}{%
\chapter{Optimal Individualized Treatment Regimes}\label{optimal-individualized-treatment-regimes}}

\emph{Ivana Malenica}

Based on the \href{https://github.com/tlverse/tmle3mopttx}{\passthrough{\lstinline!tmle3mopttx!} \passthrough{\lstinline!R!} package}
by \emph{Ivana Malenica, Jeremy Coyle, and Mark van der Laan}.

Updated: 2021-09-21

\hypertarget{learning-objectives-1}{%
\section{Learning Objectives}\label{learning-objectives-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Differentiate dynamic and optimal dynamic treatment interventions from static
  interventions.
\item
  Explain the benefits, and challenges, associated with using optimal
  individualized treatment regimes in practice.
\item
  Contrast the impact of implementing an optimal individualized treatment
  regime in the population with the impact of implementing static and dynamic
  treatment regimes in the population.
\item
  Estimate causal effects under optimal individualized treatment regimes with
  the \passthrough{\lstinline!tmle3mopttx!} \passthrough{\lstinline!R!} package.
\item
  Assess the mean under optimal individualized treatment with resource
  constraints.
\item
  Implement optimal individualized treatment rules based on sub-optimal
  rules, or ``simple'' rules, and recognize the practical benefit of these rules.
\item
  Construct ``realistic'' optimal individualized treatment regimes that respect
  real data and subject-matter knowledge limitations on interventions by
  only considering interventions that are supported by the data.
\item
  Measure variable importance as defined in terms of the optimal individualized
  treatment interventions.
\end{enumerate}

\hypertarget{introduction-to-optimal-individualized-interventions}{%
\section{Introduction to Optimal Individualized Interventions}\label{introduction-to-optimal-individualized-interventions}}

Identifying which intervention will be effective for which patient based on
lifestyle, genetic and environmental factors is a common goal in precision
medicine. To put it in context, Abacavir and Tenofovir are commonly prescribed
as part of the antiretroviral therapy to Human Immunodeficiency Virus (HIV)
patients. However, not all individuals benefit from the two medications equally.
In particular, patients with renal dysfunction might further deteriorate if
prescribed Tenofovir, due to the high nephrotoxicity caused by the medication.
While Tenofovir is still highly effective treatment option for HIV patients, in
order to maximize the patient's well-being, it would be beneficial to prescribe
Tenofovir only to individuals with healthy kidney function. Along the same
lines, one might seek to improve retention in HIV care. In a randomized clinical
trial, several interventions show efficacy- including appointment reminders
through text messages, small cash incentives for on time clinic visits, and peer
health workers. Ideally, we want to improve effectiveness by assigning each
patient the intervention they are most likely to benefit from, as well as
improve efficiency by not allocating resources to individuals that do not need
them, or would not benefit from it.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{img/png/DynamicA_Illustration} 

}

\caption{Dynamic Treatment Regime in a Clinical Setting}\label{fig:unnamed-chunk-1}
\end{figure}

One opts to administer the intervention to individuals who will profit from it instead,
instead of assigning treatment on a population level. But how do we know which
intervention works for which patient? This aim motivates a different type of
intervention, as opposed to the static exposures we described in previous chapters. In
particular, in this chapter we learn about dynamic or ``individualized''
interventions that tailor the treatment decision based on the collected
covariates. Formally, dynamic treatments represent interventions that at each
treatment-decision stage are allowed to respond to the currently available
treatment and covariate history.

In the statistics community such a treatment strategy is termed an
\textbf{individualized treatment regime} (ITR), and the (counterfactual) population
mean outcome under an ITR is the value of the ITR \citep{neyman1990, robins1986, pearl2009}. Even more, suppose one wishes to maximize the population mean of an
outcome, where for each individual we have access to some set of measured
covariates. This means, for example, that we can learn for which individual
characteristics assigning treatment increases the probability of a beneficial
outcome. An ITR with the maximal value is referred to as an
optimal ITR or the \textbf{optimal individualized treatment}. Consequently, the value
of an optimal ITR is termed the optimal value, or the \textbf{mean under the optimal
individualized treatment}.

The problem of estimating the optimal individualized treatment has received much
attention in the statistics literature over the years, especially with the
advancement of precision medicine; see \citet{murphy2003}, \citet{robins2004}, \citet{laber2012},
\citet{kosorok2012}, \citet{moodie2013} and \citet{robins2014} to name a few. However, much of the
early work depends on parametric assumptions. As such, even in a randomized
trial, the statistical inference for the optimal individualized treatment relies
on assumptions that are generally believed to be false, and can lead to biased
results.

In this chapter, we consider estimation of the mean outcome under the optimal
individualized treatment where the candidate rules are restricted to depend only
on user-supplied subset of the baseline covariates. The estimation problem is
addressed in a statistical model for the data distribution that is
nonparametric, and at most places restrictions on the probability of a patient
receiving treatment given covariates (as in a randomized trial). As such, we
don't need to make any assumptions about the relationship of the outcome with
the treatment and covariates, or the relationship between the treatment and
covariates. Further, we provide a Targeted Maximum Likelihood Estimator for the
mean under the optimal individualized treatment that allows us to generate valid
inference for our parameter, without having any parametric assumptions. For a
technical presentation of the algorithm, the interested reader is invited to
further consult \citet{vanderLaanLuedtke15} and \citet{luedtke2016super}.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{data-structure-and-notation}{%
\section{Data Structure and Notation}\label{data-structure-and-notation}}

Suppose we observe \(n\) independent and identically distributed observations of
the form \(O=(W,A,Y) \sim P_0\). We denote \(A\) as categorical treatment, and \(Y\)
as the final outcome. In particular, we define \(A \in \mathcal{A}\) where
\(\mathcal{A} \equiv \{a_1, \cdots, a_{n_A} \}\) and \(n_A = |\mathcal{A}|\), with
\(n_A\) denoting the number of categories (possibly only two, for a binary setup).
Note that we treat \(W\) as vector-valued, representing all of our collected
baseline covariates. Therefore, for a single random individual \(i\), we have that
their observed data is \(O_i\): with corresponding baseline covariates \(W_i\),
treatment \(A_i\), and final outcome \(Y_i\). We say that \(O \sim P_0\), or that all
data was drawn from some true probability distribution \(P_0\). Let \(\mathcal{M}\)
denote a statistical model, with \(P_0 \in \mathcal{M}\). We emphasize that we
make no assumptions about the distribution of \(P_0\), hence \(\mathcal{M}\) is a
fully nonparametric model. As previously mentioned, this means that we make no
assumptions on the relationship between variables, but might be able to say
something about the relationship of \(A\) and \(W\), as is the case of a randomized
trial. As in previous chapters, we denote \(P_n\) as the empirical distribution
which gives each observation weight \(1/n\).

We use the nonparametric structural equation model (NPSEM) in order to define
the process that gives rise to the observed (endogenous) and not observed
(exogenous) variables, as described by \citet{pearl2009causality}. In particular, we
denote \(U=(U_W,U_A,U_Y)\) as the exogenous random variables, and \(O=(W,A,Y)\) as
endogenous variables we observe. The joint distribution of exogenous and
endogenous random variables in \(\mathcal{M}^F\) (defined by the NPSEM) is
\(P_{U,X}\). We can define the relationships between variables with the following
structural equations:
\begin{align}
  W &= f_W(U_W) \\ A &= f_A(W, U_A) \\ Y &= f_Y(A, W, U_Y),
  \label{eq:npsem-mopttx}
\end{align}
where the collection \(f=(f_W,f_A,f_Y)\) denotes unspecified functions. Note that
in the case of a randomized trial, we can write the above NPSEM as
\begin{align}
  W &= f_W(U_W) \\ A &= U_A \\ Y &= f_Y(A, W, U_Y),
  \label{eq:npsem-rt-mopttx}
\end{align}
indicating no dependence of treatment on baseline covariates.

The likelihood of the data admits a factorization, implied by the time ordering
of \(O\). We denote the density of \(O\) as \(p_0\), corresponding to the
distribution \(P_0\) and dominating measure \(\mu\).
\begin{equation}
  p_0(O) = p_{Y,0}(Y \mid A,W) p_{A,0}(A \mid W) p_{W,0}(W) =
    q_{Y,0}(Y \mid A,W) q_{A,0}(A \mid W) q_{W,0}(W),
  \label{eq:likelihood-factorization-mopttx}
\end{equation}
where \(p_{Y,0}(Y|A,W)\) is the conditional density of \(Y\) given \((A, W)\) with
respect to some dominating measure \(\mu_Y\), \(p_{A,0}\) is the conditional density
of \(A\) given \(W\) with respect to dominating measure \(\mu_A\), and \(p_{W,0}\) is
the density of \(W\) with respect to dominating measure \(\mu_W\). Consequently, we
define \(P_{Y,0}(Y \mid A, W) = Q_{Y,0}(Y \mid A,W)\), \(P_{A,0}(A \mid W) = g_0(A \mid W)\) and \(P_{W,0}(W)=Q_{W,0}(W)\) as the corresponding conditional
distribution of \(Y\) given \((A,W)\), treatment mechanism \(A\) given \(W\), and
distribution of baseline covariates. For notational simplicity, we also define
\(\bar{Q}_{Y,0}(A,W) \equiv \E_0[Y \mid A,W]\) as the conditional expectation of
\(Y\) given \((A,W)\).

Lastly, we define \(V\) as a subset of the baseline covariates the optimal
individualized rule depends on, where \(V \in W\). Note that \(V\) could be all of
\(W\), or an empty set, depending on the subject matter knowledge. In particular,
a researcher might want to consider known effect modifiers available at the time
of treatment decision as possible \(V\) covariates. Defining \(V\) allows us to
consider possibly sub-optimal rules that are easier to estimate, and thereby
allows for statistical inference for the counterfactual mean outcome under the
sub-optimal rule.

\hypertarget{defining-the-causal-effect-of-an-optimal-individualized-intervention}{%
\section{Defining the Causal Effect of an Optimal Individualized Intervention}\label{defining-the-causal-effect-of-an-optimal-individualized-intervention}}

Consider dynamic treatment rules \(d\) in the set of all possible rules
\(\mathcal{D}\). Then, \(d\) is a function that takes as input \(V\) and outputs a
treatment decision, \(V \rightarrow d(V) \in \{a_1, \cdots, a_{n_A} \} \times \{1\}\). We will use dynamic treatment rules, and the corresponding treatment
decision, to describe an intervention on the treatment mechanism and the
corresponding outcome under a dynamic treatment rule.

As mentioned in the previous section, causal effects are defined in terms of
hypothetical interventions on the NPSEM \eqref{eq:npsem-mopttx}. We can define
counterfactuals \(Y_{d(V)}\) defined by a modified system in which the equation
for \(A\) is replaced by the rule \(d(V)\), dependent on covariates \(V\). Our
modified system then takes the following form:
\begin{align}
  W &= f_W(U_W) \\ A &= d(V) \\ Y_{d(V)} &= f_Y(d(V), W, U_Y),
  \label{eq:npsem-causal-mopttx}
\end{align}
where the dynamic treatment regime may be viewed as an intervention in which \(A\)
is set equal to a value based on a hypothetical regime \(d(V)\), possibly contrary
to the fact, and \(Y_{d(V)}\) is the corresponding outcome under \(d(V)\). We
denote the distribution of the counterfactual quantities as \(P_{0,d(V)}\).

The goal of any causal analysis motivated by such dynamic interventions is to
estimate a parameter defined as the counterfactual mean of the outcome with
respect to the modified intervention distribution. That is, subject's outcome
if, possibly contrary to the fact, the subject received treatment that would
have been assigned by rule \(d(V)\). We can consider different treatment rules,
all in the set \(\mathcal{D}\):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The true rule, \(d_0\), and the corresponding causal parameter
  \(\E_{U,X}[Y_{d_0(V)}]\);
\item
  The estimated rule, \(d_n\), and the corresponding causal parameter
  \(\E_{U,X}[Y_{d_n(V)}]\).
\end{enumerate}

In this chapter, we will focus on the estimated rule \(d_n\), and the
corresponding data-adaptive parameter.

The optimal individualized rule is the rule with the maximal value:
\[d_{opt}(V) \equiv \text{argmax}_{d(V) \in \mathcal{D}}
\E_{P_{U,X}}[Y_{d(V)}]\].

We note that, in case the problem at hand requires minimizing the mean of an
outcome, our optimal individualized rule will be the rule with the minimal value
instead. Our causal target parameter of interest is the expected outcome under
the estimated optimal individualized rule:

\[\Psi_{d_{n, \text{opt}}(V)}(P_{U,X}) \coloneqq \E_{P_{U,X}}[Y_{d_{n,
\text{opt}}(V)}].\]

\hypertarget{identification-and-statistical-estimand}{%
\subsection{Identification and Statistical Estimand}\label{identification-and-statistical-estimand}}

The optimal individualized rule, as well as the value of a optimal
individualized rule, are causal parameters based on the unobserved
counterfactuals. In order for the causal quantities to be estimated from the
observed data, they need to be identified with statistical parameters. This step
of the roadmap requires me make few assumptions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{Strong ignorability}: \(A \indep Y^{d_n(v)} \mid W\), for all \(a \in \mathcal{A}\).
\item
  \emph{Positivity (or overlap)}: \(P_0(\min_{a \in \mathcal{A}} g_0(a \mid W) > 0) = 1\)
\end{enumerate}

Under the above causal assumptions, we can identify \(P_{0,d}\) with observed data
using the G-computation formula:

\[P_{0,d_{n, \text{opt}}}(O) = Q_{Y,0}(Y \mid A=d_{n,\text{opt}}(V),W)
g_0(A=d_{n,\text{opt}}(V) \mid W)Q_{W,0}(W).\]
The value of an individualized rule can now be expressed as

\[\E_0[Y_{d_n(V)}] = \E_{0,W}[\bar{Q}_{Y,0}(A=d_n(V),W)],\]

which, under causal assumptions, can is interpreted as the mean outcome if
(possibly contrary to fact), treatment was assigned according to the rule.
Finally, the statistical counterpart to the causal parameter of interest is
defined as
\[\psi_0 = \E_{0,W}[\bar{Q}_{Y,0}(A=d_{n,\text{opt}}(V),W)].\]

Inference for the optimal value has been shown to be difficult at exceptional
laws, defined as probability distributions for which treatment is neither
beneficial nor harmful. Inference is similarly difficult in finite samples if
the treatment effect is very small in all strata, even though valid asymptotic
estimators exist in this setting. With that in mind, we address the estimation
problem under the assumption of non-exceptional laws in effect.

Many methods for learning the optimal rule from data have been developed
\citep{murphy2003, robins2004, laber2012, kosorok2012, moodie2013}. In this
chapter, we focus on the methods discussed in \citet{luedtke2016super} and
\citet{vanderLaanLuedtke15}. Note however, that \passthrough{\lstinline!tmle3mopttx!} also supports the widely
used Q-learning approach, where the optimal individualized rule is based on the
initial estimate of \(\bar{Q}_{Y,0}(A,W)\) \citep{Sutton1998}.

We follow the methodology outlined in \citet{luedtke2016super} and
\citet{vanderLaanLuedtke15}, where we learn the optimal ITR using Super Learner
\citep{vdl2007super}, and estimate its value with cross-validated Targeted Minimum
Loss-based Estimation (CV-TMLE) \citep{cvtmle2010}. In great generality, we first
need to estimate the true individual treatment regime, \(d_0(V)\), which
corresponds to dynamic treatment rule (\(d(V)\)) that takes a subset of covariates
\(V \in W\) and assigns treatment to each individual based on their observed
covariates \(v\). With the estimate of the true optimal ITR in hand, we can
estimate its corresponding value.

\hypertarget{binary-treatment}{%
\subsection{Binary treatment}\label{binary-treatment}}

How do we estimate the optimal individualized treatment regime? In the case of a
binary treatment, a key quantity for optimal ITR is the blip function. One can
show that any optimal ITR assigns treatment to individuals falling in strata in
which the stratum specific average treatment effect, the blip function, is
positive and does not assign treatment to individuals for which this quantity is
negative. Therefore for a binary treatment, under causal assumptions, we define
the blip function as:
\[\bar{Q}_0(V) \equiv \E_0[Y_1-Y_0 \mid V] \equiv \E_0[\bar{Q}_{Y,0}(1,W) -
\bar{Q}_{Y,0}(0,W) \mid V],\]
or the average treatment effect within a stratum of \(V\). The note that the
optimal individualized rule can now be derived as \(d_{n,\text{opt}}(V) = \mathbb{I}(\bar{Q}_{0}(V) > 0)\).

The package \passthrough{\lstinline!tmle3mopttx!} relies on using the Super Learner to estimate the blip
function, as it easily extends to more general categorical treatment. With that
in mind, the loss function utilized for learning the optimal individualized rule
corresponds to conditional mean type losses. It is however worth mentioning that
\citet{luedtke2016super} present three different approaches for learning the optimal
rule. Namely, they focus on:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Super Learning the Blip Function,
\item
  Super Learning the Weighted Classification Problem,
\item
  Joint Super Learner of the Blip and Weighted Classification Problem.
\end{enumerate}

We refer the interested reader to \citet{luedtke2016super} for further reference on
advantages of each approach.

Relying on the Targeted Maximum Likelihood (TML) estimator and the Super Learner
estimate of the blip function, we follow the below steps in order to obtain
value of the ITR:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Estimate \(\bar{Q}_{Y,0}(A,W)\) and \(g_0(A \mid W)\) using \passthrough{\lstinline!sl3!}. We denote such
  estimates as \(\bar{Q}_{Y,n}(A,W)\) and \(g_n(A \mid W)\).
\item
  Apply the doubly robust Augmented-Inverse Probability Weighted (A-IPW)
  transform to our outcome, where we define:
  \[D_{\bar{Q}_Y,g,a}(O) \equiv \frac{\mathbb{I}(A=a)}{g(A \mid W)} (Y -
  \bar{Q}_Y(A,W)) + \bar{Q}_Y(A=a,W)\]
\end{enumerate}

Note that under the randomization and positivity assumptions we have that
\(\E[D_{\bar{Q}_Y,g,a}(O) \mid V] = \E[Y_a \mid V]\). We emphasize the double
robust nature of the A-IPW transform-consistency of \(\E[Y_a \mid V]\) will depend
on correct estimation of either \(\bar{Q}_{Y,0}(A,W)\) or \(g_0(A \mid W)\). As
such, in a randomized trial, we are guaranteed a consistent estimate of \(\E[Y_a \mid V]\) even if we get \(\bar{Q}_{Y,0}(A,W)\) wrong!

Using this transform, we can define the following contrast:
\(D_{\bar{Q}_Y,g}(O) = D_{\bar{Q}_Y, g, a=1}(O) - D_{\bar{Q}_Y, g, a=0}(O)\)

We estimate the blip function, \(\bar{Q}_{0,a}(V)\), by regressing
\(D_{\bar{Q}_Y,g}(O)\) on \(V\) using the specified \passthrough{\lstinline!sl3!} library of learners and an
appropriate loss function.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Our estimated rule corresponds to \(\text{argmax}_{a \in \mathcal{A}} \bar{Q}_{0,a}(V)\).
\item
  We obtain inference for the mean outcome under the estimated optimal rule
  using CV-TMLE.
\end{enumerate}

\hypertarget{categorical-treatment}{%
\subsection{Categorical treatment}\label{categorical-treatment}}

In line with the approach considered for binary treatment, we extend the blip
function to allow for categorical treatment. We denote such blip function
extensions as \emph{pseudo-blips}, which are our new estimation targets in a
categorical setting. We define pseudo-blips as vector-valued entities where the
output for a given \(V\) is a vector of length equal to the number of treatment
categories, \(n_A\). As such, we define it as:
\[\bar{Q}_0^{pblip}(V) = \{\bar{Q}_{0,a}^{pblip}(V): a \in \mathcal{A} \}\]

We implement three different pseudo-blips in \passthrough{\lstinline!tmle3mopttx!}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{Blip1} corresponds to choosing a reference category of treatment, and
  defining the blip for all other categories relative to the specified
  reference. Hence we have that:
  \[\bar{Q}_{0,a}^{pblip-ref}(V) \equiv \E_0(Y_a-Y_0 \mid V)\] where \(Y_0\) is
  the specified reference category with \(A=0\). Note that, for the case of
  binary treatment, this strategy reduces to the approach described for the
  binary setup.
\item
  \emph{Blip2} approach corresponds to defining the blip relative to the average of
  all categories. As such, we can define \(\bar{Q}_{0,a}^{pblip-avg}(V)\) as:
  \[\bar{Q}_{0,a}^{pblip-avg}(V) \equiv \E_0(Y_a - \frac{1}{n_A} \sum_{a \in
    \mathcal{A}} Y_a \mid V)\]
  In the case where subject-matter knowledge regarding which reference category
  to use is not available, blip2 might be a viable option.
\item
  \emph{Blip3} reflects an extension of Blip2, where the average is now a weighted
  average:
  \[\bar{Q}_{0,a}^{pblip-wavg}(V) \equiv \E_0(Y_a - \frac{1}{n_A} \sum_{a \in
    \mathcal{A}} Y_{a} P(A=a \mid V) \mid V)\]
\end{enumerate}

Just like in the binary case, pseudo-blips are estimated by regressing contrasts
composed using the A-IPW transform on \(V\).

\hypertarget{note-on-inference-and-data-adaptive-parameter}{%
\subsection{Note on Inference and data-adaptive parameter}\label{note-on-inference-and-data-adaptive-parameter}}

In a randomized trial, statistical inference relies on the second-order
difference between the estimator of the optimal individualized treatment and the
optimal individualized treatment itself to be asymptotically negligible. This is
a reasonable condition if we consider rules that depend on a small number of
covariates, or if we are willing to make smoothness assumptions. Alternatively,
we can consider TMLEs and statistical inference for data-adaptive target
parameters defined in terms of an estimate of the optimal individualized
treatment. In particular, instead of trying to estimate the mean under the true
optimal individualized treatment, we aim to estimate the mean under the
estimated optimal individualized treatment. As such, we develop cross-validated
TMLE approach that provides asymptotic inference under minimal conditions for
the mean under the estimate of the optimal individualized treatment. In
particular, considering the data adaptive parameter allows us to avoid
consistency and rate condition for the fitted optimal rule, as required for
asymptotic linearity of the TMLE of the mean under the actual, true optimal
rule. Practically, the estimated (data-adaptive) rule should be preferred, as
this possibly sub-optimal rule is the one implemented in the population.

\hypertarget{why-cv-tmle}{%
\subsection{Why CV-TMLE?}\label{why-cv-tmle}}

As discussed in \citet{vanderLaanLuedtke15}, CV-TMLE is necessary as the
non-cross-validated TMLE is biased upward for the mean outcome under the rule,
and therefore overly optimistic. More generally however, using CV-TMLE allows us
more freedom in estimation and therefore greater data adaptivity, without
sacrificing inference.

\hypertarget{interpreting-the-causal-effect-of-an-optimal-individualized-intervention}{%
\section{Interpreting the Causal Effect of an Optimal Individualized Intervention}\label{interpreting-the-causal-effect-of-an-optimal-individualized-intervention}}

In summary, the mean outcome under the optimal individualized treatment is a
counterfactual quantity of interest representing what the mean outcome would
have been if everybody, contrary to the fact, received treatment that optimized
their outcome. The optimal individualized treatment regime is a rule that
optimizes the mean outcome under the dynamic treatment, where the candidate
rules are restricted to only respond to a user-supplied subset of the baseline
and intermediate covariates. In essence, our target parameter answers the key
aim of precision medicine: allocating the available treatment by tailoring it to
the individual characteristics of the patient, with the goal of optimizing the
final outcome.

\hypertarget{oit-eval-bin}{%
\section{Evaluating the Causal Effect of an OIT with Binary Treatment}\label{oit-eval-bin}}

Finally, we demonstrate how to evaluate the mean outcome under the optimal
individualized treatment using \passthrough{\lstinline!tmle3mopptx!}. To start, let's load the packages
we'll use and set a seed:

\begin{lstlisting}[language=R]
library(data.table)
library(sl3)
library(tmle3)
library(tmle3mopttx)
\end{lstlisting}

\hypertarget{simulated-data}{%
\subsection{Simulated Data}\label{simulated-data}}

First, we load the simulated data. We will start with the more general setup
where the treatment is a binary variable; later in the chapter we will consider
another data-generating distribution where \(A\) is categorical. In this example,
our data generating distribution is of the following form:
\begin{align*}
  W &\sim \mathcal{N}(\bf{0},I_{3 \times 3})\\
  \P(A=1 \mid W) &= \frac{1}{1+\exp^{(-0.8*W_1)}}\\
  \P(Y=1 \mid A,W) &= 0.5\text{logit}^{-1}[-5I(A=1)(W_1-0.5)+5I(A=0)(W_1-0.5)] +
     0.5\text{logit}^{-1}(W_2W_3)
\end{align*}

\begin{lstlisting}[language=R]
data("data_bin")
\end{lstlisting}

The above composes our observed data structure \(O = (W, A, Y)\). Note that the
mean under the true optimal rule is \(\psi=0.578\) for this data generating
distribution.

To formally express this fact using the \passthrough{\lstinline!tlverse!} grammar introduced by the
\passthrough{\lstinline!tmle3!} package, we create a single data object and specify the functional
relationships between the nodes in the \emph{directed acyclic graph} (DAG) via
\emph{nonparametric structural equation models} (NPSEMs), reflected in the node list
that we set up:

\begin{lstlisting}[language=R]
# organize data and nodes for tmle3
data <- data_bin
node_list <- list(
  W = c("W1", "W2", "W3"),
  A = "A",
  Y = "Y"
)
\end{lstlisting}

We now have an observed data structure (\passthrough{\lstinline!data!}) and a specification of the role
that each variable in the data set plays as the nodes in a DAG.

\hypertarget{constructing-optimal-stacked-regressions-with-sl3}{%
\subsection{\texorpdfstring{Constructing Optimal Stacked Regressions with \texttt{sl3}}{Constructing Optimal Stacked Regressions with sl3}}\label{constructing-optimal-stacked-regressions-with-sl3}}

To easily incorporate ensemble machine learning into the estimation procedure,
we rely on the facilities provided in the \href{https://tlverse.org/sl3}{\passthrough{\lstinline!sl3!} R
package}. Using the framework provided by the \href{https://tlverse.org/sl3}{\passthrough{\lstinline!sl3!}
package}, the nuisance parameters of the TML estimator
may be fit with ensemble learning, using the cross-validation framework of the
Super Learner algorithm of \citet{vdl2007super}.

\begin{lstlisting}[language=R]
# Define sl3 library and metalearners:
lrn_xgboost_50 <- Lrnr_xgboost$new(nrounds = 50)
lrn_xgboost_100 <- Lrnr_xgboost$new(nrounds = 100)
lrn_xgboost_300 <- Lrnr_xgboost$new(nrounds = 300)
lrn_mean <- Lrnr_mean$new()
lrn_glm <- Lrnr_glm_fast$new()

## Define the Q learner:
Q_learner <- Lrnr_sl$new(
  learners = list(
    lrn_xgboost_50, lrn_xgboost_100, lrn_xgboost_300, lrn_mean, lrn_glm
  ),
  metalearner = Lrnr_nnls$new()
)

## Define the g learner:
g_learner <- Lrnr_sl$new(
  learners = list(lrn_xgboost_100, lrn_glm),
  metalearner = Lrnr_nnls$new()
)

## Define the B learner:
b_learner <- Lrnr_sl$new(
  learners = list(
    lrn_xgboost_50, lrn_xgboost_100, lrn_xgboost_300, lrn_mean, lrn_glm
  ),
  metalearner = Lrnr_nnls$new()
)
\end{lstlisting}

As seen above, we generate three different ensemble learners that must be fit,
corresponding to the learners for the outcome regression (Q), propensity score
(g), and the blip function (B). We make the above explicit with respect to
standard notation by bundling the ensemble learners into a list object below:

\begin{lstlisting}[language=R]
# specify outcome and treatment regressions and create learner list
learner_list <- list(Y = Q_learner, A = g_learner, B = b_learner)
\end{lstlisting}

The \passthrough{\lstinline!learner\_list!} object above specifies the role that each of the ensemble
learners we've generated is to play in computing initial estimators. Recall that
we need initial estimators of relevant parts of the likelihood in order to
building a TMLE for the parameter of interest. In particular, \passthrough{\lstinline!learner\_list!}
makes explicit the fact that our \passthrough{\lstinline!Y!} is used in fitting the outcome regression,
while \passthrough{\lstinline!A!} is used in fitting the treatment mechanism regression, and finally \passthrough{\lstinline!B!}
is used in fitting the blip function.

\hypertarget{targeted-estimation-of-the-mean-under-the-optimal-individualized-interventions-effects}{%
\subsection{Targeted Estimation of the Mean under the Optimal Individualized Interventions Effects}\label{targeted-estimation-of-the-mean-under-the-optimal-individualized-interventions-effects}}

To start, we will initialize a specification for the TMLE of our parameter of
interest simply by calling \passthrough{\lstinline!tmle3\_mopttx\_blip\_revere!}. We specify the argument
\passthrough{\lstinline!V = c("W1", "W2", "W3")!} when initializing the \passthrough{\lstinline!tmle3\_Spec!} object in order to
communicate that we're interested in learning a rule dependent on \passthrough{\lstinline!V!}
covariates. Note that we don't have to specify \passthrough{\lstinline!V!}- this will result in a rule
that is not based on any collected covariates. We also need to specify the type
of pseudo-blip we will use in this estimation problem, the list of learners used
to estimate the blip function, whether we want to maximize or minimize the final
outcome, and few other more advanced features including searching for a less
complex rule and realistic interventions.

\begin{lstlisting}[language=R]
# initialize a tmle specification
tmle_spec <- tmle3_mopttx_blip_revere(
  V = c("W1", "W2", "W3"), type = "blip1",
  learners = learner_list,
  maximize = TRUE, complex = TRUE, realistic = FALSE
)
\end{lstlisting}

As seen above, the \passthrough{\lstinline!tmle3\_mopttx\_blip\_revere!} specification object
(like all \passthrough{\lstinline!tmle3\_Spec!} objects) does \emph{not} store the data for our
specific analysis of interest. Later,
we'll see that passing a data object directly to the \passthrough{\lstinline!tmle3!} wrapper function,
alongside the instantiated \passthrough{\lstinline!tmle\_spec!}, will serve to construct a \passthrough{\lstinline!tmle3\_Task!}
object internally.

We elaborate more on the initialization specifications. In initializing the
specification for the TMLE of our parameter of interest, we have specified the
set of covariates the rule depends on (\passthrough{\lstinline!V!}), the type of pseudo-blip to use
(\passthrough{\lstinline!type!}), and the learners used for estimating the relevant parts of the
likelihood and the blip function. In addition, we need to specify whether we
want to maximize the mean outcome under the rule (\passthrough{\lstinline!maximize!}), and whether we
want to estimate the rule under all the covariates \(V\) provided by the user
(\passthrough{\lstinline!complex!}). If \passthrough{\lstinline!FALSE!}, \passthrough{\lstinline!tmle3mopttx!} will instead consider all the possible
rules under a smaller set of covariates including the static rules, and optimize
the mean outcome over all the subsets of \(V\). As such, while the user might have
provided a full set of collected covariates as input for \(V\), it is possible
that the true rule only depends on a subset of the set provided by the user. In
that case, our returned mean under the optimal individualized rule will be based
on the smaller subset. In addition, we provide an option to search for realistic
optimal individualized interventions via the \passthrough{\lstinline!realistic!} specification. If
\passthrough{\lstinline!TRUE!}, only treatments supported by the data will be considered, therefore
alleviating concerns regarding practical positivity issues. We explore all the
important extensions of \passthrough{\lstinline!tmle3mopttx!} in later sections.

\begin{lstlisting}[language=R]
# fit the TML estimator
fit <- tmle3(tmle_spec, data, node_list, learner_list)
fit
A tmle3_Fit that took 1 step(s)
   type         param init_est tmle_est       se   lower   upper
1:  TSM E[Y_{A=NULL}]  0.42223  0.56606 0.027015 0.51311 0.61901
   psi_transformed lower_transformed upper_transformed
1:         0.56606           0.51311           0.61901
\end{lstlisting}

We can see that the estimate of \(psi_0\) is \(0.56\), and that the confidence
interval covers our true mean under the true optimal individualized treatment.

\hypertarget{oit-eval-cat}{%
\section{Evaluating the Causal Effect of an optimal ITR with Categorical Treatment}\label{oit-eval-cat}}

In this section, we consider how to evaluate the mean outcome under the optimal
individualized treatment when \(A\) has more than two categories. While the
procedure is analogous to the previously described binary treatment, we now need
to pay attention to the type of blip we define in the estimation stage, as well
as how we construct our learners.

\hypertarget{simulated-data-1}{%
\subsection{Simulated Data}\label{simulated-data-1}}

First, we load the simulated data. Here, our data generating distribution was
of the following form:
\begin{align*}
  W &\sim \mathcal{N}(\bf{0},I_{4 \times 4})\\
  \P(A=a \mid W) &= \frac{1}{1+\exp^{(-0.8*W_1)}}\\
  \P(Y=1 \mid A,W) = 0.5\text{logit}^{-1}[15I(A=1)(W_1-0.5) -
    3I(A=2)(2W_1+0.5) +
    3I(A=3)(3W_1-0.5)] +\text{logit}^{-1}(W_2W_1)
\end{align*}

We can just load the data available as part of the package as follows:

\begin{lstlisting}[language=R]
data("data_cat_realistic")
\end{lstlisting}

The above composes our observed data structure \(O = (W, A, Y)\). Note that the
mean under the true optimal rule is \(\psi=0.658\), which is the quantity we aim
to estimate.

\begin{lstlisting}[language=R]
# organize data and nodes for tmle3
data <- data_cat_realistic
node_list <- list(
  W = c("W1", "W2", "W3", "W4"),
  A = "A",
  Y = "Y"
)
\end{lstlisting}

We'll now create new ensemble learners using the
\passthrough{\lstinline!sl3!} learners initialized previously:

\begin{lstlisting}[language=R]
## Define the Q learner, which is just a regular learner:
Q_learner <- Lrnr_sl$new(
  learners = list(
    lrn_xgboost_50, lrn_xgboost_100, lrn_xgboost_300, lrn_mean, lrn_glm
  ),
  metalearner = Lrnr_nnls$new()
)

# Define the g learner, which is a multinomial learner:
# specify the appropriate loss of the multinomial learner:
mn_metalearner <- make_learner(Lrnr_solnp,
  loss_function = loss_loglik_multinomial,
  learner_function =
    metalearner_linear_multinomial
)
g_learner <- make_learner(
  Lrnr_sl,
  list(lrn_xgboost_100, lrn_xgboost_300, lrn_mean),
  mn_metalearner
)

# Define the Blip learner, which is a multivariate learner:
learners <- list(
  lrn_xgboost_50, lrn_xgboost_100, lrn_xgboost_300, lrn_mean, lrn_glm
)
b_learner <- create_mv_learners(learners = learners)
\end{lstlisting}

As seen above, we generate three different ensemble learners that must be fit,
corresponding to the learners for the outcome regression, propensity score, and
the blip function. Note that we need to estimate \(g_0(A \mid W)\) for a
categorical \(A\) -- therefore, we use the multinomial Super Learner option
available within the \passthrough{\lstinline!sl3!} package with learners that can address multi-class
classification problems. In order to see which learners can be used to estimate
\(g_0(A \mid W)\) in \passthrough{\lstinline!sl3!}, we run the following:

\begin{lstlisting}[language=R]
# See which learners support multi-class classification:
sl3_list_learners(c("categorical"))
 [1] "Lrnr_bound"                "Lrnr_caret"               
 [3] "Lrnr_cv_selector"          "Lrnr_glmnet"              
 [5] "Lrnr_grf"                  "Lrnr_gru_keras"           
 [7] "Lrnr_h2o_glm"              "Lrnr_h2o_grid"            
 [9] "Lrnr_independent_binomial" "Lrnr_lightgbm"            
[11] "Lrnr_lstm_keras"           "Lrnr_mean"                
[13] "Lrnr_multivariate"         "Lrnr_nnet"                
[15] "Lrnr_optim"                "Lrnr_polspline"           
[17] "Lrnr_pooled_hazards"       "Lrnr_randomForest"        
[19] "Lrnr_ranger"               "Lrnr_rpart"               
[21] "Lrnr_screener_correlation" "Lrnr_solnp"               
[23] "Lrnr_svm"                  "Lrnr_xgboost"             
\end{lstlisting}

Note that since the corresponding blip will be vector valued, we will have a
column for each additional level of treatment. As such, we need to create
multivariate learners with the helper function \passthrough{\lstinline!create\_mv\_learners!} that takes a
list of initialized learners as input.

We make the above explicit with respect to standard notation by bundling the
ensemble learners into a list object below:

\begin{lstlisting}[language=R]
# specify outcome and treatment regressions and create learner list
learner_list <- list(Y = Q_learner, A = g_learner, B = b_learner)
\end{lstlisting}

\hypertarget{targeted-estimation-of-the-mean-under-the-optimal-individualized-interventions-effects-1}{%
\subsection{Targeted Estimation of the Mean under the Optimal Individualized Interventions Effects}\label{targeted-estimation-of-the-mean-under-the-optimal-individualized-interventions-effects-1}}

\begin{lstlisting}[language=R]
# initialize a tmle specification
tmle_spec <- tmle3_mopttx_blip_revere(
  V = c("W1", "W2", "W3", "W4"), type = "blip2",
  learners = learner_list, maximize = TRUE, complex = TRUE,
  realistic = FALSE
)
\end{lstlisting}

\begin{lstlisting}[language=R]
# fit the TML estimator
fit <- tmle3(tmle_spec, data, node_list, learner_list)
fit
A tmle3_Fit that took 1 step(s)
   type         param init_est tmle_est       se   lower   upper
1:  TSM E[Y_{A=NULL}]  0.55273  0.61149 0.065326 0.48346 0.73953
   psi_transformed lower_transformed upper_transformed
1:         0.61149           0.48346           0.73953
\end{lstlisting}

We can see that the estimate of \(psi_0\) is \(0.60\), and that the confidence
interval covers our true mean under the true optimal individualized treatment.

\hypertarget{extensions-to-causal-effect-of-an-oit}{%
\section{Extensions to Causal Effect of an OIT}\label{extensions-to-causal-effect-of-an-oit}}

In this section, we consider two extensions to the procedure described for
estimating the value of the OIT. First one considers a setting where the user
might be interested in a grid of possible sub-optimal rules, corresponding to
potentially limited knowledge of potential effect modifiers. The second
extension concerns implementation of a realistic optimal individual
interventions where certain regimes might be preferred, but due to practical or
global positivity restraints are not realistic to implement.

\hypertarget{simpler-rules}{%
\subsection{Simpler Rules}\label{simpler-rules}}

In order to not only consider the most ambitious fully \(V\)-optimal rule, we
define \(S\)-optimal rules as the optimal rule that considers all possible subsets
of \(V\) covariates, with card(\(S\)) \(\leq\) card(\(V\)) and \(\emptyset \in S\). This
allows us to consider sub-optimal rules that are easier to estimate and
potentially provide more realistic rules- as such, we allow for statistical
inference for the counterfactual mean outcome under the sub-optimal rule.
Within the \passthrough{\lstinline!tmle3mopttx!} paradigm, we just need to change the \passthrough{\lstinline!complex!}
parameter to \passthrough{\lstinline!FALSE!}:

\begin{lstlisting}[language=R]
# initialize a tmle specification
tmle_spec <- tmle3_mopttx_blip_revere(
  V = c("W4", "W3", "W2", "W1"), type = "blip2",
  learners = learner_list,
  maximize = TRUE, complex = FALSE, realistic = FALSE
)
\end{lstlisting}

\begin{lstlisting}[language=R]
# fit the TML estimator
fit <- tmle3(tmle_spec, data, node_list, learner_list)
fit
A tmle3_Fit that took 1 step(s)
   type                param init_est tmle_est       se   lower   upper
1:  TSM E[Y_{d(V=W3,W2,W1)}]  0.54382  0.61714 0.070518 0.47893 0.75536
   psi_transformed lower_transformed upper_transformed
1:         0.61714           0.47893           0.75536
\end{lstlisting}

Therefore even though the user specified all baseline covariates as the basis
for rule estimation, a simpler rule based on only \(W_2\) and \(W_1\) is sufficient
to maximize the mean under the optimal individualized treatment.

\hypertarget{realistic-optimal-individual-regimes}{%
\subsection{Realistic Optimal Individual Regimes}\label{realistic-optimal-individual-regimes}}

In addition to considering less complex rules, \passthrough{\lstinline!tmle3mopttx!} also provides an
option to estimate the mean under the realistic, or implementable, optimal
individualized treatment. It is often the case that assigning particular regime
might have the ability to fully maximize (or minimize) the desired outcome, but
due to global or practical positivity constrains, such treatment can never be
implemented in real life (or is highly unlikely). As such, specifying
\passthrough{\lstinline!realistic!} to \passthrough{\lstinline!TRUE!}, we consider possibly suboptimal treatments that optimize
the outcome in question while being supported by the data.

\begin{lstlisting}[language=R]
# initialize a tmle specification
tmle_spec <- tmle3_mopttx_blip_revere(
  V = c("W4", "W3", "W2", "W1"), type = "blip2",
  learners = learner_list,
  maximize = TRUE, complex = TRUE, realistic = TRUE
)
\end{lstlisting}

\begin{lstlisting}[language=R]
# fit the TML estimator
fit <- tmle3(tmle_spec, data, node_list, learner_list)
fit
A tmle3_Fit that took 1 step(s)
   type         param init_est tmle_est       se   lower   upper
1:  TSM E[Y_{A=NULL}]  0.54896  0.65453 0.021603 0.61219 0.69687
   psi_transformed lower_transformed upper_transformed
1:         0.65453           0.61219           0.69687

# How many individuals got assigned each treatment?
table(tmle_spec$return_rule)

  2   3 
507 493 
\end{lstlisting}

\hypertarget{q-learning}{%
\subsection{Q-learning}\label{q-learning}}

Alternatively, we could estimate the mean under the optimal individualized
treatment using Q-learning. The optimal rule can be learned through fitting the
likelihood, and consequently estimating the optimal rule under this fit of the
likelihood \citep{Sutton1998, murphy2003}.

Below we outline how to use \passthrough{\lstinline!tmle3mopttx!} package in order to estimate the mean
under the ITR using Q-learning. As demonstrated in the previous sections, we
first need to initialize a specification for the TMLE of our parameter of
interest. As opposed to the previous section however, we will now use
\passthrough{\lstinline!tmle3\_mopttx\_Q!} instead of \passthrough{\lstinline!tmle3\_mopttx\_blip\_revere!} in order to indicate that
we want to use Q-learning instead of TMLE.

\begin{lstlisting}[language=R]
# initialize a tmle specification
tmle_spec_Q <- tmle3_mopttx_Q(maximize = TRUE)

# Define data:
tmle_task <- tmle_spec_Q$make_tmle_task(data, node_list)

# Define likelihood:
initial_likelihood <- tmle_spec_Q$make_initial_likelihood(
  tmle_task,
  learner_list
)

# Estimate the parameter:
Q_learning(tmle_spec_Q, initial_likelihood, tmle_task)[1]
\end{lstlisting}

\hypertarget{variable-importance-analysis-with-oit}{%
\section{Variable Importance Analysis with OIT}\label{variable-importance-analysis-with-oit}}

Suppose one wishes to assess the importance of each observed covariate, in
terms of maximizing (or minimizing) the population mean of an outcome under an
optimal individualized treatment regime. In particular, a covariate that
maximizes (or minimizes) the population mean outcome the most under an optimal
individualized treatment out of all other considered covariates under optimal
assignment might be considered \emph{more important} for the outcome. To put it in
context, perhaps optimal allocation of treatment 1, denoted \(A_1\), results in a
larger mean outcome than optimal allocation of another treatment (\(A_2\)).
Therefore, we would label \(A_1\) as having a higher variable importance with
regard to maximizing (minimizing) the mean outcome under the optimal
individualized treatment.

\hypertarget{simulated-data-2}{%
\subsection{Simulated Data}\label{simulated-data-2}}

In order to run \passthrough{\lstinline!tmle3mopttx!} variable importance measure, we need to consider
covariates to be categorical variables. For illustration purpose, we bin
baseline covariates corresponding to the data-generating distribution
\protect\hyperlink{oit-eval}{described previously}:

\begin{lstlisting}[language=R]
# bin baseline covariates to 3 categories:
data$W1 <- ifelse(data$W1 < quantile(data$W1)[2], 1,
  ifelse(data$W1 < quantile(data$W1)[3], 2, 3)
)

node_list <- list(
  W = c("W3", "W4", "W2"),
  A = c("W1", "A"),
  Y = "Y"
)
\end{lstlisting}

Note that our node list now includes \(W_1\) as treatments as well! Don't worry,
we will still properly adjust for all baseline covariates.

\hypertarget{variable-importance-using-targeted-estimation-of-the-value-of-the-itr}{%
\subsection{Variable Importance using Targeted Estimation of the value of the ITR}\label{variable-importance-using-targeted-estimation-of-the-value-of-the-itr}}

In the previous sections we have seen how to obtain a contrast between the mean
under the optimal individualized rule and the mean under the observed outcome
for a single covariate- we are now ready to run the variable importance analysis
for all of our specified covariates. In order to run the variable importance
analysis, we first need to initialize a specification for the TMLE of our
parameter of interest as we have done before. In addition, we need to specify
the data and the corresponding list of nodes, as well as the appropriate
learners for the outcome regression, propensity score, and the blip function.
Finally, we need to specify whether we should adjust for all the other
covariates we are assessing variable importance for. We will adjust for all \(W\)s
in our analysis, and if \passthrough{\lstinline!adjust\_for\_other\_A=TRUE!}, also for all \(A\) covariates
that are not treated as exposure in the variable importance loop.

To start, we will initialize a specification for the TMLE of our parameter of
interest (called a \passthrough{\lstinline!tmle3\_Spec!} in the \passthrough{\lstinline!tlverse!} nomenclature) simply by calling
\passthrough{\lstinline!tmle3\_mopttx\_vim!}. First, we indicate the method used for learning the optimal
individualized treatment by specifying the \passthrough{\lstinline!method!} argument of
\passthrough{\lstinline!tmle3\_mopttx\_vim!}. If \passthrough{\lstinline!method="Q"!}, then we will be using Q-learning for rule
estimation, and we do not need to specify \passthrough{\lstinline!V!}, \passthrough{\lstinline!type!} and \passthrough{\lstinline!learners!} arguments
in the spec, since they are not important for Q-learning. However, if
\passthrough{\lstinline!method="SL"!}, which corresponds to learning the optimal individualized
treatment using the above outlined methodology, then we need to specify the type
of pseudo-blip we will use in this estimation problem, whether we want to
maximize or minimize the outcome, complex and realistic rules. Finally, for
\passthrough{\lstinline!method="SL"!} we also need to communicate that we're interested in learning a
rule dependent on \passthrough{\lstinline!V!} covariates by specifying the \passthrough{\lstinline!V!} argument. For both
\passthrough{\lstinline!method="Q"!} and \passthrough{\lstinline!method="SL"!}, we need to indicate whether we want to maximize
or minimize the mean under the optimal individualized rule. Finally, we also
need to specify whether the final comparison of the mean under the optimal
individualized rule and the mean under the observed outcome should be on the
multiplicative scale (risk ratio) or linear (similar to average treatment
effect).

\begin{lstlisting}[language=R]
# initialize a tmle specification
tmle_spec <- tmle3_mopttx_vim(
  V = c("W2"),
  type = "blip2",
  learners = learner_list,
  contrast = "multiplicative",
  maximize = FALSE,
  method = "SL",
  complex = TRUE,
  realistic = FALSE
)
\end{lstlisting}

\begin{lstlisting}[language=R]
# fit the TML estimator
vim_results <- tmle3_vim(tmle_spec, data, node_list, learner_list,
  adjust_for_other_A = TRUE
)
print(vim_results)
\end{lstlisting}

The final result of \passthrough{\lstinline!tmle3\_vim!} with the \passthrough{\lstinline!tmle3mopttx!} spec is an ordered list
of mean outcomes under the optimal individualized treatment for all categorical
covariates in our dataset.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{exercises-2}{%
\section{Exercises}\label{exercises-2}}

\hypertarget{real-world-data-and-tmle3mopttx}{%
\subsection{\texorpdfstring{Real World Data and \texttt{tmle3mopttx}}{Real World Data and tmle3mopttx}}\label{real-world-data-and-tmle3mopttx}}

Finally, we cement everything we learned so far with a real data application.

As in the previous sections, we will be using the WASH Benefits data,
corresponding to the effect of water quality, sanitation, hand washing, and
nutritional interventions on child development in rural Bangladesh.

The main aim of the cluster-randomized controlled trial was to assess the
impact of six intervention groups, including:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  control;
\item
  hand-washing with soap;
\item
  improved nutrition through counseling and provision of lipid-based nutrient
  supplements;
\item
  combined water, sanitation, hand-washing, and nutrition;
\item
  improved sanitation;
\item
  combined water, sanitation, and hand-washing;
\item
  chlorinated drinking water.
\end{enumerate}

We aim to estimate the optimal ITR and the corresponding value under the optimal
ITR for the main intervention in WASH Benefits data.

Our outcome of interest is the weight-for-height Z-score, whereas our primary
treatment is the six intervention groups aimed at improving living conditions.

Questions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Define \(V\) as mother's education (\passthrough{\lstinline!momedu!}), current living conditions (\passthrough{\lstinline!floor!}),
  and possession of material items including the refrigerator (\passthrough{\lstinline!asset\_refrig!}).
  Why do you think we use these covariates as \(V\)? Do we want to minimize or
  maximize the outcome? Which blip type should we use?
\item
  Load the WASH Benefits data, and define the appropriate nodes for treatment
  and outcome. Use all the rest of the covariates as \(W\) except for
  \passthrough{\lstinline!momheight!} for now. Construct an appropriate \passthrough{\lstinline!sl3!} library for \(A\), \(Y\) and
  \(B\).
\item
  Based on the \(V\) defined in the previous question, estimate the mean under
  the ITR for the main randomized intervention used in the WASH Benefits trial
  with weight-for-height Z-score as the outcome. What's the TMLE value of the
  optimal ITR? How does it change from the initial estimate? Which
  intervention is the most dominant? Why do you think that is?
\item
  Using the same formulation as in questions 1 and 2, estimate the realistic
  optimal ITR and the corresponding value of the realistic ITR. Did the results
  change? Which intervention is the most dominant under realistic rules? Why do
  you think that is?
\item
  Consider simpler rules for the WASH benefits data example. What set of rules
  are picked?
\item
  Change the treatment to a binary variable (\passthrough{\lstinline!asset\_sewmach!}), and estimate the
  value under the ITR in this setting under a \(60\%\) resource constraint. What
  do the results indicate?
\item
  Change the treatment once again, now to mother's education (\passthrough{\lstinline!momedu!}), and
  estimate the value under the ITR in this setting. What do the results
  indicate? Can we intervene on such a variable?
\end{enumerate}

\hypertarget{review-of-key-concepts-1}{%
\subsection{Review of Key Concepts}\label{review-of-key-concepts-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  What is the difference between dynamic and optimal individualized regimes?
\item
  What's the intuition behind using different blip types? Why did we switch
  from \passthrough{\lstinline!blip1!} to \passthrough{\lstinline!blip2!} when considering categorical treatment? What are some
  of the advantages of each?
\item
  Look back at the results generated in the \protect\hyperlink{oit-eval-cat}{section on categorical
  treatments}, and compare then to the mean under the optimal
  individualized treatment in the \protect\hyperlink{oit-eval-bin}{section on binary
  treatments}. Why do you think the estimate is higher under the
  less complex rule? How does the set of covariates picked by \passthrough{\lstinline!tmle3mopttx!}
  compare to the baseline covariates the true rule depends on?
\item
  Compare the distribution of treatments assigned under the true optimal
  individualized treatment and realistic optimal individualized treatment.
  Referring back to the data-generating distribution, why do you think the
  distribution of allocated treatment changed?
\item
  Using the same simulation, perform a variable importance analysis using
  Q-learning. How do the results change and why?
\end{enumerate}

\hypertarget{advanced-topics-1}{%
\subsection{Advanced Topics}\label{advanced-topics-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  How can we extend the current approach to include exceptional laws?
\item
  How can we extend the current approach to continuous interventions?
\end{enumerate}

\hypertarget{stochastic-treatment-regimes}{%
\chapter{Stochastic Treatment Regimes}\label{stochastic-treatment-regimes}}

\emph{Nima Hejazi}

Based on the \href{https://github.com/tlverse/tmle3shift}{\passthrough{\lstinline!tmle3shift!} \passthrough{\lstinline!R!} package}
by \emph{Nima Hejazi, Jeremy Coyle, and Mark van der Laan}.

Updated: 2021-09-21

\begin{VT1}
\VH{Learning Objectives}



1. Differentiate stochastic treatment regimes from static, dynamic, and optimal
   treatment regimes.
2. Describe how estimating causal effects of stochastic interventions informs a
   real-world data analysis.
3. Contrast a population level stochastic intervention policy from a modified
   treatment policy.
4. Estimate causal effects under stochastic treatment regimes with the
   `tmle3shift` `R` package.
6. Specify a grid of counterfactual shift interventions to be used for defining
   a set of stochastic intervention policies.
7. Interpret a set of effect estimates from a grid of counterfactual shift
   interventions.
5. Construct marginal structural models to measure variable importance in terms
   of stochastic interventions, using a grid of shift interventions.
8. Implement a shift intervention at the individual level, to facilitate
   shifting each individual to a value that's supported by the data.
9. Define novel shift intervention functions to extend the `tmle3shift` `R`
   package.

\end{VT1}

\hypertarget{introduction-to-stochastic-interventions}{%
\section{Introduction to Stochastic Interventions}\label{introduction-to-stochastic-interventions}}

Stochastic treatment regimes present a relatively simple, yet extremely flexible
manner by which \emph{realistic} causal effects (and contrasts thereof) may be
defined. Importantly, stochastic treatment regimes may be applied to nearly
any manner of treatment variable -- continuous, ordinal, categorical, binary --
allowing for a rich set of causal effects to be defined through this formalism.
In this chapter, we examine a simple example of stochastic treatment regimes in
the context of a continuous treatment variable of interest, defining an
intuitive causal effect through which to examine stochastic interventions more
generally. In later sections, we introduce numerous extensions based on this
broad class of interventions -- from stochastic interventions on binary
treatment variables to stochastic mediation effects and data-adaptive inference
for stochastic intervention effects. As a first step to using stochastic
treatment regimes in practice, we present the \href{https://github.com/tlverse/tmle3shift}{\passthrough{\lstinline!tmle3shift!} R
package}, which features an
implementation of a recently developed algorithm for computing targeted minimum
loss-based estimates of a causal effect based on a stochastic treatment regime
that shifts the natural value of the treatment based on a shifting function
\(d(A,W)\). For a comprehensive technical presentation of some of the material in
this chapter, the interested reader is invited to consult \citet{diaz2018stochastic}.
Additional background on the field of Targeted Learning, as well as prior work
on stochastic treatment regimes, is available in \citet{vdl2011targeted},
\citet{vdl2018targeted}, and \citet{diaz2012population}.

While stochastic treatment regimes are arguably the most general of the
classes of interventions through which causal effects may be defined, such
interventions are conceptually simple.

\hypertarget{data-structure-and-notation-1}{%
\section{Data Structure and Notation}\label{data-structure-and-notation-1}}

Consider \(n\) observed units \(O_1, \ldots, O_n\), where each random variable \(O = (W, A, Y)\) corresponds to a single observational unit. Let \(W\) denote baseline
covariates (e.g., age, sex, education level), \(A\) an intervention variable of
interest (e.g., nutritional supplements), and \(Y\) an outcome of interest (e.g.,
disease status). Though it need not be the case, let \(A\) be continuous-valued,
i.e. \(A \in \R\). Let \(O_i \sim \mathcal{P} \in \M\), where \(\M\) is the
nonparametric statistical model defined as the set of continuous densities on
\(O\) with respect to some dominating measure. To formalize the definition of
stochastic interventions and their corresponding causal effects, we introduce a
nonparametric structural equation model (NPSEM), based on \citet{pearl2009causality},
to define how the system changes under posited interventions:
\begin{align}
  W &= f_W(U_W) \\ A &= f_A(W, U_A) \\ Y &= f_Y(A, W, U_Y),
  \label{eq:npsem-shift}
\end{align}
where the set of structural equations provide a mechanistic model by which the
observed data \(O\) is assumed to have been generated. There are several standard
assumptions embedded in the NPSEM -- specifically, a temporal ordering that
supposes that \(Y\) occurs after \(A\), which occurs after \(W\); each variable (i.e.,
\(\{W, A, Y\}\)) is assumed to have been generated from its corresponding
deterministic function (i.e., \(\{f_W, f_A, f_Y\}\)) of the observed variables
that precede it temporally, as well as an exogenous variable, denoted by \(U\);
lastly, each exogenous variable is assumed to contain all unobserved causes of
the corresponding observed variable.

The likelihood of the data \(O\) admits a factorization, wherein, for \(p_0^O\),
the density of \(O\) with respect to the product measure, the density evaluated
on a particular observation \(o\) may be a written
\begin{equation}
  p_0^O(x) = q^O_{0,Y}(y \mid A = a, W = w) q^O_{0,A}(a \mid W = w)
  q^O_{0,W}(w),
  \label{eq:likelihood-factorization-shift}
\end{equation}
where \(q_{0, Y}\) is the conditional density of \(Y\) given \((A, W)\) with respect
to some dominating measure, \(q_{0, A}\) is the conditional density of \(A\) given
\(W\) with respect to dominating measure \(\mu\), and \(q_{0, W}\) is the density of
\(W\) with respect to dominating measure \(\nu\). Further, for ease of notation, let
\(Q(A, W) = \E[Y \mid A, W]\), \(g(A \mid W) = \P(A \mid W)\), and \(q_W\) the
marginal distribution of \(W\). These components of the likelihood will be
essential in developing an understanding of the manner in which stochastic
treatment regimes perturb a system and how a corresponding causal effect may be
evaluated. Importantly, the NPSEM parameterizes \(p_0^O\) in terms of the
distribution of random variables \((O, U)\) modeled by the system of equations. In
turn, this implies a model for the distribution of counterfactual random
variables generated by interventions on the data-generating process.

\hypertarget{defining-the-causal-effect-of-a-stochastic-intervention}{%
\section{Defining the Causal Effect of a Stochastic Intervention}\label{defining-the-causal-effect-of-a-stochastic-intervention}}

As causal effects are defined in terms of hypothetical interventions on the
NPSEM \eqref{eq:npsem-shift}, we may consider stochastic interventions in two
equivalent ways: (1) where the equation \(f_A\), giving rise to \(A\), is replaced
by a probabilistic mechanism \(g_{\delta}(A \mid W)\) that differs from the
original \(g(A \mid W)\), or (2) where the observed value \(A\) is replaced by a
new value \(A_{d(A,W)}\) based on applying a user-defined function \(d(A,W)\) to
\(A\). In the former case, the \emph{stochastically modified} value of the treatment
\(A_{\delta}\) is drawn from a user-specified distribution \(g_\delta(A \mid W)\),
which may depend on the original distribution \(g(A \mid W)\) and is indexed by
a user-specified parameter \(\delta\). In this case, the stochastically modified
value of the treatment \(A_{\delta} \sim g_{\delta}(\cdot \mid W)\).
Alternatively, in the latter case, the stochastic treatment regime may be
viewed as an intervention in which \(A\) is set equal to a value based on a
hypothetical regime \(d(A, W)\), where regime \(d\) depends on the treatment level
\(A\) that would be assigned in the absence of the regime as well as the
covariates \(W\). In either case, one may view the stochastic intervention as
generating a counterfactual random variable \(Y_{d(A,W)} := f_Y(d(A,W), W, U_Y) \equiv Y_{g_{\delta}} := f_Y(A_{\delta}, W, U_Y)\), where the counterfactual
outcome \(Y_{d(A,W)} \sim \mathcal{P}_0^{\delta}\).

Stochastic interventions of this second variety may be referred to as depending
on the \emph{natural value of treatment} or as \emph{modified treatment policies}.
\citet{haneuse2013estimation} and \citet{young2014identification} provide a discussion of the
critical differences and similarities in the identification and interpretation
of these two classes of stochastic intervention. In the sequel, we will
restrict our attention to a simple stochastic treatment regime that has been
characterized as a \emph{modified treatment policy} (MTP). Letting \(A\) denote a
continuous-valued treatment, such as the taking of nutritional supplements
(e.g., number of vitamin pills) and assume that the distribution of \(A\)
conditional on \(W = w\) has support in the interval \((l(w), u(w))\). That is, the
minimum observed number of pills taken \(A\) for an individual with covariates
\(W = w\) is \(l(w)\); similarly, the maximum is \(u(w)\). Then, a simple stochastic
intervention, based on a shift \(\delta\), may be defined
\begin{equation}
  d(a, w) =
  \begin{cases}
    a - \delta & \text{if } a > l(w) + \delta \\
    a & \text{if } a \leq l(w) + \delta,
  \end{cases}
  \label{eq:shift}
\end{equation}
where \(0 \leq \delta \leq u(w)\) is an arbitrary pre-specified value that
defines the degree to which the observed value \(A\) is to be shifted, where
possible. Such a stochastic treatment regime may be interpreted as the result
of a clinic policy that encourages individuals to consume \(\delta\) more vitamin
pills than they would normally, i.e., based on their baseline characteristics.
The interpretation of this stochastic intervention may be made more interesting
by allowing the modification \(\delta\) that it engenders to be a function of the
baseline covariates \(W\), thereby allowing for the number of vitamin pills taken
to be a function of covariates such as age, sex, comorbidities, etc. This class
of stochastic interventions was first introduced by \citet{diaz2012population} and has
been further discussed in \citet{haneuse2013estimation}, \citet{diaz2018stochastic}, and
\citet{hejazi2020efficient}. Note that this intervention may be written in a manner
consistent with the first class of stochastic treatment regimes discussed as
well -- that is, as per \citet{diaz2012population}, \(\P_{\delta}(g_0)(A = a \mid W) = g_0(a - \delta(W) \mid W)\).

The goal of any causal analysis motivated by such a stochastic intervention is
to estimate a parameter defined as the counterfactual mean of the outcome with
respect to the stochastically modified intervention distribution. In
particular, the target causal estimand of our analysis is \(\psi_{0, \delta} \coloneqq \E_{P_0^{\delta}}\{Y_{d(A,W)}\}\), the mean of the counterfactual
outcome variable \(Y_{d(A, W)}\). In prior work, \citet{diaz2012population} showed that
the causal quantity of interest \(\E_0 \{Y_{d(A, W)}\}\) is identified by
a functional of the distribution of \(O\):
\begin{align}
  \psi_{0,d} = \int_{\mathcal{W}} \int_{\mathcal{A}} & \E_{P_0}
   \{Y \mid A = d(a, w), W = w\} \cdot \\ &q_{0, A}^O(a \mid W = w) \cdot
   q_{0, W}^O(w) d\mu(a)d\nu(w).
  \label{eq:identification2012}
\end{align}
If the identification conditions may be assumed to hold, then the statistical
parameter in \eqref{eq:identification2012} matches exactly the counterfactual
outcome \(\psi_{0, \delta}\) under such an intervention, allowing for the causal
effect to be learned from the observed data \(O\). \citet{diaz2012population} provide a
derivation based on the efficient influence function (EIF) in the nonparametric
model \(\M\) and develop several estimators of this quantity, including
substitution, inverse probability weighted (IPW), one-step (OS) and targeted
maximum likelihood (TML) estimators, allowing for semiparametric-efficient
estimation and inference on the quantity of interest. As per
\citet{diaz2018stochastic}, the statistical target parameter may also be denoted
\(\Psi(P_0) = \E_{P_0}{\overline{Q}(d(A, W), W)}\), where \(\overline{Q}(d(A, W), W)\) is the counterfactual outcome value of a given individual under the
stochastic intervention distribution.

Although the focus of this work is neither the establishment of identification
results nor the development of theoretical details, we review the necessary
identification details for the counterfactual mean under a stochastic
intervention here, in the interest of completeness. Paraphrasing from
\citet{diaz2012population} and \citet{diaz2018stochastic}, four standard assumptions are
necessary in order to establish identifiability of the causal parameter from
the observed data via the statistical functional -- these are

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{Consistency}: \(Y^{d(a_i, w_i)}_i = Y_i\) in the event \(A_i = d(a_i, w_i)\),
  for \(i = 1, \ldots, n\)
\item
  \emph{Stable unit value treatment assumption (SUTVA)}: \(Y^{d(a_i, w_i)}_i\) does
  not depend on \(d(a_j, w_j)\) for \(i = 1, \ldots, n\) and \(j \neq i\), or lack
  of interference \citep{rubin1978bayesian, rubin1980randomization}.
\item
  \emph{Strong ignorability}: \(A_i \indep Y^{d(a_i, w_i)}_i \mid W_i\), for \(i = 1, \ldots, n\).
\item
  \emph{Positivity (or overlap)}: \(a_i \in \mathcal{A} \implies d(a_i, w_i) \in \mathcal{A}\) for all \(w \in \mathcal{W}\), where \(\mathcal{A}\) denotes the
  support of \(A \mid W = w_i \quad \forall i = 1, \ldots n\).
\end{enumerate}

With the identification assumptions satisfied, \citet{diaz2012population} and
\citet{diaz2018stochastic} provide an efficient influence function with respect to
the nonparametric model \(\M\) as
\begin{equation}
  D(P_0)(x) = H(a, w)({y - \overline{Q}(a, w)}) +
  \overline{Q}(d(a, w), w) - \Psi(P_0),
  \label{eq:eif-shift}
\end{equation}
where the auxiliary covariate \(H(a,w)\) may be expressed
\begin{equation}
  H(a,w) = \mathbb{I}(a + \delta < u(w)) \frac{g_0(a - \delta \mid w)}
  {g_0(a \mid w)} + \mathbb{I}(a + \delta \geq u(w)),
  \label{eq:aux-covar-full-shift}
\end{equation}
which may be reduced to
\begin{equation}
  H(a,w) = \frac{g_0(a - \delta \mid w)}{g_0(a \mid w)} + 1
  \label{eq:aux-covar-simple-shift}
\end{equation}
in the case that the treatment is within the limits that arise from conditioning
on \(W\), i.e., for \(A_i \in (u(w) - \delta, u(w))\).

The efficient influence function allows the construction of a
semiparametric-efficient estimators may be constructed. In the sequel, we focus
on a targeted maximum likelihood (TML) estimator, for which \citet{diaz2018stochastic}
give a recipe:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Construct initial estimators \(g_n\) of \(g_0(A, W)\) and \(Q_n\) of
  \(\overline{Q}_0(A, W)\), perhaps using data-adaptive regression techniques.
\item
  For each observation \(i\), compute an estimate \(H_n(a_i, w_i)\) of the
  auxiliary covariate \(H(a_i,w_i)\).
\item
  Estimate the parameter \(\epsilon\) in the logistic regression model
  \[ \text{logit}\overline{Q}_{\epsilon, n}(a, w) =
  \text{logit}\overline{Q}_n(a, w) + \epsilon H_n(a, w),\]
  or an alternative regression model incorporating weights.
\item
  Compute TML estimator \(\Psi_n\) of the target parameter, defining update
  \(\overline{Q}_n^{\star}\) of the initial estimate
  \(\overline{Q}_{n, \epsilon_n}\):
  \begin{equation}
    \Psi_n = \Psi(P_n^{\star}) = \frac{1}{n} \sum_{i = 1}^n
    \overline{Q}_n^{\star}(d(A_i, W_i), W_i).
    \label{eq:tmle}
  \end{equation}
\end{enumerate}

\hypertarget{evaluating-the-causal-effect-of-a-stochastic-intervention}{%
\section{Evaluating the Causal Effect of a Stochastic Intervention}\label{evaluating-the-causal-effect-of-a-stochastic-intervention}}

To start, let's load the packages we'll be using throughout our simple data example

\begin{lstlisting}[language=R]
library(data.table)
library(haldensify)
library(sl3)
library(tmle3)
library(tmle3shift)
\end{lstlisting}

We need to estimate two components of the likelihood in order to construct a TML
estimator. The first of these components is the outcome regression, \(\hat{Q}_n\),
which is a simple regression of the form \(\E[Y \mid A,W]\). An estimate
for such a quantity may be constructed using the Super Learner algorithm. We
construct the components of an \passthrough{\lstinline!sl3!}-style Super Learner for a regression below,
using a small variety of parametric and nonparametric regression techniques:

\begin{lstlisting}[language=R]
# learners used for conditional mean of the outcome
mean_lrnr <- Lrnr_mean$new()
fglm_lrnr <- Lrnr_glm_fast$new()
rf_lrnr <- Lrnr_ranger$new()
hal_lrnr <- Lrnr_hal9001$new(max_degree = 3, n_folds = 3)

# SL for the outcome regression
sl_reg_lrnr <- Lrnr_sl$new(
  learners = list(mean_lrnr, fglm_lrnr, rf_lrnr, hal_lrnr),
  metalearner = Lrnr_nnls$new()
)
\end{lstlisting}

The second of these is an estimate of the treatment mechanism, \(\hat{g}_n\),
i.e., the \emph{propensity score}. In the case of a continuous intervention node \(A\),
such a quantity takes the form \(p(A \mid W)\), which is a conditional density.
Generally speaking, conditional density estimation is a challenging problem that
has received much attention in the literature. To estimate the treatment
mechanism, we must make use of learning algorithms specifically suited to
conditional density estimation; a list of such learners may be extracted from
\passthrough{\lstinline!sl3!} by using \passthrough{\lstinline!sl3\_list\_learners()!}:

\begin{lstlisting}[language=R]
sl3_list_learners("density")
[1] "Lrnr_density_discretize"     "Lrnr_density_hse"           
[3] "Lrnr_density_semiparametric" "Lrnr_haldensify"            
[5] "Lrnr_solnp_density"         
\end{lstlisting}

To proceed, we'll select two of the above learners, \passthrough{\lstinline!Lrnr\_haldensify!} for using
the highly adaptive lasso for conditional density estimation, based on an
algorithm given by \citet{diaz2011super} and implemented in \citet{hejazi2020haldensify}, and
semiparametric location-scale conditional density estimators implemented in the
\href{https://github.com/tlverse/sl3}{\passthrough{\lstinline!sl3!} package}. A Super Learner may be
constructed by pooling estimates from each of these modified conditional density
regression techniques (note that we exclude the approach based on the
\passthrough{\lstinline!haldensify!} learner from our Super Learner on account of the computationally
intensive nature of the approach).

\begin{lstlisting}[language=R]
# learners used for conditional densities (i.e., generalized propensity score)
haldensify_lrnr <- Lrnr_haldensify$new(
  n_bins = c(5, 10, 20),
  lambda_seq = exp(seq(-1, -10, length = 200))
)
# semiparametric density estimator based on homoscedastic errors (HOSE)
hose_hal_lrnr <- make_learner(Lrnr_density_semiparametric,
  mean_learner = hal_lrnr
)
# semiparametric density estimator based on heteroscedastic errors (HESE)
hese_rf_glm_lrnr <- make_learner(Lrnr_density_semiparametric,
  mean_learner = rf_lrnr,
  var_learner = fglm_lrnr
)

# SL for the conditional treatment density
sl_dens_lrnr <- Lrnr_sl$new(
  learners = list(hose_hal_lrnr, hese_rf_glm_lrnr),
  metalearner = Lrnr_solnp_density$new()
)
\end{lstlisting}

Finally, we construct a \passthrough{\lstinline!learner\_list!} object for use in constructing a TML
estimator of our target parameter of interest:

\begin{lstlisting}[language=R]
learner_list <- list(Y = sl_reg_lrnr, A = sl_dens_lrnr)
\end{lstlisting}

The \passthrough{\lstinline!learner\_list!} object above specifies the role that each of the ensemble
learners we have generated is to play in computing initial estimators to be
used in building a TMLE for the parameter of interest here. In particular, it
makes explicit the fact that our \passthrough{\lstinline!Q\_learner!} is used in fitting the outcome
regression while our \passthrough{\lstinline!g\_learner!} is used in estimating the treatment mechanism.

\hypertarget{example-with-simulated-data}{%
\subsection{Example with Simulated Data}\label{example-with-simulated-data}}

\begin{lstlisting}[language=R]
# simulate simple data for tmle-shift sketch
n_obs <- 400 # number of observations
tx_mult <- 2 # multiplier for the effect of W = 1 on the treatment

## baseline covariates -- simple, binary
W <- replicate(2, rbinom(n_obs, 1, 0.5))

## create treatment based on baseline W
A <- rnorm(n_obs, mean = tx_mult * W, sd = 1)

## create outcome as a linear function of A, W + white noise
Y <- rbinom(n_obs, 1, prob = plogis(A + W))

# organize data and nodes for tmle3
data <- data.table(W, A, Y)
setnames(data, c("W1", "W2", "A", "Y"))
node_list <- list(
  W = c("W1", "W2"),
  A = "A",
  Y = "Y"
)
head(data)
   W1 W2         A Y
1:  1  1  0.271651 1
2:  0  0 -0.663368 1
3:  0  0  0.113366 0
4:  0  1 -0.732558 0
5:  1  1  0.388835 1
6:  0  0  0.043986 0
\end{lstlisting}

The above composes our observed data structure \(O = (W, A, Y)\). To formally
express this fact using the \passthrough{\lstinline!tlverse!} grammar introduced by the \passthrough{\lstinline!tmle3!} package,
we create a single data object and specify the functional relationships between
the nodes in the \emph{directed acyclic graph} (DAG) via \emph{nonparametric structural
equation models} (NPSEMs), reflected in the node list that we set up:

We now have an observed data structure (\passthrough{\lstinline!data!}) and a specification of the role
that each variable in the data set plays as the nodes in a DAG.

To start, we will initialize a specification for the TMLE of our parameter of
interest (called a \passthrough{\lstinline!tmle3\_Spec!} in the \passthrough{\lstinline!tlverse!} nomenclature) simply by calling
\passthrough{\lstinline!tmle\_shift!}. We specify the argument \passthrough{\lstinline!shift\_val = 0.5!} when initializing the
\passthrough{\lstinline!tmle3\_Spec!} object to communicate that we're interested in a shift of \(0.5\) on
the scale of the treatment \(A\) -- that is, we specify \(\delta = 0.5\) (note that
this is an arbitrarily chosen value for this example).

\begin{lstlisting}[language=R]
# initialize a tmle specification
tmle_spec <- tmle_shift(
  shift_val = 0.5,
  shift_fxn = shift_additive,
  shift_fxn_inv = shift_additive_inv
)
\end{lstlisting}

As seen above, the \passthrough{\lstinline!tmle\_shift!} specification object (like all \passthrough{\lstinline!tmle3\_Spec!}
objects) does \emph{not} store the data for our specific analysis of interest. Later,
we'll see that passing a data object directly to the \passthrough{\lstinline!tmle3!} wrapper function,
alongside the instantiated \passthrough{\lstinline!tmle\_spec!}, will serve to construct a \passthrough{\lstinline!tmle3\_Task!}
object internally (see the \passthrough{\lstinline!tmle3!} documentation for details).

\hypertarget{targeted-estimation-of-stochastic-interventions-effects}{%
\subsection{Targeted Estimation of Stochastic Interventions Effects}\label{targeted-estimation-of-stochastic-interventions-effects}}

\begin{lstlisting}[language=R]
tmle_fit <- tmle3(tmle_spec, data, node_list, learner_list)

Iter: 1 fn: 548.8338     Pars:  0.94735 0.05265
Iter: 2 fn: 548.8338     Pars:  0.94736 0.05264
solnp--> Completed in 2 iterations
tmle_fit
A tmle3_Fit that took 1 step(s)
   type         param init_est tmle_est       se   lower   upper
1:  TSM E[Y_{A=NULL}]  0.76372  0.76011 0.022838 0.71535 0.80488
   psi_transformed lower_transformed upper_transformed
1:         0.76011           0.71535           0.80488
\end{lstlisting}

The \passthrough{\lstinline!print!} method of the resultant \passthrough{\lstinline!tmle\_fit!} object conveniently displays the
results from computing our TML estimator.

\hypertarget{statistical-inference-for-targeted-maximum-likelihood-estimates}{%
\subsection{Statistical Inference for Targeted Maximum Likelihood Estimates}\label{statistical-inference-for-targeted-maximum-likelihood-estimates}}

Recall that the asymptotic distribution of TML estimators has been studied
thoroughly:
\[\psi_n - \psi_0 = (P_n - P_0) \cdot D(\bar{Q}_n^{\star}, g_n) +
R(\hat{P}^{\star}, P_0),\]
which, provided the following two conditions,

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  If \(D(\bar{Q}_n^{\star}, g_n)\) converges to \(D(P_0)\) in \(L_2(P_0)\) norm, and
\item
  the size of the class of functions considered for estimation of
  \(\bar{Q}_n^{\star}\) and \(g_n\) is bounded (technically, \(\exists \mathcal{F}\)
  such that \(D(\bar{Q}_n^{\star}, g_n) \in \mathcal{F}\) \emph{whp}, where
  \(\mathcal{F}\) is a Donsker class),
  readily admits the conclusion that
  \(\psi_n - \psi_0 = (P_n - P_0) \cdot D(P_0) + R(\hat{P}^{\star}, P_0)\).
\end{enumerate}

Under the additional condition that the remainder term \(R(\hat{P}^{\star}, P_0)\)
decays as \(o_P \left( \frac{1}{\sqrt{n}} \right),\) we have that
\[\psi_n - \psi_0 = (P_n - P_0) \cdot D(P_0) + o_P \left( \frac{1}{\sqrt{n}}
\right),\]
which, by a central limit theorem, establishes a Gaussian limiting distribution
for the estimator:

\[\sqrt{n}(\psi_n - \psi) \to N(0, V(D(P_0))),\]
where \(V(D(P_0))\) is the variance of the efficient influence curve (canonical
gradient) when \(\psi\) admits an asymptotically linear representation.

The above implies that \(\psi_n\) is a \(\sqrt{n}\)-consistent estimator of \(\psi\),
that it is asymptotically normal (as given above), and that it is locally
efficient. This allows us to build Wald-type confidence intervals in a
straightforward manner:

\[\psi_n \pm z_{\alpha} \cdot \frac{\sigma_n}{\sqrt{n}},\]
where \(\sigma_n^2\) is an estimator of \(V(D(P_0))\). The estimator \(\sigma_n^2\)
may be obtained using the bootstrap or computed directly via the following

\[\sigma_n^2 = \frac{1}{n} \sum_{i = 1}^{n} D^2(\bar{Q}_n^{\star}, g_n)(O_i)\]

Having now re-examined these facts, let's simply examine the results of
computing our TML estimator:

\hypertarget{extensions-variable-importance-analysis-with-stochastic-interventions}{%
\section{Extensions: Variable Importance Analysis with Stochastic Interventions}\label{extensions-variable-importance-analysis-with-stochastic-interventions}}

\hypertarget{defining-a-grid-of-counterfactual-interventions}{%
\subsection{Defining a grid of counterfactual interventions}\label{defining-a-grid-of-counterfactual-interventions}}

In order to specify a \emph{grid} of shifts \(\delta\) to be used in defining a set of
stochastic intervention policies in an \emph{a priori} manner, let us consider an
arbitrary scalar \(\delta\) that defines a counterfactual outcome \(\psi_n = Q_n(d(A, W), W)\), where, for simplicity, let \(d(A, W) = A + \delta\). A
simplified expression of the auxiliary covariate for the TMLE of \(\psi\) is
\(H_n = \frac{g^{\star}(a \mid w)}{g(a \mid w)}\), where \(g^{\star}(a \mid w)\)
defines the treatment mechanism with the stochastic intervention implemented.
Then, to ascertain whether a given choice of the shift \(\delta\) is admissable
(in the sense of avoiding violations of the positivity assumption), let there
be a bound \(C(\delta) = \frac{g^{\star}(a \mid w)}{g(a \mid w)} < M\), where
\(g^{\star}(a \mid w)\) is a function of \(\delta\) in part, and \(M\) is a potentially
user-specified upper bound of \(C(\delta)\). Then, \(C(\delta)\) is a measure of
the influence of a given observation, thereby providing a way to limit the
maximum influence of a given observation (by way of the bound \(M\) placed on
\(C(\delta)\)) through a choice of the shift \(\delta\).

We formalize and extend the procedure to determine an acceptable set of values
for the shift \(\delta\) in the sequel. Specifically, let there be a shift \(d(A, W) = A + \delta(A, W)\), where the shift \(\delta(A, W)\) is defined as
\begin{equation}
  \delta(a, w) =
    \begin{cases}
      \delta, & \delta_{\text{min}}(a,w) \leq \delta \leq
        \delta_{\text{max}}(a,w) \\
      \delta_{\text{max}}(a,w), & \delta \geq \delta_{\text{max}}(a,w) \\
      \delta_{\text{min}}(a,w), & \delta \leq \delta_{\text{min}}(a,w) \\
    \end{cases},
\end{equation}
where \[\delta_{\text{max}}(a, w) = \text{argmax}_{\left\{\delta \geq 0,
\frac{g(a - \delta \mid w)}{g(a \mid w)} \leq M \right\}} \frac{g(a - \delta
\mid w)}{g(a \mid w)}\] and
\[\delta_{\text{min}}(a, w) = \text{argmin}_{\left\{\delta \leq 0,
\frac{g(a - \delta \mid w)}{g(a \mid w)} \leq M \right\}} \frac{g(a - \delta
\mid w)}{g(a \mid w)}.\]

The above provides a strategy for implementing a shift at the level of a given
observation \((a_i, w_i)\), thereby allowing for all observations to be shifted
to an appropriate value -- whether \(\delta_{\text{min}}\), \(\delta\), or
\(\delta_{\text{max}}\).

For the purpose of using such a shift in practice, the present software
provides the functions \passthrough{\lstinline!shift\_additive\_bounded!} and
\passthrough{\lstinline!shift\_additive\_bounded\_inv!}, which define a variation of this shift:
\begin{equation}
  \delta(a, w) =
    \begin{cases}
      \delta, & C(\delta) \leq M \\
      0, \text{otherwise} \\
    \end{cases},
  \label{eq:shift-simple}
\end{equation}
which corresponds to an intervention in which the natural value of treatment
of a given observational unit is shifted by a value \(\delta\) in the case that
the ratio of the intervened density \(g^{\star}(a \mid w)\) to the natural
density \(g(a \mid w)\) (that is, \(C(\delta)\)) does not exceed a bound \(M\). In
the case that the ratio \(C(\delta)\) exceeds the bound \(M\), the stochastic
intervention policy does not apply to the given unit and they remain at their
natural value of treatment \(a\).

\hypertarget{initializing-vimshift-through-its-tmle3_spec}{%
\subsection{\texorpdfstring{Initializing \texttt{vimshift} through its \texttt{tmle3\_Spec}}{Initializing vimshift through its tmle3\_Spec}}\label{initializing-vimshift-through-its-tmle3_spec}}

To start, we will initialize a specification for the TMLE of our parameter of
interest (called a \passthrough{\lstinline!tmle3\_Spec!} in the \passthrough{\lstinline!tlverse!} nomenclature) simply by calling
\passthrough{\lstinline!tmle\_shift!}. We specify the argument \passthrough{\lstinline!shift\_grid = seq(-1, 1, by = 1)!}
when initializing the \passthrough{\lstinline!tmle3\_Spec!} object to communicate that we're interested
in assessing the mean counterfactual outcome over a grid of shifts -1, 0, 1 on the scale of the treatment \(A\) (note that the numerical
choice of shift is an arbitrarily chosen set of values for this example).

\begin{lstlisting}[language=R]
# what's the grid of shifts we wish to consider?
delta_grid <- seq(-1, 1, 1)

# initialize a tmle specification
tmle_spec <- tmle_vimshift_delta(
  shift_grid = delta_grid,
  max_shifted_ratio = 2
)
\end{lstlisting}

As seen above, the \passthrough{\lstinline!tmle\_vimshift!} specification object (like all \passthrough{\lstinline!tmle3\_Spec!}
objects) does \emph{not} store the data for our specific analysis of interest. Later,
we'll see that passing a data object directly to the \passthrough{\lstinline!tmle3!} wrapper function,
alongside the instantiated \passthrough{\lstinline!tmle\_spec!}, will serve to construct a \passthrough{\lstinline!tmle3\_Task!}
object internally (see the \passthrough{\lstinline!tmle3!} documentation for details).

\hypertarget{targeted-estimation-of-stochastic-interventions-effects-1}{%
\subsection{Targeted Estimation of Stochastic Interventions Effects}\label{targeted-estimation-of-stochastic-interventions-effects-1}}

One may walk through the step-by-step procedure for fitting the TML estimator
of the mean counterfactual outcome under each shift in the grid, using the
machinery exposed by the \href{https://tmle3.tlverse.org/}{\passthrough{\lstinline!tmle3!} R package}.

One may invoke the \passthrough{\lstinline!tmle3!} wrapper function (a user-facing convenience utility)
to fit the series of TML estimators (one for each parameter defined by the grid
delta) in a single function call:

\begin{lstlisting}[language=R]
tmle_fit <- tmle3(tmle_spec, data, node_list, learner_list)
tmle_fit
\end{lstlisting}

\emph{Remark}: The \passthrough{\lstinline!print!} method of the resultant \passthrough{\lstinline!tmle\_fit!} object conveniently
displays the results from computing our TML estimator.

\hypertarget{inference-with-marginal-structural-models}{%
\subsection{Inference with Marginal Structural Models}\label{inference-with-marginal-structural-models}}

Since we consider estimating the mean counterfactual outcome \(\psi_n\) under
several values of the intervention \(\delta\), taken from the aforementioned
\(\delta\)-grid, one approach for obtaining inference on a single summary measure
of these estimated quantities involves leveraging working marginal structural
models (MSMs). Summarizing the estimates \(\psi_n\) through a working MSM allows
for inference on the \emph{trend} imposed by a \(\delta\)-grid to be evaluated via a
simple hypothesis test on a parameter of this working MSM. Letting
\(\psi_{\delta}(P_0)\) be the mean outcome under a shift \(\delta\) of the
treatment, we have \(\vec{\psi}_{\delta} = (\psi_{\delta}: \delta)\) with
corresponding estimators \(\vec{\psi}_{n, \delta} = (\psi_{n, \delta}: \delta)\).
Further, let \(\beta(\vec{\psi}_{\delta}) = \phi((\psi_{\delta}: \delta))\).

For a given MSM \(m_{\beta}(\delta)\), we have that
\[\beta_0 = \text{argmin}_{\beta} \sum_{\delta}(\psi_{\delta}(P_0) -
m_{\beta}(\delta))^2 h(\delta),\]
which is the solution to
\[u(\beta, (\psi_{\delta}: \delta)) = \sum_{\delta}h(\delta)
\left(\psi_{\delta}(P_0) - m_{\beta}(\delta) \right) \frac{d}{d\beta}
m_{\beta}(\delta) = 0.\]
This then leads to the following expansion
\[\beta(\vec{\psi}_n) - \beta(\vec{\psi}_0) \approx -\frac{d}{d\beta}
  u(\beta_0, \vec{\psi}_0)^{-1} \frac{d}{d\psi} u(\beta_0, \psi_0)
  (\vec{\psi}_n - \vec{\psi}_0),\]
where we have
\[\frac{d}{d\beta} u(\beta, \psi) = -\sum_{\delta} h(\delta) \frac{d}{d\beta}
m_{\beta}(\delta)^t \frac{d}{d\beta} m_{\beta}(\delta)
-\sum_{\delta} h(\delta) m_{\beta}(\delta) \frac{d^2}{d\beta^2}
m_{\beta}(\delta),\]
which, in the case of an MSM that is a linear model (since
\(\frac{d^2}{d\beta^2} m_{\beta}(\delta) = 0\)), reduces simply to
\[\frac{d}{d\beta} u(\beta, \psi) = -\sum_{\delta} h(\delta) \frac{d}{d\beta}
m_{\beta}(\delta)^t \frac{d}{d\beta} m_{\beta}(\delta),\]
and
\[\frac{d}{d\psi}u(\beta, \psi)(\psi_n - \psi_0) = \sum_{\delta} h(\delta)
\frac{d}{d\beta} m_{\beta}(\delta) (\psi_n - \psi_0)(\delta),\]
which we may write in terms of the efficient influence function (EIF) of \(\psi\)
by using the first order approximation \((\psi_n - \psi_0)(\delta) = \frac{1}{n}\sum_{i = 1}^n \text{EIF}_{\psi_{\delta}}(O_i)\),
where \(\text{EIF}_{\psi_{\delta}}\) is the efficient influence function (EIF) of
\(\vec{\psi}\).

Now, say, \(\vec{\psi} = (\psi(\delta): \delta)\) is d-dimensional, then we may
write the efficient influence function of the MSM parameter \(\beta\) as follows
\[\text{EIF}_{\beta}(O) = \left(\sum_{\delta} h(\delta) \frac{d}{d\beta}
m_{\beta}(\delta) \frac{d}{d\beta} m_{\beta}(\delta)^t \right)^{-1} \cdot
\sum_{\delta} h(\delta) \frac{d}{d\beta} m_{\beta}(\delta)
\text{EIF}_{\psi_{\delta}}(O),\] where the first term is of dimension
\(d \times d\) and the second term is of dimension \(d \times 1\). In the above, we
assume a linear working MSM; however, an analogous procedure may be applied for
working MSMs based on GLMs.

Inference for a parameter of an MSM may be obtained by straightforward
application of the delta method (discussed previously) -- that is, we may
write the efficient influence function of the MSM parameter \(\beta\) in terms of
the EIFs of each of the corresponding point estimates. Based on this, inference
from a working MSM is rather straightforward. To wit, the limiting distribution
for \(m_{\beta}(\delta)\) may be expressed \[\sqrt{n}(\beta_n - \beta_0) \to N(0,
\Sigma),\] where \(\Sigma\) is the empirical covariance matrix of
\(\text{EIF}_{\beta}(O)\).

\hypertarget{directly-targeting-the-msm-parameter-beta}{%
\subsubsection{\texorpdfstring{Directly Targeting the MSM Parameter \(\beta\)}{Directly Targeting the MSM Parameter \textbackslash{}beta}}\label{directly-targeting-the-msm-parameter-beta}}

Note that in the above, a working MSM is fit to the individual TML estimates of
the mean counterfactual outcome under a given value of the shift \(\delta\) in the
supplied grid. The parameter of interest \(\beta\) of the MSM is asymptotically
linear (and, in fact, a TML estimator) as a consequence of its construction from
individual TML estimators. In smaller samples, it may be prudent to perform a
TML estimation procedure that targets the parameter \(\beta\) directly, as opposed
to constructing it from several independently targeted TML estimates. An
approach for constructing such an estimator is proposed in the sequel.

Suppose a simple working MSM \(\mathbb{E}Y_{g^0_{\delta}} = \beta_0 + \beta_1 \delta\), then a TML estimator targeting \(\beta_0\) and \(\beta_1\) may be
constructed as
\[\overline{Q}_{n, \epsilon}(A,W) = \overline{Q}_n(A,W) + \epsilon (H_1(g),
H_2(g),\] for all \(\delta\), where \(H_1(g)\) is the auxiliary covariate for
\(\beta_0\) and \(H_2(g)\) is the auxiliary covariate for \(\beta_1\).

To construct a targeted maximum likelihood estimator that directly targets the
parameters of the working marginal structural model, we may use the
\passthrough{\lstinline!tmle\_vimshift\_msm!} Spec (instead of the \passthrough{\lstinline!tmle\_vimshift\_delta!} Spec that
appears above):

\begin{lstlisting}[language=R]
# initialize a tmle specification
tmle_msm_spec <- tmle_vimshift_msm(
  shift_grid = delta_grid,
  max_shifted_ratio = 2
)

# fit the TML estimator and examine the results
tmle_msm_fit <- tmle3(tmle_msm_spec, data, node_list, learner_list)
tmle_msm_fit
\end{lstlisting}

\hypertarget{example-with-the-wash-benefits-data}{%
\subsection{Example with the WASH Benefits Data}\label{example-with-the-wash-benefits-data}}

To complete our walk through, let's turn to using stochastic interventions to
investigate the data from the WASH Benefits trial. To start, let's load the
data, convert all columns to be of class \passthrough{\lstinline!numeric!}, and take a quick look at it

\begin{lstlisting}[language=R]
washb_data <- fread(
  paste0(
    "https://raw.githubusercontent.com/tlverse/tlverse-data/master/",
    "wash-benefits/washb_data.csv"
  ),
  stringsAsFactors = TRUE
)
washb_data <- washb_data[!is.na(momage), lapply(.SD, as.numeric)]
head(washb_data, 3)
     whz tr fracode month aged sex momage momedu momheight hfiacat Nlt18 Ncomp
1:  0.00  1       4     9  268   2     30      2    146.40       1     3    11
2: -1.16  1       4     9  286   2     25      2    148.75       3     2     4
3: -1.05  1      20     9  264   2     25      2    152.15       1     1    10
   watmin elec floor walls roof asset_wardrobe asset_table asset_chair
1:      0    1     0     1    1              0           1           1
2:      0    1     0     1    1              0           1           0
3:      0    0     0     1    1              0           0           1
   asset_khat asset_chouki asset_tv asset_refrig asset_bike asset_moto
1:          1            0        1            0          0          0
2:          1            1        0            0          0          0
3:          0            1        0            0          0          0
   asset_sewmach asset_mobile
1:             0            1
2:             0            1
3:             0            1
\end{lstlisting}

Next, we specify our NPSEM via the \passthrough{\lstinline!node\_list!} object. For our example analysis,
we'll consider the outcome to be the weight-for-height Z-score (as in previous
chapters), the intervention of interest to be the mother's age at time of
child's birth, and take all other covariates to be potential confounders.

\begin{lstlisting}[language=R]
node_list <- list(
  W = names(washb_data)[!(names(washb_data) %in%
    c("whz", "momage"))],
  A = "momage",
  Y = "whz"
)
\end{lstlisting}

Were we to consider the counterfactual weight-for-height Z-score under shifts in
the age of the mother at child's birth, how would we interpret estimates of our
parameter? To simplify our interpretation, consider a shift of just a year in
the mother's age (i.e., \(\delta = 1\)); in this setting, a stochastic
intervention would correspond to a policy advocating that potential mothers
defer having a child for a single calendar year, possibly implemented through an
encouragement design deployed in a clinical setting.

For this example, we'll use the variable importance strategy of considering a
grid of stochastic interventions to evaluate the weight-for-height Z-score under
a shift in the mother's age down by two years (\(\delta = -2\)) or up by two years
(\(\delta = 2\)). To do this, we simply initialize a \passthrough{\lstinline!Spec!} \passthrough{\lstinline!tmle\_vimshift\_delta!}
just as we did in a previous example:

\begin{lstlisting}[language=R]
# initialize a tmle specification for the variable importance parameter
washb_vim_spec <- tmle_vimshift_delta(
  shift_grid = c(-2, 2),
  max_shifted_ratio = 2
)
\end{lstlisting}

Prior to running our analysis, we'll modify the \passthrough{\lstinline!learner\_list!} object we had
created such that the density estimation procedure we rely on will be only the
location-scale conditional density estimation procedure, as the nonparametric
conditional density approach based on the highly adaptive lasso \citep{diaz2011super, benkeser2016hal, coyle2020hal9001, hejazi2020hal9001, hejazi2020haldensify}
is currently unable to accommodate larger datasets.

\begin{lstlisting}[language=R]
# we need to turn on cross-validation for the HOSE learner
cv_hose_hal_lrnr <- Lrnr_cv$new(
  learner = hose_hal_lrnr,
  full_fit = TRUE
)

# modify learner list, using existing SL for Q fit
learner_list <- list(Y = sl_reg_lrnr, A = cv_hose_hal_lrnr)
\end{lstlisting}

Having made the above preparations, we're now ready to estimate the
counterfactual mean of the weight-for-height Z-score under a small grid of
shifts in the mother's age at child's birth. Just as before, we do this through
a simple call to our \passthrough{\lstinline!tmle3!} wrapper function:

\begin{lstlisting}[language=R]
washb_tmle_fit <- tmle3(washb_vim_spec, washb_data, node_list, learner_list)
washb_tmle_fit
\end{lstlisting}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{exercises-3}{%
\section{Exercises}\label{exercises-3}}

\hypertarget{the-ideas-in-action-1}{%
\subsection{The Ideas in Action}\label{the-ideas-in-action-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Set the \passthrough{\lstinline!sl3!} library of algorithms for the Super Learner to a simple,
  interpretable library and use this new library to estimate the
  counterfactual mean of mother's age at child's birth (\passthrough{\lstinline!momage!}) under a
  shift \(\delta = 0\). What does this counterfactual mean equate to in terms
  of the observed data?
\item
  Using a grid of values of the shift parameter \(\delta\) (e.g., \(\{-1, 0, +1\}\)), repeat the analysis on the variable chosen in the preceding
  question, summarizing the trend for this sequence of shifts using a marginal
  structural model.
\item
  Repeat the preceding analysis, using the same grid of shifts, but instead
  directly targeting the parameters of the marginal structural model.
  Interpret the results -- that is, what does the slope of the marginal
  structural model tell us about the trend across the chosen sequence of
  shifts?
\end{enumerate}

\hypertarget{review-of-key-concepts-2}{%
\subsection{Review of Key Concepts}\label{review-of-key-concepts-2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Describe two (equivalent) ways in which the causal effects of stochastic
  interventions may be interpreted.
\item
  How does the marginal structural model we used to summarize the trend along
  the sequence of shifts previously help to contextualize the estimated effect
  for a single shift? That is, how does access to estimates across several
  shifts and the marginal structural model parameters allow us to more richly
  interpret our findings?
\item
  What advantages, if any, are there to targeting directly the parameters of a
  marginal structural model?
\end{enumerate}

\hypertarget{causal-mediation-analysis}{%
\chapter{Causal Mediation Analysis}\label{causal-mediation-analysis}}

\emph{Nima Hejazi}

Based on the \href{https://github.com/tlverse/tmle3mediate}{\passthrough{\lstinline!tmle3mediate!} \passthrough{\lstinline!R!}
package} by \emph{Nima Hejazi, James
Duncan, and David McCoy}.

Updated: 2021-09-21

\textbackslash{}begin\{VT1\}
\VH{Learning Objectives}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Appreciate how the presence of a mediating variable in a causal pathway can
  allow direct and indirect effects of the treatment on the outcome to be
  defined.
\item
  Describe the major differences between direct and indirect causal effects.
\item
  Differentiate the joint interventions required to define direct and indirect
  effects from the static, dynamic, and stochastic interventions that yield
  the \emph{total} causal effects previously described.
\item
  Describe the assumptions needed for identification of the natural direct and
  indirect effects, as well as the limitations of these effect definitions.
\item
  Estimate the natural direct and indirect effects of a binary treatment using
  the \passthrough{\lstinline!tmle3mediate!} \passthrough{\lstinline!R!} package.
\item
  Differentiate the population intervention direct and indirect effects of
  stochastic interventions from the natural direct and indirect effects,
  including differences in the assumptions required for their identification.
\item
  Estimate the population intervention direct effect of a binary treatment
  using the \passthrough{\lstinline!tmle3mediate!} \passthrough{\lstinline!R!} package.
\end{enumerate}

\textbackslash{}end\{VT1\}

\hypertarget{introduction-to-causal-mediation-analysis}{%
\section{Introduction to Causal Mediation Analysis}\label{introduction-to-causal-mediation-analysis}}

A treatment often affects an outcome indirectly, through a particular pathway,
by its effect on \emph{intermediate variables} (mediators). Causal mediation analysis
concerns the construction and evaluation of these \emph{indirect effects} and their
complementary \emph{direct effects}. Generally, the indirect effect (IE) of a
treatment on an outcome is the portion of the total effect that is found to work
\emph{through} mediator variables, while the direct effect often encompasses all
other components of the total effect, including both the effect of the treatment
on the outcome \emph{and} the effect through all paths not explicitly involving the
mediators). Identifying and quantifying the mechanisms underlying causal effects
is an increasingly desirable endeavor in public health, medicine, and the social
sciences, as such mechanistic knowledge improves understanding of both \emph{why} and
\emph{how} treatments may be effective.

While the study of mediation analysis may be traced back quite far, the field
only came into its modern form with the identification and careful study of the
natural direct and indirect effects \citep{robins1992identifiability, pearl2001direct}. The natural direct effect (NDE) and the natural indirect
effect (NIE) are based on a decomposition of the average treatment effect (ATE)
in the presence of mediators \citep{vanderweele2015explanation}; requisite
theory for the construction of efficient estimators of these quantities only
receiving attention relatively recently \citep{tchetgen2012semiparametric}.

\hypertarget{data-structure-and-notation-2}{%
\section{Data Structure and Notation}\label{data-structure-and-notation-2}}

Consider \(n\) observed units \(O_1, \ldots, O_n\), where each observed data random
variable takes the form \(O = (W, A, Z, Y)\), for a vector of observed covariates
\(W\), a binary or continuous treatment \(A\), possibly multivariate mediators \(Z\),
and a binary or continuous outcome \(Y\). To avoid undue assumptions, we assume
only that \(O \sim \mathcal{P} \in \M\) where \(\M\) is the nonparametric
statistical model defined as all continuous densities on \(O\) with respect to an
arbitrary dominating measure.

We formalize the definition of our counterfactual variables using the following
non-parametric structural equation model (NPSEM):
\begin{align}
  W &= f_W(U_W) \\
  A &= f_A(W, U_A) \\
  Z &= f_Z(W, A, U_Z) \\
  Y &= f_Y(W, A, Z, U_Y).
  \label{eq:npsem-mediate}
\end{align}
This set of equations
represents a mechanistic model generating the observed data \(O\); furthermore,
the NPSEM encodes several fundamental assumptions. Firstly, there is an implicit
temporal ordering: \(W\) occurs first, depending only on exogenous factors \(U_W\);
\(A\) happens next, based on both \(W\) and exogenous factors \(U_A\); then come the
mediators \(Z\), which depend on \(A\), \(W\), and another set of exogenous factors
\(U_Z\); and finally appears the outcome \(Y\). We assume neither access to the set
of exogenous factors \(\{U_W, U_A, U_Z, U_Y\}\) nor knowledge of the forms of the
deterministic generating functions \(\{f_W, f_A, f_Z, f_Y\}\). The NPSEM
corresponds to the following DAG:

\begin{lstlisting}[language=R]
library(dagitty)
library(ggdag)

# make DAG by specifying dependence structure
dag <- dagitty(
  "dag {
    W -> A
    W -> Z
    W -> Y
    A -> Z
    A -> Y
    Z -> Y
    W -> A -> Y
    W -> A -> Z -> Y
  }"
)
exposures(dag) <- c("A")
outcomes(dag) <- c("Y")
tidy_dag <- tidy_dagitty(dag)

# visualize DAG
ggdag(tidy_dag) +
  theme_dag()
\end{lstlisting}

\begin{center}\includegraphics[width=0.8\linewidth]{10-tmle3mediate_files/figure-latex/mediation-DAG-1} \end{center}

The likelihood of the data \(O\) admits a factorization, wherein, for \(p_0^O\),
the density of \(O\) with respect to the product measure, the density evaluated
on a particular observation \(o\) may be a written
\begin{align}
  p_0^O(x) = &q^O_{0,Y}(y \mid Z = z, A = a, W = w) \cdot \\
    &q^O_{0,Z}(z \mid A = a, W = w) \cdot \\
    &q^O_{0,A}(a \mid W = w) \cdot \\
    &q^O_{0,W}(w),\\
  \label{eq:likelihood-factorization-mediate}
\end{align}
where \(q_{0, Y}\) is the conditional density of \(Y\) given \((Z, A, W)\), \(q_{0, Z}\)
is the conditional density of \(Z\) given \((A, W)\), \(q_{0, A}\) is the conditional
density of \(A\) given \(W\), and \(q_{0, W}\) is the density of \(W\). For ease of
notation, we let \(\bar{Q}_Y(Z, A, W) = \E[Y \mid Z, A, W]\), \(Q_Z(A, W) = P[Z \mid A, W]\), \(g(A \mid W) = \P(A \mid W)\), and \(q_W\) the marginal
distribution of \(W\).

Finally, note that we have explicitly excluded potential confounders of the
mediator-outcome relationship affected by exposure (i.e., variables affected by
\(A\) and affecting both \(Z\) and \(Y\)). Mediation analysis in the presence of such
variables is exceptionally challenging \citep{avin2005identifiability}; thus, most
efforts to develop definitions of causal direct and indirect effects explicitly
disallowed such a form of confounding. While we will not discuss the matter
here, the interested reader may consult recent advances in the vast literature
on causal mediation analysis, among them \citet{diaz2020nonparametric} and
\citet{hejazi2021nonparametric}.

\hypertarget{decomposing-the-average-treatment-effect}{%
\section{Decomposing the Average Treatment Effect}\label{decomposing-the-average-treatment-effect}}

The natural direct and indirect effects arise from a decomposition of the ATE:
\begin{equation*}
  \E[Y(1) - Y(0)] =
    \underbrace{\E[Y(1, Z(0)) - Y(0, Z(0))]}_{NDE} +
    \underbrace{\E[Y(1, Z(1)) - Y(1, Z(0))]}_{NIE}.
\end{equation*}
In particular, the natural indirect effect (NIE) measures the effect of the
treatment \(A \in \{0, 1\}\) on the outcome \(Y\) through the mediators \(Z\), while
the natural direct effect (NDE) measures the effect of the treatment on the
outcome \emph{through all other paths}. Identification of the natural direct and
indirect effects requires the following non-testable causal assumptions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{Exchangeability} (randomization): \(Y(a, z) \indep (A, Z) \mid W\), further
  implying \(\E\{Y(a, z) \mid A=a, W=w, Z=z\} = \E\{Y(a, z) \mid W=w\}\). This
  is a special case of the randomization assumption, extended to observational
  studies with mediators.
\item
  \emph{Treatment positivity}: For any \(a \in \mathcal{A}\) and \(w \in \mathcal{W}\), \(\xi < g(a \mid w) < 1 - \xi\), \(\xi > 0\). This mirrors the
  assumption required for static intervention, discussed previously.
\item
  \emph{Mediator positivity}: For any \(z \in \mathcal{Z}\), \(a \in \mathcal{A}\), and
  \(w \in \mathcal{W}\), \(\epsilon < Q(z \mid a, w)\), for \(\epsilon > 0\). This
  only requires that the conditional density of the mediators be bounded away
  from zero for all \((z, a, w)\) in their joint support \(\mathcal{Z} \times \mathcal{A} \times \mathcal{W}\).
\item
  \emph{Cross-world counterfactual independence}: For all \(a \neq a'\), both
  contained in \(\mathcal{A}\) and \(z \in \mathcal{Z}\), \(Y(a', z)\) is independent
  of \(Z(a)\), given \(W\). That is, the counterfactual outcome under the treatment
  contrast \(a' \in \mathcal{A}\) and the counterfactual mediator \(Z(a) \in \mathcal{Z}\) (under a different contrast \(a \in \mathcal{A}\)) are
  independent. Note that the counterfactual outcome and mediator are defined
  under differing contrasts, hence the ``cross-world'' designation.
\end{enumerate}

We note that many attempts have been made to weaken the last assumption, that of
cross-world counterfactual independence, including work by
\citet{petersen2006estimation} and \citet{imai2010identification}; however, importantly,
\citet{robins2010alternative} established that this assumption cannot be satisfied in
randomized experiments. Thus, the natural direct and indirect effects are not
identifiable in randomized experiments, calling into question their utility.
Despite this significant limitation, we will turn to considering estimation of
the statistical functionals corresponding to these effects in observational
studies.

\hypertarget{the-natural-direct-effect}{%
\section{The Natural Direct Effect}\label{the-natural-direct-effect}}

The NDE is defined as
\begin{align*}
  \Psi_{NDE} &= \E[Y(1, Z(0)) - Y(0, Z(0))] \\
  &\overset{\text{rand.}}{=} \sum_w \sum_z
  [\underbrace{\E(Y \mid A = 1, z, w)}_{\bar{Q}_Y(A = 1, z, w)} -
  \underbrace{\E(Y \mid A = 0, z, w)}_{\bar{Q}_Y(A = 0, z, w)}] \times
  \underbrace{p(z \mid A = 0, w)}_{Q_Z(0, w))} \underbrace{p(w)}_{q_W},
\end{align*}
where the likelihood factors \(p(z \mid A = 0, w)\) and \(p(w)\) (among other
conditional densities) arise from a factorization of the joint likelihood:
\begin{equation*}
  p(w, a, z, y) = \underbrace{p(y \mid w, a, z)}_{Q_Y(A, W, Z)}
  \underbrace{p(z \mid w, a)}_{Q_Z(Z \mid A, W)}
  \underbrace{p(a \mid w)}_{g(A \mid W)}
  \underbrace{p(w)}_{Q_W}.
\end{equation*}

The process of estimating the NDE begins by constructing \(\bar{Q}_{Y, n}\), an
estimate of the outcome mechanism \(\bar{Q}_Y(Z, A, W) = \E \{Y \mid Z, A, W\}\) (i.e., the conditional mean of \(Y\), given \(Z\), \(A\), and \(W\)). With an
estimate of this conditional expectation in hand, predictions of the
counterfactual quantities \(\bar{Q}_Y(Z, 1, W)\) (setting \(A = 1\)) and, likewise,
\(\bar{Q}_Y(Z, 0, W)\) (setting \(A = 0\)) can readily be obtained. We denote the
difference of these counterfactual quantities \(\bar{Q}_{\text{diff}}\), i.e.,
\(\bar{Q}_{\text{diff}} = \bar{Q}_Y(Z, 1, W) - \bar{Q}_Y(Z, 0, W)\).
\(\bar{Q}_{\text{diff}}\) represents the difference in the conditional mean of
\(Y\) attributable to changes in \(A\) while keeping \(Z\) and \(W\) at their \emph{natural}
(that is, observed) values.

The estimation procedure treats \(\bar{Q}_{\text{diff}}\) itself as a nuisance
parameter, regressing its estimate \(\bar{Q}_{\text{diff}, n}\) on \(W\), among
control observations only (i.e., those for whom \(A = 0\) is observed); the goal
of this step is to remove part of the marginal impact of \(Z\) on
\(\bar{Q}_{\text{diff}}\), since \(W\) is a parent of \(Z\). Regressing this
difference on \(W\) among the controls recovers the expected
\(\bar{Q}_{\text{diff}}\), had all individuals been set to the control condition
\(A = 0\). Any residual additive effect of \(Z\) on \(\bar{Q}_{\text{diff}}\) is
removed during the TML estimation step using the auxiliary (or ``clever'')
covariate, which accounts for the mediators \(Z\). This auxiliary covariate takes
the form
\begin{equation*}
  C_Y(Q_Z, g)(O) = \Bigg\{\frac{\mathbb{I}(A = 1)}{g(1 \mid W)}
  \frac{Q_Z(Z \mid 0, W)}{Q_Z(Z \mid 1, W)} -
  \frac{\mathbb{I}(A = 0)}{g(0 \mid W)} \Bigg\}.
\end{equation*}
Breaking this down, \(\frac{\mathbb{I}(A = 1)}{g(1 \mid W)}\) is the inverse
propensity score weight for \(A = 1\) and, likewise, \(\frac{\mathbb{I}(A = 0)} {g(0 \mid W)}\) is the inverse propensity score weight for \(A = 0\). The middle
term is the ratio of the conditional densities of the mediator under the control
(\(A = 0\)) and treatment (\(A = 1\)) conditions.

This subtle appearance of a ratio of conditional densities is concerning --
tools to estimate such quantities are sparse in the statistics literature,
unfortunately, and the problem is still more complicated (and computationally
taxing) when \(Z\) is high-dimensional. As only the ratio of these conditional
densities is required, a convenient re-parametrization may be achieved, that is,
\begin{equation*}
  \frac{p(A = 0 \mid Z, W) g(0 \mid W)}{p(A = 1 \mid Z, W) g(1 \mid W)}.
\end{equation*}
Going forward, we will denote this re-parameterized conditional probability
\(e(A \mid Z, W) := p(A \mid Z, W)\). Similar re-parameterizations have been used
in \citet{zheng2012targeted} and \citet{tchetgen2013inverse}. This is particularly useful
since this reformulation reduces the problem to one concerning only the
estimation of conditional means, opening the door to the use of a wide range of
machine learning algorithms (e.g., most of those in
\href{https://github.com/tlverse/sl3}{\passthrough{\lstinline!sl3!}}).

Underneath the hood, the counterfactual outcome difference
\(\bar{Q}_{\text{diff}}\) and \(e(A \mid Z, W)\), the conditional probability of \(A\)
given \(Z\) and \(W\), are used in constructing the auxiliary covariate for TML
estimation. These nuisance parameters play an important role in the
bias-correcting update step of the TMLE procedure.

\hypertarget{the-natural-indirect-effect}{%
\section{The Natural Indirect Effect}\label{the-natural-indirect-effect}}

Derivation and estimation of the NIE is analogous to that of the NDE. The NIE
is the effect of \(A\) on \(Y\) \emph{only through the mediator(s) \(Z\)}. This quantity
-- known as the natural indirect effect \(\E(Y(Z(1), 1) - \E(Y(Z(0), 1)\) --
corresponds to the difference of the conditional expectation of \(Y\) given \(A = 1\) and \(Z(1)\) (the values the mediator would take under \(A = 1\)) and the
conditional expectation of \(Y\) given \(A = 1\) and \(Z(0)\) (the values the mediator
would take under \(A = 0\)).

As with the NDE, the re-parameterization trick can be used to estimate \(\E(A \mid Z, W)\), avoiding estimation of a possibly multivariate conditional density.
However, in this case, the mediated mean outcome difference, denoted
\(\Psi_Z(Q)\), is instead estimated as follows
\begin{equation*}
  \Psi_{NIE}(Q) = \E (\Psi_{NIE, Z}(Q)(1, W) - \Psi_{NIE, Z}(Q)(0, W))
\end{equation*}

Here, \(\bar{Q}_Y(Z, 1, W)\) (the predicted values for \(Y\) given \(Z\) and \(W\) when
\(A = 1\)) is regressed on \(W\), among the treated units (for whom \(A = 1\) is
observed) to obtain the conditional mean \(\Psi_{NIE, Z}(Q)(1, W)\). Performing
the same procedure, but now regressing \(\bar{Q}_Y(Z, 1, W)\) on \(W\) among the
control units (for whom \(A = 0\) is observed) yields \(\Psi_{NIE,Z}(Q)(0, W)\). The
difference of these two estimates is the NIE and can be thought of as the
additive marginal effect of treatment on the conditional expectation of \(Y\)
given \(W\), \(A = 1\), \(Z\) through its effects on \(Z\). So, in the case of the NIE,
our estimate \(\psi_n\) is slightly different, but the same quantity \(e(A \mid Z, W)\) comes into play as the auxiliary covariate.

\hypertarget{the-population-intervention-indirect-effects}{%
\section{The Population Intervention (In)Direct Effects}\label{the-population-intervention-indirect-effects}}

At times, the natural direct and indirect effects may prove too limiting, as
these effect definitions are based on \emph{static interventions} (i.e., setting
\(A = 0\) or \(A = 1\)), which may be unrealistic for real-world interventions. In
such cases, one may turn instead to the population intervention direct effect
(PIDE) and the population intervention indirect effect (PIIE), which are based
on decomposing the effect of the population intervention effect (PIE) of
flexible stochastic interventions \citep{diaz2020causal}.

A particular type of stochastic intervention well-suited to working with binary
treatments is the \emph{incremental propensity score intervention} (IPSI), first
proposed by \citet{kennedy2017nonparametric}. Such interventions do not
deterministically set the treatment level of an observed unit to a fixed
quantity (i.e., setting \(A = 1\)), but instead \emph{alter the odds of receiving the
treatment} by a fixed amount (\(0 \leq \delta \leq \infty\)) for each individual.
In particular, this intervention takes the form
\begin{equation*}
  g_{\delta}(1 \mid w) = \frac{\delta g(1 \mid w)}{\delta g(1 \mid w) + 1
  - g(1\mid w)},
\end{equation*}
where the scalar \(0 < \delta < \infty\) specifies a \emph{change in the odds of
receiving treatment}. As described by \citet{diaz2020causal}, this stochastic
intervention is a special case of exponential tilting, a framework that unifies
post-intervention treatment values that are draws from an altered distribution.

Unlike the natural direct and indirect effects, the conditions required for
identifiability of the population intervention direct and indirect effects are
more lax. Most importantly, these differences involve a (1) treatment positivity
assumption that only requires that the counterfactual treatment be in the
observed support of the treatment \(\mathcal{A}\), and (2) no requirement of the
independence any cross-world counterfactuals.

\hypertarget{decomposing-the-population-intervention-effect}{%
\section{Decomposing the Population Intervention Effect}\label{decomposing-the-population-intervention-effect}}

We may decompose the population intervention effect (PIE) in terms of the
\emph{population intervention direct effect} (PIDE) and the \emph{population
intervention indirect effect} (PIIE):
\begin{equation*}
  \mathbb{E}\{Y(A_\delta)\} - \mathbb{E}Y =
    \overbrace{\mathbb{E}\{Y(A_\delta, Z(A_\delta))
      - Y(A_\delta, Z)\}}^{\text{PIIE}} +
    \overbrace{\mathbb{E}\{Y(A_\delta, Z) - Y(A, Z)\}}^{\text{PIDE}}.
\end{equation*}

This decomposition of the PIE as the sum of the population intervention direct
and indirect effects has an interpretation analogous to the corresponding
standard decomposition of the average treatment effect. In the sequel, we will
compute each of the components of the direct and indirect effects above using
appropriate estimators as follows

\begin{itemize}
\tightlist
\item
  For \(\mathbb{E}\{Y(A, Z)\}\), the sample mean \(\frac{1}{n}\sum_{i=1}^n Y_i\) is
  consistent;
\item
  for \(\mathbb{E}\{Y(A_{\delta}, Z)\}\), a TML estimator for the effect of a
  joint intervention altering the treatment mechanism but not the mediation
  mechanism, based on the proposal in \citet{diaz2020causal}; and,
\item
  for \(\mathbb{E}\{Y(A_{\delta}, Z_{A_{\delta}})\}\), an efficient estimator for
  the effect of a joint intervention altering both the treatment and mediation
  mechanisms, as proposed in \citet{kennedy2017nonparametric} and implemented in the
  \href{https://github.com/ehkennedy/npcausal}{\passthrough{\lstinline!npcausal!} R package}.
\end{itemize}

\hypertarget{estimating-the-effect-decomposition-term}{%
\section{Estimating the Effect Decomposition Term}\label{estimating-the-effect-decomposition-term}}

As described by \citet{diaz2020causal}, the statistical functional identifying the
decomposition term that appears in both the PIDE and PIIE
\(\mathbb{E}\{Y(A_{\delta}, Z)\}\), which corresponds to altering the treatment
mechanism while keeping the mediation mechanism fixed, is
\begin{equation*}
  \theta_0(\delta) = \int m_0(a, z, w) g_{0,\delta}(a \mid w) p_0(z, w)
    d\nu(a, z, w),
\end{equation*}
for which a TML estimator is available. The corresponding \emph{efficient influence
function} (EIF) with respect to the nonparametric model \(\mathcal{M}\) is
\(D_{\eta,\delta}(o) = D^Y_{\eta,\delta}(o) + D^A_{\eta,\delta}(o) + D^{Z,W}_{\eta,\delta}(o) - \theta(\delta)\).

The TML estimator may be computed basd on the EIF estimating equation and may
incorporate cross-validation \citep{zheng2011cross, chernozhukov2018double} to
circumvent possibly restrictive entropy conditions (e.g., Donsker class). The
resultant estimator is
\begin{equation*}
  \hat{\theta}(\delta) = \frac{1}{n} \sum_{i = 1}^n D_{\hat{\eta}_{j(i)},
  \delta}(O_i) = \frac{1}{n} \sum_{i = 1}^n \left\{ D^Y_{\hat{\eta}_{j(i)},
  \delta}(O_i) + D^A_{\hat{\eta}_{j(i)}, \delta}(O_i) +
  D^{Z,W}_{\hat{\eta}_{j(i)}, \delta}(O_i) \right\},
\end{equation*}
which is implemented in \passthrough{\lstinline!tmle3mediate!} (a one-step estimator is also avaialble,
in the \href{https://github.com/nhejazi/medshift}{\passthrough{\lstinline!medshift!} R package}). We
demonstrate the use of \passthrough{\lstinline!tmle3mediate!} to obtain \(\mathbb{E}\{Y(A_{\delta}, Z)\}\)
via its TML estimator.

\hypertarget{evaluating-the-direct-and-indirect-effects}{%
\section{Evaluating the Direct and Indirect Effects}\label{evaluating-the-direct-and-indirect-effects}}

We now turn to estimating the natural direct and indirect effects, as well as
the population intervention direct effect, using the WASH Benefits data,
introduced in earlier chapters. Let's first load the data:

\begin{lstlisting}[language=R]
library(data.table)
library(sl3)
library(tmle3)
library(tmle3mediate)

# download data
washb_data <- fread(
  paste0(
    "https://raw.githubusercontent.com/tlverse/tlverse-data/master/",
    "wash-benefits/washb_data.csv"
  ),
  stringsAsFactors = TRUE
)

# make intervention node binary and subsample
washb_data <- washb_data[sample(.N, 600), ]
washb_data[, tr := as.numeric(tr != "Control")]
\end{lstlisting}

We'll next define the baseline covariates \(W\), treatment \(A\), mediators \(Z\),
and outcome \(Y\) nodes of the NPSEM via a ``Node List'' object:

\begin{lstlisting}[language=R]
node_list <- list(
  W = c(
    "momage", "momedu", "momheight", "hfiacat", "Nlt18", "Ncomp", "watmin",
    "elec", "floor", "walls", "roof"
  ),
  A = "tr",
  Z = c("sex", "month", "aged"),
  Y = "whz"
)
\end{lstlisting}

Here the \passthrough{\lstinline!node\_list!} encodes the parents of each node -- for example, \(Z\) (the
mediators) have parents \(A\) (the treatment) and \(W\) (the baseline confounders),
and \(Y\) (the outcome) has parents \(Z\), \(A\), and \(W\). We'll also handle any
missingness in the data by invoking \passthrough{\lstinline!process\_missing!}:

\begin{lstlisting}[language=R]
processed <- process_missing(washb_data, node_list)
washb_data <- processed$data
node_list <- processed$node_list
\end{lstlisting}

We'll now construct an ensemble learner using a handful of popular machine
learning algorithms:

\begin{lstlisting}[language=R]
# SL learners used for continuous data (the nuisance parameter Z)
enet_contin_learner <- Lrnr_glmnet$new(
  alpha = 0.5, family = "gaussian", nfolds = 3
)
lasso_contin_learner <- Lrnr_glmnet$new(
  alpha = 1, family = "gaussian", nfolds = 3
)
fglm_contin_learner <- Lrnr_glm_fast$new(family = gaussian())
mean_learner <- Lrnr_mean$new()
contin_learner_lib <- Stack$new(
  enet_contin_learner, lasso_contin_learner, fglm_contin_learner, mean_learner
)
sl_contin_learner <- Lrnr_sl$new(learners = contin_learner_lib)

# SL learners used for binary data (nuisance parameters G and E in this case)
enet_binary_learner <- Lrnr_glmnet$new(
  alpha = 0.5, family = "binomial", nfolds = 3
)
lasso_binary_learner <- Lrnr_glmnet$new(
  alpha = 1, family = "binomial", nfolds = 3
)
fglm_binary_learner <- Lrnr_glm_fast$new(family = binomial())
binary_learner_lib <- Stack$new(
  enet_binary_learner, lasso_binary_learner, fglm_binary_learner, mean_learner
)
sl_binary_learner <- Lrnr_sl$new(learners = binary_learner_lib)

# create list for treatment and outcome mechanism regressions
learner_list <- list(
  Y = sl_contin_learner,
  A = sl_binary_learner
)
\end{lstlisting}

\hypertarget{estimating-the-natural-indirect-effect}{%
\section{Estimating the Natural Indirect Effect}\label{estimating-the-natural-indirect-effect}}

We demonstrate calculation of the NIE below, starting by instantiating a ``Spec''
object that encodes exactly which learners to use for the nuisance parameters
\(e(A \mid Z, W)\) and \(\Psi_Z\). We then pass our Spec object to the \passthrough{\lstinline!tmle3!}
function, alongside the data, the node list (created above), and a learner list
indicating which machine learning algorithms to use for estimating the nuisance
parameters based on \(A\) and \(Y\).

\begin{lstlisting}[language=R]
tmle_spec_NIE <- tmle_NIE(
  e_learners = Lrnr_cv$new(lasso_binary_learner, full_fit = TRUE),
  psi_Z_learners = Lrnr_cv$new(lasso_contin_learner, full_fit = TRUE),
  max_iter = 1
)
washb_NIE <- tmle3(
  tmle_spec_NIE, washb_data, node_list, learner_list
)
washb_NIE
A tmle3_Fit that took 1 step(s)
   type                  param  init_est  tmle_est       se     lower    upper
1:  NIE NIE[Y_{A=1} - Y_{A=0}] 0.0022912 0.0026608 0.044295 -0.084156 0.089478
   psi_transformed lower_transformed upper_transformed
1:       0.0026608         -0.084156          0.089478
\end{lstlisting}

Based on the output, we conclude that the indirect effect of the treatment
through the mediators (sex, month, aged) is
0.00266.

\hypertarget{estimating-the-natural-direct-effect}{%
\section{Estimating the Natural Direct Effect}\label{estimating-the-natural-direct-effect}}

An analogous procedure applies for estimation of the NDE, only replacing the
Spec object for the NIE with \passthrough{\lstinline!tmle\_spec\_NDE!} to define learners for the NDE
nuisance parameters:

\begin{lstlisting}[language=R]
tmle_spec_NDE <- tmle_NDE(
  e_learners = Lrnr_cv$new(lasso_binary_learner, full_fit = TRUE),
  psi_Z_learners = Lrnr_cv$new(lasso_contin_learner, full_fit = TRUE),
  max_iter = 1
)
washb_NDE <- tmle3(
  tmle_spec_NDE, washb_data, node_list, learner_list
)
washb_NDE
A tmle3_Fit that took 1 step(s)
   type                  param init_est tmle_est      se   lower   upper
1:  NDE NDE[Y_{A=1} - Y_{A=0}] 0.012983 0.012983 0.10285 -0.1886 0.21457
   psi_transformed lower_transformed upper_transformed
1:        0.012983           -0.1886           0.21457
\end{lstlisting}

From this, we can draw the conclusion that the direct effect of the treatment
(through all paths not involving the mediators (sex, month, aged)) is
0.01298. Note that, together, the estimates of
the natural direct and indirect effects approximately recover the \emph{average
treatment effect}, that is, based on these estimates of the NDE and NIE, the
ATE is roughly
0.01564.

\hypertarget{estimating-the-population-intervention-direct-effect}{%
\section{Estimating the Population Intervention Direct Effect}\label{estimating-the-population-intervention-direct-effect}}

As previously noted, the assumptions underlying the natural direct and indirect
effects may be challenging to justify; moreover, the effect definitions
themselves depend on the application of a static intervention to the treatment,
sharply limiting their flexibility. When considering binary treatments,
incremental propensity score shifts provide an alternative class of flexible,
stochastic interventions. We'll now consider estimating the PIDE with an IPSI
that modulates the odds of receiving treatment by \(\delta = 3\). Such an
intervention may be interpreted (hypothetically) as the effect of a design that
encourages study participants to opt in to receiving the treatment, thus
increasing their relative odds of receiving said treatment. To exemplify our
approach, we postulate a motivational intervention that \emph{triples the odds}
(i.e., \(\delta = 3\)) of receiving the treatment for each individual:

\begin{lstlisting}[language=R]
# set the IPSI multiplicative shift
delta_ipsi <- 3

# instantiate tmle3 spec for stochastic mediation
tmle_spec_pie_decomp <- tmle_medshift(
  delta = delta_ipsi,
  e_learners = Lrnr_cv$new(lasso_binary_learner, full_fit = TRUE),
  phi_learners = Lrnr_cv$new(lasso_contin_learner, full_fit = TRUE)
)

# compute the TML estimate
washb_pie_decomp <- tmle3(
  tmle_spec_pie_decomp, washb_data, node_list, learner_list
)
washb_pie_decomp

# get the PIDE
washb_pie_decomp$summary$tmle_est - mean(washb_data[, get(node_list$Y)])
\end{lstlisting}

Recall that, based on the decomposition outlined previously, the PIDE may be
denoted \(\beta_{\text{PIDE}}(\delta) = \theta_0(\delta) - \mathbb{E}Y\). Thus,
an estimator of the PIDE, \(\hat{\beta}_{\text{PIDE}}(\delta)\) may be expressed
as a composition of estimators of its constituent parameters:
\begin{equation*}
  \hat{\beta}_{\text{PIDE}}({\delta}) = \hat{\theta}(\delta) -
  \frac{1}{n} \sum_{i = 1}^n Y_i.
\end{equation*}

\hypertarget{r6}{%
\chapter{\texorpdfstring{A Primer on the \texttt{R6} Class System}{A Primer on the R6 Class System}}\label{r6}}

A central goal of the Targeted Learning statistical paradigm is to estimate
scientifically relevant parameters in realistic (usually nonparametric) models.

The \passthrough{\lstinline!tlverse!} is designed using basic OOP principles and the \passthrough{\lstinline!R6!} OOP framework.
While we've tried to make it easy to use the \passthrough{\lstinline!tlverse!} packages without worrying
much about OOP, it is helpful to have some intuition about how the \passthrough{\lstinline!tlverse!} is
structured. Here, we briefly outline some key concepts from OOP. Readers
familiar with OOP basics are invited to skip this section.

\hypertarget{classes-fields-and-methods}{%
\section{Classes, Fields, and Methods}\label{classes-fields-and-methods}}

The key concept of OOP is that of an object, a collection of data and functions
that corresponds to some conceptual unit. Objects have two main types of
elements:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{fields}, which can be thought of as nouns, are information about an object,
  and
\item
  \emph{methods}, which can be thought of as verbs, are actions an object can
  perform.
\end{enumerate}

Objects are members of classes, which define what those specific fields and
methods are. Classes can inherit elements from other classes (sometimes called
base classes) -- accordingly, classes that are similar, but not exactly the
same, can share some parts of their definitions.

Many different implementations of OOP exist, with variations in how these
concepts are implemented and used. R has several different implementations,
including \passthrough{\lstinline!S3!}, \passthrough{\lstinline!S4!}, reference classes, and \passthrough{\lstinline!R6!}. The \passthrough{\lstinline!tlverse!} uses the \passthrough{\lstinline!R6!}
implementation. In \passthrough{\lstinline!R6!}, methods and fields of a class object are accessed using
the \passthrough{\lstinline!$!} operator. For a more thorough introduction to \passthrough{\lstinline!R!}'s various OOP systems,
see \url{http://adv-r.had.co.nz/OO-essentials.html}, from Hadley Wickham's \emph{Advanced
R} \citep{wickham2014advanced}.

\hypertarget{object-oriented-programming-python-and-r}{%
\section{\texorpdfstring{Object Oriented Programming: \texttt{Python} and \texttt{R}}{Object Oriented Programming: Python and R}}\label{object-oriented-programming-python-and-r}}

OO concepts (classes with inherentence) were baked into Python from the first
published version (version 0.9 in 1991). In contrast, \passthrough{\lstinline!R!} gets its OO ``approach''
from its predecessor, \passthrough{\lstinline!S!}, first released in 1976. For the first 15 years, \passthrough{\lstinline!S!}
had no support for classes, then, suddenly, \passthrough{\lstinline!S!} got two OO frameworks bolted on
in rapid succession: informal classes with \passthrough{\lstinline!S3!} in 1991, and formal classes with
\passthrough{\lstinline!S4!} in 1998. This process continues, with new OO frameworks being periodically
released, to try to improve the lackluster OO support in \passthrough{\lstinline!R!}, with reference
classes (\passthrough{\lstinline!R5!}, 2010) and \passthrough{\lstinline!R6!} (2014). Of these, \passthrough{\lstinline!R6!} behaves most like Python
classes (and also most like OOP focused languages like C++ and Java), including
having method definitions be part of class definitions, and allowing objects to
be modified by reference.

\bibliography{book.bib,packages.bib}

\backmatter
\printindex

\end{document}
