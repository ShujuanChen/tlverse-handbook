<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 The Roadmap for Targeted Learning | The Hitchhiker’s Guide to the tlverse</title>
  <meta name="description" content="An open-source and fully-reproducible electronic handbook for applying the targeted learning methodology in practice using the tlverse software ecosystem." />
  <meta name="generator" content="bookdown 0.10.2 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 The Roadmap for Targeted Learning | The Hitchhiker’s Guide to the tlverse" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://tlverse.org/tlverse-handbook/" />
  
  <meta property="og:description" content="An open-source and fully-reproducible electronic handbook for applying the targeted learning methodology in practice using the tlverse software ecosystem." />
  <meta name="github-repo" content="tlverse/tlverse-handbook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 The Roadmap for Targeted Learning | The Hitchhiker’s Guide to the tlverse" />
  
  <meta name="twitter:description" content="An open-source and fully-reproducible electronic handbook for applying the targeted learning methodology in practice using the tlverse software ecosystem." />
  

<meta name="author" content="Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips, Alan Hubbard, Mark van der Laan" />


<meta name="date" content="2019-05-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="img/logos/favicons/favicon.png" type="image/x-icon" />
<link rel="prev" href="motivation.html">
<link rel="next" href="tlverse.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<link href="libs/vis-4.20.1/vis.css" rel="stylesheet" />
<script src="libs/vis-4.20.1/vis.min.js"></script>
<script src="libs/visNetwork-binding-2.0.7/visNetwork.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-89938436-1', 'auto');
  ga('send', 'pageview');
</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">The Hitchhiker's Guide to the tlverse</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-this-book"><i class="fa fa-check"></i>About this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#outline"><i class="fa fa-check"></i>Outline</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#what-this-book-is-not"><i class="fa fa-check"></i>What this book is not</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-authors"><i class="fa fa-check"></i>About the authors</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#jeremy-coyle"><i class="fa fa-check"></i>Jeremy Coyle</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#nima-hejazi"><i class="fa fa-check"></i>Nima Hejazi</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#ivana-malenica"><i class="fa fa-check"></i>Ivana Malenica</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#rachael-phillips"><i class="fa fa-check"></i>Rachael Phillips</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#alan-hubbard"><i class="fa fa-check"></i>Alan Hubbard</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#mark-van-der-laan"><i class="fa fa-check"></i>Mark van der Laan</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#learn"><i class="fa fa-check"></i><b>0.1</b> Recommended Learning Resources</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#setup-instructions"><i class="fa fa-check"></i><b>0.2</b> Setup instructions</a><ul>
<li class="chapter" data-level="0.2.1" data-path="index.html"><a href="index.html#r-and-rstudio"><i class="fa fa-check"></i><b>0.2.1</b> R and RStudio</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="motivation.html"><a href="motivation.html"><i class="fa fa-check"></i>Motivation</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> The Roadmap for Targeted Learning</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#learning-objectives"><i class="fa fa-check"></i><b>1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#introduction"><i class="fa fa-check"></i><b>1.2</b> Introduction</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#the-roadmap"><i class="fa fa-check"></i><b>1.3</b> The Roadmap</a><ul>
<li><a href="intro.html#data-as-a-random-variable-with-a-probability-distribution-o-sim-p_0">(1) Data as a random variable with a probability distribution, <span class="math inline">\(O \sim P_0\)</span></a></li>
<li><a href="intro.html#the-statistical-model-mathcalm-such-that-p_0-in-mathcalm">(2) The statistical model <span class="math inline">\(\mathcal{M}\)</span> such that <span class="math inline">\(P_0 \in \mathcal{M}\)</span></a></li>
<li><a href="intro.html#the-statistical-target-parameter-psi-and-estimand-psip_0">(3) The statistical target parameter <span class="math inline">\(\Psi\)</span> and estimand <span class="math inline">\(\Psi(P_0)\)</span></a></li>
<li><a href="intro.html#the-estimator-hatpsi-and-estimate-hatpsip_n">(4) The estimator <span class="math inline">\(\hat{\Psi}\)</span> and estimate <span class="math inline">\(\hat{\Psi}(P_n)\)</span></a></li>
<li><a href="intro.html#a-measure-of-uncertainty-for-the-estimate-hatpsip_n">(5) A measure of uncertainty for the estimate <span class="math inline">\(\hat{\Psi}(P_n)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#summary-of-the-roadmap"><i class="fa fa-check"></i><b>1.4</b> Summary of the Roadmap</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#causal"><i class="fa fa-check"></i><b>1.5</b> Causal Target Parameters</a><ul>
<li class="chapter" data-level="1.5.1" data-path="intro.html"><a href="intro.html#the-causal-model"><i class="fa fa-check"></i><b>1.5.1</b> The Causal Model</a></li>
<li class="chapter" data-level="1.5.2" data-path="intro.html"><a href="intro.html#identifiability"><i class="fa fa-check"></i><b>1.5.2</b> Identifiability</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#the-wash-benefits-example-dataset"><i class="fa fa-check"></i><b>1.6</b> The WASH Benefits Example Dataset</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="tlverse.html"><a href="tlverse.html"><i class="fa fa-check"></i><b>2</b> Welcome to the <code>tlverse</code></a><ul>
<li class="chapter" data-level="2.1" data-path="tlverse.html"><a href="tlverse.html#learning-objectives-1"><i class="fa fa-check"></i><b>2.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="2.2" data-path="tlverse.html"><a href="tlverse.html#what-is-the-tlverse"><i class="fa fa-check"></i><b>2.2</b> What is the <code>tlverse</code>?</a></li>
<li class="chapter" data-level="2.3" data-path="tlverse.html"><a href="tlverse.html#tlverse-components"><i class="fa fa-check"></i><b>2.3</b> <code>tlverse</code> components</a></li>
<li class="chapter" data-level="2.4" data-path="tlverse.html"><a href="tlverse.html#installation"><i class="fa fa-check"></i><b>2.4</b> Installation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html"><i class="fa fa-check"></i><b>3</b> Ensemble Machine Learning</a><ul>
<li class="chapter" data-level="3.1" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#learning-objectives-2"><i class="fa fa-check"></i><b>3.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="3.2" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#introduction-1"><i class="fa fa-check"></i><b>3.2</b> Introduction</a><ul>
<li class="chapter" data-level="3.2.1" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#background"><i class="fa fa-check"></i><b>3.2.1</b> Background</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#basic-implementation"><i class="fa fa-check"></i><b>3.3</b> Basic Implementation</a><ul>
<li class="chapter" data-level="3.3.1" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#wash-benefits-study-example"><i class="fa fa-check"></i><b>3.3.1</b> WASH Benefits Study Example</a></li>
<li class="chapter" data-level="" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#load-the-necessary-libraries-and-data"><i class="fa fa-check"></i>0. Load the necessary libraries and data</a></li>
<li class="chapter" data-level="" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#define-the-machine-learning-task"><i class="fa fa-check"></i>1. Define the machine learning task</a></li>
<li class="chapter" data-level="" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#make-a-super-learner"><i class="fa fa-check"></i>2. Make a super learner</a></li>
<li class="chapter" data-level="" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#train-the-super-learner-on-the-machine-learning-task"><i class="fa fa-check"></i>3. Train the super learner on the machine learning task</a></li>
<li class="chapter" data-level="" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#obtain-predicted-values"><i class="fa fa-check"></i>4. Obtain predicted values</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#cross-validated-super-learner"><i class="fa fa-check"></i><b>3.4</b> Cross-validated Super Learner</a></li>
<li class="chapter" data-level="3.5" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#variable-importance-measures-with-sl3"><i class="fa fa-check"></i><b>3.5</b> Variable Importance Measures with <code>sl3</code></a></li>
<li class="chapter" data-level="3.6" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#sl3ex1"><i class="fa fa-check"></i><b>3.6</b> Exercise 1 – Predicting Myocardial Infarction with <code>sl3</code></a></li>
<li class="chapter" data-level="3.7" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#super-learning-of-a-conditional-density"><i class="fa fa-check"></i><b>3.7</b> Super Learning of a Conditional Density</a></li>
<li class="chapter" data-level="3.8" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#sl3ex2"><i class="fa fa-check"></i><b>3.8</b> Exercise 2 – Estimating the Propensity Score with <code>sl3</code></a></li>
<li class="chapter" data-level="3.9" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#super-learning-of-an-optimal-individualized-treatment-rule"><i class="fa fa-check"></i><b>3.9</b> Super Learning of an Optimal Individualized Treatment Rule</a></li>
<li class="chapter" data-level="3.10" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#sl3ex3"><i class="fa fa-check"></i><b>3.10</b> Exercise 3 – Estimating the Blip</a></li>
<li class="chapter" data-level="3.11" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#concluding-remarks"><i class="fa fa-check"></i><b>3.11</b> Concluding Remarks</a></li>
<li class="chapter" data-level="3.12" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#appendix"><i class="fa fa-check"></i><b>3.12</b> Appendix</a><ul>
<li class="chapter" data-level="3.12.1" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#exercise-1-solution"><i class="fa fa-check"></i><b>3.12.1</b> Exercise 1 Solution</a></li>
<li class="chapter" data-level="3.12.2" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#exercise-2-solution"><i class="fa fa-check"></i><b>3.12.2</b> Exercise 2 Solution</a></li>
<li class="chapter" data-level="3.12.3" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#exercise-3-solution"><i class="fa fa-check"></i><b>3.12.3</b> Exercise 3 Solution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html"><i class="fa fa-check"></i><b>4</b> The TMLE Framework</a><ul>
<li class="chapter" data-level="4.1" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#learning-objectives-3"><i class="fa fa-check"></i><b>4.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="4.2" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#example-tmle3-for-ate"><i class="fa fa-check"></i><b>4.2</b> Example: <code>tmle3</code> for ATE</a><ul>
<li class="chapter" data-level="4.2.1" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#load-the-data"><i class="fa fa-check"></i><b>4.2.1</b> Load the Data</a></li>
<li class="chapter" data-level="4.2.2" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#define-the-variable-roles"><i class="fa fa-check"></i><b>4.2.2</b> Define the variable roles</a></li>
<li class="chapter" data-level="4.2.3" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#handle-missingness"><i class="fa fa-check"></i><b>4.2.3</b> Handle Missingness</a></li>
<li class="chapter" data-level="4.2.4" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#create-a-spec-object"><i class="fa fa-check"></i><b>4.2.4</b> Create a “Spec” Object</a></li>
<li class="chapter" data-level="4.2.5" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#define-the-learners"><i class="fa fa-check"></i><b>4.2.5</b> Define the learners</a></li>
<li class="chapter" data-level="4.2.6" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#fit-the-tmle"><i class="fa fa-check"></i><b>4.2.6</b> Fit the TMLE</a></li>
<li class="chapter" data-level="4.2.7" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#evaluate-the-estimates"><i class="fa fa-check"></i><b>4.2.7</b> Evaluate the Estimates</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#tmle3-components"><i class="fa fa-check"></i><b>4.3</b> <code>tmle3</code> Components</a><ul>
<li class="chapter" data-level="4.3.1" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#tmle3_task"><i class="fa fa-check"></i><b>4.3.1</b> <code>tmle3_task</code></a></li>
<li class="chapter" data-level="4.3.2" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#initial-likelihood"><i class="fa fa-check"></i><b>4.3.2</b> Initial Likelihood</a></li>
<li class="chapter" data-level="4.3.3" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#targeted-likelihood-updater"><i class="fa fa-check"></i><b>4.3.3</b> Targeted Likelihood (updater)</a></li>
<li class="chapter" data-level="4.3.4" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#parameter-mapping"><i class="fa fa-check"></i><b>4.3.4</b> Parameter Mapping</a></li>
<li class="chapter" data-level="4.3.5" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#putting-it-all-together"><i class="fa fa-check"></i><b>4.3.5</b> Putting it all together</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#fitting-tmle3-with-multiple-parameters"><i class="fa fa-check"></i><b>4.4</b> Fitting <code>tmle3</code> with multiple parameters</a><ul>
<li class="chapter" data-level="4.4.1" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#delta-method"><i class="fa fa-check"></i><b>4.4.1</b> Delta Method</a></li>
<li class="chapter" data-level="4.4.2" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#fit"><i class="fa fa-check"></i><b>4.4.2</b> Fit</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#exercise"><i class="fa fa-check"></i><b>4.5</b> Exercise</a></li>
<li class="chapter" data-level="4.6" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#summary"><i class="fa fa-check"></i><b>4.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html"><i class="fa fa-check"></i><b>5</b> Optimal Individualized Treatment Regimes</a><ul>
<li class="chapter" data-level="5.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#learning-objectives-4"><i class="fa fa-check"></i><b>5.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="5.2" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#introduction-to-optimal-individualized-interventions"><i class="fa fa-check"></i><b>5.2</b> Introduction to Optimal Individualized Interventions</a></li>
<li class="chapter" data-level="5.3" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#data-structure-and-notation"><i class="fa fa-check"></i><b>5.3</b> Data Structure and Notation</a></li>
<li class="chapter" data-level="5.4" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#defining-the-causal-effect-of-an-optimal-individualized-intervention"><i class="fa fa-check"></i><b>5.4</b> Defining the Causal Effect of an Optimal Individualized Intervention</a><ul>
<li class="chapter" data-level="5.4.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#binary-treatment"><i class="fa fa-check"></i><b>5.4.1</b> Binary treatment</a></li>
<li class="chapter" data-level="5.4.2" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#categorical-treatment"><i class="fa fa-check"></i><b>5.4.2</b> Categorical treatment</a></li>
<li class="chapter" data-level="5.4.3" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#note-on-inference"><i class="fa fa-check"></i><b>5.4.3</b> Note on Inference</a></li>
<li class="chapter" data-level="5.4.4" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#why-cv-tmle"><i class="fa fa-check"></i><b>5.4.4</b> Why CV-TMLE?</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#interpreting-the-causal-effect-of-an-optimal-individualized-intervention"><i class="fa fa-check"></i><b>5.5</b> Interpreting the Causal Effect of an Optimal Individualized Intervention</a></li>
<li class="chapter" data-level="5.6" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#evaluating-the-causal-effect-of-an-oit-with-binary-treatment"><i class="fa fa-check"></i><b>5.6</b> Evaluating the Causal Effect of an OIT with Binary Treatment</a><ul>
<li class="chapter" data-level="5.6.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#simulated-data"><i class="fa fa-check"></i><b>5.6.1</b> Simulated Data</a></li>
<li class="chapter" data-level="5.6.2" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#constructing-optimal-stacked-regressions-with-sl3"><i class="fa fa-check"></i><b>5.6.2</b> Constructing Optimal Stacked Regressions with <code>sl3</code></a></li>
<li class="chapter" data-level="5.6.3" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#targeted-estimation-of-the-mean-under-the-optimal-individualized-interventions-effects"><i class="fa fa-check"></i><b>5.6.3</b> Targeted Estimation of the Mean under the Optimal Individualized Interventions Effects</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#evaluating-the-causal-effect-of-an-optimal-itr-with-categorical-treatment"><i class="fa fa-check"></i><b>5.7</b> Evaluating the Causal Effect of an optimal ITR with Categorical Treatment</a><ul>
<li class="chapter" data-level="5.7.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#simulated-data-1"><i class="fa fa-check"></i><b>5.7.1</b> Simulated Data</a></li>
<li class="chapter" data-level="5.7.2" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#constructing-optimal-stacked-regressions-with-sl3-1"><i class="fa fa-check"></i><b>5.7.2</b> Constructing Optimal Stacked Regressions with <code>sl3</code></a></li>
<li class="chapter" data-level="5.7.3" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#targeted-estimation-of-the-mean-under-the-optimal-individualized-interventions-effects-1"><i class="fa fa-check"></i><b>5.7.3</b> Targeted Estimation of the Mean under the Optimal Individualized Interventions Effects</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#extensions-to-causal-effect-of-an-oit"><i class="fa fa-check"></i><b>5.8</b> Extensions to Causal Effect of an OIT</a><ul>
<li class="chapter" data-level="5.8.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#simpler-rules"><i class="fa fa-check"></i><b>5.8.1</b> Simpler Rules</a></li>
<li class="chapter" data-level="5.8.2" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#realistic-optimal-individual-regimes"><i class="fa fa-check"></i><b>5.8.2</b> Realistic Optimal Individual Regimes</a></li>
<li class="chapter" data-level="5.8.3" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#q-learning"><i class="fa fa-check"></i><b>5.8.3</b> Q-learning</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#variable-importance-analysis-with-oit"><i class="fa fa-check"></i><b>5.9</b> Variable Importance Analysis with OIT</a><ul>
<li class="chapter" data-level="5.9.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#simulated-data-2"><i class="fa fa-check"></i><b>5.9.1</b> Simulated Data</a></li>
<li class="chapter" data-level="5.9.2" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#variable-importance-using-targeted-estimation-of-the-value-of-the-itr"><i class="fa fa-check"></i><b>5.9.2</b> Variable Importance using Targeted Estimation of the value of the ITR</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#real-world-data-and-tmle3mopttx"><i class="fa fa-check"></i><b>5.10</b> Real World Data and <code>tmle3mopttx</code></a></li>
<li class="chapter" data-level="5.11" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#exercises"><i class="fa fa-check"></i><b>5.11</b> Exercises</a><ul>
<li class="chapter" data-level="5.11.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#review-of-key-concepts"><i class="fa fa-check"></i><b>5.11.1</b> Review of Key Concepts</a></li>
<li class="chapter" data-level="5.11.2" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#the-ideas-in-action"><i class="fa fa-check"></i><b>5.11.2</b> The Ideas in Action</a></li>
<li class="chapter" data-level="5.11.3" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#advanced-topics"><i class="fa fa-check"></i><b>5.11.3</b> Advanced Topics</a></li>
</ul></li>
<li class="chapter" data-level="5.12" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#appendix-1"><i class="fa fa-check"></i><b>5.12</b> Appendix</a><ul>
<li class="chapter" data-level="5.12.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#exercise-solutions"><i class="fa fa-check"></i><b>5.12.1</b> Exercise solutions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html"><i class="fa fa-check"></i><b>6</b> Stochastic Treatment Regimes</a><ul>
<li class="chapter" data-level="6.1" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#learning-objectives-5"><i class="fa fa-check"></i><b>6.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="6.2" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#introduction-to-stochastic-interventions"><i class="fa fa-check"></i><b>6.2</b> Introduction to Stochastic Interventions</a></li>
<li class="chapter" data-level="6.3" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#data-structure-and-notation-1"><i class="fa fa-check"></i><b>6.3</b> Data Structure and Notation</a></li>
<li class="chapter" data-level="6.4" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#defining-the-causal-effect-of-a-stochastic-intervention"><i class="fa fa-check"></i><b>6.4</b> Defining the Causal Effect of a Stochastic Intervention</a></li>
<li class="chapter" data-level="6.5" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#interpreting-the-causal-effect-of-a-stochastic-intervention"><i class="fa fa-check"></i><b>6.5</b> Interpreting the Causal Effect of a Stochastic Intervention</a></li>
<li class="chapter" data-level="6.6" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#evaluating-the-causal-effect-of-a-stochastic-intervention"><i class="fa fa-check"></i><b>6.6</b> Evaluating the Causal Effect of a Stochastic Intervention</a><ul>
<li class="chapter" data-level="6.6.1" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#example-with-simulated-data"><i class="fa fa-check"></i><b>6.6.1</b> Example with Simulated Data</a></li>
<li class="chapter" data-level="6.6.2" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#targeted-estimation-of-stochastic-interventions-effects"><i class="fa fa-check"></i><b>6.6.2</b> Targeted Estimation of Stochastic Interventions Effects</a></li>
<li class="chapter" data-level="6.6.3" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#statistical-inference-for-targeted-maximum-likelihood-estimates"><i class="fa fa-check"></i><b>6.6.3</b> Statistical Inference for Targeted Maximum Likelihood Estimates</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#extensions-variable-importance-analysis-with-stochastic-interventions"><i class="fa fa-check"></i><b>6.7</b> Extensions: Variable Importance Analysis with Stochastic Interventions</a><ul>
<li class="chapter" data-level="6.7.1" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#defining-a-grid-of-counterfactual-interventions"><i class="fa fa-check"></i><b>6.7.1</b> Defining a grid of counterfactual interventions</a></li>
<li class="chapter" data-level="6.7.2" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#initializing-vimshift-through-its-tmle3_spec"><i class="fa fa-check"></i><b>6.7.2</b> Initializing <code>vimshift</code> through its <code>tmle3_Spec</code></a></li>
<li class="chapter" data-level="6.7.3" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#targeted-estimation-of-stochastic-interventions-effects-1"><i class="fa fa-check"></i><b>6.7.3</b> Targeted Estimation of Stochastic Interventions Effects</a></li>
<li class="chapter" data-level="6.7.4" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#inference-with-marginal-structural-models"><i class="fa fa-check"></i><b>6.7.4</b> Inference with Marginal Structural Models</a></li>
<li class="chapter" data-level="6.7.5" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#example-with-the-wash-benefits-data"><i class="fa fa-check"></i><b>6.7.5</b> Example with the WASH Benefits Data</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#exercises-1"><i class="fa fa-check"></i><b>6.8</b> Exercises</a><ul>
<li class="chapter" data-level="6.8.1" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#the-ideas-in-action-1"><i class="fa fa-check"></i><b>6.8.1</b> The Ideas in Action</a></li>
<li class="chapter" data-level="6.8.2" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#review-of-key-concepts-1"><i class="fa fa-check"></i><b>6.8.2</b> Review of Key Concepts</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="r6.html"><a href="r6.html"><i class="fa fa-check"></i><b>7</b> A Primer on the <code>R6</code> Class System</a><ul>
<li class="chapter" data-level="7.1" data-path="r6.html"><a href="r6.html#classes-fields-and-methods"><i class="fa fa-check"></i><b>7.1</b> Classes, Fields, and Methods</a></li>
<li class="chapter" data-level="7.2" data-path="r6.html"><a href="r6.html#object-oriented-programming-python-and-r"><i class="fa fa-check"></i><b>7.2</b> Object Oriented Programming: <code>Python</code> and <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Hitchhiker’s Guide to the <code>tlverse</code></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intro" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> The Roadmap for Targeted Learning</h1>
<div id="learning-objectives" class="section level2">
<h2><span class="header-section-number">1.1</span> Learning Objectives</h2>
<p>By the end of this chapter you will be able to:</p>
<ol style="list-style-type: decimal">
<li>Translate scientific questions to statistical questions.</li>
<li>Define a statistical model based on the knowledge of the experiment that
generated the data.</li>
<li>Identify a causal parameter as a function of the observed data distribution.</li>
<li>Explain the following causal and statistical assumptions and their
implications: i.i.d., consistency, interference, positivity, SUTVA.</li>
</ol>
</div>
<div id="introduction" class="section level2">
<h2><span class="header-section-number">1.2</span> Introduction</h2>
<p>The roadmap of statistical learning is concerned with the translation from
real-world data applications to a mathematical and statistical formulation of
the relevant estimation problem. This involves data as a random variable having
a probability distribution, scientific knowledge represented by a statistical
model, a statistical target parameter representing an answer to the question of
interest, and the notion of an estimator and sampling distribution of the
estimator.</p>
</div>
<div id="the-roadmap" class="section level2">
<h2><span class="header-section-number">1.3</span> The Roadmap</h2>
<p>Following the roadmap is a process of five stages.</p>
<ol style="list-style-type: decimal">
<li>Data as a random variable with a probability distribution, <span class="math inline">\(O \sim P_0\)</span>.</li>
<li>The statistical model <span class="math inline">\(\mathcal{M}\)</span> such that <span class="math inline">\(P_0 \in \mathcal{M}\)</span>.</li>
<li>The statistical target parameter <span class="math inline">\(\Psi\)</span> and estimand <span class="math inline">\(\Psi(P_0)\)</span>.</li>
<li>The estimator <span class="math inline">\(\hat{\Psi}\)</span> and estimate <span class="math inline">\(\hat{\Psi}(P_n)\)</span>.</li>
<li>A measure of uncertainty for the estimate <span class="math inline">\(\hat{\Psi}(P_n)\)</span>.</li>
</ol>
<div id="data-as-a-random-variable-with-a-probability-distribution-o-sim-p_0" class="section level3 unnumbered">
<h3>(1) Data as a random variable with a probability distribution, <span class="math inline">\(O \sim P_0\)</span></h3>
<p>The data set we’re confronted with is the result of an experiment and we can
view the data as a random variable, <span class="math inline">\(O\)</span>, because if we repeat the experiment
we would have a different realization of this experiment. In particular, if we
repeat the experiment many times we could learn the probability distribution,
<span class="math inline">\(P_0\)</span>, of our data. So, the observed data <span class="math inline">\(O\)</span> with probability distribution
<span class="math inline">\(P_0\)</span> are <span class="math inline">\(n\)</span> independent identically distributed (i.i.d.) observations of the
random variable <span class="math inline">\(O; O_1, \ldots, O_n\)</span>. Note that while not all data are i.i.d.,
there are ways to handle non-i.i.d. data, such as establishing conditional
independence, stratifying data to create sets of identically distributed data,
etc. It is crucial that researchers be absolutely clear about what they actually
know about the data-generating distribution for a given problem of interest.
Unfortunately, communication between statisticians and researchers is often
fraught with misinterpretation. The roadmap provides a mechanism by which to
ensure clear communication between research and statistician – it truly helps
with this communication!</p>
<div id="the-empirical-probability-measure-p_n" class="section level4 unnumbered">
<h4>The empirical probability measure, <span class="math inline">\(P_n\)</span></h4>
<p>Once we have <span class="math inline">\(n\)</span> of such i.i.d. observations we have an empirical probability
measure, <span class="math inline">\(P_n\)</span>. The empirical probability measure is an approximation of the
true probability measure <span class="math inline">\(P_0\)</span>, allowing us to learn from our data. For
example, we can define the empirical probability measure of a set, <span class="math inline">\(A\)</span>, to be
the proportion of observations which end up in <span class="math inline">\(A\)</span>. That is,
<span class="math display">\[\begin{equation*}
  P_n(A) = \frac{1}{n}\sum_{i=1}^{n}I(O_i \in A)
\end{equation*}\]</span></p>
<p>In order to start learning something, we need to ask <em>“What do we know about the
probability distribution of the data?”</em> This brings us to Step 2.</p>
</div>
</div>
<div id="the-statistical-model-mathcalm-such-that-p_0-in-mathcalm" class="section level3 unnumbered">
<h3>(2) The statistical model <span class="math inline">\(\mathcal{M}\)</span> such that <span class="math inline">\(P_0 \in \mathcal{M}\)</span></h3>
<p>The statistical model <span class="math inline">\(\mathcal{M}\)</span> is defined by the question we asked at the
end of . It is defined as the set of possible probability
distributions for our observed data. Often <span class="math inline">\(\mathcal{M}\)</span> is very large (possibly
infinite-dimensional), to reflect the fact that statistical knowledge is
limited. In the case that <span class="math inline">\(\mathcal{M}\)</span> is infinite-dimensional, we deem this a
nonparametric statistical model.</p>
<p>Alternatively, if the probability distribution of the data at hand is described
by a finite number of parameters, then the statistical model is parametric. In
this case, we prescribe to the belief that the random variable <span class="math inline">\(O\)</span> being
observed has, e.g., a normal distribution with mean <span class="math inline">\(\mu\)</span> and variance
<span class="math inline">\(\sigma^2\)</span>. More formally, a parametric model may be defined
<span class="math display">\[\begin{equation*}
  \mathcal{M} = \{P_{\theta} : \theta \in \mathcal{R}^d \}
\end{equation*}\]</span></p>
<p>Sadly, the assumption that the data-generating distribution has a specific,
parametric forms is all-too-common, even when such is a leap of faith. This
practice of oversimplification in the current culture of data analysis typically
derails any attempt at trying to answer the scientific question at hand; alas,
such statements as the ever-popular quip of Box that “All models are wrong but
some are useful,” encourage the data analyst to make arbitrary choices even when
that often force significant differences in answers to the same estimation
problem. The Targeted Learning paradigm does not suffer from this bias since it
defines the statistical model through a representation of the true
data-generating distribution corresponding to the observed data.</p>
<p>Now, on to Step 3: <em>``What are we trying to learn from the data?&quot;</em></p>
</div>
<div id="the-statistical-target-parameter-psi-and-estimand-psip_0" class="section level3 unnumbered">
<h3>(3) The statistical target parameter <span class="math inline">\(\Psi\)</span> and estimand <span class="math inline">\(\Psi(P_0)\)</span></h3>
<p>The statistical target parameter, <span class="math inline">\(\Psi\)</span>, is defined as a mapping from the
statistical model, <span class="math inline">\(\mathcal{M}\)</span>, to the parameter space (i.e., a real number)
<span class="math inline">\(\mathcal{R}\)</span>. That is, <span class="math inline">\(\Psi: \mathcal{M}\rightarrow\mathbb{R}\)</span>. The target
parameter may be seen as a representation of the
quantity that we wish to learn from the data, the answer to a well-specified
(often causal) question of interest. In contrast to purely statistical target
parameters, causal target parameters require <em>identification from the observed
data</em>, based on causal models that include several untestable assumptions,
described in more detail in the section on <a href="intro.html#causal">causal target parameters</a>.</p>
<p>For a simple example, consider a data set which contains observations of a
survival time on every subject, for which our question of interest is “What’s
the probability that someone lives longer than five years?” We have,
<span class="math display">\[\begin{equation*}
  \Psi(P_0) = P_0(O &gt; 5)
\end{equation*}\]</span></p>
<p>This answer to this question is the <strong>estimand, <span class="math inline">\(\Psi(P_0)\)</span></strong>, which is the
quantity we’re trying to learn from the data. Once we have defined <span class="math inline">\(O\)</span>,
<span class="math inline">\(\mathcal{M}\)</span> and <span class="math inline">\(\Psi(P_0)\)</span> we have formally defined the statistical
estimation problem.</p>
</div>
<div id="the-estimator-hatpsi-and-estimate-hatpsip_n" class="section level3 unnumbered">
<h3>(4) The estimator <span class="math inline">\(\hat{\Psi}\)</span> and estimate <span class="math inline">\(\hat{\Psi}(P_n)\)</span></h3>
<p>To obtain a good approximation of the estimand, we need an estimator, an <em>a
priori</em>-specified algorithm defined as a mapping from the set of possible
empirical distributions, <span class="math inline">\(P_n\)</span>, which live in a non-parametric statistical
model, <span class="math inline">\(\mathcal{M}_{NP}\)</span> (<span class="math inline">\(P_n \in \mathcal{M}_{NP}\)</span>), to the parameter space
of the parameter of interest. That is, <span class="math inline">\(\hat{\Psi} : \mathcal{M}_{NP} \rightarrow \mathbb{R}^d\)</span>. The estimator is a function that takes as input
the observed data, a realization of <span class="math inline">\(P_n\)</span>, and gives as output a value in the
parameter space, which is the <strong>estimate, <span class="math inline">\(\hat{\Psi}(P_n)\)</span></strong>.</p>
<p>Where the estimator may be seen as an operator that maps the observed data and
corresponding empirical distribution to a value in the parameter space, the
numerical output that produced such a function is the estimate. Thus, it is an
element of the parameter space based on the empirical probability distribution
of the observed data. If we plug in a realization of <span class="math inline">\(P_n\)</span> (based on a sample
size <span class="math inline">\(n\)</span> of the random variable <span class="math inline">\(O\)</span>), we get back an estimate <span class="math inline">\(\hat{\Psi}(P_n)\)</span>
of the true parameter value <span class="math inline">\(\Psi(P_0)\)</span>.</p>
<p>In order to quantify the uncertainty in our estimate of the target parameter
(i.e., to construct statistical inference), an understanding of the sampling
distribution of our estimator will be necessary. This brings us to Step 5.</p>
</div>
<div id="a-measure-of-uncertainty-for-the-estimate-hatpsip_n" class="section level3 unnumbered">
<h3>(5) A measure of uncertainty for the estimate <span class="math inline">\(\hat{\Psi}(P_n)\)</span></h3>
<p>Since the estimator <span class="math inline">\(\hat{\Psi}\)</span> is a function of the empirical
distribution <span class="math inline">\(P_n\)</span>, the estimator itself is a random variable with a sampling
distribution. So, if we repeat the experiment of drawing <span class="math inline">\(n\)</span> observations we
would every time end up with a different realization of our estimate and our
estimator has a sampling distribution. The sampling distribution of an estimator
can be theoretically validated to be approximately normally distributed by a
Central Limit Theorem (CLT).</p>
<p>A class of <strong>Central Limit Theorems</strong> (CLTs) are statements regarding the
convergence of the <strong>sampling distribution of an estimator</strong> to a normal
distribution. In general, we will construct estimators whose limit sampling
distributions may be shown to be approximately normal distributed as sample size
increases. For large enough <span class="math inline">\(n\)</span> we have,
<span class="math display">\[\begin{equation*}
  \hat{\Psi}(P_n) \sim N \left(\Psi(P_0), \frac{\sigma^2}{n}\right),
\end{equation*}\]</span>
permitting statistical inference. Now, we can proceed to quantify the
uncertainty of our chosen estimator by construction of hypothesis tests and
confidence intervals. For example, we may construct a 95% confidence interval
for our estimand, <span class="math inline">\(\Psi(P_0)\)</span>:
<span class="math display">\[\begin{equation*}
  $$\hat{\Psi}(P_n) \pm 1.96 \left(\frac{\sigma}{\sqrt{n}}\right)
\end{equation*}\]</span></p>
<p><em>Note:</em> we typically have to estimate the standard error,
<span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span>.</p>
<p>A 95% confidence interval means that if we were to take 100 different samples
of size <span class="math inline">\(n\)</span> and compute a 95% confidence interval for each sample then
approximately 95 of the 100 confidence intervals would contain the estimand,
<span class="math inline">\(\Psi(P_0)\)</span>. More practically, this means that there is a 95% probability
(or 95% confidence) that the confidence interval procedure will contain the
true estimand. However, any single estimated confidence interval either will
contain the true estimand or will not.</p>
</div>
</div>
<div id="summary-of-the-roadmap" class="section level2">
<h2><span class="header-section-number">1.4</span> Summary of the Roadmap</h2>
<p>Data, <span class="math inline">\(O\)</span>, is viewed as a random variable that has a probability distribution.
We often have <span class="math inline">\(n\)</span> units of independent identically distributed units with
probability distribution <span class="math inline">\(P_0\)</span> (<span class="math inline">\(O_1, \ldots, O_n \sim P_0\)</span>). We have
statistical knowledge about the experiment that generated this data. In other
words, we make a statement that the true data distribution <span class="math inline">\(P_0\)</span> falls in a
certain set called a statistical model, <span class="math inline">\(\mathcal{M}\)</span>. Often these sets are very
large because statistical knowledge is very limited so these statistical models
are often infinite dimensional models. Our statistical query is, “What are we
trying to learn from the data?” denoted by the statistical target parameter,
<span class="math inline">\(\Psi\)</span>, which maps the <span class="math inline">\(P_0\)</span> into the estimand, <span class="math inline">\(\Psi(P_0)\)</span>. At this point the
statistical estimation problem is formally defined and now we will need
statistical theory to guide us in the construction of estimators. There’s a lot
of statistical theory we will review in this course that, in particular, relies
on the Central Limit Theorem, allowing us to come up with estimators that are
approximately normally distributed and also allowing us to come with statistical
inference (i.e., confidence intervals and hypothesis tests).</p>
</div>
<div id="causal" class="section level2">
<h2><span class="header-section-number">1.5</span> Causal Target Parameters</h2>
<div id="the-causal-model" class="section level3">
<h3><span class="header-section-number">1.5.1</span> The Causal Model</h3>
<p>The next step in the roadmap is to use a causal framework to formalize the
experiment and thereby define the parameter of interest. Causal graphs are one
useful tool to express what we know about the causal relations among variables
that are relevant to the question under study <span class="citation">(Pearl <a href="#ref-pearl2009causality">2009</a><a href="#ref-pearl2009causality">a</a>)</span>. While
directed acyclic graphs (DAGs) provide a convenient means by which to visualize
causal relations between variables, the same causal relations among variables
can be represented via a set of structural equations:
<span class="math display">\[\begin{align*}
  W &amp;= f_W(U_W) \\
  A &amp;= f_A(W, U_A) \\
  Y &amp;= f_Y(W, A, U_Y),
\end{align*}\]</span>
where <span class="math inline">\(U_W\)</span>, <span class="math inline">\(U_A\)</span>, and <span class="math inline">\(U_Y\)</span> represent the unmeasured exogenous background
characteristics that influence the value of each variable. In the NPSEM, <span class="math inline">\(f_W\)</span>,
<span class="math inline">\(f_A\)</span> and <span class="math inline">\(f_Y\)</span> denote that each variable (for <span class="math inline">\(W\)</span>, <span class="math inline">\(A\)</span> and <span class="math inline">\(Y\)</span>, respectively)
is a function of its parents and unmeasured background characteristics, but note
that there is no imposition of any particular functional constraints. For this
reason, they are called non-parametric structural equation models (NPSEMs). The
DAG and set of nonparametric structural equations represent exactly the same
information and so may be used interchangeably.</p>
<p>The first hypothetical experiment we will consider is assigning exposure to the
whole population and observing the outcome, and then assigning no exposure to
the whole population and observing the outcome. On the nonparametric structural
equations, this corresponds to a comparison of the outcome distribution in the
population under two interventions:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(A\)</span> is set to <span class="math inline">\(1\)</span> for all individuals, and</li>
<li><span class="math inline">\(A\)</span> is set to <span class="math inline">\(0\)</span> for all individuals.</li>
</ol>
<p>These interventions imply two new nonparametric structural equation models. For
the case <span class="math inline">\(A = 1\)</span>, we have
<span class="math display">\[\begin{align*}
  W &amp;= f_W(U_W) \\
  A &amp;= 1 \\
  Y(1) &amp;= f_Y(W, 1, U_Y),
\end{align*}\]</span>
and for the case <span class="math inline">\(A=0\)</span>,
<span class="math display">\[\begin{align*}
  W &amp;= f_W(U_W) \\
  A &amp;= 0 \\
  Y(1) &amp;= f_Y(W, 0, U_Y).
\end{align*}\]</span></p>
<p>In these equations, <span class="math inline">\(A\)</span> is no longer a function of <span class="math inline">\(W\)</span> because we have
intervened on the system, setting <span class="math inline">\(A\)</span> deterministically to either of the values
<span class="math inline">\(1\)</span> or <span class="math inline">\(0\)</span>. The new symbols <span class="math inline">\(Y(1)\)</span> and <span class="math inline">\(Y(0)\)</span> indicate the outcome variable in
our population if it were generated by the respective NPSEMs above; these are
often called <em>counterfactuals</em> (since they run contrary-to-fact). The difference
between the means of the outcome under these two interventions defines a
parameter that is often called the “average treatment effect” (ATE), denoted
<span class="math display">\[\begin{equation}\label{eqn:ate}
  ATE = \mathbb{E}_X(Y(1)-Y(0)),
\end{equation}\]</span>
where <span class="math inline">\(\mathbb{E}_X\)</span> is the mean under the theoretical (unobserved) full data
<span class="math inline">\(X = (W, Y(1), Y(0))\)</span>.</p>
</div>
<div id="identifiability" class="section level3">
<h3><span class="header-section-number">1.5.2</span> Identifiability</h3>
<p>Because we can never observe both <span class="math inline">\(Y(0)\)</span> (the counterfactual outcome when <span class="math inline">\(A=0\)</span>)
and <span class="math inline">\(Y(1)\)</span>, we cannot estimate  directly. Instead, we have to make
assumptions under which this quantity may be estimated from the observed data
<span class="math inline">\(O \sim P_0\)</span> under the data-generating distribution <span class="math inline">\(P_0\)</span>. Fortunately, given
the causal model specified in the NPSEM above, we can, with a handful of
untestable assumptions, estimate the ATE, even from observational data. These
assumptions may be summarized as follows</p>
<ol style="list-style-type: decimal">
<li>The causal graph implies <span class="math inline">\(Y(a) \perp A\)</span> for all <span class="math inline">\(a \in \mathcal{A}\)</span>, which
is the <em>randomization</em> assumption. In the case of observational data, the
analogous assumption is <em>strong ignorability</em> or <em>no unmeasured confounding</em>
<span class="math inline">\(Y(a) \perp A \mid W\)</span> for all <span class="math inline">\(a \in \mathcal{A}\)</span>;</li>
<li>Although not represented in the causal graph, also required is the assumption
of no interference between units, that is, the outcome for unit <span class="math inline">\(i\)</span> <span class="math inline">\(Y_i\)</span> is
not affected by exposure for unit <span class="math inline">\(j\)</span> <span class="math inline">\(A_j\)</span> unless <span class="math inline">\(i=j\)</span>;</li>
<li><em>Consistency</em> of the treatment mechanism is also required, i.e., the outcome
for unit <span class="math inline">\(i\)</span> is <span class="math inline">\(Y_i(a)\)</span> whenever <span class="math inline">\(A_i = a\)</span>, an assumption also known as “no
other versions of treatment”;</li>
<li>It is also necessary that all observed units, across strata defined by <span class="math inline">\(W\)</span>,
have a bounded (non-deterministic) probability of receiving treatment –
that is, <span class="math inline">\(0 &lt; P_0(A = a \mid W) &lt; 1\)</span> for all <span class="math inline">\(a\)</span> and <span class="math inline">\(W\)</span>). This assumption is
referred to as <em>positivity</em>.</li>
</ol>
<p><em>Remark</em>: Together, (2) and (3), the assumptions of no interference and
consistency, respectively, are jointly referred to as the <em>stable unit
treatment value assumption</em> (SUTVA).</p>
<p>Given these assumptions, the ATE may be re-written as a function of <span class="math inline">\(P_0\)</span>,
specifically
<span class="math display">\[\begin{equation}\label{eqn:estimand}
  ATE = \mathbb{E}_0(Y(1) - Y(0)) = \mathbb{E}_0
    \left(\mathbb{E}_0[Y \mid A = 1, W] - \mathbb{E}_0[Y \mid A = 0, W]\right),
\end{equation}\]</span>
or the difference in the predicted outcome values for each subject, under the
contrast of treatment conditions (<span class="math inline">\(A = 0\)</span> vs. <span class="math inline">\(A = 1\)</span>), in the population,
averaged over all observations. Thus, a parameter of a theoretical “full” data
distribution can be represented as an estimand of the observed data
distribution. Significantly, there is nothing about the representation in
 that requires parameteric assumptions; thus, the regressions
on the right hand side may be estimated freely with machine learning. With
different parameters, there will be potentially different identifiability
assumptions and the resulting estimands can be functions of different components
of <span class="math inline">\(P_0\)</span>. We discuss several more complex estimands in later sections of this
workshop.</p>
</div>
</div>
<div id="the-wash-benefits-example-dataset" class="section level2">
<h2><span class="header-section-number">1.6</span> The WASH Benefits Example Dataset</h2>
<p>The data come from a study of the effect of water quality, sanitation, hand
washing, and nutritional interventions on child development in rural Bangladesh
(WASH Benefits Bangladesh): a cluster-randomised controlled trial
<span class="citation">(“Temporary,” <a href="#ref-luby2018effects">n.d.</a>)</span>. The study enrolled pregnant women in their first or second
trimester from the rural villages of Gazipur, Kishoreganj, Mymensingh, and
Tangail districts of central Bangladesh, with an average of eight women per
cluster. Groups of eight geographically adjacent clusters were block-randomised,
using a random number generator, into six intervention groups (all of which
received weekly visits from a community health promoter for the first 6 months
and every 2 weeks for the next 18 months) and a double-sized control group (no
intervention or health promoter visit). The six intervention groups were:</p>
<ol style="list-style-type: decimal">
<li>chlorinated drinking water;</li>
<li>improved sanitation;</li>
<li>handwashing with soap;</li>
<li>combined water, sanitation, and hand washing;</li>
<li>improved nutrition through counseling and provision of lipid-based nutrient
supplements; and</li>
<li>combined water, sanitation, handwashing, and nutrition.</li>
</ol>
<p>In the workshop, we concentrate on child growth (size for age) as the outcome of
interest. For reference, this trial was registered with ClinicalTrials.gov as
NCT01590095.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(here)
<span class="kw">library</span>(tidyverse)

<span class="co"># read in data</span>
dat &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="kw">here</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;washb_data.csv&quot;</span>))
dat</code></pre>
<pre><code># A tibble: 4,695 x 28
     whz tr    fracode month  aged sex   momage momedu momheight hfiacat Nlt18
   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;
 1  0    Cont… N05265      9   268 male      30 Prima…      146. Food S…     3
 2 -1.16 Cont… N05265      9   286 male      25 Prima…      149. Modera…     2
 3 -1.05 Cont… N08002      9   264 male      25 Prima…      152. Food S…     1
 4 -1.26 Cont… N08002      9   252 fema…     28 Prima…      140. Food S…     3
 5 -0.59 Cont… N06531      9   336 fema…     19 Secon…      151. Food S…     2
 6 -0.51 Cont… N06531      9   304 male      20 Secon…      154. Severe…     0
 7 -2.46 Cont… N08002      9   336 fema…     19 Prima…      151. Food S…     2
 8 -0.6  Cont… N06528      9   312 fema…     25 No ed…      142. Food S…     2
 9 -0.23 Cont… N06528      9   322 male      30 Secon…      153. Food S…     1
10 -0.14 Cont… N06453      9   376 male      30 No ed…      156. Modera…     2
# … with 4,685 more rows, and 17 more variables: Ncomp &lt;dbl&gt;, watmin &lt;dbl&gt;,
#   elec &lt;dbl&gt;, floor &lt;dbl&gt;, walls &lt;dbl&gt;, roof &lt;dbl&gt;, asset_wardrobe &lt;dbl&gt;,
#   asset_table &lt;dbl&gt;, asset_chair &lt;dbl&gt;, asset_khat &lt;dbl&gt;, asset_chouki &lt;dbl&gt;,
#   asset_tv &lt;dbl&gt;, asset_refrig &lt;dbl&gt;, asset_bike &lt;dbl&gt;, asset_moto &lt;dbl&gt;,
#   asset_sewmach &lt;dbl&gt;, asset_mobile &lt;dbl&gt;</code></pre>
<p>For the purposes of this workshop, we we start by treating the data as
independent and identically distributed (i.i.d.) random draws from a very large
target population. We could, with available options, account for the clustering
of the data (within sampled geographic units), but, for simplification, we avoid
these details in these workshop presentations, although modifications of our
methodology for biased samples, repeated measures, etc., are available.</p>
<p>We have 28 variables measured, of which 1 variable is set to be the outcome of
interest. This outcome, <span class="math inline">\(Y\)</span>, is the weight-for-height Z-score (<code>whz</code> in <code>dat</code>);
the treatment of interest, <span class="math inline">\(A\)</span>, is the randomized treatment group (<code>tr</code> in
<code>dat</code>); and the adjustment set, <span class="math inline">\(W\)</span>, consists simply of <em>everything else</em>. This
results in our observed data structure being <span class="math inline">\(n\)</span> i.i.d. copies of <span class="math inline">\(O_i = (W_i, A_i, Y_i)\)</span>, for <span class="math inline">\(i = 1, \ldots, n\)</span>.</p>
<p>Using the <a href="https://CRAN.R-project.org/package=skimr"><code>skimr</code> package</a>, we can
quickly summarize the variables measured in the WASH Benefits data set:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(skimr)
<span class="kw">skim</span>(dat)</code></pre>
<pre><code>Skim summary statistics
 n obs: 4695 
 n variables: 28 

── Variable type:character ─────────────────────────────────────────────────────
 variable missing complete    n min max empty n_unique
  fracode       0     4695 4695   2   6     0       20
  hfiacat       0     4695 4695  11  24     0        4
   momedu       0     4695 4695  12  15     0        3
      sex       0     4695 4695   4   6     0        2
       tr       0     4695 4695   3  15     0        7

── Variable type:numeric ───────────────────────────────────────────────────────
       variable missing complete    n    mean    sd     p0    p25   p50    p75
           aged       0     4695 4695 266.32  52.17  42    230    266   303   
     asset_bike       0     4695 4695   0.32   0.47   0      0      0     1   
    asset_chair       0     4695 4695   0.73   0.44   0      0      1     1   
   asset_chouki       0     4695 4695   0.78   0.41   0      1      1     1   
     asset_khat       0     4695 4695   0.61   0.49   0      0      1     1   
   asset_mobile       0     4695 4695   0.86   0.35   0      1      1     1   
     asset_moto       0     4695 4695   0.066  0.25   0      0      0     0   
   asset_refrig       0     4695 4695   0.079  0.27   0      0      0     0   
  asset_sewmach       0     4695 4695   0.065  0.25   0      0      0     0   
    asset_table       0     4695 4695   0.73   0.44   0      0      1     1   
       asset_tv       0     4695 4695   0.3    0.46   0      0      0     1   
 asset_wardrobe       0     4695 4695   0.17   0.37   0      0      0     0   
           elec       0     4695 4695   0.6    0.49   0      0      1     1   
          floor       0     4695 4695   0.11   0.31   0      0      0     0   
         momage      18     4677 4695  23.91   5.24  14     20     23    27   
      momheight      31     4664 4695 150.5    5.23 120.65 147.05 150.6 154.06
          month       0     4695 4695   6.45   3.33   1      4      6     9   
          Ncomp       0     4695 4695  11.04   6.35   2      6     10    14   
          Nlt18       0     4695 4695   1.6    1.25   0      1      1     2   
           roof       0     4695 4695   0.99   0.12   0      1      1     1   
          walls       0     4695 4695   0.72   0.45   0      0      1     1   
         watmin       0     4695 4695   0.95   9.48   0      0      0     1   
            whz       0     4695 4695  -0.59   1.03  -4.67  -1.28  -0.6   0.08
   p100     hist
 460    ▁▁▂▇▇▅▁▁
   1    ▇▁▁▁▁▁▁▃
   1    ▃▁▁▁▁▁▁▇
   1    ▂▁▁▁▁▁▁▇
   1    ▅▁▁▁▁▁▁▇
   1    ▁▁▁▁▁▁▁▇
   1    ▇▁▁▁▁▁▁▁
   1    ▇▁▁▁▁▁▁▁
   1    ▇▁▁▁▁▁▁▁
   1    ▃▁▁▁▁▁▁▇
   1    ▇▁▁▁▁▁▁▃
   1    ▇▁▁▁▁▁▁▂
   1    ▆▁▁▁▁▁▁▇
   1    ▇▁▁▁▁▁▁▁
  60    ▅▇▅▂▁▁▁▁
 168    ▁▁▁▂▇▇▂▁
  12    ▅▃▇▃▂▇▃▅
  52    ▇▇▃▁▁▁▁▁
  10    ▇▃▂▁▁▁▁▁
   1    ▁▁▁▁▁▁▁▇
   1    ▃▁▁▁▁▁▁▇
 600    ▇▁▁▁▁▁▁▁
   4.97 ▁▁▅▇▃▁▁▁</code></pre>
<p>A convenient summary of the relevant variables is given just above, complete
with a small visualization describing the marginal characteristics of each
covariate. Note that the <em>asset</em> variables reflect socio-economic status of the
study participants. Notice also the uniform distribution of the treatment groups
(with twice as many controls); this is, of course, by design.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-pearl2009causality">
<p>Pearl, Judea. 2009a. <em>Causality: Models, Reasoning, and Inference</em>. Cambridge University Press.</p>
</div>
<div id="ref-luby2018effects">
<p>“Temporary.” n.d.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="motivation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="tlverse.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/tlverse/tlverse-handbook/edit/master/02-intro.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["handbook.pdf", "handbook.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
