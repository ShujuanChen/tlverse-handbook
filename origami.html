<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 5 Cross-validation | Targeted Learning in R</title>
<meta name="author" content="Mark van der Laan, Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips, Alan Hubbard">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.4.9002/tabs.js"></script><script src="libs/bs3compat-0.2.4.9002/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script><link href="libs/vis-4.20.1/vis.css" rel="stylesheet">
<script src="libs/vis-4.20.1/vis.min.js"></script><script src="libs/visNetwork-binding-2.0.9/visNetwork.js"></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="Causal Data Science with the tlverse Software Ecosystem">Targeted Learning in R</a>:
        <small class="text-muted">Causal Data Science with the tlverse Software Ecosystem</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">About this book</a></li>
<li><a class="" href="robust.html"><span class="header-section-number">1</span> Robust Statistics and Reproducible Science</a></li>
<li><a class="" href="intro.html"><span class="header-section-number">2</span> The Roadmap for Targeted Learning</a></li>
<li><a class="" href="tlverse.html"><span class="header-section-number">3</span> Welcome to the tlverse</a></li>
<li><a class="" href="data.html"><span class="header-section-number">4</span> Meet the Data</a></li>
<li><a class="active" href="origami.html"><span class="header-section-number">5</span> Cross-validation</a></li>
<li><a class="" href="tmle3.html"><span class="header-section-number">6</span> The TMLE Framework</a></li>
<li><a class="" href="optimal-individualized-treatment-regimes.html"><span class="header-section-number">7</span> Optimal Individualized Treatment Regimes</a></li>
<li><a class="" href="stochastic-treatment-regimes.html"><span class="header-section-number">8</span> Stochastic Treatment Regimes</a></li>
<li><a class="" href="r6.html"><span class="header-section-number">9</span> A Primer on the R6 Class System</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/tlverse/tlverse-handbook">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="origami" class="section level1">
<h1>
<span class="header-section-number">5</span> Cross-validation<a class="anchor" aria-label="anchor" href="#origami"><i class="fas fa-link"></i></a>
</h1>
<p><em>Ivana Malenica</em></p>
<p>Based on the <a href="https://github.com/tlverse/origami"><code>origami</code> <code>R</code> package</a>
by <em>Jeremy Coyle, Nima Hejazi, Ivana Malenica and Rachael Phillips</em>.</p>
<p>Updated: 2021-03-11</p>
<div id="learning-objectives-2" class="section level2">
<h2>
<span class="header-section-number">5.1</span> Learning Objectives<a class="anchor" aria-label="anchor" href="#learning-objectives-2"><i class="fas fa-link"></i></a>
</h2>
<ol style="list-style-type: decimal">
<li>Differentiate between training, validation and test sets.</li>
<li>Understand the concept of a loss function, risk and cross-validation.</li>
<li>Select a loss function that is appropriate for the functional parameter to be
estimated.</li>
<li>Understand and contrast different cross-validation schemes for i.i.d. data.</li>
<li>Understand and contrast different cross-validation schemes for time dependent
data.</li>
<li>Setup the proper fold structure, build custom fold-based function, and
cross-validate the proposed function using the <code>origami</code> <code>R</code> package.</li>
<li>Setup the proper cross-validation structure for the use by the Super Learner
using the the <code>origami</code> <code>R</code> package.</li>
</ol>
</div>
<div id="introduction-1" class="section level2">
<h2>
<span class="header-section-number">5.2</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-1"><i class="fas fa-link"></i></a>
</h2>
<p>In this chapter, we start elaborating on the estimation step outlined in the
<a href="intro.html#intro">introductory chapter</a>, which discussed the <a href="intro.html#roadmap"><em>Roadmap for Targeted
Learning</em></a>. In order to generate an initial estimate of our target
parameter – which is the focus of the following <a href="#sl3">chapter on Super
Learning</a>, we first need to translate, and incorporate, our knowledge
about the data generating process into the estimation procedure, and decide how
to evaluate our estimation performance.</p>
<p>The performance, or error, of any algorithm used in the estimation procedure
directly relates to its generalizability on the independent data. The proper
assessment of the performance of proposed algorithms is extremely important; it
guides the choice of the final learning method, and it gives us a quantitative
assessment of how good the chosen algorithm is doing. In order to assess the
performance of an algorithm, we introduce the concept of a <strong>loss</strong> function,
which helps us define the <strong>risk</strong>, also referred to as the <strong>expected
prediction error</strong>. Our goal, as further specified in the next chapter, will be
to estimate the true risk of the proposed statistical learning method. Our
goal(s) consist of:</p>
<ol style="list-style-type: decimal">
<li>Estimating the performance of different algorithms in order to choose the
best one.</li>
<li>Having chosen a winner, try to estimate the true risk of the proposed
statistical learning method.</li>
</ol>
<p>In the following, we propose a method to do so using the observed data and
<strong>cross-validation</strong> procedure using the <code>origami</code> package <span class="citation">(Coyle and Hejazi <a href="references.html#ref-coyle2018origami">2018</a>)</span>.</p>
</div>
<div id="background" class="section level2">
<h2>
<span class="header-section-number">5.3</span> Background<a class="anchor" aria-label="anchor" href="#background"><i class="fas fa-link"></i></a>
</h2>
<p>Ideally, in a data-rich scenario, we would split our dataset into three parts:</p>
<ol style="list-style-type: decimal">
<li>training set,</li>
<li>validation set,</li>
<li>test set.</li>
</ol>
<p>The training set is used to fit algorithm(s) of interest; we evaluate the
performance of the fit(s) on a validation set, which can be used to estimate
prediction error (e.g., for tuning and model selection). The final error of the
chosen algorithm(s) is obtained by using the test set, which is kept separately,
and doesn’t see the data before the final evaluation. One might wonder, with
training data readily available, why not use the training error to evaluate the
proposed algorithm’s performance? Unfortunately, the training error is not a
good estimate of the true risk; it consistently decreases with model complexity,
resulting in a possible overfit to the training data and low generalizability.</p>
<p>Since data are often scarce, separating it into training, validation and test
set is usually not possible. In the absence of a large data set and a designated
test set, we must resort to methods that estimate the true risk by efficient
sample re-use. Re-sampling methods, in great generality, involve repeatedly
sampling from the training set and fitting proposed algorithms on the new
samples. While often computationally intensive, re-sampling methods are
particularly useful for model selection and estimation of the true risk. In
addition, they might provide more insight on variability and robustness of the
algorithm fit then fitting an algorithm only once on all the training data.</p>
<div id="introducing-cross-validation" class="section level3">
<h3>
<span class="header-section-number">5.3.1</span> Introducing: cross-validation<a class="anchor" aria-label="anchor" href="#introducing-cross-validation"><i class="fas fa-link"></i></a>
</h3>
<p>In this chapter, we focus on <strong>cross-validation</strong> – an essential tool for
evaluating how any given algorithm extends from a sample to the target
population from which the sample is derived. It has seen widespread application
in all facets of statistics, perhaps most notably statistical machine learning.
The cross-validation procedure can be used for model selection, as well as for
estimation of the true risk associated with any statistical learning method in
order to evaluate its performance. It particular, cross-validation directly
estimates the true risk when the estimate is applied to an independent sample
from the joint distribution of the predictors and outcome. When used for model
selection, cross-validation has powerful optimality properties. The asymptotic
optimality results state that the cross-validated selector performs (in terms of
risk) asymptotically as well as an optimal oracle selector based on the true,
unknown data generating distribution. For further details on the theoretical
results, we suggest <span class="citation">van der Laan, Dudoit, and Keles (<a href="references.html#ref-vdl2004asymptotic">2004</a>)</span>, <span class="citation">Dudoit and van der Laan (<a href="references.html#ref-dudoit2005asymptotics">2005</a>)</span> and
<span class="citation">Van der Vaart, Dudoit, and Laan (<a href="references.html#ref-vaart2006oracle">2006</a>)</span>.</p>
<p>In great generality, cross-validation works by partitioning a sample into
complementary subsets, applying a particular algorithm(s) on a subset (the
training set), and evaluating the method of choice on the complementary subset
(the validation/test set). This procedure is repeated across multiple partitions
of the data. A variety of different partitioning schemes exist, depending on the
problem of interest, data size, prevalence of the outcome, and dependence
structure. The <code>origami</code> package provides a suite of tools that generalize the
application of cross-validation to arbitrary data analytic procedures. In the
the following, we describe different types of cross-validation schemes readily
available in <code>origami</code>, introduce the general structure of the <code>origami</code>
package, and show their use in applied settings.</p>
<hr>
</div>
</div>
<div id="estimation-roadmap-how-does-it-all-fit-together" class="section level2">
<h2>
<span class="header-section-number">5.4</span> Estimation Roadmap: how does it all fit together?<a class="anchor" aria-label="anchor" href="#estimation-roadmap-how-does-it-all-fit-together"><i class="fas fa-link"></i></a>
</h2>
<p>Similarly to how we defined the <a href="intro.html#roadmap"><em>Roadmap for Targeted Learning</em></a>, we
can define the <strong>Estimation Roadmap</strong> to guide the estimation process. In
particular, we have developed a unified loss-based cross-validation methodology
for estimator construction, selection, and performance assessment in a series of
articles (e.g., see <span class="citation">van der Laan, Dudoit, and Keles (<a href="references.html#ref-vdl2004asymptotic">2004</a>)</span>, <span class="citation">Dudoit and van der Laan (<a href="references.html#ref-dudoit2005asymptotics">2005</a>)</span>,
<span class="citation">Van der Vaart, Dudoit, and Laan (<a href="references.html#ref-vaart2006oracle">2006</a>)</span>, and <span class="citation">van der Laan, Polley, and Hubbard (<a href="references.html#ref-vdl2007super">2007</a>)</span>) that follow three main steps:</p>
<ol style="list-style-type: decimal">
<li><p><strong>The loss funtion</strong>:
Define the target parameter as the minimizer of the expected loss (risk) for a
full data loss function chosen to represent the desired performance measure.
Map the full data loss function into an observed data loss function, having the
same expected value and leading to an efficient estimator of risk.</p></li>
<li><p><strong>The algorithms</strong>:
Construct a finite collection of candidate estimators for the parameter of
interest.</p></li>
<li><p><strong>The cross-validation scheme</strong>:
Apply appropriate cross-validation to select an optimal estimator among the
candidates, and assess the overall performance of the resulting estimator.</p></li>
</ol>
<p>Step 1 of the Estimation Roadmap allows us to unify a broad range of problems
that are traditionally treated separately in the statistical literature,
including density estimation, prediction of polychotomous and continuous
outcomes. For example, if we are interested in estimating the full joint
conditional density, we could use the negative log-likelihood loss. If instead
we are interested in the conditional mean with continuous outcome, one could use
the squared error loss; had the outcome been binary, one could resort to the
indicator (0-1) loss. The unified loss-based framework also reconciles censored
and full data estimation methods, as full data estimators are recovered as
special cases of censored data estimators.</p>
</div>
<div id="example-cross-validation-and-prediction" class="section level2">
<h2>
<span class="header-section-number">5.5</span> Example: cross-validation and prediction<a class="anchor" aria-label="anchor" href="#example-cross-validation-and-prediction"><i class="fas fa-link"></i></a>
</h2>
<p>Now that we introduced the Estimation Roadmap, we can define our objective with
more mathematical notation, using prediction as an example. Let the observed
data be defined as <span class="math inline">\(X = (W,Y)\)</span>, where a unit specific data can be written as
<span class="math inline">\(X_i = (W_i,Y_i)\)</span>, for <span class="math inline">\(i = 1, \ldots, n\)</span>. For each of the <span class="math inline">\(n\)</span> samples, we
denote <span class="math inline">\(Y_i\)</span> as the outcome of interest (polychotomous or continuous), and <span class="math inline">\(W_i\)</span>
as a <span class="math inline">\(p\)</span>-dimensional set of covariates. Let <span class="math inline">\(\psi_0(W)\)</span> denote the target
parameter of interest we want to estimate; for this example, we are interested
in estimating the conditional expectation of the outcome given the covariates,
<span class="math inline">\(\psi_0(W) = E(Y \mid W)\)</span>. Following the Estimation Roadmap, we chose the
appropriate loss function, <span class="math inline">\(L\)</span>, such that <span class="math inline">\(\psi_0(W) = \text{argmin}_{\psi} E[L(X,\psi(W))]\)</span>. But how do we know how each <span class="math inline">\(\psi\)</span> is doing? In order to pick
the optimal estimator among the candidates, and assess the overall performance
of the resulting estimator, use cross-validation – dividing the available data
into the training set and validation set. Observations in the training set are
used to fit (or train) the estimator, while the validation set is used to assess
the risk of (or validate) it.</p>
<p>To derive a general representation for cross-validation, we define a <strong>split
vector</strong>, <span class="math inline">\(B_n = (B_n(i): i = 1, \ldots, n) \in \{0,1\}^n\)</span>. Note that split
vector is independent of the empirical distribution, <span class="math inline">\(P_n\)</span>. A realization of
<span class="math inline">\(B_n\)</span> defines a random split of the data into a training and validation set such
that if
<span class="math display">\[B_n(i) = 0, \ \ \text{i sample is in the training set}\]</span>
<span class="math display">\[B_n(i) = 1, \ \ \text{i sample is in the validation set.}\]</span>
We can further define <span class="math inline">\(P_{n,B_n}^0\)</span> and <span class="math inline">\(P_{n,B_n}^1\)</span> as the empirical
distributions of the training and validation sets, respectively. Then <span class="math inline">\(n_0 = \sum_i 1-B_n(i)\)</span> and <span class="math inline">\(n_1 = \sum_i B_n(i)\)</span> denote the number of samples in each
set. The particular distribution of the split vector <span class="math inline">\(B_n\)</span> defines the type of
cross-validation scheme, tailored to the problem and data set in hand.</p>
</div>
<div id="cross-validation-schemes-in-origami" class="section level2">
<h2>
<span class="header-section-number">5.6</span> Cross-validation schemes in <code>origami</code><a class="anchor" aria-label="anchor" href="#cross-validation-schemes-in-origami"><i class="fas fa-link"></i></a>
</h2>
<p>As we specified earlier, the particular distribution of the split vector <span class="math inline">\(B_n\)</span>
defines the type of cross-validation method. In the following, we describe
different types of cross-validation schemes available in <code>origami</code> package, and
show their use in the sequel.</p>
<div id="wash-benefits-study-example" class="section level3 unnumbered">
<h3>WASH Benefits Study Example<a class="anchor" aria-label="anchor" href="#wash-benefits-study-example"><i class="fas fa-link"></i></a>
</h3>
<p>In order to illustrate different cross-validation schemes, we will be using the
WASH data. Detailed information on the WASH Benefits Example Dataset can be
found in <span id="data">Chapter 3</span>. In particular, we are interested in predicting
weight-for-height z-score <code>whz</code> using the available covariate data. For this
illustration, we will start by treating the data as independent and identically
distributed (i.i.d.) random draws. To see what each cross-validation scheme is
doing, we will subset the data to only <span class="math inline">\(n=30\)</span>. Note that each row represents an
i.i.d. sample, indexed by the row number.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://r-datatable.com">data.table</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tlverse.org/origami">origami</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://yihui.org/knitr/">knitr</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://haozhu233.github.io/kableExtra/">kableExtra</a></span><span class="op">)</span>

<span class="co"># load data set and take a peek</span>
<span class="va">washb_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/fread.html">fread</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span>
    <span class="st">"https://raw.githubusercontent.com/tlverse/tlverse-data/master/"</span>,
    <span class="st">"wash-benefits/washb_data.csv"</span>
  <span class="op">)</span>,
  stringsAsFactors <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span>

<span class="va">washb_data</span> <span class="op">&lt;-</span> <span class="va">washb_data</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">30</span>, <span class="op">]</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html">kable</a></span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">kableExtra</span><span class="fu">:::</span><span class="fu"><a href="https://rdrr.io/pkg/kableExtra/man/kable_styling.html">kable_styling</a></span><span class="op">(</span>fixed_thead <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/pkg/kableExtra/man/scroll_box.html">scroll_box</a></span><span class="op">(</span>width <span class="op">=</span> <span class="st">"100%"</span>, height <span class="op">=</span> <span class="st">"300px"</span><span class="op">)</span></code></pre></div>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; ">
<div class="inline-table"><table class="table" style="margin-left: auto; margin-right: auto;">
<thead><tr>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
whz
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
tr
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
fracode
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
month
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
aged
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
sex
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momage
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momedu
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momheight
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
hfiacat
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
Nlt18
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
Ncomp
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
watmin
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
elec
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
floor
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
walls
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
roof
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_wardrobe
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_table
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_chair
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_khat
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_chouki
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_tv
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_refrig
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_bike
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_moto
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_sewmach
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_mobile
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N05265
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
268
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
146.40
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.16
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N05265
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
286
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
148.75
</td>
<td style="text-align:left;">
Moderately Food Insecure
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.05
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N08002
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
264
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
152.15
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.26
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N08002
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
252
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
28
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
140.25
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.59
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N06531
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
336
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:left;">
Secondary (&gt;5y)
</td>
<td style="text-align:right;">
150.95
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.51
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N06531
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
304
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:left;">
Secondary (&gt;5y)
</td>
<td style="text-align:right;">
154.20
</td>
<td style="text-align:left;">
Severely Food Insecure
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
</tbody>
</table></div>
</div>
</div>
<div id="cross-validation-for-i.i.d.-data" class="section level3">
<h3>
<span class="header-section-number">5.6.1</span> Cross-validation for i.i.d. data<a class="anchor" aria-label="anchor" href="#cross-validation-for-i.i.d.-data"><i class="fas fa-link"></i></a>
</h3>
<div id="re-substitution" class="section level4">
<h4>
<span class="header-section-number">5.6.1.1</span> Re-substitution<a class="anchor" aria-label="anchor" href="#re-substitution"><i class="fas fa-link"></i></a>
</h4>
<p>The re-substitution method is the simplest strategy for estimating the risk
associated with fitting a proposed algorithm on a set of observations. Here, all
observed data is used for both training and validation set.</p>
<p>We illustrate the usage of the re-substitution method with <code>origami</code> package
below; we will use the function <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_resubstitution(n)</a></code>. In order to setup
<code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_resubstitution(n)</a></code>, we just need the total number of samples we want to
allocate to training and validation sets; remember that each row of data is a
unique i.i.d. sample. Notice the structure of the <code>origami</code> output:</p>
<ol style="list-style-type: decimal">
<li>v: the cross-validation fold</li>
<li>training_set: the indexes of the samples in the training set</li>
<li>validation_set: the indexes of the samples in the training set.</li>
</ol>
<p>This structure of the <code>origami</code> output (fold(s)) will persist for each of the
cross-validation schemes we present in this chapter. Below, we show the fold
generated by the re-substitution method:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_resubstitution</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; [[1]]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25</span>
<span class="co">#&gt; [26] 26 27 28 29 30</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25</span>
<span class="co">#&gt; [26] 26 27 28 29 30</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span></code></pre></div>
</div>
<div id="holdout-method" class="section level4">
<h4>
<span class="header-section-number">5.6.1.2</span> Holdout method<a class="anchor" aria-label="anchor" href="#holdout-method"><i class="fas fa-link"></i></a>
</h4>
<p>The holdout method, or the validation set approach, consists of randomly
dividing the available data into the training set and validation set (holdout
set). The model is then fitted on the training set, and further evaluated on
the observations in the validation set. Typically, the data is split into
<span class="math inline">\(60/40\)</span>, <span class="math inline">\(70/30\)</span> or <span class="math inline">\(80/20\)</span> splits.</p>
<p>The holdout method is intuitive, conceptually easy, and computationally not too
demanding. However, if we repeat the process of randomly splitting the data into
the training and validation set, we might get a different validation loss (e.g.,
MSE). In particular, the loss over the validation sets might be highly
variable, depending on which samples were included in the training/validation
split. For classification problems, there is a possibility of an uneven
distribution of different classes in the training and validation set unless data
is stratified. Finally, note that we are not using all of the data to train and
evaluate the performance of the proposed algorithm, which might result in bias.</p>
</div>
<div id="leave-one-out" class="section level4">
<h4>
<span class="header-section-number">5.6.1.3</span> Leave-one-out<a class="anchor" aria-label="anchor" href="#leave-one-out"><i class="fas fa-link"></i></a>
</h4>
<p>The leave-one-out cross-validation scheme is closely related to the holdout
method. In particular, it also involves splitting the data into the training and
validation set; however, instead of partitioning the observed data into sets of
similar size, a single observation is used as a validation set. With that,
majority of the units are employed for training (fitting) the proposed
algorithm. Since only one unit (for example <span class="math inline">\(x_1 = (w_1, y_1)\)</span>) is not used in
the fitting process, leave-one-out cross-validation results in a possibly less
biased estimate of the true risk; typically, leave-one-out approach will not
overestimate the risk as much as the holdout method. On the other hand, since
the estimate of risk is based on a single sample, it is typically a highly
variable estimate.</p>
<p>We can repeat the process of spiting the data into training and validation set
until all samples are part of the validation set at some point. For example,
next iteration of the cross-validation might have <span class="math inline">\(x_2 = (w_2,y_2)\)</span> as the
validation set and all the rest of <span class="math inline">\(n-1\)</span> samples as the training set. Repeating
this approach <span class="math inline">\(n\)</span> times results in, for example, <span class="math inline">\(n\)</span> squared errors <span class="math inline">\(MSE_1, MSE_2, \ldots, MSE_n\)</span>. The estimate of the true risk is the average over the
<span class="math inline">\(n\)</span> squared errors. While the leave-one-out cross-validation results in a less
biased (albeit, more variable) estimate of risk than the holdout method, it
could be expensive to implement if <span class="math inline">\(n\)</span> is large.</p>
<p>We illustrate the usage of the leave-one-out cross-validation with <code>origami</code>
package below; we will use the function <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_loo(n)</a></code>. In order to setup
<code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_loo(n)</a></code>, similarly to the re-substitution method, we just need the total
number of samples we want to cross-validate. We show the first two folds
generated by the leave-one-out cross-validation below.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">folds</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_loo</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span><span class="op">)</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26</span>
<span class="co">#&gt; [26] 27 28 29 30</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26</span>
<span class="co">#&gt; [26] 27 28 29 30</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span></code></pre></div>
</div>
<div id="v-fold" class="section level4">
<h4>
<span class="header-section-number">5.6.1.4</span> V-fold<a class="anchor" aria-label="anchor" href="#v-fold"><i class="fas fa-link"></i></a>
</h4>
<p>An alternative to leave-one-out is V-fold cross-validation. This
cross-validation scheme randomly divides the data into <span class="math inline">\(v\)</span> sets (folds) of equal
size; for each fold, the number of samples in the validation set are the same.
For V-fold cross-validation, one of the folds is treated as a validation set,
whereas the proposed algorithm is fit on the remaining <span class="math inline">\(v-1\)</span> folds in the
training set. The loss, for example MSE, is computed on the samples in the
validation set. With the proposed algorithm trained and its performance
evaluated on the first fold, we repeat this process <span class="math inline">\(v\)</span> times; each time, a
different group of samples is treated as a validation set. Note that with V-fold
cross-validation we effectively use all of the data to train and evaluate the
proposed algorithm without overfitting to the training data. In the end, the
V-fold cross-validation results in <span class="math inline">\(v\)</span> estimates of validation error. The final
V-fold CV estimate is computed as an average over all the validation losses.</p>
<p>For a dataset with <span class="math inline">\(n\)</span> samples, V-fold cross-validation with <span class="math inline">\(v=n\)</span> is just
leave-one-out; similarly, if we set <span class="math inline">\(n=1\)</span>, we can get the holdout method’s
estimate of algorithm’s performance. Despite the obvious computational
advantages, V-fold cross-validation often gives more accurate estimates of the
true risk. The reason for this comes from the bias-variance trade-off that comes
from employing both methods; while leave-one-out might be less biased, it has
higher variance. This difference becomes more obvious as <span class="math inline">\(v&lt;&lt;n\)</span> (but not too
small, as then we increase bias). With V-fold cross-validation, we end up
averaging output from <span class="math inline">\(v\)</span> fits that are typically less correlated than the
outputs from leave-one-out fits. Since the mean of many highly correlated
quantities has higher variance, leave-one-out estimate of the risk will also
have higher variance than the estimate based on V-fold cross-validation.</p>
<p>Let’s see V-fold cross-validation with <code>origami</code> in action! In the next chapter
we will study the Super Learner, an actual algorithm that we fit and evaluate
its performance, that uses V-fold as default cross-validation scheme. In order
to set up V-fold CV, we need to call function <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_vfold(n, V)</a></code>. Arguments
for <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_vfold(n, V)</a></code> require the total number of samples to be
cross-validated, and the number of folds we want to get.</p>
<p>At <span class="math inline">\(V=2\)</span>, we get 2 folds with <span class="math inline">\(n/2\)</span> number of samples in both training and
validation set.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">folds</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_vfold</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span>, V <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  2  3  4  6  7  8 11 12 14 15 19 22 23 24 28</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1]  1  5  9 10 13 16 17 18 20 21 25 26 27 29 30</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  1  5  9 10 13 16 17 18 20 21 25 26 27 29 30</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1]  2  3  4  6  7  8 11 12 14 15 19 22 23 24 28</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span></code></pre></div>
</div>
<div id="monte-carlo" class="section level4">
<h4>
<span class="header-section-number">5.6.1.5</span> Monte Carlo<a class="anchor" aria-label="anchor" href="#monte-carlo"><i class="fas fa-link"></i></a>
</h4>
<p>With Monte Carlo cross-validation, we randomly select some fraction of the data
(without replacement) to form the training set; we assign the rest of the
samples to the validation set. With that, the data is repeatedly and randomly
divided into two sets, a training set of <span class="math inline">\(n_0 = n \cdot (1-p)\)</span> observations and
a validation set of <span class="math inline">\(n_1 = n \cdot p\)</span> observations. This process is then
repeated multiple times, generating (at random) new training and validation
partitions each time.</p>
<p>Since the partitions are independent across folds, the same sample can appear in
the validation set multiple times – note that this is a stark difference
between Monte Carlo and V-fold cross-validation. With Monte Carlo
cross-validation, one is able to explore many more available partitions than
with V-fold cross-validation – resulting in a possibly less variable estimate
of the risk, at a cost of an increase in bias.</p>
<p>We illustrate the usage of the Monte Carlo cross-validation with <code>origami</code>
package below using the function <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_montecarlo(n, V, pvalidation)</a></code>. In order
to setup <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_montecarlo(n, V, pvalidation)</a></code>, we need:</p>
<ol style="list-style-type: decimal">
<li>the total number of samples we want to cross-validate;</li>
<li>the number of folds;</li>
<li>the proportion of observations to be placed in the validation set.</li>
</ol>
<p>At <span class="math inline">\(V=2\)</span> and <span class="math inline">\(pvalidation=0.2\)</span>, we obtain 2 folds with approximately <span class="math inline">\(6\)</span> samples
in validation set per fold.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">folds</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_montecarlo</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span>, V <span class="op">=</span> <span class="fl">2</span>, pvalidation <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1] 19 27 16 29 23 12  1  3 18 11  5  7  8  6  9 22 10 25 20 28 15  2 24 26</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt; [1]  4 13 14 17 21 30</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1] 19 15 28 25 29 11 20 17 14  4  9 12 30  8 27 18 16 10 13  6 24  3 26  1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt; [1]  2  5  7 21 22 23</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span></code></pre></div>
</div>
<div id="bootstrap" class="section level4">
<h4>
<span class="header-section-number">5.6.1.6</span> Bootstrap<a class="anchor" aria-label="anchor" href="#bootstrap"><i class="fas fa-link"></i></a>
</h4>
<p>The bootstrap cross-validation also consists of randomly selecting samples, with
replacement, for the training set. The rest of the samples not picked for the
training set are allocated to the validation set. This process is then repeated
multiple times, generating (at random) new training and validation partitions
each time. In contract to the Monte Carlo cross-validation, the total number of
samples in a training and validation size across folds is not constant. We also
sample with replacement, hence the same samples can be in multiple training
sets. The proportion of observations in the validation sets is a random
variable, with expectation <span class="math inline">\(\sim 0.368\)</span>.</p>
<p>We illustrate the usage of the bootstrap cross-validation with <code>origami</code> package
below using the function <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_bootstrap(n, V)</a></code>. In order to setup
<code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_bootstrap(n, V)</a></code>, we need:</p>
<ol style="list-style-type: decimal">
<li>the total number of samples we want to cross-validate;</li>
<li>the number of folds.</li>
</ol>
<p>At <span class="math inline">\(V=2\)</span>, we obtain <span class="math inline">\(2\)</span> folds with different number of samples in the validation
set across folds.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">folds</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_bootstrap</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span>, V <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  2  5 30  1 29 16 10 11  8 25 28  2 11  2 16 28 15 28  1 27  9 19 20 30 18</span>
<span class="co">#&gt; [26] 11 13  2 18 12</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1]  3  4  6  7 14 17 21 22 23 24 26</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1] 12 16 10 29 22 15 27  9 27 16 12 28 10 28 26  1 14  6 23 14 21 16  5 20  8</span>
<span class="co">#&gt; [26] 23 25  8 27  5</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1]  2  3  4  7 11 13 17 18 19 24 30</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span></code></pre></div>
</div>
</div>
<div id="cross-validation-for-dependent-data" class="section level3">
<h3>
<span class="header-section-number">5.6.2</span> Cross-validation for dependent data<a class="anchor" aria-label="anchor" href="#cross-validation-for-dependent-data"><i class="fas fa-link"></i></a>
</h3>
<p>The <code>origami</code> package also supports numerous cross-validation schemes for
time-series data, for both single and multiple time-series with arbitrary time
and network dependence.</p>
</div>
<div id="airpassenger-example" class="section level3 unnumbered">
<h3>AirPassenger Example<a class="anchor" aria-label="anchor" href="#airpassenger-example"><i class="fas fa-link"></i></a>
</h3>
<p>In order to illustrate different cross-validation schemes for time-series, we
will be using the AirPassenger data; this is a widely used, freely available
dataset. The AirPassenger dataset in <code>R</code> provides monthly totals of
international airline passengers from 1949 to 1960. This dataset is already of a
time series class therefore no further class or date manipulation is required.</p>
<p><strong>Goal:</strong> we want to forecast the number of airline passengers at time <span class="math inline">\(h\)</span>
horizon using the historical data from 1949 to 1960.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/sinhrks/ggfortify">ggfortify</a></span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">AirPassengers</span><span class="op">)</span>
<span class="va">AP</span> <span class="op">&lt;-</span> <span class="va">AirPassengers</span>

<span class="fu">autoplot</span><span class="op">(</span><span class="va">AP</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">labs</span><span class="op">(</span>
    x <span class="op">=</span> <span class="st">"Date"</span>,
    y <span class="op">=</span> <span class="st">"Passenger numbers (1000's)"</span>,
    title <span class="op">=</span> <span class="st">"Air Passengers from 1949 to 1961"</span>
  <span class="op">)</span>

<span class="va">t</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">AP</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="05-origami_files/figure-html/plot_airpass-1.png" width="80%" style="display: block; margin: auto;"></div>
<div id="rolling-origin" class="section level4">
<h4>
<span class="header-section-number">5.6.2.1</span> Rolling origin<a class="anchor" aria-label="anchor" href="#rolling-origin"><i class="fas fa-link"></i></a>
</h4>
<p>Rolling origin cross-validation scheme lends itself to “online” algorithms,
where large streams of data have to be fit continually, and the final fit is
constantly updated with more data acquired. In general, the rolling origin
scheme defines an initial training set, and with each iteration the size of the
training set grows by <span class="math inline">\(m\)</span> observations until we reach time <span class="math inline">\(t\)</span> for a particular
fold. The time points included in the training set are always behind the
validation set time points; in addition, there might be a gap between training
and validation times of size <span class="math inline">\(h\)</span>.</p>
<p>To further illustrate rolling origin cross-validation, we show below an example
with 3 folds. Here, the first window size is 15 time points, on which we first
train the proposed algorithm. We then evaluate its performance on 10 time
points, with a gap of size 5 between the training and validation time points.
For the following fold, we train the algorithm on a longer stream of data, 25
time points, including the original 15 we started with. We then evaluate its
performance on 10 time points in the future.</p>
<div class="figure" style="text-align: center">
<span id="fig:unnamed-chunk-1"></span>
<img src="img/image/rolling_origin.png" alt="Rolling origin CV" width="80%"><p class="caption">
FIGURE 5.1: Rolling origin CV
</p>
</div>
<p>We illustrate the usage of the rolling origin cross-validation with <code>origami</code>
package below using the function <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_rolling_origin(n, first_window, validation_size, gap, batch)</a></code>. In order to setup <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_rolling_origin(n, first_window, validation_size, gap, batch)</a></code>, we need:</p>
<ol style="list-style-type: decimal">
<li>the total number of time points we want to cross-validate</li>
<li>the size of the first training set</li>
<li>the size of the validation set</li>
<li>the gap between training and validation set</li>
<li>the size of the update on the training set per each iteration of CV</li>
</ol>
<p>Our time-series has <span class="math inline">\(t=144\)</span> time points. Setting the <code>first_window</code> to <span class="math inline">\(50\)</span>,
<code>validation_size</code> to 10, <code>gap</code> to 5 and <code>batch</code> to 20, we get 4 time-series
folds; we show the first two below.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">folds</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_rolling_origin</a></span><span class="op">(</span>
  <span class="va">t</span>,
  first_window <span class="op">=</span> <span class="fl">50</span>, validation_size <span class="op">=</span> <span class="fl">10</span>, gap <span class="op">=</span> <span class="fl">5</span>, batch <span class="op">=</span> <span class="fl">20</span>
<span class="op">)</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25</span>
<span class="co">#&gt; [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1] 56 57 58 59 60 61 62 63 64 65</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25</span>
<span class="co">#&gt; [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50</span>
<span class="co">#&gt; [51] 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1] 76 77 78 79 80 81 82 83 84 85</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span></code></pre></div>
</div>
<div id="rolling-window" class="section level4">
<h4>
<span class="header-section-number">5.6.2.2</span> Rolling window<a class="anchor" aria-label="anchor" href="#rolling-window"><i class="fas fa-link"></i></a>
</h4>
<p>Instead of adding more time points to the training set per each iteration, the
rolling window cross-validation scheme “rolls” the training sample forward by
<span class="math inline">\(m\)</span> time units. The rolling window scheme might be considered in parametric
settings when one wishes to guard against moment or parameter drift that is
difficult to model explicitly; it is also more efficient for computationally
demanding settings such as streaming data, in which large amounts of training
data cannot be stored. In contrast to rolling origin CV, the training sample for
each iteration of the rolling window scheme is always the same.</p>
<p>To illustrate the rolling window cross-validation with 3 time-series folds
below. The first window size is 15 time points, on which we first train the
proposed algorithm. As in the previous illustration, we evaluate its performance
on 10 time points, with a gap of size 5 between the training and validation time
points. However, for the next fold, we train the algorithm on time points
further away from the origin (here, 10 time points). Note that the size of the
training set in the new fold is the same as in the first fold (15 time points).
This setup keeps the training sets comparable over time (and fold) as compared
to the rolling origin CV. We then evaluate the performance of the proposed
algorithm on 10 time points in the future.</p>
<div class="figure" style="text-align: center">
<span id="fig:unnamed-chunk-2"></span>
<img src="img/image/rolling_window.png" alt="Rolling window CV" width="80%"><p class="caption">
FIGURE 5.2: Rolling window CV
</p>
</div>
<p>We illustrate the usage of the rolling window cross-validation with <code>origami</code>
package below using the function <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_rolling_window(n, window_size, validation_size, gap, batch)</a></code>. In order to setup <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_rolling_window(n, window_size, validation_size, gap, batch)</a></code>, we need:</p>
<ol style="list-style-type: decimal">
<li>the total number of time points we want to cross-validate</li>
<li>the size of the training sets</li>
<li>the size of the validation set</li>
<li>the gap between training and validation set</li>
<li>the size of the update on the training set per each iteration of CV</li>
</ol>
<p>Setting the <code>window_size</code> to <span class="math inline">\(50\)</span>, <code>validation_size</code> to 10, <code>gap</code> to 5 and
<code>batch</code> to 20, we also get 4 time-series folds; we show the first two below.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">folds</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_rolling_window</a></span><span class="op">(</span>
  <span class="va">t</span>,
  window_size <span class="op">=</span> <span class="fl">50</span>, validation_size <span class="op">=</span> <span class="fl">10</span>, gap <span class="op">=</span> <span class="fl">5</span>, batch <span class="op">=</span> <span class="fl">20</span>
<span class="op">)</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25</span>
<span class="co">#&gt; [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1] 56 57 58 59 60 61 62 63 64 65</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1] 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45</span>
<span class="co">#&gt; [26] 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1] 76 77 78 79 80 81 82 83 84 85</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span></code></pre></div>
</div>
<div id="rolling-origin-with-v-fold" class="section level4">
<h4>
<span class="header-section-number">5.6.2.3</span> Rolling origin with V-fold<a class="anchor" aria-label="anchor" href="#rolling-origin-with-v-fold"><i class="fas fa-link"></i></a>
</h4>
<p>A variant of rolling origin scheme which accounts for sample dependence is the
rolling-origin-<span class="math inline">\(V\)</span>-fold cross-validation. In contrast to the canonical rolling
origin CV, samples in the training and validation set are not the same, as the
variant encompasses <span class="math inline">\(V\)</span>-fold CV in addition to the time-series setup. The
predictions are evaluated on the future times of time-series units not seen
during the training step, allowing for dependence in both samples and time. One
can use the rolling-origin-<span class="math inline">\(v\)</span>-fold cross-validation with <code>origami</code> package
using the function <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_vfold_rolling_origin_pooled(n, t, id, time, V, first_window, validation_size, gap, batch)</a></code>. In the figure below, we show <span class="math inline">\(V=2\)</span>
<span class="math inline">\(V\)</span>-folds, and 2 time-series CV folds.</p>
<div class="figure" style="text-align: center">
<span id="fig:unnamed-chunk-3"></span>
<img src="img/image/rolling_origin_v_fold.png" alt="Rolling origin V-fold CV" width="80%"><p class="caption">
FIGURE 5.3: Rolling origin V-fold CV
</p>
</div>
</div>
<div id="rolling-window-with-v-fold" class="section level4">
<h4>
<span class="header-section-number">5.6.2.4</span> Rolling window with v-fold<a class="anchor" aria-label="anchor" href="#rolling-window-with-v-fold"><i class="fas fa-link"></i></a>
</h4>
<p>Analogous to the previous section, we can extend rolling window CV to support
multiple time-series with arbitrary sample dependence. One can use the
rolling-window-<span class="math inline">\(V\)</span>-fold cross-validation with <code>origami</code> package using the
function <code><a href="http://tlverse.org/origami/reference/fold_funs.html">folds_vfold_rolling_window_pooled(n, t, id, time, V, window_size, validation_size, gap, batch)</a></code>. In the figure below, we show <span class="math inline">\(V=2\)</span> <span class="math inline">\(V\)</span>-folds, and
2 time-series CV folds.</p>
<div class="figure" style="text-align: center">
<span id="fig:unnamed-chunk-4"></span>
<img src="img/image/rolling_window_v_fold.png" alt="Rolling window V-fold CV" width="80%"><p class="caption">
FIGURE 5.4: Rolling window V-fold CV
</p>
</div>
</div>
</div>
</div>
<div id="general-workflow-of-origami" class="section level2">
<h2>
<span class="header-section-number">5.7</span> General workflow of <code>origami</code><a class="anchor" aria-label="anchor" href="#general-workflow-of-origami"><i class="fas fa-link"></i></a>
</h2>
<p>Before we dive into more details, let’s take a moment to review some of the
basic functionality in <code>origami</code> R package. The main function in the <code>origami</code>
is <code>cross_validate</code>. To start off, the user must define folds and a function
that operates on each fold. Once these are passed to <code>cross_validate</code>, this
function will map the fold-specific function across the folds, combining the
results in a reasonable way. We will see this in action in later sections; for
now, we provide specific details on each each step of this process below.</p>
<div id="define-folds" class="section level3">
<h3>
<span class="header-section-number">5.7.1</span> (1) Define folds<a class="anchor" aria-label="anchor" href="#define-folds"><i class="fas fa-link"></i></a>
</h3>
<p>The <code>folds</code> object passed to <code>cross_validate</code> is a list of folds; such lists can
be generated using the <code>make_folds</code> function. Each fold consists of a list with
a <code>training</code> index vector, a <code>validation</code> index vector, and a <code>fold_index</code> (its
order in the list of folds). This function supports a variety of
cross-validation schemes we describe in the following section. The <code>make_folds</code>
can balance across levels of a variable (<code>stratify_ids</code>), and it can also keep
all observations from the same independent unit together (<code>cluster</code>).</p>
</div>
<div id="define-fold-function" class="section level3">
<h3>
<span class="header-section-number">5.7.2</span> (2) Define fold function<a class="anchor" aria-label="anchor" href="#define-fold-function"><i class="fas fa-link"></i></a>
</h3>
<p>The <code>cv_fun</code> argument to <code>cross_validate</code> is a function that will perform some
operation on each fold. The first argument to this function must be <code>fold</code>,
which will receive an individual fold object to operate on. Additional arguments
can be passed to <code>cv_fun</code> using the <code>...</code> argument to <code>cross_validate</code>. Within
this function, the convenience functions <code>training</code>, <code>validation</code> and
<code>fold_index</code> can return the various components of a fold object. If <code>training</code>
or <code>validation</code> is passed an object, it will index into it in a sensible way.
For instance, if it is a vector, it will index the vector directly. If it is a
<code>data.frame</code> or <code>matrix</code>, it will index rows. This allows the user to easily
partition data into training and validation sets. The fold function must return
a named list of results containing whatever fold-specific outputs are generated.</p>
</div>
<div id="apply-cross_validate" class="section level3">
<h3>
<span class="header-section-number">5.7.3</span> (3) Apply <code>cross_validate</code><a class="anchor" aria-label="anchor" href="#apply-cross_validate"><i class="fas fa-link"></i></a>
</h3>
<p>After defining folds, <code>cross_validate</code> can be used to map the <code>cv_fun</code> across
the <code>folds</code> using <code>future_lapply</code>. This means that it can be easily parallelized
by specifying a parallelization scheme (i.e., a <code>plan</code> from the <a href="https://Cran.R-project.org/package=future">future
parallelization framework for <code>R</code></a>
<span class="citation">(Bengtsson <a href="references.html#ref-bengtsson2020unifying">2020</a>)</span>). The application of <code>cross_validate</code> generates a list
of results. As described above, each call to <code>cv_fun</code> itself returns a list of
results, with different elements for each type of result we care about. The main
loop generates a list of these individual lists of results (a sort of
“meta-list”). This “meta-list” is then inverted such that there is one element
per result type (this too is a list of the results for each fold). By default,
<code>combine_results</code> is used to combine these results type lists in a sensible
manner. How results are combined is determined automatically by examining the
data types of the results from the first fold. This can be modified by
specifying a list of arguments to <code>.combine_control</code>.</p>
</div>
</div>
<div id="cross-validation-in-action" class="section level2">
<h2>
<span class="header-section-number">5.8</span> Cross-validation in action<a class="anchor" aria-label="anchor" href="#cross-validation-in-action"><i class="fas fa-link"></i></a>
</h2>
<p>Let’s see <code>origami</code> in action! In the following chapter we will learn how to use
cross-validation with the Super Learner, and how we can utilize the power of
cross-validation to build optimal ensembles of algorithms, not just its use on a
single statistical learning method.</p>
<div id="cross-validation-with-linear-regression" class="section level3">
<h3>
<span class="header-section-number">5.8.1</span> Cross-validation with linear regression<a class="anchor" aria-label="anchor" href="#cross-validation-with-linear-regression"><i class="fas fa-link"></i></a>
</h3>
<p>First, we will load the relevant <code>R</code> packages, set a seed, and load the full
WASH data once again. In order to illustrate cross-validation with <code>origami</code> and
linear regression, we will focus on predicting the weight-for-height Z-score
<code>whz</code> using all of the available covariate data. As stated previously, we will
assume the data is independent and identically distributed, ignoring the cluster
structure imposed by the clinical trial design. For the sake of illustration, we
will work with a subset of data, and remove all samples with missing data from
the dataset; we will learn in the next chapter how to deal with missingness.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://stringr.tidyverse.org">stringr</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyr.tidyverse.org">tidyr</a></span><span class="op">)</span>

<span class="co"># load data set and take a peek</span>
<span class="va">washb_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/fread.html">fread</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span>
    <span class="st">"https://raw.githubusercontent.com/tlverse/tlverse-data/master/"</span>,
    <span class="st">"wash-benefits/washb_data.csv"</span>
  <span class="op">)</span>,
  stringsAsFactors <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span>

<span class="co"># Remove missing data, then pick just the first 500 rows</span>
<span class="va">washb_data</span> <span class="op">&lt;-</span> <span class="va">washb_data</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://tidyr.tidyverse.org/reference/drop_na.html">drop_na</a></span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/slice.html">slice</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">500</span><span class="op">)</span>

<span class="va">outcome</span> <span class="op">&lt;-</span> <span class="st">"whz"</span>
<span class="va">covars</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span> <span class="op">==</span> <span class="va">outcome</span><span class="op">)</span><span class="op">]</span>

<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html">kable</a></span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">kableExtra</span><span class="fu">:::</span><span class="fu"><a href="https://rdrr.io/pkg/kableExtra/man/kable_styling.html">kable_styling</a></span><span class="op">(</span>fixed_thead <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/pkg/kableExtra/man/scroll_box.html">scroll_box</a></span><span class="op">(</span>width <span class="op">=</span> <span class="st">"100%"</span>, height <span class="op">=</span> <span class="st">"300px"</span><span class="op">)</span></code></pre></div>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; ">
<div class="inline-table"><table class="table" style="margin-left: auto; margin-right: auto;">
<thead><tr>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
whz
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
tr
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
fracode
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
month
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
aged
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
sex
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momage
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momedu
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momheight
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
hfiacat
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
Nlt18
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
Ncomp
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
watmin
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
elec
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
floor
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
walls
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
roof
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_wardrobe
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_table
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_chair
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_khat
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_chouki
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_tv
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_refrig
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_bike
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_moto
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_sewmach
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_mobile
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N05265
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
268
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
146.40
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.16
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N05265
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
286
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
148.75
</td>
<td style="text-align:left;">
Moderately Food Insecure
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.05
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N08002
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
264
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
152.15
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.26
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N08002
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
252
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
28
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
140.25
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.59
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N06531
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
336
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:left;">
Secondary (&gt;5y)
</td>
<td style="text-align:right;">
150.95
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.51
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N06531
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
304
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:left;">
Secondary (&gt;5y)
</td>
<td style="text-align:right;">
154.20
</td>
<td style="text-align:left;">
Severely Food Insecure
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
</tbody>
</table></div>
</div>
<p>We can see the covariates used in the prediction:</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">outcome</span>
<span class="co">#&gt; [1] "whz"</span>
<span class="va">covars</span>
<span class="co">#&gt;  [1] "tr"             "fracode"        "month"          "aged"          </span>
<span class="co">#&gt;  [5] "sex"            "momage"         "momedu"         "momheight"     </span>
<span class="co">#&gt;  [9] "hfiacat"        "Nlt18"          "Ncomp"          "watmin"        </span>
<span class="co">#&gt; [13] "elec"           "floor"          "walls"          "roof"          </span>
<span class="co">#&gt; [17] "asset_wardrobe" "asset_table"    "asset_chair"    "asset_khat"    </span>
<span class="co">#&gt; [21] "asset_chouki"   "asset_tv"       "asset_refrig"   "asset_bike"    </span>
<span class="co">#&gt; [25] "asset_moto"     "asset_sewmach"  "asset_mobile"</span></code></pre></div>
<p>Next, we fit a linear model on the full data, with the goal of predicting the
weight-for-height Z-score <code>whz</code> using all of the available covariate data. Let’s
try it out:</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lm_mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">whz</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">washb_data</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">lm_mod</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = whz ~ ., data = washb_data)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;     Min      1Q  Median      3Q     Max </span>
<span class="co">#&gt; -2.8890 -0.6799 -0.0169  0.6595  3.1005 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;                                 Estimate Std. Error t value Pr(&gt;|t|)   </span>
<span class="co">#&gt; (Intercept)                     -1.89006    1.72022   -1.10   0.2725   </span>
<span class="co">#&gt; trHandwashing                   -0.25276    0.17032   -1.48   0.1385   </span>
<span class="co">#&gt; trNutrition                     -0.09695    0.15696   -0.62   0.5371   </span>
<span class="co">#&gt; trNutrition + WSH               -0.09587    0.16528   -0.58   0.5622   </span>
<span class="co">#&gt; trSanitation                    -0.27702    0.15846   -1.75   0.0811 . </span>
<span class="co">#&gt; trWSH                           -0.02846    0.15967   -0.18   0.8586   </span>
<span class="co">#&gt; trWater                         -0.07148    0.15813   -0.45   0.6515   </span>
<span class="co">#&gt; fracodeN05160                    0.62355    0.30719    2.03   0.0430 * </span>
<span class="co">#&gt; fracodeN05265                    0.38762    0.31011    1.25   0.2120   </span>
<span class="co">#&gt; fracodeN05359                    0.10187    0.31329    0.33   0.7452   </span>
<span class="co">#&gt; fracodeN06229                    0.30933    0.29766    1.04   0.2993   </span>
<span class="co">#&gt; fracodeN06453                    0.08066    0.30006    0.27   0.7882   </span>
<span class="co">#&gt; fracodeN06458                    0.43707    0.29970    1.46   0.1454   </span>
<span class="co">#&gt; fracodeN06473                    0.45406    0.30912    1.47   0.1426   </span>
<span class="co">#&gt; fracodeN06479                    0.60994    0.31463    1.94   0.0532 . </span>
<span class="co">#&gt; fracodeN06489                    0.25923    0.31901    0.81   0.4169   </span>
<span class="co">#&gt; fracodeN06500                    0.07539    0.35794    0.21   0.8333   </span>
<span class="co">#&gt; fracodeN06502                    0.36748    0.30504    1.20   0.2290   </span>
<span class="co">#&gt; fracodeN06505                    0.20038    0.31560    0.63   0.5258   </span>
<span class="co">#&gt; fracodeN06516                    0.55455    0.29807    1.86   0.0635 . </span>
<span class="co">#&gt; fracodeN06524                    0.49429    0.31423    1.57   0.1164   </span>
<span class="co">#&gt; fracodeN06528                    0.75966    0.31060    2.45   0.0148 * </span>
<span class="co">#&gt; fracodeN06531                    0.36856    0.30155    1.22   0.2223   </span>
<span class="co">#&gt; fracodeN06862                    0.56932    0.29293    1.94   0.0526 . </span>
<span class="co">#&gt; fracodeN08002                    0.36779    0.26846    1.37   0.1714   </span>
<span class="co">#&gt; month                            0.17161    0.10865    1.58   0.1149   </span>
<span class="co">#&gt; aged                            -0.00336    0.00112   -3.00   0.0029 **</span>
<span class="co">#&gt; sexmale                          0.12352    0.09203    1.34   0.1802   </span>
<span class="co">#&gt; momage                          -0.01379    0.00973   -1.42   0.1570   </span>
<span class="co">#&gt; momeduPrimary (1-5y)            -0.13214    0.15225   -0.87   0.3859   </span>
<span class="co">#&gt; momeduSecondary (&gt;5y)            0.12632    0.16041    0.79   0.4314   </span>
<span class="co">#&gt; momheight                        0.00512    0.00919    0.56   0.5776   </span>
<span class="co">#&gt; hfiacatMildly Food Insecure      0.05804    0.19341    0.30   0.7643   </span>
<span class="co">#&gt; hfiacatModerately Food Insecure -0.01362    0.12887   -0.11   0.9159   </span>
<span class="co">#&gt; hfiacatSeverely Food Insecure   -0.13447    0.25418   -0.53   0.5970   </span>
<span class="co">#&gt; Nlt18                           -0.02557    0.04060   -0.63   0.5291   </span>
<span class="co">#&gt; Ncomp                            0.00179    0.00762    0.23   0.8145   </span>
<span class="co">#&gt; watmin                           0.01347    0.00861    1.57   0.1182   </span>
<span class="co">#&gt; elec                             0.08906    0.10700    0.83   0.4057   </span>
<span class="co">#&gt; floor                           -0.17763    0.17734   -1.00   0.3171   </span>
<span class="co">#&gt; walls                           -0.03001    0.21445   -0.14   0.8888   </span>
<span class="co">#&gt; roof                            -0.03716    0.49214   -0.08   0.9399   </span>
<span class="co">#&gt; asset_wardrobe                  -0.05754    0.13736   -0.42   0.6755   </span>
<span class="co">#&gt; asset_table                     -0.22079    0.12276   -1.80   0.0728 . </span>
<span class="co">#&gt; asset_chair                      0.28012    0.13750    2.04   0.0422 * </span>
<span class="co">#&gt; asset_khat                       0.02306    0.11766    0.20   0.8447   </span>
<span class="co">#&gt; asset_chouki                    -0.13943    0.14084   -0.99   0.3227   </span>
<span class="co">#&gt; asset_tv                         0.17723    0.12972    1.37   0.1726   </span>
<span class="co">#&gt; asset_refrig                     0.12613    0.23162    0.54   0.5863   </span>
<span class="co">#&gt; asset_bike                      -0.02568    0.10083   -0.25   0.7990   </span>
<span class="co">#&gt; asset_moto                      -0.32094    0.19944   -1.61   0.1083   </span>
<span class="co">#&gt; asset_sewmach                    0.05090    0.17795    0.29   0.7750   </span>
<span class="co">#&gt; asset_mobile                     0.01420    0.14972    0.09   0.9245   </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 0.984 on 447 degrees of freedom</span>
<span class="co">#&gt; Multiple R-squared:  0.129,  Adjusted R-squared:  0.0277 </span>
<span class="co">#&gt; F-statistic: 1.27 on 52 and 447 DF,  p-value: 0.104</span></code></pre></div>
<p>We can assess how well the model fits the data by comparing the predictions of
the linear model to the true outcomes observed in the data set. This is the well
known (and standard) mean squared error. We can extract that from the <code>lm</code> model
object like so:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="op">(</span><span class="va">err</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">resid</a></span><span class="op">(</span><span class="va">lm_mod</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.86568</span></code></pre></div>
<p>The mean squared error is 0.86568. There is an important problem that arises
when we assess the model in this way - that is, we have trained our linear
regression model on the full data set and assessed the error on the full data
set, using up all of our data. We, of course, are generally not interested in
how well the model explains variation in the observed data; rather, we are
interested in how the explanation provided by the model generalizes to a target
population from which the sample is presumably derived. Having used all of our
available data, we cannot honestly evaluate how well the model fits (and thus
explains) variation at the population level.</p>
<p>To resolve this issue, cross-validation allows for a particular procedure (e.g.,
linear regression) to be implemented over subsets of the data, evaluating how
well the procedure fits on a testing (“validation”) set, thereby providing an
honest evaluation of the error.</p>
<p>We can easily add cross-validation to our linear regression procedure using
<code>origami</code>. First, let us define a new function to perform linear regression on a
specific partition of the data (called a “fold”):</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">cv_lm</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">fold</span>, <span class="va">data</span>, <span class="va">reg_form</span><span class="op">)</span> <span class="op">{</span>
  <span class="co"># get name and index of outcome variable from regression formula</span>
  <span class="va">out_var</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unlist.html">unlist</a></span><span class="op">(</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_split.html">str_split</a></span><span class="op">(</span><span class="va">reg_form</span>, <span class="st">" "</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>
  <span class="va">out_var_ind</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span> <span class="op">==</span> <span class="va">out_var</span><span class="op">)</span><span class="op">)</span>

  <span class="co"># split up data into training and validation sets</span>
  <span class="va">train_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_helpers.html">training</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>
  <span class="va">valid_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_helpers.html">validation</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>

  <span class="co"># fit linear model on training set and predict on validation set</span>
  <span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/formula.html">as.formula</a></span><span class="op">(</span><span class="va">reg_form</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">train_data</span><span class="op">)</span>
  <span class="va">preds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">valid_data</span><span class="op">)</span>
  <span class="va">valid_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="va">valid_data</span><span class="op">)</span>

  <span class="co"># capture results to be returned as output</span>
  <span class="va">out</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
    coef <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,
    SE <span class="op">=</span> <span class="op">(</span><span class="va">preds</span> <span class="op">-</span> <span class="va">valid_data</span><span class="op">[</span>, <span class="va">out_var_ind</span><span class="op">]</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span>
  <span class="op">)</span>
  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">out</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>Our <code>cv_lm</code> function is rather simple: we merely split the available data into a
training and validation sets, using the eponymous functions provided in
<code>origami</code>, fit the linear model on the training set, and evaluate the model on
the testing set. This is a simple example of what <code>origami</code> considers to be
<code>cv_fun</code> – functions for using cross-validation to perform a particular routine
over an input data set. Having defined such a function, we can simply generate a
set of partitions using <code>origami</code>’s <code>make_folds</code> function, and apply our <code>cv_lm</code>
function over the resultant <code>folds</code> object. Below, we replicate the
re-substitution estimate of the error – we did this “by hand” above – using
the functions <code>make_folds</code> and <code>cv_lm</code>.</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># re-substitution estimate</span>
<span class="va">resub</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/make_folds.html">make_folds</a></span><span class="op">(</span><span class="va">washb_data</span>, fold_fun <span class="op">=</span> <span class="va">folds_resubstitution</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>
<span class="va">resub_results</span> <span class="op">&lt;-</span> <span class="fu">cv_lm</span><span class="op">(</span>fold <span class="op">=</span> <span class="va">resub</span>, data <span class="op">=</span> <span class="va">washb_data</span>, reg_form <span class="op">=</span> <span class="st">"whz ~ ."</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">resub_results</span><span class="op">$</span><span class="va">SE</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.86568</span></code></pre></div>
<p>This (nearly) matches the estimate of the error that we obtained above.</p>
<p>We can more honestly evaluate the error by V-fold cross-validation, which
partitions the data into <span class="math inline">\(v\)</span> subsets, fitting the model on <span class="math inline">\(v - 1\)</span> of the
subsets and evaluating on the subset that was held out for testing. This is
repeated such that each subset is used for testing. We can easily apply our
<code>cv_lm</code> function using <code>origami</code>’s <code>cross_validate</code> (n.b., by default this
performs 10-fold cross-validation):</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># cross-validated estimate</span>
<span class="va">folds</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/make_folds.html">make_folds</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span>
<span class="va">cvlm_results</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/cross_validate.html">cross_validate</a></span><span class="op">(</span>
  cv_fun <span class="op">=</span> <span class="va">cv_lm</span>, folds <span class="op">=</span> <span class="va">folds</span>, data <span class="op">=</span> <span class="va">washb_data</span>, reg_form <span class="op">=</span> <span class="st">"whz ~ ."</span>,
  use_future <span class="op">=</span> <span class="cn">FALSE</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">cvlm_results</span><span class="op">$</span><span class="va">SE</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="co">#&gt; [1] 1.35</span></code></pre></div>
<p>Having performed 10-fold cross-validation, we quickly notice that our previous
estimate of the model error (by resubstitution) was a bit optimistic. The honest
estimate of the error is larger.</p>
</div>
<div id="cross-validation-with-random-forests" class="section level3">
<h3>
<span class="header-section-number">5.8.2</span> Cross-validation with random forests<a class="anchor" aria-label="anchor" href="#cross-validation-with-random-forests"><i class="fas fa-link"></i></a>
</h3>
<p>To examine <code>origami</code> further, let us return to our example analysis using the
WASH data set. Here, we will write a new <code>cv_fun</code> type object. As an example, we
will use Breiman’s <code>randomForest</code> <span class="citation">(Breiman <a href="references.html#ref-breiman2001random">2001</a>)</span>:</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># make sure to load the package!</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://www.stat.berkeley.edu/~breiman/RandomForests/">randomForest</a></span><span class="op">)</span>

<span class="va">cv_rf</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">fold</span>, <span class="va">data</span>, <span class="va">reg_form</span><span class="op">)</span> <span class="op">{</span>
  <span class="co"># get name and index of outcome variable from regression formula</span>
  <span class="va">out_var</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unlist.html">unlist</a></span><span class="op">(</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_split.html">str_split</a></span><span class="op">(</span><span class="va">reg_form</span>, <span class="st">" "</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>
  <span class="va">out_var_ind</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span> <span class="op">==</span> <span class="va">out_var</span><span class="op">)</span><span class="op">)</span>

  <span class="co"># define training and validation sets based on input object of class "folds"</span>
  <span class="va">train_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_helpers.html">training</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>
  <span class="va">valid_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_helpers.html">validation</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>

  <span class="co"># fit Random Forest regression on training set and predict on holdout set</span>
  <span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html">randomForest</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/formula.html">as.formula</a></span><span class="op">(</span><span class="va">reg_form</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">train_data</span><span class="op">)</span>
  <span class="va">preds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">valid_data</span><span class="op">)</span>
  <span class="va">valid_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="va">valid_data</span><span class="op">)</span>

  <span class="co"># define output object to be returned as list (for flexibility)</span>
  <span class="va">out</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
    coef <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">mod</span><span class="op">$</span><span class="va">coefs</span><span class="op">)</span>,
    SE <span class="op">=</span> <span class="op">(</span><span class="op">(</span><span class="va">preds</span> <span class="op">-</span> <span class="va">valid_data</span><span class="op">[</span>, <span class="va">out_var_ind</span><span class="op">]</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>
  <span class="op">)</span>
  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">out</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>Above, in writing our <code>cv_rf</code> function to cross-validate <code>randomForest</code>, we used
our previous function <code>cv_lm</code> as an example. For now, individual <code>cv_fun</code> must
be written by hand; however, in future releases, a wrapper may be available to
support auto-generating <code>cv_fun</code>s to be used with <code>origami</code>.</p>
<p>Below, we use <code>cross_validate</code> to apply our new <code>cv_rf</code> function over the <code>folds</code>
object generated by <code>make_folds</code>.</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># now, let's cross-validate...</span>
<span class="va">folds</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/make_folds.html">make_folds</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span>
<span class="va">cvrf_results</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/cross_validate.html">cross_validate</a></span><span class="op">(</span>
  cv_fun <span class="op">=</span> <span class="va">cv_rf</span>, folds <span class="op">=</span> <span class="va">folds</span>, data <span class="op">=</span> <span class="va">washb_data</span>, reg_form <span class="op">=</span> <span class="st">"whz ~ ."</span>,
  use_future <span class="op">=</span> <span class="cn">FALSE</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">cvrf_results</span><span class="op">$</span><span class="va">SE</span><span class="op">)</span>
<span class="co">#&gt; [1] 1.0271</span></code></pre></div>
<p>Using 10-fold cross-validation (the default), we obtain an honest estimate of
the prediction error of random forests. From this, we gather that the use of
<code>origami</code>’s <code>cross_validate</code> procedure can be generalized to arbitrary estimation
techniques, given availability of an appropriate <code>cv_fun</code> function.</p>
</div>
<div id="cross-validation-with-arima" class="section level3">
<h3>
<span class="header-section-number">5.8.3</span> Cross-validation with arima<a class="anchor" aria-label="anchor" href="#cross-validation-with-arima"><i class="fas fa-link"></i></a>
</h3>
<p>Cross-validation can also be used for forecast model selection in a time series
setting. Here, the partitioning scheme mirrors the application of the
forecasting model: we’ll train the data on past observations (either all
available or a recent subset), and then use the model fit to predict the next
few observations. We consider the <code>AirPassengers</code> dataset again, a monthly time
series of passenger air traffic in thousands of people.</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">AirPassengers</span><span class="op">)</span>
<span class="fu"><a href="https://docs.ropensci.org/skimr/reference/print.html">print</a></span><span class="op">(</span><span class="va">AirPassengers</span><span class="op">)</span>
<span class="co">#&gt;      Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec</span>
<span class="co">#&gt; 1949 112 118 132 129 121 135 148 148 136 119 104 118</span>
<span class="co">#&gt; 1950 115 126 141 135 125 149 170 170 158 133 114 140</span>
<span class="co">#&gt; 1951 145 150 178 163 172 178 199 199 184 162 146 166</span>
<span class="co">#&gt; 1952 171 180 193 181 183 218 230 242 209 191 172 194</span>
<span class="co">#&gt; 1953 196 196 236 235 229 243 264 272 237 211 180 201</span>
<span class="co">#&gt; 1954 204 188 235 227 234 264 302 293 259 229 203 229</span>
<span class="co">#&gt; 1955 242 233 267 269 270 315 364 347 312 274 237 278</span>
<span class="co">#&gt; 1956 284 277 317 313 318 374 413 405 355 306 271 306</span>
<span class="co">#&gt; 1957 315 301 356 348 355 422 465 467 404 347 305 336</span>
<span class="co">#&gt; 1958 340 318 362 348 363 435 491 505 404 359 310 337</span>
<span class="co">#&gt; 1959 360 342 406 396 420 472 548 559 463 407 362 405</span>
<span class="co">#&gt; 1960 417 391 419 461 472 535 622 606 508 461 390 432</span></code></pre></div>
<p>Suppose we want to pick between two forecasting models with different <code>arima</code>
configurations. We can do that by evaluating their forecasting performance.
First, we set up the appropriate cross-validation scheme for time-series.</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">folds</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/make_folds.html">make_folds</a></span><span class="op">(</span><span class="va">AirPassengers</span>,
  fold_fun <span class="op">=</span> <span class="va">folds_rolling_origin</span>,
  first_window <span class="op">=</span> <span class="fl">36</span>, validation_size <span class="op">=</span> <span class="fl">24</span>, batch <span class="op">=</span> <span class="fl">10</span>
<span class="op">)</span>

<span class="co"># How many folds where generated?</span>
<span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">folds</span><span class="op">)</span>
<span class="co">#&gt; [1] 9</span>

<span class="co"># Examine the first 2 folds.</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25</span>
<span class="co">#&gt; [26] 26 27 28 29 30 31 32 33 34 35 36</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1] 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span>
<span class="va">folds</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span>
<span class="co">#&gt; $v</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_set</span>
<span class="co">#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25</span>
<span class="co">#&gt; [26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $validation_set</span>
<span class="co">#&gt;  [1] 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; attr(,"class")</span>
<span class="co">#&gt; [1] "fold"</span></code></pre></div>
<p>By default, <code>folds_rolling_origin</code> will increase the size of the training set by
one time point each fold. Had we followed the default option, we would have 85
folds to train! Luckily, we can pass the <code>batch</code> as option to
<code>folds_rolling_origin</code> that tells it to increase the size of the training set by
10 points each iteration. Since we want to forecast the immediate next point,
<code>gap</code> argument remains the default (0).</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># make sure to load the package!</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://pkg.robjhyndman.com/forecast/">forecast</a></span><span class="op">)</span>

<span class="co"># function to calculate cross-validated squared error</span>
<span class="va">cv_forecasts</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">fold</span>, <span class="va">data</span><span class="op">)</span> <span class="op">{</span>
  <span class="co"># Get training and validation data</span>
  <span class="va">train_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_helpers.html">training</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>
  <span class="va">valid_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_helpers.html">validation</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>
  <span class="va">valid_size</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">valid_data</span><span class="op">)</span>

  <span class="va">train_ts</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/ts.html">ts</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log10</a></span><span class="op">(</span><span class="va">train_data</span><span class="op">)</span>, frequency <span class="op">=</span> <span class="fl">12</span><span class="op">)</span>

  <span class="co"># First arima model</span>
  <span class="va">arima_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/arima.html">arima</a></span><span class="op">(</span><span class="va">train_ts</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>,
    seasonal <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
      order <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>,
      period <span class="op">=</span> <span class="fl">12</span>
    <span class="op">)</span>
  <span class="op">)</span>
  <span class="va">raw_arima_pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">arima_fit</span>, n.ahead <span class="op">=</span> <span class="va">valid_size</span><span class="op">)</span>
  <span class="va">arima_pred</span> <span class="op">&lt;-</span> <span class="fl">10</span><span class="op">^</span><span class="va">raw_arima_pred</span><span class="op">$</span><span class="va">pred</span>
  <span class="va">arima_MSE</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">arima_pred</span> <span class="op">-</span> <span class="va">valid_data</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>

  <span class="co"># Second arima model</span>
  <span class="va">arima_fit2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/arima.html">arima</a></span><span class="op">(</span><span class="va">train_ts</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>,
    seasonal <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
      order <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>,
      period <span class="op">=</span> <span class="fl">12</span>
    <span class="op">)</span>
  <span class="op">)</span>
  <span class="va">raw_arima_pred2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">arima_fit2</span>, n.ahead <span class="op">=</span> <span class="va">valid_size</span><span class="op">)</span>
  <span class="va">arima_pred2</span> <span class="op">&lt;-</span> <span class="fl">10</span><span class="op">^</span><span class="va">raw_arima_pred2</span><span class="op">$</span><span class="va">pred</span>
  <span class="va">arima_MSE2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">arima_pred2</span> <span class="op">-</span> <span class="va">valid_data</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>

  <span class="va">out</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>mse <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>
    fold <span class="op">=</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_helpers.html">fold_index</a></span><span class="op">(</span><span class="op">)</span>,
    arima <span class="op">=</span> <span class="va">arima_MSE</span>, arima2 <span class="op">=</span> <span class="va">arima_MSE2</span>
  <span class="op">)</span><span class="op">)</span>
  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">out</span><span class="op">)</span>
<span class="op">}</span>

<span class="va">mses</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/cross_validate.html">cross_validate</a></span><span class="op">(</span>
  cv_fun <span class="op">=</span> <span class="va">cv_forecasts</span>, folds <span class="op">=</span> <span class="va">folds</span>, data <span class="op">=</span> <span class="va">AirPassengers</span>,
  use_future <span class="op">=</span> <span class="cn">FALSE</span>
<span class="op">)</span>
<span class="va">mses</span><span class="op">$</span><span class="va">mse</span>
<span class="co">#&gt;   fold   arima  arima2</span>
<span class="co">#&gt; 1    1   68.21  137.28</span>
<span class="co">#&gt; 2    2  319.68  313.15</span>
<span class="co">#&gt; 3    3  578.35  713.36</span>
<span class="co">#&gt; 4    4  428.69  505.31</span>
<span class="co">#&gt; 5    5  407.33  371.27</span>
<span class="co">#&gt; 6    6  281.82  250.99</span>
<span class="co">#&gt; 7    7  827.56  910.12</span>
<span class="co">#&gt; 8    8 2099.59 2213.15</span>
<span class="co">#&gt; 9    9  398.37  293.38</span>
<span class="fu"><a href="https://rdrr.io/r/base/colSums.html">colMeans</a></span><span class="op">(</span><span class="va">mses</span><span class="op">$</span><span class="va">mse</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"arima"</span>, <span class="st">"arima2"</span><span class="op">)</span><span class="op">]</span><span class="op">)</span>
<span class="co">#&gt;  arima arima2 </span>
<span class="co">#&gt; 601.07 634.22</span></code></pre></div>
<p>The arima model with no AR component seems to be a better fit for this data.</p>
</div>
</div>
<div id="exercises" class="section level2">
<h2>
<span class="header-section-number">5.9</span> Exercises<a class="anchor" aria-label="anchor" href="#exercises"><i class="fas fa-link"></i></a>
</h2>
<div id="review-of-key-concepts" class="section level3">
<h3>
<span class="header-section-number">5.9.1</span> Review of Key Concepts<a class="anchor" aria-label="anchor" href="#review-of-key-concepts"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li><p>Compare and contrast V-fold cross-validation with resubstitution
cross-validation. What are some of the differences between the two methods?
How are they similar? Describe a scenario when you would use one over the
other.</p></li>
<li>What are the advantages and disadvantages of <span class="math inline">\(v\)</span>-fold CV relative to:
<ol style="list-style-type: lower-alpha">
<li>holdout CV?</li>
<li>leave-one-out CV?</li>
</ol>
</li>
<li><p>Why can’t we use V-fold cross-validation for time-series data?</p></li>
<li><p>Would you use rolling window or origin for non-stationary time-series? Why?</p></li>
</ol>
</div>
<div id="the-ideas-in-action" class="section level3">
<h3>
<span class="header-section-number">5.9.2</span> The Ideas in Action<a class="anchor" aria-label="anchor" href="#the-ideas-in-action"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li><p>Let <span class="math inline">\(Y\)</span> be a binary variable with <span class="math inline">\(P(Y=1 \mid W) = 0.01\)</span>. What kind of
cross-validation should be use for a rare outcome? How can we do this with
the <code>origami</code> package?</p></li>
<li><p>Consider the WASH benefits dataset presented in this chapter. How can we
include cluster information into cross-validation? How can we do this with
the <code>origami</code> package?</p></li>
</ol>
</div>
<div id="advanced-topics" class="section level3">
<h3>
<span class="header-section-number">5.9.3</span> Advanced Topics<a class="anchor" aria-label="anchor" href="#advanced-topics"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li><p>Think about a dataset with arbitrary spatial dependence, where we know
the extent of dependence, and groups formed by such dependence are clear
with no spillover effects. What kind of cross-validation can we use?</p></li>
<li><p>Continuing on the last problem, what kind of procedure, and cross-validation
method, can we use if the spatial dependence is not clearly defined as in the
previous problem?</p></li>
<li>
<p>Consider a classification problem with a large number of predictors. A
statistician proposes the following analysis:</p>
<ol style="list-style-type: lower-alpha">
<li>First screen the predictors, leaving only covariates with a strong
correlation with the class labels.</li>
<li>Fit some algorithm using only the subset of highly correlated covariates.</li>
<li>Use cross-validation to estimate the tuning parameters and the performance
of the proposed algorithm.</li>
</ol>
<p>Is this a correct application of cross-validation? Why?</p>
</li>
</ol>
<!--
## Appendix

### Exercise solutions
--><p>output:
pdf_document: default
html_document: default
—
# Super (Machine) Learning {#sl3}</p>
<p><em>Rachael Phillips</em></p>
<p>Based on the <a href="https://github.com/tlverse/sl3"><code>sl3</code> <code>R</code> package</a> by <em>Jeremy
Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips, and Oleg Sofrygin</em>.</p>
<p>Updated: 2021-03-11</p>
</div>
</div>
<div id="learning-objectives-3" class="section level2 unnumbered">
<h2>Learning Objectives<a class="anchor" aria-label="anchor" href="#learning-objectives-3"><i class="fas fa-link"></i></a>
</h2>
<p>By the end of this chapter you will be able to:</p>
<ol style="list-style-type: decimal">
<li>Select a loss function that is appropriate for the functional parameter to
be estimated.</li>
<li>Assemble an ensemble of learners based on the properties that identify what
features they support.</li>
<li>Customize learner tuning parameters to incorporate a diversity of different
settings.</li>
<li>Select a subset of available covariates and pass only those variables to the
modeling algorithm.</li>
<li>Fit an ensemble with nested cross-validation to obtain an estimate of the
performance of the ensemble itself.</li>
<li>Obtain <code>sl3</code> variable importance metrics.</li>
<li>Interpret the discrete and continuous Super Learner fits.</li>
<li>Rationalize the need to remove bias from the Super Learner to make an
optimal bias–variance tradeoff for the parameter of interest.</li>
</ol>
</div>
<div id="motivation" class="section level2 unnumbered">
<h2>Motivation<a class="anchor" aria-label="anchor" href="#motivation"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>A common task in data analysis is prediction — using the observed data to
learn a function, which can be used to map new input variables into a
predicted outcome. <!--  Oftentimes, the scientific question of interest translates 
  to a statistical question that requires (causal) effect estimation. Even in 
  these scenarios, where prediction is not in the forefront, there are Often
  prediction steps embedded in the procedure. --->
</li>
<li>For some data, algorithms that can model a complex function are necessary to<br>
adequately model the data. For other data, a main terms regression model might
fit the data quite well.<br>
</li>
<li>The Super Learner (SL), an ensemble learner, solves this issue, by allowing a
combination of algorithms from the simplest (intercept-only) to most complex
(neural nets, random forests, SVM, etc).</li>
<li>It works by using cross-validation in a manner which guarantees that the
resulting fit will be as good as possible, given the learners provided.</li>
</ul>
</div>
<div id="introduction-2" class="section level2 unnumbered">
<h2>Introduction<a class="anchor" aria-label="anchor" href="#introduction-2"><i class="fas fa-link"></i></a>
</h2>
<p>In <a href="intro.html#intro">Chapter 1</a>, we introduced the <a href="intro.html#roadmap"><em>Roadmap for Targeted
Learning</em></a> as a general template to translate real-world data
applications into formal statistical estimation problems. The first steps of
this roadmap define the <em>statistical estimation problem</em>, which establish</p>
<ol style="list-style-type: decimal">
<li>Data as a random variable, or equivalently, a realization of a
particular experiment/study. We assume the observations in the data are
independent and identically distributed.</li>
<li>A statistical model as the set of possible probability distributions that
could have given rise to the observed data.</li>
<li>A translation of the scientific question, which is often causal, into a
target estimand.</li>
</ol>
<p>Note that if the estimand is causal, step 3 also requires establishing
identifiability of the estimand from the observed data, under possible
non-testable assumptions that may not necessarily be reasonable. Still, the
target quantity does have a valid statistical interpretation. See <a href="intro.html#causal">causal target
parameters</a> for more detail on causal models and identifiability.</p>
<p>Now that we have defined the statistical estimation problem, we are ready to
construct the TMLE; an asymptotically linear and efficient substitution
estimator of this estimand. The first step in this estimation procedure
is an initial estimate of the data-generating distribution, or the relevant part
of this distribution that is needed to evaluate the target parameter. For this
initial estimation, we use the Super Learner (SL) <span class="citation">(van der Laan, Polley, and Hubbard <a href="references.html#ref-vdl2007super">2007</a>)</span>.</p>
<p>The SL provides an important step in creating a robust estimator. It is a
loss- function- based tool that uses cross-validation to obtain the best
prediction of our target parameter, based on a weighted average of a library of
machine learning algorithms. The library of machine learning algorithms
consists of functions (“learners” in the <code>sl3</code> nomenclature) that we think might
be consistent with the true data-generating distribution. By “consistent with
the true data-generating distribution”, we mean that the algorithms selected
should not violate subject-matter knowledge about the experiment that
generated the data. Also, the library should contain a diversity of algorithms
that range from parametric regression models to multi-step algorithms involving
screening covariates, penalizations, optimizing tuning parameters, etc.</p>
<p>The ensembling of the collection of algorithms with weights (“metalearning” in
the <code>sl3</code> nomenclature) has been shown to be adaptive and robust, even in small
samples <span class="citation">(Polley and van der Laan <a href="references.html#ref-polley2010super">2010</a>)</span>. The SL is proven to be asymptotically as accurate
as the best possible prediction algorithm in the library <span class="citation">(van der Laan and Dudoit <a href="references.html#ref-vdl2003unified">2003</a>; Van der Vaart, Dudoit, and Laan <a href="references.html#ref-vaart2006oracle">2006</a>)</span>.</p>
<div id="general-step-by-step-overview-of-the-super-learner-algorithm" class="section level3 unnumbered">
<h3>General step-by-step overview of the Super Learner algorithm<a class="anchor" aria-label="anchor" href="#general-step-by-step-overview-of-the-super-learner-algorithm"><i class="fas fa-link"></i></a>
</h3>
<p>Consider the scenario in which we have <span class="math inline">\(n\)</span> independent and identically
distributed observations in the data, and our data structure is not a time
series. Also, let’s say we have <span class="math inline">\(k\)</span> number of candidate learners/algorithms.</p>
<ol style="list-style-type: decimal">
<li>
<p>Create the validation data for all <span class="math inline">\(V=v\)</span> folds. Break up the data evenly
into <span class="math inline">\(V=v\)</span> splits; such that no observation is contained more than one split,
and the splits contain about the same number of observations (e.g., about
<span class="math inline">\(n/V\)</span> observations in each split).</p>
<ul>
<li>If a rare binary outcome (or highly important binary predictor, such as
a treatment) is present in the data, we should consider making the
prevalence of this binary outcome in the splits similar to the
prevalence that exists in the data. We can achieve this by specifying,
for the <code>strata_ids</code> argument in <code><a href="http://tlverse.org/origami/reference/make_folds.html">origami::make_folds()</a></code>, the vector of
binary outcomes (or important binary covariate).</li>
<li>If we have repeated measures or cluster-level dependence in the data,
then all observations within a subject/cluster should be placed in the
same split.</li>
</ul>
</li>
<li>
<p>For each fold <span class="math inline">\(v\)</span>:</p>
<ol style="list-style-type: lower-alpha">
<li>Separate (a) the data that was selected for fold <span class="math inline">\(v\)</span> in Step 1, which
should contain roughly <span class="math inline">\(n/V\)</span> total observations; from (b) the data that
was NOT selected for fold <span class="math inline">\(v\)</span>, which should contain roughly <span class="math inline">\(n - n/V\)</span>
total observations. We will use the (b) data to model/fit the learners,
referring to this subset of the data as the “training data”. We will use
the (b) data to validate/test the learners on data that was not used for
fitting, referring to this subset of the data as the “validation data”.
Let’s call <span class="math inline">\(n_{\text{validation}}\)</span> the number of observations in the
validation data, and <span class="math inline">\(n_{\text{training}}\)</span> the number of observations in
the training data. Note that
<span class="math inline">\(n_{\text{validation}} + n_{\text{training}}\)</span> should be equal to <span class="math inline">\(n\)</span>.</li>
<li>Fit each of the <span class="math inline">\(k\)</span> learners on the training data.</li>
<li>Using each of the <span class="math inline">\(k\)</span> trained learners, predict the outcomes in the
validation data. We can call these predictions
“cross-validated predictions”; since they were obtained from the
validation sample’s covariate information, which was never seen while
fitting these models. We thus end up with a <span class="math inline">\(n_{validation} \by k\)</span>
matrix of cross-validated predictions.</li>
</ol>
</li>
<li>Bind together the rows of all <span class="math inline">\(v\)</span> <span class="math inline">\(n_{validation} \by k\)</span> matrices of
cross-validated predictions, to obtain an <span class="math inline">\(n \by k\)</span> matrix of
cross-validated predictions. This matrix is often referred to as the
“level-one” or “Z” matrix.</li>
<li>Retain the observed outcome <span class="math inline">\(Y\)</span> for each of the <span class="math inline">\(n\)</span> observations, using
them to measure the “loss” of each cross-validated prediction
(e.g., (Y − ^2$).</li>
<li>For each <span class="math inline">\(k\)</span> column, take the (potentially weighted) mean across all of the
<span class="math inline">\(n\)</span> losses, so we have a measure of performance, which we call the
“cross-validated empirical risk”, for each of the <span class="math inline">\(k\)</span> learners. The weights,
and subsequent weighted mean, can be used to up/down-weight samples whose
should be considered less/more important (e.g., survey weights).</li>
<li>
<p>Fit the so-called “metalearner”. The metalearner is just a function that
decides on weights to be assigned to each of the <span class="math inline">\(k\)</span> learners, taking as
input the <span class="math inline">\(k\)</span> learner losses (or the loss function itself) and the Z matrix.</p>
<ol style="list-style-type: lower-alpha">
<li>The discrete SL (or cross-validated selector) employs a simple
metalearner that assigns weight of 1 to the single learner with
smallest cross-validated risk, and weight of 0 to all other learners.</li>
<li>The ensemble SL (often referred to just as the “Super Learner”) employs
a metalearner that assigns weights that minimize the cross-validated
risk (e.g., non-negative least squares regression). This often results
in more than one learner having positive weight. Aggressive
metalearning (e.g., assigning negative weight) comes with consequences
that we will discuss later.</li>
</ol>
</li>
<li>Fit the learners on the entire sample of <span class="math inline">\(n\)</span> observations, ignoring the
cross-validation folds, and use the weights that were obtained in Step 5
to get the SL fit. The SL fit is actually just all of <span class="math inline">\(k\)</span> learner fits —
the weights don’t come in to play until we obtain the predictions from the
SL, which are the weighted combination of the <span class="math inline">\(k\)</span> learner predictions as
determined by the metalearner. are the SL predictions. Notice that, we use
this rigorous, optimal, and fair procedure to derive the weights from the
<span class="math inline">\(n \by k\)</span> Z-matrix of cross-validated predictions; but once we’ve done
that, we move our focus to obtaining the best fit possible of our <span class="math inline">\(k\)</span>
learners by capitalizing on the entire sample of observations.</li>
<li><p>Predictions, variable importance, and/or a cross-validated SL can be
obtained from an SL fit (like most other learners). The cross-validated SL
provides an estimate of the performance of the SL on unseen data, and
incorporates a outer layer of cross-validation in order to cross-validate
this entire procedure.</p></li>
</ol>
<embed src="img/misc/SLKaiserNew.pdf" width="80%" style="display: block; margin: auto;" type="application/pdf"></embed>
</div>
<div id="summary-of-super-learners-foundations" class="section level3 unnumbered">
<h3>Summary of Super Learner’s Foundations<a class="anchor" aria-label="anchor" href="#summary-of-super-learners-foundations"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>
<p>We use a <em>loss function</em> <span class="math inline">\(L\)</span> to assign a measure of performance to each
learner <span class="math inline">\(\psi\)</span> when applied to the data <span class="math inline">\(O\)</span>, and subsequently compare
performance across the learners. More generally, <span class="math inline">\(L\)</span> maps every
<span class="math inline">\(\psi \in \mathbb{R}\)</span> to <span class="math inline">\(L(\psi) : (O) \mapsto L(\psi)(O)\)</span>. We use the terms
“learner”, “algorithm”, and “estimator” interchangeably.</p>
<ul>
<li>It is important to recall that <span class="math inline">\(\psi\)</span> is an estimator of <span class="math inline">\(\psi_0\)</span>, the
unknown and true parameter value under <span class="math inline">\(P_0\)</span>.</li>
<li>A valid loss function will have expectation (risk) that is minimized at
the true value of the parameter <span class="math inline">\(\psi_0\)</span>. Thus, minimizing the expected
loss will bring an estimator <span class="math inline">\(\psi\)</span> closer to the true <span class="math inline">\(\psi_0\)</span>.</li>
<li>For example, say we observe a learning data set <span class="math inline">\(O_i=(Y_i,X_i)\)</span>, of
<span class="math inline">\(i=1, \ldots, n\)</span> independent and identically distributed observations,
where <span class="math inline">\(Y_i\)</span> is a continuous outcome of interest, <span class="math inline">\(X_i\)</span> is a set of
covariates. Also, let our objective be to estimate the function
<span class="math inline">\(\psi_0: X \mapsto \psi_0(X) = E_0(Y|X)\)</span>, which is the conditional mean
outcome given covariates. This function can be expressed as the minimizer
of the expected squared error loss:
<span class="math inline">\(\psi_0 = \text{argmin}_{\psi} E[L(O,\psi(X))]\)</span>, where
<span class="math inline">\(L(O,\psi(X)) = (Y − \psi(X))^2\)</span>.</li>
<li>We can estimate the loss by substituting the empirical distribution of
the data <span class="math inline">\(P_n\)</span> for the true and unknown distribution of the observed data
<span class="math inline">\(P_0\)</span>.</li>
<li>Also, we can use the cross-validated risk to empirically determine the
relative performance of an estimator (i.e., a candidate learner), and
perhaps how it’s performance compares to other estimators.</li>
<li>Once we have tested different estimators on actual data, and looked at
the performance (e.g., MSE of predictions across all learners), we can
see which algorithm (or weighted combination) has the lowest risk, and
thus is closest to the true <span class="math inline">\(\psi_0\)</span>.</li>
</ul>
</li>
<li>The <em>cross-validated empirical risk</em> of an algorithm is defined as the
empirical mean over a validation sample of the loss of the algorithm fitted
on the training sample, averaged across the splits of the data.</li>
<li>The <em>discrete Super Learner</em>, or <em>cross-validation selector</em>, is the algorithm
in the library that minimizes the cross-validated empirical risk.</li>
<li>The <em>continuous/ensemble Super Learner</em>, often referred to as <em>Super Learner</em>
is a weighted average of the library of algorithms, where the weights are
chosen to minimize the cross-validated empirical risk of the library.
Restricting the weights to be positive and sum to one (i.e., a convex
combination) has been shown to improve upon the discrete Super Learner
<span class="citation">(Polley and van der Laan <a href="references.html#ref-polley2010super">2010</a>; van der Laan, Polley, and Hubbard <a href="references.html#ref-vdl2007super">2007</a>)</span>. This notion of weighted combinations was
introduced in <span class="citation">Wolpert (<a href="references.html#ref-wolpert1992stacked">1992</a>)</span> for neural networks and adapted for
regressions in <span class="citation">Breiman (<a href="references.html#ref-breiman1996stacked">1996</a>)</span>.</li>
<li><p>Cross-validation is proven to be optimal for selection among estimators. This
result was established through the oracle inequality for the cross-validation
selector among a collection of candidate estimators <span class="citation">(van der Laan and Dudoit <a href="references.html#ref-vdl2003unified">2003</a>; Van der Vaart, Dudoit, and Laan <a href="references.html#ref-vaart2006oracle">2006</a>)</span>. The only condition is that loss function is uniformly
bounded, which is guaranteed in <code>sl3</code>.</p></li>
</ul>
<!--
The *oracle results* prove that, if the number of algorithms in the library are
polynomial in sample size, then the cross-validation selector (i.e., discrete
Super Learner) (1) is equivalent with the oracle selector asymptotically (based
on sample of size of training samples), or (2) achieves the parametric rate
(log $n/n$) for convergence with respect to the loss-based dissimilarity (risk)
between a candidate estimate $\psi$ and the true parameter value $\psi_0$.


### Super Learner for Prediction {-}

Below, we show the results of
such a study, comparing the fits of several different learners, including the SL
algorithms.

r cv_fig3, results="asis", echo = FALSE
knitr::include_graphics("img/misc/ericSL.pdf")


For more detail on Super Learner we refer the reader to @vdl2007super and
@polley2010super. The optimality results for the cross-validation selector
among a family of algorithms were established in @vdl2003unified and extended
in @vaart2006oracle.
-->
</div>
</div>
<div id="sl3-microwave-dinner-implementation" class="section level2 unnumbered">
<h2>
<code>sl3</code> “Microwave Dinner” Implementation<a class="anchor" aria-label="anchor" href="#sl3-microwave-dinner-implementation"><i class="fas fa-link"></i></a>
</h2>
<p>We begin by illustrating the core functionality of the SL algorithm as
implemented in <code>sl3</code>.</p>
<p>The <code>sl3</code> implementation consists of the following steps:</p>
<ol start="0" style="list-style-type: decimal">
<li>Load the necessary libraries and data</li>
<li>Define the machine learning task</li>
<li>Make an SL by creating library of base learners and a metalearner</li>
<li>Train the SL on the machine learning task</li>
<li>Obtain predicted values</li>
</ol>
<div id="wash-benefits-study-example-1" class="section level3 unnumbered">
<h3>WASH Benefits Study Example<a class="anchor" aria-label="anchor" href="#wash-benefits-study-example-1"><i class="fas fa-link"></i></a>
</h3>
<p>Using the WASH Benefits Bangladesh data, we are interested in predicting
weight-for-height z-score <code>whz</code> using the available covariate data. More
information on this dataset, and all other data that we will work with in this
handbook, is contained in <span id="data">Chapter 3</span>. Let’s begin!</p>
</div>
<div id="load-the-necessary-libraries-and-data" class="section level3 unnumbered">
<h3>0. Load the necessary libraries and data<a class="anchor" aria-label="anchor" href="#load-the-necessary-libraries-and-data"><i class="fas fa-link"></i></a>
</h3>
<p>First, we will load the relevant <code>R</code> packages, set a seed, and load the data.</p>
<!--
If you would like to use newer `sl3` functionality that is available in the
devel branch of the `sl3` GitHub repository, you need to install that version
of the package (i.e., `usethis::install_github(tlverse/sl3@devel)`), re-start
your `R` session, and then re-load the `sl3` package.
-->
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://r-datatable.com">data.table</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://readr.tidyverse.org">readr</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/ecpolley/SuperLearner">SuperLearner</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tlverse.org/origami">origami</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tlverse.org/sl3">sl3</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://yihui.org/knitr/">knitr</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://haozhu233.github.io/kableExtra/">kableExtra</a></span><span class="op">)</span>

<span class="co"># load data set and take a peek</span>
<span class="va">washb_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/fread.html">fread</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span>
    <span class="st">"https://raw.githubusercontent.com/tlverse/tlverse-data/master/"</span>,
    <span class="st">"wash-benefits/washb_data.csv"</span>
  <span class="op">)</span>,
  stringsAsFactors <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html">kable</a></span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">kableExtra</span><span class="fu">:::</span><span class="fu"><a href="https://rdrr.io/pkg/kableExtra/man/kable_styling.html">kable_styling</a></span><span class="op">(</span>fixed_thead <span class="op">=</span> <span class="cn">T</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/pkg/kableExtra/man/scroll_box.html">scroll_box</a></span><span class="op">(</span>width <span class="op">=</span> <span class="st">"100%"</span>, height <span class="op">=</span> <span class="st">"300px"</span><span class="op">)</span></code></pre></div>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; ">
<div class="inline-table"><table class="table" style="margin-left: auto; margin-right: auto;">
<thead><tr>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
whz
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
tr
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
fracode
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
month
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
aged
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
sex
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momage
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momedu
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momheight
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
hfiacat
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
Nlt18
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
Ncomp
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
watmin
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
elec
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
floor
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
walls
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
roof
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_wardrobe
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_table
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_chair
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_khat
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_chouki
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_tv
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_refrig
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_bike
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_moto
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_sewmach
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_mobile
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N05265
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
268
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
146.40
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.16
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N05265
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
286
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
148.75
</td>
<td style="text-align:left;">
Moderately Food Insecure
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.05
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N08002
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
264
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
152.15
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.26
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N08002
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
252
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
28
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
140.25
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.59
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N06531
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
336
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:left;">
Secondary (&gt;5y)
</td>
<td style="text-align:right;">
150.95
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.51
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N06531
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
304
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:left;">
Secondary (&gt;5y)
</td>
<td style="text-align:right;">
154.20
</td>
<td style="text-align:left;">
Severely Food Insecure
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
</tbody>
</table></div>
</div>
</div>
<div id="define-the-machine-learning-task" class="section level3 unnumbered">
<h3>1. Define the machine learning task<a class="anchor" aria-label="anchor" href="#define-the-machine-learning-task"><i class="fas fa-link"></i></a>
</h3>
<p>To define the machine learning <strong>“task”</strong> (predict weight-for-height Z-score
<code>whz</code> using the available covariate data), we need to create an <code>sl3_Task</code>
object.</p>
<p>The <code>sl3_Task</code> keeps track of the roles the variables play in the machine
learning problem, the data, and any metadata (e.g., observational-level
weights, IDs, offset).</p>
<p>Also, if we had missing outcomes, we would need to set <code>drop_missing_outcome = TRUE</code> when we create the task. In the next analysis, with the <a href="data.html#ist">IST stroke trial
data</a>, we do have a missing outcome. In the following chapter, we need to
estimate this “missingness mechanism”; which is the conditional probably that
the outcome is observed, given the history (i.e., variables that were measured
before the missingness). Estimating the missingness mechanism requires learning
a prediction function that outputs the predicted probability that a unit
is missing, given their history.</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># specify the outcome and covariates</span>
<span class="va">outcome</span> <span class="op">&lt;-</span> <span class="st">"whz"</span>
<span class="va">covars</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span> <span class="op">==</span> <span class="va">outcome</span><span class="op">)</span><span class="op">]</span>

<span class="co"># create the sl3 task</span>
<span class="va">washb_task</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/sl3_Task.html">make_sl3_Task</a></span><span class="op">(</span>
  data <span class="op">=</span> <span class="va">washb_data</span>,
  covariates <span class="op">=</span> <span class="va">covars</span>,
  outcome <span class="op">=</span> <span class="va">outcome</span>
<span class="op">)</span>
<span class="co">#&gt; Warning in process_data(data, nodes, column_names = column_names, flag = flag, :</span>
<span class="co">#&gt; Missing covariate data detected: imputing covariates.</span></code></pre></div>
<p><em>This warning is important.</em> The task just imputed missing covariates for us.
Specifically, for each covariate column with missing values, <code>sl3</code> uses the
median to impute missing continuous covariates, and the mode to impute binary
and categorical covariates.</p>
<p>Also, for each covariate column with missing values, <code>sl3</code> adds an additional
column indicating whether or not the value was imputed, which is particularly
handy when the missingness in the data might be informative.</p>
<p>Also, notice that we did not specify the number of folds, or the loss function
in the task. The default cross-validation scheme is V-fold, with <span class="math inline">\(V=10\)</span> number
of folds.</p>
<p>Let’s visualize our <code>washb_task</code>:</p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">washb_task</span>
<span class="co">#&gt; A sl3 Task with 4695 obs and these nodes:</span>
<span class="co">#&gt; $covariates</span>
<span class="co">#&gt;  [1] "tr"              "fracode"         "month"           "aged"           </span>
<span class="co">#&gt;  [5] "sex"             "momage"          "momedu"          "momheight"      </span>
<span class="co">#&gt;  [9] "hfiacat"         "Nlt18"           "Ncomp"           "watmin"         </span>
<span class="co">#&gt; [13] "elec"            "floor"           "walls"           "roof"           </span>
<span class="co">#&gt; [17] "asset_wardrobe"  "asset_table"     "asset_chair"     "asset_khat"     </span>
<span class="co">#&gt; [21] "asset_chouki"    "asset_tv"        "asset_refrig"    "asset_bike"     </span>
<span class="co">#&gt; [25] "asset_moto"      "asset_sewmach"   "asset_mobile"    "delta_momage"   </span>
<span class="co">#&gt; [29] "delta_momheight"</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $outcome</span>
<span class="co">#&gt; [1] "whz"</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $id</span>
<span class="co">#&gt; NULL</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $weights</span>
<span class="co">#&gt; NULL</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $offset</span>
<span class="co">#&gt; NULL</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $time</span>
<span class="co">#&gt; NULL</span></code></pre></div>
<p>We can’t see when we print the task, but the default cross-validation fold
structure (<span class="math inline">\(V\)</span>-fold cross-validation with <span class="math inline">\(V\)</span>=10 folds) was created when we
defined the task.</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">washb_task</span><span class="op">$</span><span class="va">folds</span><span class="op">)</span> <span class="co"># how many folds?</span>
<span class="co">#&gt; [1] 10</span>

<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">washb_task</span><span class="op">$</span><span class="va">folds</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">training_set</span><span class="op">)</span> <span class="co"># row indexes for fold 1 training</span>
<span class="co">#&gt; [1] 1 2 3 4 5 6</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">washb_task</span><span class="op">$</span><span class="va">folds</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">validation_set</span><span class="op">)</span> <span class="co"># row indexes for fold 1 validation</span>
<span class="co">#&gt; [1] 12 21 29 41 43 53</span>

<span class="fu"><a href="https://rdrr.io/r/base/any.html">any</a></span><span class="op">(</span><span class="va">washb_task</span><span class="op">$</span><span class="va">folds</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">training_set</span> <span class="op">%in%</span> <span class="va">washb_task</span><span class="op">$</span><span class="va">folds</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">validation_set</span><span class="op">)</span>
<span class="co">#&gt; [1] FALSE</span></code></pre></div>
<p><code>R6</code> Tip: If you type <code>washb_task$</code> and then press the “tab” button (you will
need to press “tab” twice if you’re not in RStudio), you can view all of the
active and public fields and methods that can be accessed from the <code>washb_task</code>
object.</p>
</div>
<div id="make-a-super-learner" class="section level3 unnumbered">
<h3>2. Make a Super Learner<a class="anchor" aria-label="anchor" href="#make-a-super-learner"><i class="fas fa-link"></i></a>
</h3>
<p>Now that we have defined our machine learning problem with the <code>sl3_Task</code>, we
are ready to <strong>“make”</strong> the Super Learner (SL). This requires specification of</p>
<ul>
<li>A set of candidate machine learning algorithms, also commonly referred to as
a “library” of “learners”. The set should include a diversity of algorithms
that are believed to be consistent with the true data-generating distribution.</li>
<li>A metalearner, to ensemble the base learners.</li>
</ul>
<p>We might also incorporate</p>
<ul>
<li>Feature selection, to pass only a subset of the predictors to the algorithm.</li>
<li>Hyperparameter specification, to tune base learners.</li>
</ul>
<p>Learners have properties that indicate what features they support. We may use
<code><a href="https://tlverse.org/sl3/reference/list_learners.html">sl3_list_properties()</a></code> to get a list of all properties supported by at least
one learner.</p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tlverse.org/sl3/reference/list_learners.html">sl3_list_properties</a></span><span class="op">(</span><span class="op">)</span>
<span class="co">#&gt;  [1] "binomial"      "categorical"   "continuous"    "cv"           </span>
<span class="co">#&gt;  [5] "density"       "h2o"           "ids"           "importance"   </span>
<span class="co">#&gt;  [9] "offset"        "preprocessing" "sampling"      "screener"     </span>
<span class="co">#&gt; [13] "timeseries"    "weights"       "wrapper"</span></code></pre></div>
<p>Since we have a continuous outcome, we may identify the learners that support
this outcome type with <code><a href="https://tlverse.org/sl3/reference/list_learners.html">sl3_list_learners()</a></code>.</p>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tlverse.org/sl3/reference/list_learners.html">sl3_list_learners</a></span><span class="op">(</span><span class="st">"continuous"</span><span class="op">)</span>
<span class="co">#&gt;  [1] "Lrnr_arima"                     "Lrnr_bartMachine"              </span>
<span class="co">#&gt;  [3] "Lrnr_bayesglm"                  "Lrnr_bilstm"                   </span>
<span class="co">#&gt;  [5] "Lrnr_bound"                     "Lrnr_caret"                    </span>
<span class="co">#&gt;  [7] "Lrnr_cv_selector"               "Lrnr_dbarts"                   </span>
<span class="co">#&gt;  [9] "Lrnr_earth"                     "Lrnr_expSmooth"                </span>
<span class="co">#&gt; [11] "Lrnr_gam"                       "Lrnr_gbm"                      </span>
<span class="co">#&gt; [13] "Lrnr_glm"                       "Lrnr_glm_fast"                 </span>
<span class="co">#&gt; [15] "Lrnr_glmnet"                    "Lrnr_grf"                      </span>
<span class="co">#&gt; [17] "Lrnr_gru_keras"                 "Lrnr_gts"                      </span>
<span class="co">#&gt; [19] "Lrnr_h2o_glm"                   "Lrnr_h2o_grid"                 </span>
<span class="co">#&gt; [21] "Lrnr_hal9001"                   "Lrnr_HarmonicReg"              </span>
<span class="co">#&gt; [23] "Lrnr_hts"                       "Lrnr_lstm"                     </span>
<span class="co">#&gt; [25] "Lrnr_lstm_keras"                "Lrnr_mean"                     </span>
<span class="co">#&gt; [27] "Lrnr_multiple_ts"               "Lrnr_nnet"                     </span>
<span class="co">#&gt; [29] "Lrnr_nnls"                      "Lrnr_optim"                    </span>
<span class="co">#&gt; [31] "Lrnr_pkg_SuperLearner"          "Lrnr_pkg_SuperLearner_method"  </span>
<span class="co">#&gt; [33] "Lrnr_pkg_SuperLearner_screener" "Lrnr_polspline"                </span>
<span class="co">#&gt; [35] "Lrnr_randomForest"              "Lrnr_ranger"                   </span>
<span class="co">#&gt; [37] "Lrnr_rpart"                     "Lrnr_rugarch"                  </span>
<span class="co">#&gt; [39] "Lrnr_screener_correlation"      "Lrnr_solnp"                    </span>
<span class="co">#&gt; [41] "Lrnr_stratified"                "Lrnr_svm"                      </span>
<span class="co">#&gt; [43] "Lrnr_tsDyn"                     "Lrnr_xgboost"</span></code></pre></div>
<p>Now that we have an idea of some learners, we can construct them using the
<code>make_learner</code> function or the <code>new</code> method.</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># choose base learners</span>
<span class="va">lrn_glm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/Lrnr_base.html">make_learner</a></span><span class="op">(</span><span class="va">Lrnr_glm</span><span class="op">)</span>
<span class="va">lrn_mean</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_mean.html">Lrnr_mean</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span></code></pre></div>
<p>We can customize learner hyperparameters to incorporate a diversity of different
settings. Documentation for the learners and their hyperparameters can be found
in the <a href="https://tlverse.org/sl3/reference/index.html#section-sl-learners"><code>sl3</code> Learners
Reference</a>.</p>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lrn_lasso</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/Lrnr_base.html">make_learner</a></span><span class="op">(</span><span class="va">Lrnr_glmnet</span><span class="op">)</span> <span class="co"># alpha default is 1</span>
<span class="va">lrn_ridge</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glmnet.html">Lrnr_glmnet</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0</span><span class="op">)</span>
<span class="va">lrn_enet.5</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/Lrnr_base.html">make_learner</a></span><span class="op">(</span><span class="va">Lrnr_glmnet</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>

<span class="va">lrn_polspline</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_polspline.html">Lrnr_polspline</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span>

<span class="va">lrn_ranger100</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/Lrnr_base.html">make_learner</a></span><span class="op">(</span><span class="va">Lrnr_ranger</span>, num.trees <span class="op">=</span> <span class="fl">100</span><span class="op">)</span>

<span class="va">lrn_hal_faster</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_hal9001.html">Lrnr_hal9001</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>max_degree <span class="op">=</span> <span class="fl">2</span>, reduce_basis <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span>

<span class="va">xgb_fast</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_xgboost.html">Lrnr_xgboost</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span> <span class="co"># default with nrounds = 20 is pretty fast</span>
<span class="va">xgb_50</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_xgboost.html">Lrnr_xgboost</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>nrounds <span class="op">=</span> <span class="fl">50</span><span class="op">)</span></code></pre></div>
<p>We can use <code>Lrnr_define_interactions</code> to define interaction terms among
covariates. The interactions should be supplied as list of character vectors,
where each vector specifies an interaction. For example, we specify interactions
below between (1) <code>tr</code> (whether or not the subject received the WASH
intervention) and <code>elec</code> (whether or not the subject had electricity); and
between (2) <code>tr</code> and <code>hfiacat</code> (the subject’s level of food security).</p>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">interactions</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"elec"</span>, <span class="st">"tr"</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"tr"</span>, <span class="st">"hfiacat"</span><span class="op">)</span><span class="op">)</span>
<span class="co"># main terms as well as the interactions above will be included</span>
<span class="va">lrn_interaction</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/Lrnr_base.html">make_learner</a></span><span class="op">(</span><span class="va">Lrnr_define_interactions</span>, <span class="va">interactions</span><span class="op">)</span></code></pre></div>
<p>What we just defined above is incomplete. In order to fit learners with these
interactions, we need to create a <code>Pipeline</code>. A <code>Pipeline</code> is a set of learners
to be fit sequentially, where the fit from one learner is used to define the
task for the next learner. We need to create a <code>Pipeline</code> with the interaction
defining learner and another learner that incorporate these terms when fitting
a model. Let’s create a learner pipeline that will fit a linear model with the
combination of main terms and interactions terms, as specified in
<code>lrn_interaction_main</code>.</p>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># we already instantiated a linear model learner above, no need to do that again</span>
<span class="va">lrn_glm_interaction</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/Lrnr_base.html">make_learner</a></span><span class="op">(</span><span class="va">Pipeline</span>, <span class="va">lrn_interaction</span>, <span class="va">lrn_glm</span><span class="op">)</span>
<span class="va">lrn_glm_interaction</span>
<span class="co">#&gt; [1] "Lrnr_define_interactions_TRUE"</span>
<span class="co">#&gt; [1] "Lrnr_glm_TRUE"</span></code></pre></div>
<p>We can also include learners from the <code>SuperLearner</code> <code>R</code> package.</p>
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lrn_bayesglm</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/SuperLearner_interface.html">Lrnr_pkg_SuperLearner</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="st">"SL.bayesglm"</span><span class="op">)</span></code></pre></div>
<p>Here is a fun trick to create customized learners over a grid of parameters.</p>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># I like to crock pot my SLs</span>
<span class="va">grid_params</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
  cost <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">1</span>, <span class="fl">10</span>, <span class="fl">100</span>, <span class="fl">1000</span><span class="op">)</span>,
  gamma <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">1</span><span class="op">)</span>,
  kernel <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"polynomial"</span>, <span class="st">"radial"</span>, <span class="st">"sigmoid"</span><span class="op">)</span>,
  degree <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">3</span><span class="op">)</span>
<span class="op">)</span>
<span class="va">grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html">expand.grid</a></span><span class="op">(</span><span class="va">grid_params</span>, KEEP.OUT.ATTRS <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="va">svm_learners</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">grid</span>, MARGIN <span class="op">=</span> <span class="fl">1</span>, <span class="kw">function</span><span class="op">(</span><span class="va">tuning_params</span><span class="op">)</span> <span class="op">{</span>
  <span class="fu"><a href="https://rdrr.io/r/base/do.call.html">do.call</a></span><span class="op">(</span><span class="va">Lrnr_svm</span><span class="op">$</span><span class="va">new</span>, <span class="fu"><a href="https://rdrr.io/r/base/list.html">as.list</a></span><span class="op">(</span><span class="va">tuning_params</span><span class="op">)</span><span class="op">)</span>
<span class="op">}</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">grid_params</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
  max_depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">4</span>, <span class="fl">6</span><span class="op">)</span>,
  eta <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.001</span>, <span class="fl">0.1</span>, <span class="fl">0.3</span><span class="op">)</span>,
  nrounds <span class="op">=</span> <span class="fl">100</span>
<span class="op">)</span>
<span class="va">grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html">expand.grid</a></span><span class="op">(</span><span class="va">grid_params</span>, KEEP.OUT.ATTRS <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="va">grid</span>
<span class="co">#&gt;   max_depth   eta nrounds</span>
<span class="co">#&gt; 1         2 0.001     100</span>
<span class="co">#&gt; 2         4 0.001     100</span>
<span class="co">#&gt; 3         6 0.001     100</span>
<span class="co">#&gt; 4         2 0.100     100</span>
<span class="co">#&gt; 5         4 0.100     100</span>
<span class="co">#&gt; 6         6 0.100     100</span>
<span class="co">#&gt; 7         2 0.300     100</span>
<span class="co">#&gt; 8         4 0.300     100</span>
<span class="co">#&gt; 9         6 0.300     100</span>

<span class="va">xgb_learners</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">grid</span>, MARGIN <span class="op">=</span> <span class="fl">1</span>, <span class="kw">function</span><span class="op">(</span><span class="va">tuning_params</span><span class="op">)</span> <span class="op">{</span>
  <span class="fu"><a href="https://rdrr.io/r/base/do.call.html">do.call</a></span><span class="op">(</span><span class="va">Lrnr_xgboost</span><span class="op">$</span><span class="va">new</span>, <span class="fu"><a href="https://rdrr.io/r/base/list.html">as.list</a></span><span class="op">(</span><span class="va">tuning_params</span><span class="op">)</span><span class="op">)</span>
<span class="op">}</span><span class="op">)</span>
<span class="va">xgb_learners</span>
<span class="co">#&gt; [[1]]</span>
<span class="co">#&gt; [1] "Lrnr_xgboost_100_1_2_0.001"</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[2]]</span>
<span class="co">#&gt; [1] "Lrnr_xgboost_100_1_4_0.001"</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[3]]</span>
<span class="co">#&gt; [1] "Lrnr_xgboost_100_1_6_0.001"</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[4]]</span>
<span class="co">#&gt; [1] "Lrnr_xgboost_100_1_2_0.1"</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[5]]</span>
<span class="co">#&gt; [1] "Lrnr_xgboost_100_1_4_0.1"</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[6]]</span>
<span class="co">#&gt; [1] "Lrnr_xgboost_100_1_6_0.1"</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[7]]</span>
<span class="co">#&gt; [1] "Lrnr_xgboost_100_1_2_0.3"</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[8]]</span>
<span class="co">#&gt; [1] "Lrnr_xgboost_100_1_4_0.3"</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[9]]</span>
<span class="co">#&gt; [1] "Lrnr_xgboost_100_1_6_0.3"</span></code></pre></div>
<p>Did you see <code>Lrnr_caret</code> when we called <code><a href="https://tlverse.org/sl3/reference/list_learners.html">sl3_list_learners(c("binomial"))</a></code>?
All we need to specify to use this popular algorithm as a candidate in our
SL is the <code>algorithm</code> we want to tune, which is passed as <code>method</code> to
<code><a href="https://rdrr.io/pkg/caret/man/train.html">caret::train()</a></code>. The default method for parameter selection criterion with is
set to “CV” instead of the <code><a href="https://rdrr.io/pkg/caret/man/train.html">caret::train()</a></code> default <code>boot</code>. The summary metric
used to select the optimal model is <code>RMSE</code> for continuous outcomes and
<code>Accuracy</code> for categorical and binomial outcomes.</p>
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Unlike xgboost, I have no idea how to tune a neural net or BART machine, so</span>
<span class="co"># I let caret take the reins</span>
<span class="va">lrnr_caret_nnet</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/Lrnr_base.html">make_learner</a></span><span class="op">(</span><span class="va">Lrnr_caret</span>, algorithm <span class="op">=</span> <span class="st">"nnet"</span><span class="op">)</span>
<span class="va">lrnr_caret_bartMachine</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/Lrnr_base.html">make_learner</a></span><span class="op">(</span><span class="va">Lrnr_caret</span>,
  algorithm <span class="op">=</span> <span class="st">"bartMachine"</span>,
  method <span class="op">=</span> <span class="st">"boot"</span>, metric <span class="op">=</span> <span class="st">"Accuracy"</span>,
  tuneLength <span class="op">=</span> <span class="fl">10</span>
<span class="op">)</span></code></pre></div>
<p>In order to assemble the library of learners, we need to <strong>“stack”</strong> them
together.</p>
<p>A <code>Stack</code> is a special learner and it has the same interface as all other
learners. What makes a stack special is that it combines multiple learners by
training them simultaneously, so that their predictions can be either combined
or compared.</p>
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">stack</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/Lrnr_base.html">make_learner</a></span><span class="op">(</span>
  <span class="va">Stack</span>, <span class="va">lrn_glm</span>, <span class="va">lrn_polspline</span>, <span class="va">lrn_enet.5</span>, <span class="va">lrn_ridge</span>, <span class="va">lrn_lasso</span>, <span class="va">xgb_50</span>
<span class="op">)</span>
<span class="va">stack</span>
<span class="co">#&gt; [1] "Lrnr_glm_TRUE"                            </span>
<span class="co">#&gt; [2] "Lrnr_polspline_5"                         </span>
<span class="co">#&gt; [3] "Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE"</span>
<span class="co">#&gt; [4] "Lrnr_glmnet_NULL_deviance_10_0_100_TRUE"  </span>
<span class="co">#&gt; [5] "Lrnr_glmnet_NULL_deviance_10_1_100_TRUE"  </span>
<span class="co">#&gt; [6] "Lrnr_xgboost_50_1"</span></code></pre></div>
<p>We can also stack the learners by first creating a vector, and then
instantiating the stack. I prefer this method, since it easily allows us to
modify the names of the learners.</p>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># named vector of learners first</span>
<span class="va">learners</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">lrn_glm</span>, <span class="va">lrn_polspline</span>, <span class="va">lrn_enet.5</span>, <span class="va">lrn_ridge</span>, <span class="va">lrn_lasso</span>, <span class="va">xgb_50</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">learners</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"glm"</span>, <span class="st">"polspline"</span>, <span class="st">"enet.5"</span>, <span class="st">"ridge"</span>, <span class="st">"lasso"</span>, <span class="st">"xgboost50"</span><span class="op">)</span>
<span class="co"># next make the stack</span>
<span class="va">stack</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/Lrnr_base.html">make_learner</a></span><span class="op">(</span><span class="va">Stack</span>, <span class="va">learners</span><span class="op">)</span>
<span class="co"># now the names are pretty</span>
<span class="va">stack</span>
<span class="co">#&gt; [1] "glm"       "polspline" "enet.5"    "ridge"     "lasso"     "xgboost50"</span></code></pre></div>
<p>We’re jumping ahead a bit, but let’s check something out quickly. It’s
straightforward, and just one more step, to set up this stack such that
all of the learners will train in a cross-validated manner.</p>
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">cv_stack</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_cv.html">Lrnr_cv</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">stack</span><span class="op">)</span>
<span class="va">cv_stack</span>
<span class="co">#&gt; [1] "Lrnr_cv"</span>
<span class="co">#&gt; [1] "glm"       "polspline" "enet.5"    "ridge"     "lasso"     "xgboost50"</span></code></pre></div>
<div id="screening-algorithms-for-feature-selection" class="section level4 unnumbered">
<h4>Screening Algorithms for Feature Selection<a class="anchor" aria-label="anchor" href="#screening-algorithms-for-feature-selection"><i class="fas fa-link"></i></a>
</h4>
<p>We can optionally select a subset of available covariates and pass only
those variables to the modeling algorithm. The current set of learners that
can be used for prescreening covariates is included below.</p>
<ul>
<li>
<code>Lrnr_screener_importance</code> selects <code>num_screen</code> (default = 5) covariates
based on the variable importance ranking provided by the <code>learner</code>. Any
learner with an “importance” method can be used in <code>Lrnr_screener_importance</code>;
and this currently includes <code>Lrnr_ranger</code>, <code>Lrnr_randomForest</code>, and
<code>Lrnr_xgboost</code>.</li>
<li>
<code>Lrnr_screener_coefs</code>, which provides screening of covariates based on the
magnitude of their estimated coefficients in a (possibly regularized) GLM.
The <code>threshold</code> (default = 1e-3) defines the minimum absolute size of the
coefficients, and thus covariates, to be kept. Also, a <code>max_retain</code> argument
can be optionally provided to restrict the number of selected covariates to be
no more than <code>max_retain</code>.</li>
<li>
<code>Lrnr_screener_correlation</code> provides covariate screening procedures by
running a test of correlation (Pearson default), and then selecting the (1)
top ranked variables (default), or (2) the variables with a pvalue lower than
some pre-specified threshold.</li>
<li>
<code>Lrnr_screener_augment</code> augments a set of screened covariates with additional<br>
covariates that should be included by default, even if the screener did not
select them. An example of how to use this screener is included below.</li>
</ul>
<p>Let’s consider screening covariates based on their <code>randomForest</code> variable
importance ranking (ordered by mean decrease in accuracy). To select the top
5 most important covariates according to this ranking, we can combine
<code>Lrnr_screener_importance</code> with <code>Lrnr_ranger</code> (limiting the number of trees by
setting <code>ntree = 20</code>).</p>
<p>Hang on! Before you think it – I will confess: Bob Ross and I both know that 20
trees makes for a lonely forest, and I shouldn’t consider it, but these are the
sacrifices I have to make for this chapter to build in time!</p>
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">miniforest</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_ranger.html">Lrnr_ranger</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>
  num.trees <span class="op">=</span> <span class="fl">20</span>, write.forest <span class="op">=</span> <span class="cn">FALSE</span>,
  importance <span class="op">=</span> <span class="st">"impurity_corrected"</span>
<span class="op">)</span>

<span class="co"># learner must already be instantiated, we did this when we created miniforest</span>
<span class="va">screen_rf</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_screener_importance.html">Lrnr_screener_importance</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>learner <span class="op">=</span> <span class="va">miniforest</span>, num_screen <span class="op">=</span> <span class="fl">5</span><span class="op">)</span>
<span class="va">screen_rf</span>
<span class="co">#&gt; [1] "Lrnr_screener_importance_5"</span>

<span class="co"># which covariates are selected on the full data?</span>
<span class="va">screen_rf</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">washb_task</span><span class="op">)</span>
<span class="co">#&gt; [1] "Lrnr_screener_importance_5"</span>
<span class="co">#&gt; $selected</span>
<span class="co">#&gt; [1] "aged"        "month"       "momedu"      "asset_tv"    "asset_chair"</span></code></pre></div>
<p>An example of how to format <code>Lrnr_screener_augment</code> is included below for
clarity.</p>
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">keepme</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"aged"</span>, <span class="st">"momage"</span><span class="op">)</span>
<span class="co"># screener must already be instantiated, we did this when we created screen_rf</span>
<span class="va">screen_augment_rf</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_screener_augment.html">Lrnr_screener_augment</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>
  screener <span class="op">=</span> <span class="va">screen_rf</span>, default_covariates <span class="op">=</span> <span class="va">keepme</span>
<span class="op">)</span>
<span class="va">screen_augment_rf</span>
<span class="co">#&gt; [1] "Lrnr_screener_augment_c(\"aged\", \"momage\")"</span></code></pre></div>
<p>Selecting covariates with non-zero lasso coefficients is quite common. Let’s
construct <code>Lrnr_screener_coefs</code> screener that does just that, and test it
out.</p>
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># we already instantiated a lasso learner above, no need to do it again</span>
<span class="va">screen_lasso</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_screener_coefs.html">Lrnr_screener_coefs</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>learner <span class="op">=</span> <span class="va">lrn_lasso</span>, threshold <span class="op">=</span> <span class="fl">0</span><span class="op">)</span>
<span class="va">screen_lasso</span>
<span class="co">#&gt; [1] "Lrnr_screener_coefs_0_NULL"</span></code></pre></div>
<p>To <strong>“pipe”</strong> only the selected covariates to the modeling algorithm, we need to
make a <code>Pipeline</code>, similar to the one we built for the regression model with
interaction terms.</p>
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">screen_rf_pipe</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/Lrnr_base.html">make_learner</a></span><span class="op">(</span><span class="va">Pipeline</span>, <span class="va">screen_rf</span>, <span class="va">stack</span><span class="op">)</span>
<span class="va">screen_lasso_pipe</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/Lrnr_base.html">make_learner</a></span><span class="op">(</span><span class="va">Pipeline</span>, <span class="va">screen_lasso</span>, <span class="va">stack</span><span class="op">)</span></code></pre></div>
<p>Now, these learners with no internal screening will be preceded by a screening
step.</p>
<p>We also consider the original <code>stack</code>, to compare how the feature selection
methods perform in comparison to the methods without feature selection.</p>
<p>Analogous to what we have seen before, we have to stack the pipeline and
original <code>stack</code> together, so we may use them as base learners in our super
learner.</p>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># pretty names again</span>
<span class="va">learners2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">learners</span>, <span class="va">screen_rf_pipe</span>, <span class="va">screen_lasso_pipe</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">learners2</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">learners</span><span class="op">)</span>, <span class="st">"randomforest_screen"</span>, <span class="st">"lasso_screen"</span><span class="op">)</span>

<span class="va">fancy_stack</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/Lrnr_base.html">make_learner</a></span><span class="op">(</span><span class="va">Stack</span>, <span class="va">learners2</span><span class="op">)</span>
<span class="va">fancy_stack</span>
<span class="co">#&gt; [1] "glm"                 "polspline"           "enet.5"             </span>
<span class="co">#&gt; [4] "ridge"               "lasso"               "xgboost50"          </span>
<span class="co">#&gt; [7] "randomforest_screen" "lasso_screen"</span></code></pre></div>
<p>We will use the <a href="https://tlverse.org/sl3/reference/default_metalearner.html">default
metalearner</a>, which
uses <a href="https://tlverse.org/sl3/reference/Lrnr_solnp.html"><code>Lrnr_solnp()</code></a> to
provide fitting procedures for a pairing of <a href="https://tlverse.org/sl3/reference/loss_functions.html">loss
function</a> and
<a href="https://tlverse.org/sl3/reference/metalearners.html">metalearner function</a>.
This default metalearner selects a loss and metalearner pairing based on the
outcome type. Note that any learner can be used as a metalearner.</p>
<p>Now that we have made a diverse stack of base learners, we are ready to make the
SL. The SL algorithm fits a metalearner on the validation set
predictions/losses across all folds.</p>
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/Lrnr_base.html">make_learner</a></span><span class="op">(</span><span class="va">Lrnr_sl</span>, learners <span class="op">=</span> <span class="va">fancy_stack</span><span class="op">)</span></code></pre></div>
<p>We can also use <code>Lrnr_cv</code> to build a SL, cross-validate a stack of
learners to compare performance of the learners in the stack, or cross-validate
any single learner (see “Cross-validation” section of this <a href="https://tlverse.org/sl3/articles/intro_sl3.html"><code>sl3</code>
introductory tutorial</a>).</p>
<p>Furthermore, we can <a href="https://tlverse.org/sl3/articles/custom_lrnrs.html">Define New <code>sl3</code>
Learners</a> which can be used
in all the places you could otherwise use any other <code>sl3</code> learners, including
<code>Pipelines</code>, <code>Stacks</code>, and the SL.</p>
<p>Recall that the discrete SL, or cross-validated selector, is a metalearner that
assigns a weight of 1 to the learner with the lowest cross-validated empirical
risk, and weight of 0 to all other learners. This metalearner specification can
be invoked with <code>Lrnr_cv_selector</code>.</p>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">discrete_sl_metalrn</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_cv_selector.html">Lrnr_cv_selector</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span>
<span class="va">discrete_sl</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_sl.html">Lrnr_sl</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>
  learners <span class="op">=</span> <span class="va">fancy_stack</span>,
  metalearner <span class="op">=</span> <span class="va">discrete_sl_metalrn</span>
<span class="op">)</span></code></pre></div>
<!--
In the plot below, we visualize the steps for executing the Super Learner in the
`tlverse/delayed` framework. For those like myself who are not particularly
keen on understanding the intricacies of `delayed`, let's focus on the main
point of this figure: we can see there are 10 realizations of the stack which
represent the 10 cross-validation folds and there is a separate hold-out
(top branch of the figure) that will not be used to fit the Super Learner.


```r
dt_sl <- delayed_learner_train(sl, washb_task)
plot(dt_sl, color = FALSE, height = "400px", width = "90%")
```

```{=html}
<div id="htmlwidget-64e31bdf0964cb796022" style="width:90%;height:400px;" class="visNetwork html-widget"></div>
<script type="application/json" data-for="htmlwidget-64e31bdf0964cb796022">{"x":{"nodes":{"id":["9724c750-8217-11eb-9071-42010a1e0020","9724b94a-8217-11eb-9071-42010a1e0020","97247f98-8217-11eb-9071-42010a1e0020","972471ec-8217-11eb-9071-42010a1e0020","96ef25b4-8217-11eb-9071-42010a1e0020","96ef1556-8217-11eb-9071-42010a1e0020","96ec56a4-8217-11eb-9071-42010a1e0020","96ec6900-8217-11eb-9071-42010a1e0020","96ec792c-8217-11eb-9071-42010a1e0020","96ec89d0-8217-11eb-9071-42010a1e0020","96ec9a2e-8217-11eb-9071-42010a1e0020","96ecaa3c-8217-11eb-9071-42010a1e0020","96eddb6e-8217-11eb-9071-42010a1e0020","96edcdfe-8217-11eb-9071-42010a1e0020","96ecbdc4-8217-11eb-9071-42010a1e0020","96edb31e-8217-11eb-9071-42010a1e0020","96ecce90-8217-11eb-9071-42010a1e0020","96eda41e-8217-11eb-9071-42010a1e0020","96ecfca8-8217-11eb-9071-42010a1e0020","96ecdf02-8217-11eb-9071-42010a1e0020","96ed19b8-8217-11eb-9071-42010a1e0020","96ed36a0-8217-11eb-9071-42010a1e0020","96ed5644-8217-11eb-9071-42010a1e0020","96ed737c-8217-11eb-9071-42010a1e0020","96ed90c8-8217-11eb-9071-42010a1e0020","96ef03b8-8217-11eb-9071-42010a1e0020","96eef5b2-8217-11eb-9071-42010a1e0020","96edf1b2-8217-11eb-9071-42010a1e0020","96eedbd6-8217-11eb-9071-42010a1e0020","96edfe3c-8217-11eb-9071-42010a1e0020","96eeccae-8217-11eb-9071-42010a1e0020","96ee2a92-8217-11eb-9071-42010a1e0020","96ee0de6-8217-11eb-9071-42010a1e0020","96ee47e8-8217-11eb-9071-42010a1e0020","96ee64e4-8217-11eb-9071-42010a1e0020","96ee83b6-8217-11eb-9071-42010a1e0020","96eea17a-8217-11eb-9071-42010a1e0020","96eebe9e-8217-11eb-9071-42010a1e0020","972462ba-8217-11eb-9071-42010a1e0020","96f77d7c-8217-11eb-9071-42010a1e0020","96f76e68-8217-11eb-9071-42010a1e0020","96f3ea40-8217-11eb-9071-42010a1e0020","96f3fbe8-8217-11eb-9071-42010a1e0020","96f40d72-8217-11eb-9071-42010a1e0020","96f41d8a-8217-11eb-9071-42010a1e0020","96f42f0a-8217-11eb-9071-42010a1e0020","96f43f9a-8217-11eb-9071-42010a1e0020","96f634da-8217-11eb-9071-42010a1e0020","96f62756-8217-11eb-9071-42010a1e0020","96f522b6-8217-11eb-9071-42010a1e0020","96f60ce4-8217-11eb-9071-42010a1e0020","96f52fb8-8217-11eb-9071-42010a1e0020","96f5fdf8-8217-11eb-9071-42010a1e0020","96f55c2c-8217-11eb-9071-42010a1e0020","96f53f58-8217-11eb-9071-42010a1e0020","96f57a7c-8217-11eb-9071-42010a1e0020","96f597b4-8217-11eb-9071-42010a1e0020","96f5b4f6-8217-11eb-9071-42010a1e0020","96f5d17a-8217-11eb-9071-42010a1e0020","96f5ef48-8217-11eb-9071-42010a1e0020","96f75d56-8217-11eb-9071-42010a1e0020","96f74f46-8217-11eb-9071-42010a1e0020","96f64ab0-8217-11eb-9071-42010a1e0020","96f734ac-8217-11eb-9071-42010a1e0020","96f65762-8217-11eb-9071-42010a1e0020","96f724f8-8217-11eb-9071-42010a1e0020","96f68408-8217-11eb-9071-42010a1e0020","96f66612-8217-11eb-9071-42010a1e0020","96f6a190-8217-11eb-9071-42010a1e0020","96f6bf0e-8217-11eb-9071-42010a1e0020","96f6dbce-8217-11eb-9071-42010a1e0020","96f6f8de-8217-11eb-9071-42010a1e0020","96f7168e-8217-11eb-9071-42010a1e0020","97091776-8217-11eb-9071-42010a1e0020","97090718-8217-11eb-9071-42010a1e0020","97065810-8217-11eb-9071-42010a1e0020","970668b4-8217-11eb-9071-42010a1e0020","970679da-8217-11eb-9071-42010a1e0020","97068a06-8217-11eb-9071-42010a1e0020","970699c4-8217-11eb-9071-42010a1e0020","9706aa18-8217-11eb-9071-42010a1e0020","9707ccd6-8217-11eb-9071-42010a1e0020","9707be12-8217-11eb-9071-42010a1e0020","9706bbde-8217-11eb-9071-42010a1e0020","9707a274-8217-11eb-9071-42010a1e0020","9706c8ae-8217-11eb-9071-42010a1e0020","970793ec-8217-11eb-9071-42010a1e0020","9706f48c-8217-11eb-9071-42010a1e0020","9706d722-8217-11eb-9071-42010a1e0020","970711a6-8217-11eb-9071-42010a1e0020","97072e2a-8217-11eb-9071-42010a1e0020","97074ae0-8217-11eb-9071-42010a1e0020","970767dc-8217-11eb-9071-42010a1e0020","9707847e-8217-11eb-9071-42010a1e0020","9708f55c-8217-11eb-9071-42010a1e0020","9708e6ca-8217-11eb-9071-42010a1e0020","9707e1f8-8217-11eb-9071-42010a1e0020","9708cba4-8217-11eb-9071-42010a1e0020","9707ee3c-8217-11eb-9071-42010a1e0020","9708bb0a-8217-11eb-9071-42010a1e0020","97081984-8217-11eb-9071-42010a1e0020","9707fce2-8217-11eb-9071-42010a1e0020","97083874-8217-11eb-9071-42010a1e0020","9708557a-8217-11eb-9071-42010a1e0020","970872b2-8217-11eb-9071-42010a1e0020","97088f72-8217-11eb-9071-42010a1e0020","9708aca0-8217-11eb-9071-42010a1e0020","970d67f4-8217-11eb-9071-42010a1e0020","970d58cc-8217-11eb-9071-42010a1e0020","9709ad44-8217-11eb-9071-42010a1e0020","9709bf3c-8217-11eb-9071-42010a1e0020","9709d012-8217-11eb-9071-42010a1e0020","9709e048-8217-11eb-9071-42010a1e0020","9709f024-8217-11eb-9071-42010a1e0020","970a0168-8217-11eb-9071-42010a1e0020","970c196c-8217-11eb-9071-42010a1e0020","970c0b20-8217-11eb-9071-42010a1e0020","970a13ba-8217-11eb-9071-42010a1e0020","970bf00e-8217-11eb-9071-42010a1e0020","970a213e-8217-11eb-9071-42010a1e0020","970be17c-8217-11eb-9071-42010a1e0020","970a4e3e-8217-11eb-9071-42010a1e0020","970a305c-8217-11eb-9071-42010a1e0020","970a6c70-8217-11eb-9071-42010a1e0020","970a8a84-8217-11eb-9071-42010a1e0020","970aa924-8217-11eb-9071-42010a1e0020","970bb422-8217-11eb-9071-42010a1e0020","970bd2f4-8217-11eb-9071-42010a1e0020","970d4788-8217-11eb-9071-42010a1e0020","970d39be-8217-11eb-9071-42010a1e0020","970c2e66-8217-11eb-9071-42010a1e0020","970d1f10-8217-11eb-9071-42010a1e0020","970c3b22-8217-11eb-9071-42010a1e0020","970d104c-8217-11eb-9071-42010a1e0020","970c6bc4-8217-11eb-9071-42010a1e0020","970c4d60-8217-11eb-9071-42010a1e0020","970c88d4-8217-11eb-9071-42010a1e0020","970ca832-8217-11eb-9071-42010a1e0020","970cc678-8217-11eb-9071-42010a1e0020","970ce3ba-8217-11eb-9071-42010a1e0020","970d00c0-8217-11eb-9071-42010a1e0020","9710b5f8-8217-11eb-9071-42010a1e0020","9710a55e-8217-11eb-9071-42010a1e0020","970df50c-8217-11eb-9071-42010a1e0020","970e052e-8217-11eb-9071-42010a1e0020","970e1596-8217-11eb-9071-42010a1e0020","970e25ae-8217-11eb-9071-42010a1e0020","970e3576-8217-11eb-9071-42010a1e0020","970e4642-8217-11eb-9071-42010a1e0020","970f6824-8217-11eb-9071-42010a1e0020","970f5ae6-8217-11eb-9071-42010a1e0020","970e57fe-8217-11eb-9071-42010a1e0020","970f4092-8217-11eb-9071-42010a1e0020","970e64d8-8217-11eb-9071-42010a1e0020","970f31f6-8217-11eb-9071-42010a1e0020","970e90f2-8217-11eb-9071-42010a1e0020","970e7388-8217-11eb-9071-42010a1e0020","970eae16-8217-11eb-9071-42010a1e0020","970ecb8a-8217-11eb-9071-42010a1e0020","970ee94e-8217-11eb-9071-42010a1e0020","970f06ae-8217-11eb-9071-42010a1e0020","970f236e-8217-11eb-9071-42010a1e0020","971093ca-8217-11eb-9071-42010a1e0020","9710860a-8217-11eb-9071-42010a1e0020","970f7d96-8217-11eb-9071-42010a1e0020","97106b70-8217-11eb-9071-42010a1e0020","970f8a0c-8217-11eb-9071-42010a1e0020","97105c02-8217-11eb-9071-42010a1e0020","970fb5ae-8217-11eb-9071-42010a1e0020","970f9812-8217-11eb-9071-42010a1e0020","970fd322-8217-11eb-9071-42010a1e0020","970ff4a6-8217-11eb-9071-42010a1e0020","971012ce-8217-11eb-9071-42010a1e0020","97102ff2-8217-11eb-9071-42010a1e0020","97104d5c-8217-11eb-9071-42010a1e0020","9714008c-8217-11eb-9071-42010a1e0020","9713f128-8217-11eb-9071-42010a1e0020","97114108-8217-11eb-9071-42010a1e0020","971152a6-8217-11eb-9071-42010a1e0020","9711630e-8217-11eb-9071-42010a1e0020","97117330-8217-11eb-9071-42010a1e0020","9711830c-8217-11eb-9071-42010a1e0020","97119356-8217-11eb-9071-42010a1e0020","9712b83a-8217-11eb-9071-42010a1e0020","9712aa34-8217-11eb-9071-42010a1e0020","9711a562-8217-11eb-9071-42010a1e0020","97128f5e-8217-11eb-9071-42010a1e0020","9711b21e-8217-11eb-9071-42010a1e0020","97127f5a-8217-11eb-9071-42010a1e0020","9711dd84-8217-11eb-9071-42010a1e0020","9711c100-8217-11eb-9071-42010a1e0020","9711fbca-8217-11eb-9071-42010a1e0020","9712193e-8217-11eb-9071-42010a1e0020","971236b2-8217-11eb-9071-42010a1e0020","971253fe-8217-11eb-9071-42010a1e0020","971270f0-8217-11eb-9071-42010a1e0020","9713dfc6-8217-11eb-9071-42010a1e0020","9713d274-8217-11eb-9071-42010a1e0020","9712ccbc-8217-11eb-9071-42010a1e0020","9713b6ea-8217-11eb-9071-42010a1e0020","9712d9e6-8217-11eb-9071-42010a1e0020","9713a7ea-8217-11eb-9071-42010a1e0020","97130574-8217-11eb-9071-42010a1e0020","9712e850-8217-11eb-9071-42010a1e0020","971323ce-8217-11eb-9071-42010a1e0020","97134106-8217-11eb-9071-42010a1e0020","97135e2a-8217-11eb-9071-42010a1e0020","97137b94-8217-11eb-9071-42010a1e0020","97139926-8217-11eb-9071-42010a1e0020","971745ee-8217-11eb-9071-42010a1e0020","97173662-8217-11eb-9071-42010a1e0020","971488ae-8217-11eb-9071-42010a1e0020","971498ee-8217-11eb-9071-42010a1e0020","9714a960-8217-11eb-9071-42010a1e0020","9714b9d2-8217-11eb-9071-42010a1e0020","9714c9ae-8217-11eb-9071-42010a1e0020","9714da02-8217-11eb-9071-42010a1e0020","9715fde2-8217-11eb-9071-42010a1e0020","9715f02c-8217-11eb-9071-42010a1e0020","9714eb8c-8217-11eb-9071-42010a1e0020","9715d556-8217-11eb-9071-42010a1e0020","9714f91a-8217-11eb-9071-42010a1e0020","9715c6ce-8217-11eb-9071-42010a1e0020","97152534-8217-11eb-9071-42010a1e0020","971507f2-8217-11eb-9071-42010a1e0020","97154316-8217-11eb-9071-42010a1e0020","9715601c-8217-11eb-9071-42010a1e0020","97157d2c-8217-11eb-9071-42010a1e0020","97159adc-8217-11eb-9071-42010a1e0020","9715b85a-8217-11eb-9071-42010a1e0020","9717258c-8217-11eb-9071-42010a1e0020","971717cc-8217-11eb-9071-42010a1e0020","971612e6-8217-11eb-9071-42010a1e0020","9716fdb4-8217-11eb-9071-42010a1e0020","97161ffc-8217-11eb-9071-42010a1e0020","9716eeb4-8217-11eb-9071-42010a1e0020","97164dec-8217-11eb-9071-42010a1e0020","9716303c-8217-11eb-9071-42010a1e0020","97166b2e-8217-11eb-9071-42010a1e0020","971688f2-8217-11eb-9071-42010a1e0020","9716a5d0-8217-11eb-9071-42010a1e0020","9716c29a-8217-11eb-9071-42010a1e0020","9716e02c-8217-11eb-9071-42010a1e0020","971a8826-8217-11eb-9071-42010a1e0020","971a78a4-8217-11eb-9071-42010a1e0020","9717cc9e-8217-11eb-9071-42010a1e0020","9717ddba-8217-11eb-9071-42010a1e0020","9717ede6-8217-11eb-9071-42010a1e0020","9717fd68-8217-11eb-9071-42010a1e0020","97180e3e-8217-11eb-9071-42010a1e0020","97181db6-8217-11eb-9071-42010a1e0020","9719424a-8217-11eb-9071-42010a1e0020","9719339a-8217-11eb-9071-42010a1e0020","97182fb8-8217-11eb-9071-42010a1e0020","97191a04-8217-11eb-9071-42010a1e0020","97183cb0-8217-11eb-9071-42010a1e0020","97190aa0-8217-11eb-9071-42010a1e0020","97186820-8217-11eb-9071-42010a1e0020","97184b1a-8217-11eb-9071-42010a1e0020","97188544-8217-11eb-9071-42010a1e0020","9718a47a-8217-11eb-9071-42010a1e0020","9718c176-8217-11eb-9071-42010a1e0020","9718df80-8217-11eb-9071-42010a1e0020","9718fc7c-8217-11eb-9071-42010a1e0020","971a6684-8217-11eb-9071-42010a1e0020","971a5900-8217-11eb-9071-42010a1e0020","97195686-8217-11eb-9071-42010a1e0020","971a3e52-8217-11eb-9071-42010a1e0020","97196356-8217-11eb-9071-42010a1e0020","971a2ff2-8217-11eb-9071-42010a1e0020","97198ebc-8217-11eb-9071-42010a1e0020","97197210-8217-11eb-9071-42010a1e0020","9719abc2-8217-11eb-9071-42010a1e0020","9719c972-8217-11eb-9071-42010a1e0020","9719e75e-8217-11eb-9071-42010a1e0020","971a0482-8217-11eb-9071-42010a1e0020","971a211a-8217-11eb-9071-42010a1e0020","971dcaae-8217-11eb-9071-42010a1e0020","971dbb7c-8217-11eb-9071-42010a1e0020","971b0ef4-8217-11eb-9071-42010a1e0020","971b1fc0-8217-11eb-9071-42010a1e0020","971b2fe2-8217-11eb-9071-42010a1e0020","971b4004-8217-11eb-9071-42010a1e0020","971b501c-8217-11eb-9071-42010a1e0020","971b6016-8217-11eb-9071-42010a1e0020","971c80e0-8217-11eb-9071-42010a1e0020","971c737a-8217-11eb-9071-42010a1e0020","971b718c-8217-11eb-9071-42010a1e0020","971c5930-8217-11eb-9071-42010a1e0020","971b7df8-8217-11eb-9071-42010a1e0020","971c4a6c-8217-11eb-9071-42010a1e0020","971ba986-8217-11eb-9071-42010a1e0020","971b8cbc-8217-11eb-9071-42010a1e0020","971bc74a-8217-11eb-9071-42010a1e0020","971be4e6-8217-11eb-9071-42010a1e0020","971c01f6-8217-11eb-9071-42010a1e0020","971c1eac-8217-11eb-9071-42010a1e0020","971c3b6c-8217-11eb-9071-42010a1e0020","971da920-8217-11eb-9071-42010a1e0020","971d99c6-8217-11eb-9071-42010a1e0020","971c9594-8217-11eb-9071-42010a1e0020","971d7c52-8217-11eb-9071-42010a1e0020","971ca1ec-8217-11eb-9071-42010a1e0020","971d6dac-8217-11eb-9071-42010a1e0020","971cccda-8217-11eb-9071-42010a1e0020","971cb01a-8217-11eb-9071-42010a1e0020","971cea9e-8217-11eb-9071-42010a1e0020","971d07cc-8217-11eb-9071-42010a1e0020","971d2536-8217-11eb-9071-42010a1e0020","971d4246-8217-11eb-9071-42010a1e0020","971d5f4c-8217-11eb-9071-42010a1e0020","972115a6-8217-11eb-9071-42010a1e0020","97210656-8217-11eb-9071-42010a1e0020","971e510e-8217-11eb-9071-42010a1e0020","971e6194-8217-11eb-9071-42010a1e0020","971e71b6-8217-11eb-9071-42010a1e0020","971e8192-8217-11eb-9071-42010a1e0020","971e91dc-8217-11eb-9071-42010a1e0020","971ea1ae-8217-11eb-9071-42010a1e0020","971fcbc4-8217-11eb-9071-42010a1e0020","971fbbd4-8217-11eb-9071-42010a1e0020","971eb310-8217-11eb-9071-42010a1e0020","971f9eb0-8217-11eb-9071-42010a1e0020","971ec1d4-8217-11eb-9071-42010a1e0020","971f8ff6-8217-11eb-9071-42010a1e0020","971eee3e-8217-11eb-9071-42010a1e0020","971ed0a2-8217-11eb-9071-42010a1e0020","971f0b80-8217-11eb-9071-42010a1e0020","971f280e-8217-11eb-9071-42010a1e0020","971f4500-8217-11eb-9071-42010a1e0020","971f647c-8217-11eb-9071-42010a1e0020","971f81f0-8217-11eb-9071-42010a1e0020","9720f4c2-8217-11eb-9071-42010a1e0020","9720e766-8217-11eb-9071-42010a1e0020","971fe0b4-8217-11eb-9071-42010a1e0020","9720ccd6-8217-11eb-9071-42010a1e0020","971fed02-8217-11eb-9071-42010a1e0020","9720bd9a-8217-11eb-9071-42010a1e0020","97201b74-8217-11eb-9071-42010a1e0020","971ffdf6-8217-11eb-9071-42010a1e0020","97203848-8217-11eb-9071-42010a1e0020","9720556c-8217-11eb-9071-42010a1e0020","97207268-8217-11eb-9071-42010a1e0020","972090cc-8217-11eb-9071-42010a1e0020","9720aea4-8217-11eb-9071-42010a1e0020","9724540a-8217-11eb-9071-42010a1e0020","972444ce-8217-11eb-9071-42010a1e0020","97219cc4-8217-11eb-9071-42010a1e0020","9721ad4a-8217-11eb-9071-42010a1e0020","9721bd12-8217-11eb-9071-42010a1e0020","9721cdca-8217-11eb-9071-42010a1e0020","9721dd9c-8217-11eb-9071-42010a1e0020","9721ee2c-8217-11eb-9071-42010a1e0020","97231022-8217-11eb-9071-42010a1e0020","9723026c-8217-11eb-9071-42010a1e0020","9721ffca-8217-11eb-9071-42010a1e0020","9722e750-8217-11eb-9071-42010a1e0020","97220c04-8217-11eb-9071-42010a1e0020","9722d878-8217-11eb-9071-42010a1e0020","97223706-8217-11eb-9071-42010a1e0020","97221af0-8217-11eb-9071-42010a1e0020","97225470-8217-11eb-9071-42010a1e0020","9722725c-8217-11eb-9071-42010a1e0020","97228fda-8217-11eb-9071-42010a1e0020","9722ac86-8217-11eb-9071-42010a1e0020","9722c9f0-8217-11eb-9071-42010a1e0020","97243290-8217-11eb-9071-42010a1e0020","97242534-8217-11eb-9071-42010a1e0020","97232472-8217-11eb-9071-42010a1e0020","97240a7c-8217-11eb-9071-42010a1e0020","972330e8-8217-11eb-9071-42010a1e0020","9723fbd6-8217-11eb-9071-42010a1e0020","97235bea-8217-11eb-9071-42010a1e0020","97233eee-8217-11eb-9071-42010a1e0020","972378be-8217-11eb-9071-42010a1e0020","9723952e-8217-11eb-9071-42010a1e0020","9723b31a-8217-11eb-9071-42010a1e0020","9723d03e-8217-11eb-9071-42010a1e0020","9723ed6c-8217-11eb-9071-42010a1e0020","97248df8-8217-11eb-9071-42010a1e0020","9724a982-8217-11eb-9071-42010a1e0020"],"label":["CV_","bundle","CV_Stack","bundle","Stack","bundle","Lrnr_glm_TRUE","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_importance_5->Stack)","bundle","Lrnr_screener_importance_5","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_coefs_0_NULL->Stack)","bundle","Lrnr_screener_coefs_0_NULL","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","bundle","Stack","bundle","Lrnr_glm_TRUE","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_importance_5->Stack)","bundle","Lrnr_screener_importance_5","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_coefs_0_NULL->Stack)","bundle","Lrnr_screener_coefs_0_NULL","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Stack","bundle","Lrnr_glm_TRUE","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_importance_5->Stack)","bundle","Lrnr_screener_importance_5","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_coefs_0_NULL->Stack)","bundle","Lrnr_screener_coefs_0_NULL","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Stack","bundle","Lrnr_glm_TRUE","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_importance_5->Stack)","bundle","Lrnr_screener_importance_5","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_coefs_0_NULL->Stack)","bundle","Lrnr_screener_coefs_0_NULL","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Stack","bundle","Lrnr_glm_TRUE","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_importance_5->Stack)","bundle","Lrnr_screener_importance_5","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_coefs_0_NULL->Stack)","bundle","Lrnr_screener_coefs_0_NULL","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Stack","bundle","Lrnr_glm_TRUE","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_importance_5->Stack)","bundle","Lrnr_screener_importance_5","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_coefs_0_NULL->Stack)","bundle","Lrnr_screener_coefs_0_NULL","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Stack","bundle","Lrnr_glm_TRUE","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_importance_5->Stack)","bundle","Lrnr_screener_importance_5","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_coefs_0_NULL->Stack)","bundle","Lrnr_screener_coefs_0_NULL","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Stack","bundle","Lrnr_glm_TRUE","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_importance_5->Stack)","bundle","Lrnr_screener_importance_5","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_coefs_0_NULL->Stack)","bundle","Lrnr_screener_coefs_0_NULL","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Stack","bundle","Lrnr_glm_TRUE","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_importance_5->Stack)","bundle","Lrnr_screener_importance_5","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_coefs_0_NULL->Stack)","bundle","Lrnr_screener_coefs_0_NULL","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Stack","bundle","Lrnr_glm_TRUE","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_importance_5->Stack)","bundle","Lrnr_screener_importance_5","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_coefs_0_NULL->Stack)","bundle","Lrnr_screener_coefs_0_NULL","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Stack","bundle","Lrnr_glm_TRUE","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_importance_5->Stack)","bundle","Lrnr_screener_importance_5","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","Pipeline(Lrnr_screener_coefs_0_NULL->Stack)","bundle","Lrnr_screener_coefs_0_NULL","Stack","chain","bundle","Lrnr_glm_TRUE","subset","Lrnr_polspline_5","Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE","Lrnr_glmnet_NULL_deviance_10_0_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_xgboost_50_1","chain","Lrnr_solnp_TRUE_TRUE_FALSE_1e-05"],"level":[1,2,5,6,7,8,9,9,9,9,9,9,9,10,16,11,15,12,13,14,13,13,13,13,13,9,10,16,11,15,12,13,14,13,13,13,13,13,7,8,9,10,10,10,10,10,10,10,11,17,12,16,13,14,15,14,14,14,14,14,10,11,17,12,16,13,14,15,14,14,14,14,14,8,9,10,10,10,10,10,10,10,11,17,12,16,13,14,15,14,14,14,14,14,10,11,17,12,16,13,14,15,14,14,14,14,14,8,9,10,10,10,10,10,10,10,11,17,12,16,13,14,15,14,14,14,14,14,10,11,17,12,16,13,14,15,14,14,14,14,14,8,9,10,10,10,10,10,10,10,11,17,12,16,13,14,15,14,14,14,14,14,10,11,17,12,16,13,14,15,14,14,14,14,14,8,9,10,10,10,10,10,10,10,11,17,12,16,13,14,15,14,14,14,14,14,10,11,17,12,16,13,14,15,14,14,14,14,14,8,9,10,10,10,10,10,10,10,11,17,12,16,13,14,15,14,14,14,14,14,10,11,17,12,16,13,14,15,14,14,14,14,14,8,9,10,10,10,10,10,10,10,11,17,12,16,13,14,15,14,14,14,14,14,10,11,17,12,16,13,14,15,14,14,14,14,14,8,9,10,10,10,10,10,10,10,11,17,12,16,13,14,15,14,14,14,14,14,10,11,17,12,16,13,14,15,14,14,14,14,14,8,9,10,10,10,10,10,10,10,11,17,12,16,13,14,15,14,14,14,14,14,10,11,17,12,16,13,14,15,14,14,14,14,14,8,9,10,10,10,10,10,10,10,11,17,12,16,13,14,15,14,14,14,14,14,10,11,17,12,16,13,14,15,14,14,14,14,14,4,3],"sequential":[true,true,true,true,true,true,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,true,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,true,false,true,true,true,false,false,false,false,false,false,false,true,false],"state":["waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting"],"group":["none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none"]},"edges":{"from":["96ec56a4-8217-11eb-9071-42010a1e0020","96ec6900-8217-11eb-9071-42010a1e0020","96ec792c-8217-11eb-9071-42010a1e0020","96ec89d0-8217-11eb-9071-42010a1e0020","96ec9a2e-8217-11eb-9071-42010a1e0020","96ecaa3c-8217-11eb-9071-42010a1e0020","96ecbdc4-8217-11eb-9071-42010a1e0020","96ecbdc4-8217-11eb-9071-42010a1e0020","96ecce90-8217-11eb-9071-42010a1e0020","96ecce90-8217-11eb-9071-42010a1e0020","96ecdf02-8217-11eb-9071-42010a1e0020","96ecfca8-8217-11eb-9071-42010a1e0020","96ecdf02-8217-11eb-9071-42010a1e0020","96ed19b8-8217-11eb-9071-42010a1e0020","96ecdf02-8217-11eb-9071-42010a1e0020","96ed36a0-8217-11eb-9071-42010a1e0020","96ecdf02-8217-11eb-9071-42010a1e0020","96ed5644-8217-11eb-9071-42010a1e0020","96ecdf02-8217-11eb-9071-42010a1e0020","96ed737c-8217-11eb-9071-42010a1e0020","96ecdf02-8217-11eb-9071-42010a1e0020","96ed90c8-8217-11eb-9071-42010a1e0020","96eda41e-8217-11eb-9071-42010a1e0020","96edb31e-8217-11eb-9071-42010a1e0020","96edcdfe-8217-11eb-9071-42010a1e0020","96eddb6e-8217-11eb-9071-42010a1e0020","96edf1b2-8217-11eb-9071-42010a1e0020","96edf1b2-8217-11eb-9071-42010a1e0020","96edfe3c-8217-11eb-9071-42010a1e0020","96edfe3c-8217-11eb-9071-42010a1e0020","96ee0de6-8217-11eb-9071-42010a1e0020","96ee2a92-8217-11eb-9071-42010a1e0020","96ee0de6-8217-11eb-9071-42010a1e0020","96ee47e8-8217-11eb-9071-42010a1e0020","96ee0de6-8217-11eb-9071-42010a1e0020","96ee64e4-8217-11eb-9071-42010a1e0020","96ee0de6-8217-11eb-9071-42010a1e0020","96ee83b6-8217-11eb-9071-42010a1e0020","96ee0de6-8217-11eb-9071-42010a1e0020","96eea17a-8217-11eb-9071-42010a1e0020","96ee0de6-8217-11eb-9071-42010a1e0020","96eebe9e-8217-11eb-9071-42010a1e0020","96eeccae-8217-11eb-9071-42010a1e0020","96eedbd6-8217-11eb-9071-42010a1e0020","96eef5b2-8217-11eb-9071-42010a1e0020","96ef03b8-8217-11eb-9071-42010a1e0020","96ef1556-8217-11eb-9071-42010a1e0020","96ef25b4-8217-11eb-9071-42010a1e0020","96f3ea40-8217-11eb-9071-42010a1e0020","96f3fbe8-8217-11eb-9071-42010a1e0020","96f40d72-8217-11eb-9071-42010a1e0020","96f41d8a-8217-11eb-9071-42010a1e0020","96f42f0a-8217-11eb-9071-42010a1e0020","96f43f9a-8217-11eb-9071-42010a1e0020","96f522b6-8217-11eb-9071-42010a1e0020","96f522b6-8217-11eb-9071-42010a1e0020","96f52fb8-8217-11eb-9071-42010a1e0020","96f52fb8-8217-11eb-9071-42010a1e0020","96f53f58-8217-11eb-9071-42010a1e0020","96f55c2c-8217-11eb-9071-42010a1e0020","96f53f58-8217-11eb-9071-42010a1e0020","96f57a7c-8217-11eb-9071-42010a1e0020","96f53f58-8217-11eb-9071-42010a1e0020","96f597b4-8217-11eb-9071-42010a1e0020","96f53f58-8217-11eb-9071-42010a1e0020","96f5b4f6-8217-11eb-9071-42010a1e0020","96f53f58-8217-11eb-9071-42010a1e0020","96f5d17a-8217-11eb-9071-42010a1e0020","96f53f58-8217-11eb-9071-42010a1e0020","96f5ef48-8217-11eb-9071-42010a1e0020","96f5fdf8-8217-11eb-9071-42010a1e0020","96f60ce4-8217-11eb-9071-42010a1e0020","96f62756-8217-11eb-9071-42010a1e0020","96f634da-8217-11eb-9071-42010a1e0020","96f64ab0-8217-11eb-9071-42010a1e0020","96f64ab0-8217-11eb-9071-42010a1e0020","96f65762-8217-11eb-9071-42010a1e0020","96f65762-8217-11eb-9071-42010a1e0020","96f66612-8217-11eb-9071-42010a1e0020","96f68408-8217-11eb-9071-42010a1e0020","96f66612-8217-11eb-9071-42010a1e0020","96f6a190-8217-11eb-9071-42010a1e0020","96f66612-8217-11eb-9071-42010a1e0020","96f6bf0e-8217-11eb-9071-42010a1e0020","96f66612-8217-11eb-9071-42010a1e0020","96f6dbce-8217-11eb-9071-42010a1e0020","96f66612-8217-11eb-9071-42010a1e0020","96f6f8de-8217-11eb-9071-42010a1e0020","96f66612-8217-11eb-9071-42010a1e0020","96f7168e-8217-11eb-9071-42010a1e0020","96f724f8-8217-11eb-9071-42010a1e0020","96f734ac-8217-11eb-9071-42010a1e0020","96f74f46-8217-11eb-9071-42010a1e0020","96f75d56-8217-11eb-9071-42010a1e0020","96f76e68-8217-11eb-9071-42010a1e0020","96f77d7c-8217-11eb-9071-42010a1e0020","97065810-8217-11eb-9071-42010a1e0020","970668b4-8217-11eb-9071-42010a1e0020","970679da-8217-11eb-9071-42010a1e0020","97068a06-8217-11eb-9071-42010a1e0020","970699c4-8217-11eb-9071-42010a1e0020","9706aa18-8217-11eb-9071-42010a1e0020","9706bbde-8217-11eb-9071-42010a1e0020","9706bbde-8217-11eb-9071-42010a1e0020","9706c8ae-8217-11eb-9071-42010a1e0020","9706c8ae-8217-11eb-9071-42010a1e0020","9706d722-8217-11eb-9071-42010a1e0020","9706f48c-8217-11eb-9071-42010a1e0020","9706d722-8217-11eb-9071-42010a1e0020","970711a6-8217-11eb-9071-42010a1e0020","9706d722-8217-11eb-9071-42010a1e0020","97072e2a-8217-11eb-9071-42010a1e0020","9706d722-8217-11eb-9071-42010a1e0020","97074ae0-8217-11eb-9071-42010a1e0020","9706d722-8217-11eb-9071-42010a1e0020","970767dc-8217-11eb-9071-42010a1e0020","9706d722-8217-11eb-9071-42010a1e0020","9707847e-8217-11eb-9071-42010a1e0020","970793ec-8217-11eb-9071-42010a1e0020","9707a274-8217-11eb-9071-42010a1e0020","9707be12-8217-11eb-9071-42010a1e0020","9707ccd6-8217-11eb-9071-42010a1e0020","9707e1f8-8217-11eb-9071-42010a1e0020","9707e1f8-8217-11eb-9071-42010a1e0020","9707ee3c-8217-11eb-9071-42010a1e0020","9707ee3c-8217-11eb-9071-42010a1e0020","9707fce2-8217-11eb-9071-42010a1e0020","97081984-8217-11eb-9071-42010a1e0020","9707fce2-8217-11eb-9071-42010a1e0020","97083874-8217-11eb-9071-42010a1e0020","9707fce2-8217-11eb-9071-42010a1e0020","9708557a-8217-11eb-9071-42010a1e0020","9707fce2-8217-11eb-9071-42010a1e0020","970872b2-8217-11eb-9071-42010a1e0020","9707fce2-8217-11eb-9071-42010a1e0020","97088f72-8217-11eb-9071-42010a1e0020","9707fce2-8217-11eb-9071-42010a1e0020","9708aca0-8217-11eb-9071-42010a1e0020","9708bb0a-8217-11eb-9071-42010a1e0020","9708cba4-8217-11eb-9071-42010a1e0020","9708e6ca-8217-11eb-9071-42010a1e0020","9708f55c-8217-11eb-9071-42010a1e0020","97090718-8217-11eb-9071-42010a1e0020","97091776-8217-11eb-9071-42010a1e0020","9709ad44-8217-11eb-9071-42010a1e0020","9709bf3c-8217-11eb-9071-42010a1e0020","9709d012-8217-11eb-9071-42010a1e0020","9709e048-8217-11eb-9071-42010a1e0020","9709f024-8217-11eb-9071-42010a1e0020","970a0168-8217-11eb-9071-42010a1e0020","970a13ba-8217-11eb-9071-42010a1e0020","970a13ba-8217-11eb-9071-42010a1e0020","970a213e-8217-11eb-9071-42010a1e0020","970a213e-8217-11eb-9071-42010a1e0020","970a305c-8217-11eb-9071-42010a1e0020","970a4e3e-8217-11eb-9071-42010a1e0020","970a305c-8217-11eb-9071-42010a1e0020","970a6c70-8217-11eb-9071-42010a1e0020","970a305c-8217-11eb-9071-42010a1e0020","970a8a84-8217-11eb-9071-42010a1e0020","970a305c-8217-11eb-9071-42010a1e0020","970aa924-8217-11eb-9071-42010a1e0020","970a305c-8217-11eb-9071-42010a1e0020","970bb422-8217-11eb-9071-42010a1e0020","970a305c-8217-11eb-9071-42010a1e0020","970bd2f4-8217-11eb-9071-42010a1e0020","970be17c-8217-11eb-9071-42010a1e0020","970bf00e-8217-11eb-9071-42010a1e0020","970c0b20-8217-11eb-9071-42010a1e0020","970c196c-8217-11eb-9071-42010a1e0020","970c2e66-8217-11eb-9071-42010a1e0020","970c2e66-8217-11eb-9071-42010a1e0020","970c3b22-8217-11eb-9071-42010a1e0020","970c3b22-8217-11eb-9071-42010a1e0020","970c4d60-8217-11eb-9071-42010a1e0020","970c6bc4-8217-11eb-9071-42010a1e0020","970c4d60-8217-11eb-9071-42010a1e0020","970c88d4-8217-11eb-9071-42010a1e0020","970c4d60-8217-11eb-9071-42010a1e0020","970ca832-8217-11eb-9071-42010a1e0020","970c4d60-8217-11eb-9071-42010a1e0020","970cc678-8217-11eb-9071-42010a1e0020","970c4d60-8217-11eb-9071-42010a1e0020","970ce3ba-8217-11eb-9071-42010a1e0020","970c4d60-8217-11eb-9071-42010a1e0020","970d00c0-8217-11eb-9071-42010a1e0020","970d104c-8217-11eb-9071-42010a1e0020","970d1f10-8217-11eb-9071-42010a1e0020","970d39be-8217-11eb-9071-42010a1e0020","970d4788-8217-11eb-9071-42010a1e0020","970d58cc-8217-11eb-9071-42010a1e0020","970d67f4-8217-11eb-9071-42010a1e0020","970df50c-8217-11eb-9071-42010a1e0020","970e052e-8217-11eb-9071-42010a1e0020","970e1596-8217-11eb-9071-42010a1e0020","970e25ae-8217-11eb-9071-42010a1e0020","970e3576-8217-11eb-9071-42010a1e0020","970e4642-8217-11eb-9071-42010a1e0020","970e57fe-8217-11eb-9071-42010a1e0020","970e57fe-8217-11eb-9071-42010a1e0020","970e64d8-8217-11eb-9071-42010a1e0020","970e64d8-8217-11eb-9071-42010a1e0020","970e7388-8217-11eb-9071-42010a1e0020","970e90f2-8217-11eb-9071-42010a1e0020","970e7388-8217-11eb-9071-42010a1e0020","970eae16-8217-11eb-9071-42010a1e0020","970e7388-8217-11eb-9071-42010a1e0020","970ecb8a-8217-11eb-9071-42010a1e0020","970e7388-8217-11eb-9071-42010a1e0020","970ee94e-8217-11eb-9071-42010a1e0020","970e7388-8217-11eb-9071-42010a1e0020","970f06ae-8217-11eb-9071-42010a1e0020","970e7388-8217-11eb-9071-42010a1e0020","970f236e-8217-11eb-9071-42010a1e0020","970f31f6-8217-11eb-9071-42010a1e0020","970f4092-8217-11eb-9071-42010a1e0020","970f5ae6-8217-11eb-9071-42010a1e0020","970f6824-8217-11eb-9071-42010a1e0020","970f7d96-8217-11eb-9071-42010a1e0020","970f7d96-8217-11eb-9071-42010a1e0020","970f8a0c-8217-11eb-9071-42010a1e0020","970f8a0c-8217-11eb-9071-42010a1e0020","970f9812-8217-11eb-9071-42010a1e0020","970fb5ae-8217-11eb-9071-42010a1e0020","970f9812-8217-11eb-9071-42010a1e0020","970fd322-8217-11eb-9071-42010a1e0020","970f9812-8217-11eb-9071-42010a1e0020","970ff4a6-8217-11eb-9071-42010a1e0020","970f9812-8217-11eb-9071-42010a1e0020","971012ce-8217-11eb-9071-42010a1e0020","970f9812-8217-11eb-9071-42010a1e0020","97102ff2-8217-11eb-9071-42010a1e0020","970f9812-8217-11eb-9071-42010a1e0020","97104d5c-8217-11eb-9071-42010a1e0020","97105c02-8217-11eb-9071-42010a1e0020","97106b70-8217-11eb-9071-42010a1e0020","9710860a-8217-11eb-9071-42010a1e0020","971093ca-8217-11eb-9071-42010a1e0020","9710a55e-8217-11eb-9071-42010a1e0020","9710b5f8-8217-11eb-9071-42010a1e0020","97114108-8217-11eb-9071-42010a1e0020","971152a6-8217-11eb-9071-42010a1e0020","9711630e-8217-11eb-9071-42010a1e0020","97117330-8217-11eb-9071-42010a1e0020","9711830c-8217-11eb-9071-42010a1e0020","97119356-8217-11eb-9071-42010a1e0020","9711a562-8217-11eb-9071-42010a1e0020","9711a562-8217-11eb-9071-42010a1e0020","9711b21e-8217-11eb-9071-42010a1e0020","9711b21e-8217-11eb-9071-42010a1e0020","9711c100-8217-11eb-9071-42010a1e0020","9711dd84-8217-11eb-9071-42010a1e0020","9711c100-8217-11eb-9071-42010a1e0020","9711fbca-8217-11eb-9071-42010a1e0020","9711c100-8217-11eb-9071-42010a1e0020","9712193e-8217-11eb-9071-42010a1e0020","9711c100-8217-11eb-9071-42010a1e0020","971236b2-8217-11eb-9071-42010a1e0020","9711c100-8217-11eb-9071-42010a1e0020","971253fe-8217-11eb-9071-42010a1e0020","9711c100-8217-11eb-9071-42010a1e0020","971270f0-8217-11eb-9071-42010a1e0020","97127f5a-8217-11eb-9071-42010a1e0020","97128f5e-8217-11eb-9071-42010a1e0020","9712aa34-8217-11eb-9071-42010a1e0020","9712b83a-8217-11eb-9071-42010a1e0020","9712ccbc-8217-11eb-9071-42010a1e0020","9712ccbc-8217-11eb-9071-42010a1e0020","9712d9e6-8217-11eb-9071-42010a1e0020","9712d9e6-8217-11eb-9071-42010a1e0020","9712e850-8217-11eb-9071-42010a1e0020","97130574-8217-11eb-9071-42010a1e0020","9712e850-8217-11eb-9071-42010a1e0020","971323ce-8217-11eb-9071-42010a1e0020","9712e850-8217-11eb-9071-42010a1e0020","97134106-8217-11eb-9071-42010a1e0020","9712e850-8217-11eb-9071-42010a1e0020","97135e2a-8217-11eb-9071-42010a1e0020","9712e850-8217-11eb-9071-42010a1e0020","97137b94-8217-11eb-9071-42010a1e0020","9712e850-8217-11eb-9071-42010a1e0020","97139926-8217-11eb-9071-42010a1e0020","9713a7ea-8217-11eb-9071-42010a1e0020","9713b6ea-8217-11eb-9071-42010a1e0020","9713d274-8217-11eb-9071-42010a1e0020","9713dfc6-8217-11eb-9071-42010a1e0020","9713f128-8217-11eb-9071-42010a1e0020","9714008c-8217-11eb-9071-42010a1e0020","971488ae-8217-11eb-9071-42010a1e0020","971498ee-8217-11eb-9071-42010a1e0020","9714a960-8217-11eb-9071-42010a1e0020","9714b9d2-8217-11eb-9071-42010a1e0020","9714c9ae-8217-11eb-9071-42010a1e0020","9714da02-8217-11eb-9071-42010a1e0020","9714eb8c-8217-11eb-9071-42010a1e0020","9714eb8c-8217-11eb-9071-42010a1e0020","9714f91a-8217-11eb-9071-42010a1e0020","9714f91a-8217-11eb-9071-42010a1e0020","971507f2-8217-11eb-9071-42010a1e0020","97152534-8217-11eb-9071-42010a1e0020","971507f2-8217-11eb-9071-42010a1e0020","97154316-8217-11eb-9071-42010a1e0020","971507f2-8217-11eb-9071-42010a1e0020","9715601c-8217-11eb-9071-42010a1e0020","971507f2-8217-11eb-9071-42010a1e0020","97157d2c-8217-11eb-9071-42010a1e0020","971507f2-8217-11eb-9071-42010a1e0020","97159adc-8217-11eb-9071-42010a1e0020","971507f2-8217-11eb-9071-42010a1e0020","9715b85a-8217-11eb-9071-42010a1e0020","9715c6ce-8217-11eb-9071-42010a1e0020","9715d556-8217-11eb-9071-42010a1e0020","9715f02c-8217-11eb-9071-42010a1e0020","9715fde2-8217-11eb-9071-42010a1e0020","971612e6-8217-11eb-9071-42010a1e0020","971612e6-8217-11eb-9071-42010a1e0020","97161ffc-8217-11eb-9071-42010a1e0020","97161ffc-8217-11eb-9071-42010a1e0020","9716303c-8217-11eb-9071-42010a1e0020","97164dec-8217-11eb-9071-42010a1e0020","9716303c-8217-11eb-9071-42010a1e0020","97166b2e-8217-11eb-9071-42010a1e0020","9716303c-8217-11eb-9071-42010a1e0020","971688f2-8217-11eb-9071-42010a1e0020","9716303c-8217-11eb-9071-42010a1e0020","9716a5d0-8217-11eb-9071-42010a1e0020","9716303c-8217-11eb-9071-42010a1e0020","9716c29a-8217-11eb-9071-42010a1e0020","9716303c-8217-11eb-9071-42010a1e0020","9716e02c-8217-11eb-9071-42010a1e0020","9716eeb4-8217-11eb-9071-42010a1e0020","9716fdb4-8217-11eb-9071-42010a1e0020","971717cc-8217-11eb-9071-42010a1e0020","9717258c-8217-11eb-9071-42010a1e0020","97173662-8217-11eb-9071-42010a1e0020","971745ee-8217-11eb-9071-42010a1e0020","9717cc9e-8217-11eb-9071-42010a1e0020","9717ddba-8217-11eb-9071-42010a1e0020","9717ede6-8217-11eb-9071-42010a1e0020","9717fd68-8217-11eb-9071-42010a1e0020","97180e3e-8217-11eb-9071-42010a1e0020","97181db6-8217-11eb-9071-42010a1e0020","97182fb8-8217-11eb-9071-42010a1e0020","97182fb8-8217-11eb-9071-42010a1e0020","97183cb0-8217-11eb-9071-42010a1e0020","97183cb0-8217-11eb-9071-42010a1e0020","97184b1a-8217-11eb-9071-42010a1e0020","97186820-8217-11eb-9071-42010a1e0020","97184b1a-8217-11eb-9071-42010a1e0020","97188544-8217-11eb-9071-42010a1e0020","97184b1a-8217-11eb-9071-42010a1e0020","9718a47a-8217-11eb-9071-42010a1e0020","97184b1a-8217-11eb-9071-42010a1e0020","9718c176-8217-11eb-9071-42010a1e0020","97184b1a-8217-11eb-9071-42010a1e0020","9718df80-8217-11eb-9071-42010a1e0020","97184b1a-8217-11eb-9071-42010a1e0020","9718fc7c-8217-11eb-9071-42010a1e0020","97190aa0-8217-11eb-9071-42010a1e0020","97191a04-8217-11eb-9071-42010a1e0020","9719339a-8217-11eb-9071-42010a1e0020","9719424a-8217-11eb-9071-42010a1e0020","97195686-8217-11eb-9071-42010a1e0020","97195686-8217-11eb-9071-42010a1e0020","97196356-8217-11eb-9071-42010a1e0020","97196356-8217-11eb-9071-42010a1e0020","97197210-8217-11eb-9071-42010a1e0020","97198ebc-8217-11eb-9071-42010a1e0020","97197210-8217-11eb-9071-42010a1e0020","9719abc2-8217-11eb-9071-42010a1e0020","97197210-8217-11eb-9071-42010a1e0020","9719c972-8217-11eb-9071-42010a1e0020","97197210-8217-11eb-9071-42010a1e0020","9719e75e-8217-11eb-9071-42010a1e0020","97197210-8217-11eb-9071-42010a1e0020","971a0482-8217-11eb-9071-42010a1e0020","97197210-8217-11eb-9071-42010a1e0020","971a211a-8217-11eb-9071-42010a1e0020","971a2ff2-8217-11eb-9071-42010a1e0020","971a3e52-8217-11eb-9071-42010a1e0020","971a5900-8217-11eb-9071-42010a1e0020","971a6684-8217-11eb-9071-42010a1e0020","971a78a4-8217-11eb-9071-42010a1e0020","971a8826-8217-11eb-9071-42010a1e0020","971b0ef4-8217-11eb-9071-42010a1e0020","971b1fc0-8217-11eb-9071-42010a1e0020","971b2fe2-8217-11eb-9071-42010a1e0020","971b4004-8217-11eb-9071-42010a1e0020","971b501c-8217-11eb-9071-42010a1e0020","971b6016-8217-11eb-9071-42010a1e0020","971b718c-8217-11eb-9071-42010a1e0020","971b718c-8217-11eb-9071-42010a1e0020","971b7df8-8217-11eb-9071-42010a1e0020","971b7df8-8217-11eb-9071-42010a1e0020","971b8cbc-8217-11eb-9071-42010a1e0020","971ba986-8217-11eb-9071-42010a1e0020","971b8cbc-8217-11eb-9071-42010a1e0020","971bc74a-8217-11eb-9071-42010a1e0020","971b8cbc-8217-11eb-9071-42010a1e0020","971be4e6-8217-11eb-9071-42010a1e0020","971b8cbc-8217-11eb-9071-42010a1e0020","971c01f6-8217-11eb-9071-42010a1e0020","971b8cbc-8217-11eb-9071-42010a1e0020","971c1eac-8217-11eb-9071-42010a1e0020","971b8cbc-8217-11eb-9071-42010a1e0020","971c3b6c-8217-11eb-9071-42010a1e0020","971c4a6c-8217-11eb-9071-42010a1e0020","971c5930-8217-11eb-9071-42010a1e0020","971c737a-8217-11eb-9071-42010a1e0020","971c80e0-8217-11eb-9071-42010a1e0020","971c9594-8217-11eb-9071-42010a1e0020","971c9594-8217-11eb-9071-42010a1e0020","971ca1ec-8217-11eb-9071-42010a1e0020","971ca1ec-8217-11eb-9071-42010a1e0020","971cb01a-8217-11eb-9071-42010a1e0020","971cccda-8217-11eb-9071-42010a1e0020","971cb01a-8217-11eb-9071-42010a1e0020","971cea9e-8217-11eb-9071-42010a1e0020","971cb01a-8217-11eb-9071-42010a1e0020","971d07cc-8217-11eb-9071-42010a1e0020","971cb01a-8217-11eb-9071-42010a1e0020","971d2536-8217-11eb-9071-42010a1e0020","971cb01a-8217-11eb-9071-42010a1e0020","971d4246-8217-11eb-9071-42010a1e0020","971cb01a-8217-11eb-9071-42010a1e0020","971d5f4c-8217-11eb-9071-42010a1e0020","971d6dac-8217-11eb-9071-42010a1e0020","971d7c52-8217-11eb-9071-42010a1e0020","971d99c6-8217-11eb-9071-42010a1e0020","971da920-8217-11eb-9071-42010a1e0020","971dbb7c-8217-11eb-9071-42010a1e0020","971dcaae-8217-11eb-9071-42010a1e0020","971e510e-8217-11eb-9071-42010a1e0020","971e6194-8217-11eb-9071-42010a1e0020","971e71b6-8217-11eb-9071-42010a1e0020","971e8192-8217-11eb-9071-42010a1e0020","971e91dc-8217-11eb-9071-42010a1e0020","971ea1ae-8217-11eb-9071-42010a1e0020","971eb310-8217-11eb-9071-42010a1e0020","971eb310-8217-11eb-9071-42010a1e0020","971ec1d4-8217-11eb-9071-42010a1e0020","971ec1d4-8217-11eb-9071-42010a1e0020","971ed0a2-8217-11eb-9071-42010a1e0020","971eee3e-8217-11eb-9071-42010a1e0020","971ed0a2-8217-11eb-9071-42010a1e0020","971f0b80-8217-11eb-9071-42010a1e0020","971ed0a2-8217-11eb-9071-42010a1e0020","971f280e-8217-11eb-9071-42010a1e0020","971ed0a2-8217-11eb-9071-42010a1e0020","971f4500-8217-11eb-9071-42010a1e0020","971ed0a2-8217-11eb-9071-42010a1e0020","971f647c-8217-11eb-9071-42010a1e0020","971ed0a2-8217-11eb-9071-42010a1e0020","971f81f0-8217-11eb-9071-42010a1e0020","971f8ff6-8217-11eb-9071-42010a1e0020","971f9eb0-8217-11eb-9071-42010a1e0020","971fbbd4-8217-11eb-9071-42010a1e0020","971fcbc4-8217-11eb-9071-42010a1e0020","971fe0b4-8217-11eb-9071-42010a1e0020","971fe0b4-8217-11eb-9071-42010a1e0020","971fed02-8217-11eb-9071-42010a1e0020","971fed02-8217-11eb-9071-42010a1e0020","971ffdf6-8217-11eb-9071-42010a1e0020","97201b74-8217-11eb-9071-42010a1e0020","971ffdf6-8217-11eb-9071-42010a1e0020","97203848-8217-11eb-9071-42010a1e0020","971ffdf6-8217-11eb-9071-42010a1e0020","9720556c-8217-11eb-9071-42010a1e0020","971ffdf6-8217-11eb-9071-42010a1e0020","97207268-8217-11eb-9071-42010a1e0020","971ffdf6-8217-11eb-9071-42010a1e0020","972090cc-8217-11eb-9071-42010a1e0020","971ffdf6-8217-11eb-9071-42010a1e0020","9720aea4-8217-11eb-9071-42010a1e0020","9720bd9a-8217-11eb-9071-42010a1e0020","9720ccd6-8217-11eb-9071-42010a1e0020","9720e766-8217-11eb-9071-42010a1e0020","9720f4c2-8217-11eb-9071-42010a1e0020","97210656-8217-11eb-9071-42010a1e0020","972115a6-8217-11eb-9071-42010a1e0020","97219cc4-8217-11eb-9071-42010a1e0020","9721ad4a-8217-11eb-9071-42010a1e0020","9721bd12-8217-11eb-9071-42010a1e0020","9721cdca-8217-11eb-9071-42010a1e0020","9721dd9c-8217-11eb-9071-42010a1e0020","9721ee2c-8217-11eb-9071-42010a1e0020","9721ffca-8217-11eb-9071-42010a1e0020","9721ffca-8217-11eb-9071-42010a1e0020","97220c04-8217-11eb-9071-42010a1e0020","97220c04-8217-11eb-9071-42010a1e0020","97221af0-8217-11eb-9071-42010a1e0020","97223706-8217-11eb-9071-42010a1e0020","97221af0-8217-11eb-9071-42010a1e0020","97225470-8217-11eb-9071-42010a1e0020","97221af0-8217-11eb-9071-42010a1e0020","9722725c-8217-11eb-9071-42010a1e0020","97221af0-8217-11eb-9071-42010a1e0020","97228fda-8217-11eb-9071-42010a1e0020","97221af0-8217-11eb-9071-42010a1e0020","9722ac86-8217-11eb-9071-42010a1e0020","97221af0-8217-11eb-9071-42010a1e0020","9722c9f0-8217-11eb-9071-42010a1e0020","9722d878-8217-11eb-9071-42010a1e0020","9722e750-8217-11eb-9071-42010a1e0020","9723026c-8217-11eb-9071-42010a1e0020","97231022-8217-11eb-9071-42010a1e0020","97232472-8217-11eb-9071-42010a1e0020","97232472-8217-11eb-9071-42010a1e0020","972330e8-8217-11eb-9071-42010a1e0020","972330e8-8217-11eb-9071-42010a1e0020","97233eee-8217-11eb-9071-42010a1e0020","97235bea-8217-11eb-9071-42010a1e0020","97233eee-8217-11eb-9071-42010a1e0020","972378be-8217-11eb-9071-42010a1e0020","97233eee-8217-11eb-9071-42010a1e0020","9723952e-8217-11eb-9071-42010a1e0020","97233eee-8217-11eb-9071-42010a1e0020","9723b31a-8217-11eb-9071-42010a1e0020","97233eee-8217-11eb-9071-42010a1e0020","9723d03e-8217-11eb-9071-42010a1e0020","97233eee-8217-11eb-9071-42010a1e0020","9723ed6c-8217-11eb-9071-42010a1e0020","9723fbd6-8217-11eb-9071-42010a1e0020","97240a7c-8217-11eb-9071-42010a1e0020","97242534-8217-11eb-9071-42010a1e0020","97243290-8217-11eb-9071-42010a1e0020","972444ce-8217-11eb-9071-42010a1e0020","9724540a-8217-11eb-9071-42010a1e0020","972462ba-8217-11eb-9071-42010a1e0020","972471ec-8217-11eb-9071-42010a1e0020","97247f98-8217-11eb-9071-42010a1e0020","97247f98-8217-11eb-9071-42010a1e0020","97248df8-8217-11eb-9071-42010a1e0020","97248df8-8217-11eb-9071-42010a1e0020","9724a982-8217-11eb-9071-42010a1e0020","9724b94a-8217-11eb-9071-42010a1e0020"],"to":["96ef1556-8217-11eb-9071-42010a1e0020","96ef1556-8217-11eb-9071-42010a1e0020","96ef1556-8217-11eb-9071-42010a1e0020","96ef1556-8217-11eb-9071-42010a1e0020","96ef1556-8217-11eb-9071-42010a1e0020","96ef1556-8217-11eb-9071-42010a1e0020","96edcdfe-8217-11eb-9071-42010a1e0020","96ecce90-8217-11eb-9071-42010a1e0020","96edb31e-8217-11eb-9071-42010a1e0020","96ecdf02-8217-11eb-9071-42010a1e0020","96ecfca8-8217-11eb-9071-42010a1e0020","96eda41e-8217-11eb-9071-42010a1e0020","96ed19b8-8217-11eb-9071-42010a1e0020","96eda41e-8217-11eb-9071-42010a1e0020","96ed36a0-8217-11eb-9071-42010a1e0020","96eda41e-8217-11eb-9071-42010a1e0020","96ed5644-8217-11eb-9071-42010a1e0020","96eda41e-8217-11eb-9071-42010a1e0020","96ed737c-8217-11eb-9071-42010a1e0020","96eda41e-8217-11eb-9071-42010a1e0020","96ed90c8-8217-11eb-9071-42010a1e0020","96eda41e-8217-11eb-9071-42010a1e0020","96edb31e-8217-11eb-9071-42010a1e0020","96edcdfe-8217-11eb-9071-42010a1e0020","96eddb6e-8217-11eb-9071-42010a1e0020","96ef1556-8217-11eb-9071-42010a1e0020","96eef5b2-8217-11eb-9071-42010a1e0020","96edfe3c-8217-11eb-9071-42010a1e0020","96eedbd6-8217-11eb-9071-42010a1e0020","96ee0de6-8217-11eb-9071-42010a1e0020","96ee2a92-8217-11eb-9071-42010a1e0020","96eeccae-8217-11eb-9071-42010a1e0020","96ee47e8-8217-11eb-9071-42010a1e0020","96eeccae-8217-11eb-9071-42010a1e0020","96ee64e4-8217-11eb-9071-42010a1e0020","96eeccae-8217-11eb-9071-42010a1e0020","96ee83b6-8217-11eb-9071-42010a1e0020","96eeccae-8217-11eb-9071-42010a1e0020","96eea17a-8217-11eb-9071-42010a1e0020","96eeccae-8217-11eb-9071-42010a1e0020","96eebe9e-8217-11eb-9071-42010a1e0020","96eeccae-8217-11eb-9071-42010a1e0020","96eedbd6-8217-11eb-9071-42010a1e0020","96eef5b2-8217-11eb-9071-42010a1e0020","96ef03b8-8217-11eb-9071-42010a1e0020","96ef1556-8217-11eb-9071-42010a1e0020","96ef25b4-8217-11eb-9071-42010a1e0020","972471ec-8217-11eb-9071-42010a1e0020","96f76e68-8217-11eb-9071-42010a1e0020","96f76e68-8217-11eb-9071-42010a1e0020","96f76e68-8217-11eb-9071-42010a1e0020","96f76e68-8217-11eb-9071-42010a1e0020","96f76e68-8217-11eb-9071-42010a1e0020","96f76e68-8217-11eb-9071-42010a1e0020","96f62756-8217-11eb-9071-42010a1e0020","96f52fb8-8217-11eb-9071-42010a1e0020","96f60ce4-8217-11eb-9071-42010a1e0020","96f53f58-8217-11eb-9071-42010a1e0020","96f55c2c-8217-11eb-9071-42010a1e0020","96f5fdf8-8217-11eb-9071-42010a1e0020","96f57a7c-8217-11eb-9071-42010a1e0020","96f5fdf8-8217-11eb-9071-42010a1e0020","96f597b4-8217-11eb-9071-42010a1e0020","96f5fdf8-8217-11eb-9071-42010a1e0020","96f5b4f6-8217-11eb-9071-42010a1e0020","96f5fdf8-8217-11eb-9071-42010a1e0020","96f5d17a-8217-11eb-9071-42010a1e0020","96f5fdf8-8217-11eb-9071-42010a1e0020","96f5ef48-8217-11eb-9071-42010a1e0020","96f5fdf8-8217-11eb-9071-42010a1e0020","96f60ce4-8217-11eb-9071-42010a1e0020","96f62756-8217-11eb-9071-42010a1e0020","96f634da-8217-11eb-9071-42010a1e0020","96f76e68-8217-11eb-9071-42010a1e0020","96f74f46-8217-11eb-9071-42010a1e0020","96f65762-8217-11eb-9071-42010a1e0020","96f734ac-8217-11eb-9071-42010a1e0020","96f66612-8217-11eb-9071-42010a1e0020","96f68408-8217-11eb-9071-42010a1e0020","96f724f8-8217-11eb-9071-42010a1e0020","96f6a190-8217-11eb-9071-42010a1e0020","96f724f8-8217-11eb-9071-42010a1e0020","96f6bf0e-8217-11eb-9071-42010a1e0020","96f724f8-8217-11eb-9071-42010a1e0020","96f6dbce-8217-11eb-9071-42010a1e0020","96f724f8-8217-11eb-9071-42010a1e0020","96f6f8de-8217-11eb-9071-42010a1e0020","96f724f8-8217-11eb-9071-42010a1e0020","96f7168e-8217-11eb-9071-42010a1e0020","96f724f8-8217-11eb-9071-42010a1e0020","96f734ac-8217-11eb-9071-42010a1e0020","96f74f46-8217-11eb-9071-42010a1e0020","96f75d56-8217-11eb-9071-42010a1e0020","96f76e68-8217-11eb-9071-42010a1e0020","96f77d7c-8217-11eb-9071-42010a1e0020","972462ba-8217-11eb-9071-42010a1e0020","97090718-8217-11eb-9071-42010a1e0020","97090718-8217-11eb-9071-42010a1e0020","97090718-8217-11eb-9071-42010a1e0020","97090718-8217-11eb-9071-42010a1e0020","97090718-8217-11eb-9071-42010a1e0020","97090718-8217-11eb-9071-42010a1e0020","9707be12-8217-11eb-9071-42010a1e0020","9706c8ae-8217-11eb-9071-42010a1e0020","9707a274-8217-11eb-9071-42010a1e0020","9706d722-8217-11eb-9071-42010a1e0020","9706f48c-8217-11eb-9071-42010a1e0020","970793ec-8217-11eb-9071-42010a1e0020","970711a6-8217-11eb-9071-42010a1e0020","970793ec-8217-11eb-9071-42010a1e0020","97072e2a-8217-11eb-9071-42010a1e0020","970793ec-8217-11eb-9071-42010a1e0020","97074ae0-8217-11eb-9071-42010a1e0020","970793ec-8217-11eb-9071-42010a1e0020","970767dc-8217-11eb-9071-42010a1e0020","970793ec-8217-11eb-9071-42010a1e0020","9707847e-8217-11eb-9071-42010a1e0020","970793ec-8217-11eb-9071-42010a1e0020","9707a274-8217-11eb-9071-42010a1e0020","9707be12-8217-11eb-9071-42010a1e0020","9707ccd6-8217-11eb-9071-42010a1e0020","97090718-8217-11eb-9071-42010a1e0020","9708e6ca-8217-11eb-9071-42010a1e0020","9707ee3c-8217-11eb-9071-42010a1e0020","9708cba4-8217-11eb-9071-42010a1e0020","9707fce2-8217-11eb-9071-42010a1e0020","97081984-8217-11eb-9071-42010a1e0020","9708bb0a-8217-11eb-9071-42010a1e0020","97083874-8217-11eb-9071-42010a1e0020","9708bb0a-8217-11eb-9071-42010a1e0020","9708557a-8217-11eb-9071-42010a1e0020","9708bb0a-8217-11eb-9071-42010a1e0020","970872b2-8217-11eb-9071-42010a1e0020","9708bb0a-8217-11eb-9071-42010a1e0020","97088f72-8217-11eb-9071-42010a1e0020","9708bb0a-8217-11eb-9071-42010a1e0020","9708aca0-8217-11eb-9071-42010a1e0020","9708bb0a-8217-11eb-9071-42010a1e0020","9708cba4-8217-11eb-9071-42010a1e0020","9708e6ca-8217-11eb-9071-42010a1e0020","9708f55c-8217-11eb-9071-42010a1e0020","97090718-8217-11eb-9071-42010a1e0020","97091776-8217-11eb-9071-42010a1e0020","972462ba-8217-11eb-9071-42010a1e0020","970d58cc-8217-11eb-9071-42010a1e0020","970d58cc-8217-11eb-9071-42010a1e0020","970d58cc-8217-11eb-9071-42010a1e0020","970d58cc-8217-11eb-9071-42010a1e0020","970d58cc-8217-11eb-9071-42010a1e0020","970d58cc-8217-11eb-9071-42010a1e0020","970c0b20-8217-11eb-9071-42010a1e0020","970a213e-8217-11eb-9071-42010a1e0020","970bf00e-8217-11eb-9071-42010a1e0020","970a305c-8217-11eb-9071-42010a1e0020","970a4e3e-8217-11eb-9071-42010a1e0020","970be17c-8217-11eb-9071-42010a1e0020","970a6c70-8217-11eb-9071-42010a1e0020","970be17c-8217-11eb-9071-42010a1e0020","970a8a84-8217-11eb-9071-42010a1e0020","970be17c-8217-11eb-9071-42010a1e0020","970aa924-8217-11eb-9071-42010a1e0020","970be17c-8217-11eb-9071-42010a1e0020","970bb422-8217-11eb-9071-42010a1e0020","970be17c-8217-11eb-9071-42010a1e0020","970bd2f4-8217-11eb-9071-42010a1e0020","970be17c-8217-11eb-9071-42010a1e0020","970bf00e-8217-11eb-9071-42010a1e0020","970c0b20-8217-11eb-9071-42010a1e0020","970c196c-8217-11eb-9071-42010a1e0020","970d58cc-8217-11eb-9071-42010a1e0020","970d39be-8217-11eb-9071-42010a1e0020","970c3b22-8217-11eb-9071-42010a1e0020","970d1f10-8217-11eb-9071-42010a1e0020","970c4d60-8217-11eb-9071-42010a1e0020","970c6bc4-8217-11eb-9071-42010a1e0020","970d104c-8217-11eb-9071-42010a1e0020","970c88d4-8217-11eb-9071-42010a1e0020","970d104c-8217-11eb-9071-42010a1e0020","970ca832-8217-11eb-9071-42010a1e0020","970d104c-8217-11eb-9071-42010a1e0020","970cc678-8217-11eb-9071-42010a1e0020","970d104c-8217-11eb-9071-42010a1e0020","970ce3ba-8217-11eb-9071-42010a1e0020","970d104c-8217-11eb-9071-42010a1e0020","970d00c0-8217-11eb-9071-42010a1e0020","970d104c-8217-11eb-9071-42010a1e0020","970d1f10-8217-11eb-9071-42010a1e0020","970d39be-8217-11eb-9071-42010a1e0020","970d4788-8217-11eb-9071-42010a1e0020","970d58cc-8217-11eb-9071-42010a1e0020","970d67f4-8217-11eb-9071-42010a1e0020","972462ba-8217-11eb-9071-42010a1e0020","9710a55e-8217-11eb-9071-42010a1e0020","9710a55e-8217-11eb-9071-42010a1e0020","9710a55e-8217-11eb-9071-42010a1e0020","9710a55e-8217-11eb-9071-42010a1e0020","9710a55e-8217-11eb-9071-42010a1e0020","9710a55e-8217-11eb-9071-42010a1e0020","970f5ae6-8217-11eb-9071-42010a1e0020","970e64d8-8217-11eb-9071-42010a1e0020","970f4092-8217-11eb-9071-42010a1e0020","970e7388-8217-11eb-9071-42010a1e0020","970e90f2-8217-11eb-9071-42010a1e0020","970f31f6-8217-11eb-9071-42010a1e0020","970eae16-8217-11eb-9071-42010a1e0020","970f31f6-8217-11eb-9071-42010a1e0020","970ecb8a-8217-11eb-9071-42010a1e0020","970f31f6-8217-11eb-9071-42010a1e0020","970ee94e-8217-11eb-9071-42010a1e0020","970f31f6-8217-11eb-9071-42010a1e0020","970f06ae-8217-11eb-9071-42010a1e0020","970f31f6-8217-11eb-9071-42010a1e0020","970f236e-8217-11eb-9071-42010a1e0020","970f31f6-8217-11eb-9071-42010a1e0020","970f4092-8217-11eb-9071-42010a1e0020","970f5ae6-8217-11eb-9071-42010a1e0020","970f6824-8217-11eb-9071-42010a1e0020","9710a55e-8217-11eb-9071-42010a1e0020","9710860a-8217-11eb-9071-42010a1e0020","970f8a0c-8217-11eb-9071-42010a1e0020","97106b70-8217-11eb-9071-42010a1e0020","970f9812-8217-11eb-9071-42010a1e0020","970fb5ae-8217-11eb-9071-42010a1e0020","97105c02-8217-11eb-9071-42010a1e0020","970fd322-8217-11eb-9071-42010a1e0020","97105c02-8217-11eb-9071-42010a1e0020","970ff4a6-8217-11eb-9071-42010a1e0020","97105c02-8217-11eb-9071-42010a1e0020","971012ce-8217-11eb-9071-42010a1e0020","97105c02-8217-11eb-9071-42010a1e0020","97102ff2-8217-11eb-9071-42010a1e0020","97105c02-8217-11eb-9071-42010a1e0020","97104d5c-8217-11eb-9071-42010a1e0020","97105c02-8217-11eb-9071-42010a1e0020","97106b70-8217-11eb-9071-42010a1e0020","9710860a-8217-11eb-9071-42010a1e0020","971093ca-8217-11eb-9071-42010a1e0020","9710a55e-8217-11eb-9071-42010a1e0020","9710b5f8-8217-11eb-9071-42010a1e0020","972462ba-8217-11eb-9071-42010a1e0020","9713f128-8217-11eb-9071-42010a1e0020","9713f128-8217-11eb-9071-42010a1e0020","9713f128-8217-11eb-9071-42010a1e0020","9713f128-8217-11eb-9071-42010a1e0020","9713f128-8217-11eb-9071-42010a1e0020","9713f128-8217-11eb-9071-42010a1e0020","9712aa34-8217-11eb-9071-42010a1e0020","9711b21e-8217-11eb-9071-42010a1e0020","97128f5e-8217-11eb-9071-42010a1e0020","9711c100-8217-11eb-9071-42010a1e0020","9711dd84-8217-11eb-9071-42010a1e0020","97127f5a-8217-11eb-9071-42010a1e0020","9711fbca-8217-11eb-9071-42010a1e0020","97127f5a-8217-11eb-9071-42010a1e0020","9712193e-8217-11eb-9071-42010a1e0020","97127f5a-8217-11eb-9071-42010a1e0020","971236b2-8217-11eb-9071-42010a1e0020","97127f5a-8217-11eb-9071-42010a1e0020","971253fe-8217-11eb-9071-42010a1e0020","97127f5a-8217-11eb-9071-42010a1e0020","971270f0-8217-11eb-9071-42010a1e0020","97127f5a-8217-11eb-9071-42010a1e0020","97128f5e-8217-11eb-9071-42010a1e0020","9712aa34-8217-11eb-9071-42010a1e0020","9712b83a-8217-11eb-9071-42010a1e0020","9713f128-8217-11eb-9071-42010a1e0020","9713d274-8217-11eb-9071-42010a1e0020","9712d9e6-8217-11eb-9071-42010a1e0020","9713b6ea-8217-11eb-9071-42010a1e0020","9712e850-8217-11eb-9071-42010a1e0020","97130574-8217-11eb-9071-42010a1e0020","9713a7ea-8217-11eb-9071-42010a1e0020","971323ce-8217-11eb-9071-42010a1e0020","9713a7ea-8217-11eb-9071-42010a1e0020","97134106-8217-11eb-9071-42010a1e0020","9713a7ea-8217-11eb-9071-42010a1e0020","97135e2a-8217-11eb-9071-42010a1e0020","9713a7ea-8217-11eb-9071-42010a1e0020","97137b94-8217-11eb-9071-42010a1e0020","9713a7ea-8217-11eb-9071-42010a1e0020","97139926-8217-11eb-9071-42010a1e0020","9713a7ea-8217-11eb-9071-42010a1e0020","9713b6ea-8217-11eb-9071-42010a1e0020","9713d274-8217-11eb-9071-42010a1e0020","9713dfc6-8217-11eb-9071-42010a1e0020","9713f128-8217-11eb-9071-42010a1e0020","9714008c-8217-11eb-9071-42010a1e0020","972462ba-8217-11eb-9071-42010a1e0020","97173662-8217-11eb-9071-42010a1e0020","97173662-8217-11eb-9071-42010a1e0020","97173662-8217-11eb-9071-42010a1e0020","97173662-8217-11eb-9071-42010a1e0020","97173662-8217-11eb-9071-42010a1e0020","97173662-8217-11eb-9071-42010a1e0020","9715f02c-8217-11eb-9071-42010a1e0020","9714f91a-8217-11eb-9071-42010a1e0020","9715d556-8217-11eb-9071-42010a1e0020","971507f2-8217-11eb-9071-42010a1e0020","97152534-8217-11eb-9071-42010a1e0020","9715c6ce-8217-11eb-9071-42010a1e0020","97154316-8217-11eb-9071-42010a1e0020","9715c6ce-8217-11eb-9071-42010a1e0020","9715601c-8217-11eb-9071-42010a1e0020","9715c6ce-8217-11eb-9071-42010a1e0020","97157d2c-8217-11eb-9071-42010a1e0020","9715c6ce-8217-11eb-9071-42010a1e0020","97159adc-8217-11eb-9071-42010a1e0020","9715c6ce-8217-11eb-9071-42010a1e0020","9715b85a-8217-11eb-9071-42010a1e0020","9715c6ce-8217-11eb-9071-42010a1e0020","9715d556-8217-11eb-9071-42010a1e0020","9715f02c-8217-11eb-9071-42010a1e0020","9715fde2-8217-11eb-9071-42010a1e0020","97173662-8217-11eb-9071-42010a1e0020","971717cc-8217-11eb-9071-42010a1e0020","97161ffc-8217-11eb-9071-42010a1e0020","9716fdb4-8217-11eb-9071-42010a1e0020","9716303c-8217-11eb-9071-42010a1e0020","97164dec-8217-11eb-9071-42010a1e0020","9716eeb4-8217-11eb-9071-42010a1e0020","97166b2e-8217-11eb-9071-42010a1e0020","9716eeb4-8217-11eb-9071-42010a1e0020","971688f2-8217-11eb-9071-42010a1e0020","9716eeb4-8217-11eb-9071-42010a1e0020","9716a5d0-8217-11eb-9071-42010a1e0020","9716eeb4-8217-11eb-9071-42010a1e0020","9716c29a-8217-11eb-9071-42010a1e0020","9716eeb4-8217-11eb-9071-42010a1e0020","9716e02c-8217-11eb-9071-42010a1e0020","9716eeb4-8217-11eb-9071-42010a1e0020","9716fdb4-8217-11eb-9071-42010a1e0020","971717cc-8217-11eb-9071-42010a1e0020","9717258c-8217-11eb-9071-42010a1e0020","97173662-8217-11eb-9071-42010a1e0020","971745ee-8217-11eb-9071-42010a1e0020","972462ba-8217-11eb-9071-42010a1e0020","971a78a4-8217-11eb-9071-42010a1e0020","971a78a4-8217-11eb-9071-42010a1e0020","971a78a4-8217-11eb-9071-42010a1e0020","971a78a4-8217-11eb-9071-42010a1e0020","971a78a4-8217-11eb-9071-42010a1e0020","971a78a4-8217-11eb-9071-42010a1e0020","9719339a-8217-11eb-9071-42010a1e0020","97183cb0-8217-11eb-9071-42010a1e0020","97191a04-8217-11eb-9071-42010a1e0020","97184b1a-8217-11eb-9071-42010a1e0020","97186820-8217-11eb-9071-42010a1e0020","97190aa0-8217-11eb-9071-42010a1e0020","97188544-8217-11eb-9071-42010a1e0020","97190aa0-8217-11eb-9071-42010a1e0020","9718a47a-8217-11eb-9071-42010a1e0020","97190aa0-8217-11eb-9071-42010a1e0020","9718c176-8217-11eb-9071-42010a1e0020","97190aa0-8217-11eb-9071-42010a1e0020","9718df80-8217-11eb-9071-42010a1e0020","97190aa0-8217-11eb-9071-42010a1e0020","9718fc7c-8217-11eb-9071-42010a1e0020","97190aa0-8217-11eb-9071-42010a1e0020","97191a04-8217-11eb-9071-42010a1e0020","9719339a-8217-11eb-9071-42010a1e0020","9719424a-8217-11eb-9071-42010a1e0020","971a78a4-8217-11eb-9071-42010a1e0020","971a5900-8217-11eb-9071-42010a1e0020","97196356-8217-11eb-9071-42010a1e0020","971a3e52-8217-11eb-9071-42010a1e0020","97197210-8217-11eb-9071-42010a1e0020","97198ebc-8217-11eb-9071-42010a1e0020","971a2ff2-8217-11eb-9071-42010a1e0020","9719abc2-8217-11eb-9071-42010a1e0020","971a2ff2-8217-11eb-9071-42010a1e0020","9719c972-8217-11eb-9071-42010a1e0020","971a2ff2-8217-11eb-9071-42010a1e0020","9719e75e-8217-11eb-9071-42010a1e0020","971a2ff2-8217-11eb-9071-42010a1e0020","971a0482-8217-11eb-9071-42010a1e0020","971a2ff2-8217-11eb-9071-42010a1e0020","971a211a-8217-11eb-9071-42010a1e0020","971a2ff2-8217-11eb-9071-42010a1e0020","971a3e52-8217-11eb-9071-42010a1e0020","971a5900-8217-11eb-9071-42010a1e0020","971a6684-8217-11eb-9071-42010a1e0020","971a78a4-8217-11eb-9071-42010a1e0020","971a8826-8217-11eb-9071-42010a1e0020","972462ba-8217-11eb-9071-42010a1e0020","971dbb7c-8217-11eb-9071-42010a1e0020","971dbb7c-8217-11eb-9071-42010a1e0020","971dbb7c-8217-11eb-9071-42010a1e0020","971dbb7c-8217-11eb-9071-42010a1e0020","971dbb7c-8217-11eb-9071-42010a1e0020","971dbb7c-8217-11eb-9071-42010a1e0020","971c737a-8217-11eb-9071-42010a1e0020","971b7df8-8217-11eb-9071-42010a1e0020","971c5930-8217-11eb-9071-42010a1e0020","971b8cbc-8217-11eb-9071-42010a1e0020","971ba986-8217-11eb-9071-42010a1e0020","971c4a6c-8217-11eb-9071-42010a1e0020","971bc74a-8217-11eb-9071-42010a1e0020","971c4a6c-8217-11eb-9071-42010a1e0020","971be4e6-8217-11eb-9071-42010a1e0020","971c4a6c-8217-11eb-9071-42010a1e0020","971c01f6-8217-11eb-9071-42010a1e0020","971c4a6c-8217-11eb-9071-42010a1e0020","971c1eac-8217-11eb-9071-42010a1e0020","971c4a6c-8217-11eb-9071-42010a1e0020","971c3b6c-8217-11eb-9071-42010a1e0020","971c4a6c-8217-11eb-9071-42010a1e0020","971c5930-8217-11eb-9071-42010a1e0020","971c737a-8217-11eb-9071-42010a1e0020","971c80e0-8217-11eb-9071-42010a1e0020","971dbb7c-8217-11eb-9071-42010a1e0020","971d99c6-8217-11eb-9071-42010a1e0020","971ca1ec-8217-11eb-9071-42010a1e0020","971d7c52-8217-11eb-9071-42010a1e0020","971cb01a-8217-11eb-9071-42010a1e0020","971cccda-8217-11eb-9071-42010a1e0020","971d6dac-8217-11eb-9071-42010a1e0020","971cea9e-8217-11eb-9071-42010a1e0020","971d6dac-8217-11eb-9071-42010a1e0020","971d07cc-8217-11eb-9071-42010a1e0020","971d6dac-8217-11eb-9071-42010a1e0020","971d2536-8217-11eb-9071-42010a1e0020","971d6dac-8217-11eb-9071-42010a1e0020","971d4246-8217-11eb-9071-42010a1e0020","971d6dac-8217-11eb-9071-42010a1e0020","971d5f4c-8217-11eb-9071-42010a1e0020","971d6dac-8217-11eb-9071-42010a1e0020","971d7c52-8217-11eb-9071-42010a1e0020","971d99c6-8217-11eb-9071-42010a1e0020","971da920-8217-11eb-9071-42010a1e0020","971dbb7c-8217-11eb-9071-42010a1e0020","971dcaae-8217-11eb-9071-42010a1e0020","972462ba-8217-11eb-9071-42010a1e0020","97210656-8217-11eb-9071-42010a1e0020","97210656-8217-11eb-9071-42010a1e0020","97210656-8217-11eb-9071-42010a1e0020","97210656-8217-11eb-9071-42010a1e0020","97210656-8217-11eb-9071-42010a1e0020","97210656-8217-11eb-9071-42010a1e0020","971fbbd4-8217-11eb-9071-42010a1e0020","971ec1d4-8217-11eb-9071-42010a1e0020","971f9eb0-8217-11eb-9071-42010a1e0020","971ed0a2-8217-11eb-9071-42010a1e0020","971eee3e-8217-11eb-9071-42010a1e0020","971f8ff6-8217-11eb-9071-42010a1e0020","971f0b80-8217-11eb-9071-42010a1e0020","971f8ff6-8217-11eb-9071-42010a1e0020","971f280e-8217-11eb-9071-42010a1e0020","971f8ff6-8217-11eb-9071-42010a1e0020","971f4500-8217-11eb-9071-42010a1e0020","971f8ff6-8217-11eb-9071-42010a1e0020","971f647c-8217-11eb-9071-42010a1e0020","971f8ff6-8217-11eb-9071-42010a1e0020","971f81f0-8217-11eb-9071-42010a1e0020","971f8ff6-8217-11eb-9071-42010a1e0020","971f9eb0-8217-11eb-9071-42010a1e0020","971fbbd4-8217-11eb-9071-42010a1e0020","971fcbc4-8217-11eb-9071-42010a1e0020","97210656-8217-11eb-9071-42010a1e0020","9720e766-8217-11eb-9071-42010a1e0020","971fed02-8217-11eb-9071-42010a1e0020","9720ccd6-8217-11eb-9071-42010a1e0020","971ffdf6-8217-11eb-9071-42010a1e0020","97201b74-8217-11eb-9071-42010a1e0020","9720bd9a-8217-11eb-9071-42010a1e0020","97203848-8217-11eb-9071-42010a1e0020","9720bd9a-8217-11eb-9071-42010a1e0020","9720556c-8217-11eb-9071-42010a1e0020","9720bd9a-8217-11eb-9071-42010a1e0020","97207268-8217-11eb-9071-42010a1e0020","9720bd9a-8217-11eb-9071-42010a1e0020","972090cc-8217-11eb-9071-42010a1e0020","9720bd9a-8217-11eb-9071-42010a1e0020","9720aea4-8217-11eb-9071-42010a1e0020","9720bd9a-8217-11eb-9071-42010a1e0020","9720ccd6-8217-11eb-9071-42010a1e0020","9720e766-8217-11eb-9071-42010a1e0020","9720f4c2-8217-11eb-9071-42010a1e0020","97210656-8217-11eb-9071-42010a1e0020","972115a6-8217-11eb-9071-42010a1e0020","972462ba-8217-11eb-9071-42010a1e0020","972444ce-8217-11eb-9071-42010a1e0020","972444ce-8217-11eb-9071-42010a1e0020","972444ce-8217-11eb-9071-42010a1e0020","972444ce-8217-11eb-9071-42010a1e0020","972444ce-8217-11eb-9071-42010a1e0020","972444ce-8217-11eb-9071-42010a1e0020","9723026c-8217-11eb-9071-42010a1e0020","97220c04-8217-11eb-9071-42010a1e0020","9722e750-8217-11eb-9071-42010a1e0020","97221af0-8217-11eb-9071-42010a1e0020","97223706-8217-11eb-9071-42010a1e0020","9722d878-8217-11eb-9071-42010a1e0020","97225470-8217-11eb-9071-42010a1e0020","9722d878-8217-11eb-9071-42010a1e0020","9722725c-8217-11eb-9071-42010a1e0020","9722d878-8217-11eb-9071-42010a1e0020","97228fda-8217-11eb-9071-42010a1e0020","9722d878-8217-11eb-9071-42010a1e0020","9722ac86-8217-11eb-9071-42010a1e0020","9722d878-8217-11eb-9071-42010a1e0020","9722c9f0-8217-11eb-9071-42010a1e0020","9722d878-8217-11eb-9071-42010a1e0020","9722e750-8217-11eb-9071-42010a1e0020","9723026c-8217-11eb-9071-42010a1e0020","97231022-8217-11eb-9071-42010a1e0020","972444ce-8217-11eb-9071-42010a1e0020","97242534-8217-11eb-9071-42010a1e0020","972330e8-8217-11eb-9071-42010a1e0020","97240a7c-8217-11eb-9071-42010a1e0020","97233eee-8217-11eb-9071-42010a1e0020","97235bea-8217-11eb-9071-42010a1e0020","9723fbd6-8217-11eb-9071-42010a1e0020","972378be-8217-11eb-9071-42010a1e0020","9723fbd6-8217-11eb-9071-42010a1e0020","9723952e-8217-11eb-9071-42010a1e0020","9723fbd6-8217-11eb-9071-42010a1e0020","9723b31a-8217-11eb-9071-42010a1e0020","9723fbd6-8217-11eb-9071-42010a1e0020","9723d03e-8217-11eb-9071-42010a1e0020","9723fbd6-8217-11eb-9071-42010a1e0020","9723ed6c-8217-11eb-9071-42010a1e0020","9723fbd6-8217-11eb-9071-42010a1e0020","97240a7c-8217-11eb-9071-42010a1e0020","97242534-8217-11eb-9071-42010a1e0020","97243290-8217-11eb-9071-42010a1e0020","972444ce-8217-11eb-9071-42010a1e0020","9724540a-8217-11eb-9071-42010a1e0020","972462ba-8217-11eb-9071-42010a1e0020","972471ec-8217-11eb-9071-42010a1e0020","97247f98-8217-11eb-9071-42010a1e0020","9724b94a-8217-11eb-9071-42010a1e0020","97248df8-8217-11eb-9071-42010a1e0020","9724b94a-8217-11eb-9071-42010a1e0020","9724a982-8217-11eb-9071-42010a1e0020","9724b94a-8217-11eb-9071-42010a1e0020","9724c750-8217-11eb-9071-42010a1e0020"],"label":["","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""]},"nodesToDataframe":true,"edgesToDataframe":true,"options":{"width":"100%","height":"100%","nodes":{"shape":"dot"},"manipulation":{"enabled":false},"edges":{"arrows":"to"},"layout":{"hierarchical":{"enabled":true,"levelSeparation":500,"nodeSpacing":200,"direction":"RL"}},"groups":{"useDefaultGroups":true,"none":{"color":{"border":"black","background":"white"}}}},"groups":["none"],"width":"90%","height":"400px","idselection":{"enabled":false},"byselection":{"enabled":false},"main":null,"submain":null,"footer":null,"background":"rgba(0, 0, 0, 0)"},"evals":[],"jsHooks":[]}</script>
```
--->
</div>
</div>
<div id="train-the-super-learner-on-the-machine-learning-task" class="section level3 unnumbered">
<h3>3. Train the Super Learner on the machine learning task<a class="anchor" aria-label="anchor" href="#train-the-super-learner-on-the-machine-learning-task"><i class="fas fa-link"></i></a>
</h3>
<p>The SL algorithm fits a metalearner on the validation-set predictions in a
cross-validated manner, thereby avoiding overfitting.</p>
<p>Now we are ready to <strong>“train”</strong> our SL on our <code>sl3_task</code> object, <code>washb_task</code>.</p>
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">4197</span><span class="op">)</span>
<span class="va">sl_fit</span> <span class="op">&lt;-</span> <span class="va">sl</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">washb_task</span><span class="op">)</span></code></pre></div>
</div>
<div id="obtain-predicted-values" class="section level3 unnumbered">
<h3>4. Obtain predicted values<a class="anchor" aria-label="anchor" href="#obtain-predicted-values"><i class="fas fa-link"></i></a>
</h3>
<p>Now that we have fit the SL, we are ready to calculate the predicted outcome
for each subject.</p>
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># we did it! now we have SL predictions</span>
<span class="va">sl_preds</span> <span class="op">&lt;-</span> <span class="va">sl_fit</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">sl_preds</span><span class="op">)</span>
<span class="co">#&gt; [1] -0.64698 -0.76514 -0.64312 -0.68991 -0.68068 -0.66422</span></code></pre></div>
<!--
Below we visualize the observed versus predicted values.

For fun, we will also include the cross-validated predictions from most popular 
learner on the block, main terms linear regression.



```r

# df_plot <- data.frame(Observed = washb_data[["whz"]], Predicted = sl_preds,
#                        count = seq(1:nrow(washb_data))

# df_plot_melted <- melt(df_plot, id.vars = "count",
#                         measure.vars = c("Observed", "Predicted"))

# ggplot(df_plot_melted, aes(value, count, color = variable)) + geom_point()
```
-->
<p>We can also obtain a summary of the results.</p>
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sl_fit_summary</span> <span class="op">&lt;-</span> <span class="va">sl_fit</span><span class="op">$</span><span class="fu">print</span><span class="op">(</span><span class="op">)</span>
<span class="co">#&gt; [1] "SuperLearner:"</span>
<span class="co">#&gt; List of 8</span>
<span class="co">#&gt;  $ glm                : chr "Lrnr_glm_TRUE"</span>
<span class="co">#&gt;  $ polspline          : chr "Lrnr_polspline_5"</span>
<span class="co">#&gt;  $ enet.5             : chr "Lrnr_glmnet_NULL_deviance_10_0.5_100_TRUE"</span>
<span class="co">#&gt;  $ ridge              : chr "Lrnr_glmnet_NULL_deviance_10_0_100_TRUE"</span>
<span class="co">#&gt;  $ lasso              : chr "Lrnr_glmnet_NULL_deviance_10_1_100_TRUE"</span>
<span class="co">#&gt;  $ xgboost50          : chr "Lrnr_xgboost_50_1"</span>
<span class="co">#&gt;  $ randomforest_screen: chr "Pipeline(Lrnr_screener_importance_5-&gt;Stack)"</span>
<span class="co">#&gt;  $ lasso_screen       : chr "Pipeline(Lrnr_screener_coefs_0_NULL-&gt;Stack)"</span>
<span class="co">#&gt; [1] "Lrnr_solnp_TRUE_TRUE_FALSE_1e-05"</span>
<span class="co">#&gt; $pars</span>
<span class="co">#&gt;  [1] 0.055565 0.055551 0.055558 0.055564 0.055558 0.055583 0.055556 0.055573</span>
<span class="co">#&gt;  [9] 0.055555 0.055555 0.055555 0.055546 0.055553 0.055553 0.055553 0.055552</span>
<span class="co">#&gt; [17] 0.055553 0.055516</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $convergence</span>
<span class="co">#&gt; [1] 0</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $values</span>
<span class="co">#&gt; [1] 1.01 1.01</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $lagrange</span>
<span class="co">#&gt;            [,1]</span>
<span class="co">#&gt; [1,] -0.0050956</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $hessian</span>
<span class="co">#&gt;       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]</span>
<span class="co">#&gt;  [1,]    1    0    0    0    0    0    0    0    0     0     0     0     0</span>
<span class="co">#&gt;  [2,]    0    1    0    0    0    0    0    0    0     0     0     0     0</span>
<span class="co">#&gt;  [3,]    0    0    1    0    0    0    0    0    0     0     0     0     0</span>
<span class="co">#&gt;  [4,]    0    0    0    1    0    0    0    0    0     0     0     0     0</span>
<span class="co">#&gt;  [5,]    0    0    0    0    1    0    0    0    0     0     0     0     0</span>
<span class="co">#&gt;  [6,]    0    0    0    0    0    1    0    0    0     0     0     0     0</span>
<span class="co">#&gt;  [7,]    0    0    0    0    0    0    1    0    0     0     0     0     0</span>
<span class="co">#&gt;  [8,]    0    0    0    0    0    0    0    1    0     0     0     0     0</span>
<span class="co">#&gt;  [9,]    0    0    0    0    0    0    0    0    1     0     0     0     0</span>
<span class="co">#&gt; [10,]    0    0    0    0    0    0    0    0    0     1     0     0     0</span>
<span class="co">#&gt; [11,]    0    0    0    0    0    0    0    0    0     0     1     0     0</span>
<span class="co">#&gt; [12,]    0    0    0    0    0    0    0    0    0     0     0     1     0</span>
<span class="co">#&gt; [13,]    0    0    0    0    0    0    0    0    0     0     0     0     1</span>
<span class="co">#&gt; [14,]    0    0    0    0    0    0    0    0    0     0     0     0     0</span>
<span class="co">#&gt; [15,]    0    0    0    0    0    0    0    0    0     0     0     0     0</span>
<span class="co">#&gt; [16,]    0    0    0    0    0    0    0    0    0     0     0     0     0</span>
<span class="co">#&gt; [17,]    0    0    0    0    0    0    0    0    0     0     0     0     0</span>
<span class="co">#&gt; [18,]    0    0    0    0    0    0    0    0    0     0     0     0     0</span>
<span class="co">#&gt;       [,14] [,15] [,16] [,17] [,18]</span>
<span class="co">#&gt;  [1,]     0     0     0     0     0</span>
<span class="co">#&gt;  [2,]     0     0     0     0     0</span>
<span class="co">#&gt;  [3,]     0     0     0     0     0</span>
<span class="co">#&gt;  [4,]     0     0     0     0     0</span>
<span class="co">#&gt;  [5,]     0     0     0     0     0</span>
<span class="co">#&gt;  [6,]     0     0     0     0     0</span>
<span class="co">#&gt;  [7,]     0     0     0     0     0</span>
<span class="co">#&gt;  [8,]     0     0     0     0     0</span>
<span class="co">#&gt;  [9,]     0     0     0     0     0</span>
<span class="co">#&gt; [10,]     0     0     0     0     0</span>
<span class="co">#&gt; [11,]     0     0     0     0     0</span>
<span class="co">#&gt; [12,]     0     0     0     0     0</span>
<span class="co">#&gt; [13,]     0     0     0     0     0</span>
<span class="co">#&gt; [14,]     1     0     0     0     0</span>
<span class="co">#&gt; [15,]     0     1     0     0     0</span>
<span class="co">#&gt; [16,]     0     0     1     0     0</span>
<span class="co">#&gt; [17,]     0     0     0     1     0</span>
<span class="co">#&gt; [18,]     0     0     0     0     1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $ineqx0</span>
<span class="co">#&gt; NULL</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $nfuneval</span>
<span class="co">#&gt; [1] 23</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $outer.iter</span>
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $elapsed</span>
<span class="co">#&gt; Time difference of 0.012184 secs</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $vscale</span>
<span class="co">#&gt;  [1] 1.01001 0.00001 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000</span>
<span class="co">#&gt; [10] 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000 1.00000</span>
<span class="co">#&gt; [19] 1.00000 1.00000</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $coefficients</span>
<span class="co">#&gt;                           glm                     polspline </span>
<span class="co">#&gt;                      0.055565                      0.055551 </span>
<span class="co">#&gt;                        enet.5                         ridge </span>
<span class="co">#&gt;                      0.055558                      0.055564 </span>
<span class="co">#&gt;                         lasso                     xgboost50 </span>
<span class="co">#&gt;                      0.055558                      0.055583 </span>
<span class="co">#&gt;       randomforest_screen_glm randomforest_screen_polspline </span>
<span class="co">#&gt;                      0.055556                      0.055573 </span>
<span class="co">#&gt;    randomforest_screen_enet.5     randomforest_screen_ridge </span>
<span class="co">#&gt;                      0.055555                      0.055555 </span>
<span class="co">#&gt;     randomforest_screen_lasso randomforest_screen_xgboost50 </span>
<span class="co">#&gt;                      0.055555                      0.055546 </span>
<span class="co">#&gt;              lasso_screen_glm        lasso_screen_polspline </span>
<span class="co">#&gt;                      0.055553                      0.055553 </span>
<span class="co">#&gt;           lasso_screen_enet.5            lasso_screen_ridge </span>
<span class="co">#&gt;                      0.055553                      0.055552 </span>
<span class="co">#&gt;            lasso_screen_lasso        lasso_screen_xgboost50 </span>
<span class="co">#&gt;                      0.055553                      0.055516 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $training_offset</span>
<span class="co">#&gt; [1] FALSE</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $name</span>
<span class="co">#&gt; [1] "solnp"</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [1] "Cross-validated risk:"</span>
<span class="co">#&gt;                           learner coefficients   risk       se  fold_sd</span>
<span class="co">#&gt;  1:                           glm     0.055565 1.0202 0.023955 0.067500</span>
<span class="co">#&gt;  2:                     polspline     0.055551 1.0208 0.023577 0.067921</span>
<span class="co">#&gt;  3:                        enet.5     0.055558 1.0131 0.023598 0.065732</span>
<span class="co">#&gt;  4:                         ridge     0.055564 1.0153 0.023739 0.065299</span>
<span class="co">#&gt;  5:                         lasso     0.055558 1.0130 0.023592 0.065840</span>
<span class="co">#&gt;  6:                     xgboost50     0.055583 1.1136 0.025262 0.077580</span>
<span class="co">#&gt;  7:       randomforest_screen_glm     0.055556 1.0173 0.023830 0.069913</span>
<span class="co">#&gt;  8: randomforest_screen_polspline     0.055573 1.0135 0.023814 0.069240</span>
<span class="co">#&gt;  9:    randomforest_screen_enet.5     0.055555 1.0177 0.023842 0.070142</span>
<span class="co">#&gt; 10:     randomforest_screen_ridge     0.055555 1.0176 0.023855 0.069787</span>
<span class="co">#&gt; 11:     randomforest_screen_lasso     0.055555 1.0177 0.023840 0.070155</span>
<span class="co">#&gt; 12: randomforest_screen_xgboost50     0.055546 1.1277 0.026043 0.078673</span>
<span class="co">#&gt; 13:              lasso_screen_glm     0.055553 1.0164 0.023542 0.065018</span>
<span class="co">#&gt; 14:        lasso_screen_polspline     0.055553 1.0177 0.023520 0.065566</span>
<span class="co">#&gt; 15:           lasso_screen_enet.5     0.055553 1.0163 0.023544 0.065017</span>
<span class="co">#&gt; 16:            lasso_screen_ridge     0.055552 1.0166 0.023553 0.064869</span>
<span class="co">#&gt; 17:            lasso_screen_lasso     0.055553 1.0163 0.023544 0.065020</span>
<span class="co">#&gt; 18:        lasso_screen_xgboost50     0.055516 1.1256 0.025939 0.084270</span>
<span class="co">#&gt; 19:                  SuperLearner           NA 1.0100 0.023524 0.068184</span>
<span class="co">#&gt;     fold_min_risk fold_max_risk</span>
<span class="co">#&gt;  1:       0.89442        1.1200</span>
<span class="co">#&gt;  2:       0.89892        1.1255</span>
<span class="co">#&gt;  3:       0.88839        1.1058</span>
<span class="co">#&gt;  4:       0.88559        1.1063</span>
<span class="co">#&gt;  5:       0.88842        1.1060</span>
<span class="co">#&gt;  6:       0.96019        1.2337</span>
<span class="co">#&gt;  7:       0.88579        1.1119</span>
<span class="co">#&gt;  8:       0.89370        1.1190</span>
<span class="co">#&gt;  9:       0.88593        1.1137</span>
<span class="co">#&gt; 10:       0.88620        1.1128</span>
<span class="co">#&gt; 11:       0.88593        1.1136</span>
<span class="co">#&gt; 12:       1.00223        1.2465</span>
<span class="co">#&gt; 13:       0.90204        1.1156</span>
<span class="co">#&gt; 14:       0.89742        1.1162</span>
<span class="co">#&gt; 15:       0.90184        1.1154</span>
<span class="co">#&gt; 16:       0.90120        1.1146</span>
<span class="co">#&gt; 17:       0.90183        1.1154</span>
<span class="co">#&gt; 18:       0.96251        1.2327</span>
<span class="co">#&gt; 19:       0.88036        1.1041</span></code></pre></div>
<p>From the table of the printed SL fit, we note that the SL had a mean risk of
1.01 and that
this ensemble weighted the <code>ranger</code> and <code>glmnet</code> learners highest while not
weighting the <code>mean</code> learner highly.</p>
<p>We can also see that the <code>glmnet</code> learner had the lowest cross-validated mean
risk, thus making it the cross-validated selector (or the <em>discrete</em> SL). The
mean risk of the SL is calculated using all of the data, and not a separate
hold-out, so the SL’s mean risk that is reported here is an underestimation.</p>
</div>
</div>
<div id="cross-validated-super-learner" class="section level2 unnumbered">
<h2>Cross-validated Super Learner<a class="anchor" aria-label="anchor" href="#cross-validated-super-learner"><i class="fas fa-link"></i></a>
</h2>
<p>We can cross-validate the SL to see how well the SL performs on unseen data,
and obtain an estimate of the cross-validated risk of the SL.</p>
<p>This estimation procedure requires an “outer/external” layer of
cross-validation, also called nested cross-validation, which involves setting
aside a separate holdout sample that we don’t use to fit the SL. This external
cross-validation procedure may also incorporate 10 folds, which is the default
in <code>sl3</code>. However, we will incorporate 2 outer/external folds of
cross-validation for computational efficiency.</p>
<p>We also need to specify a loss function to evaluate SL. Documentation for the
available loss functions can be found in the <a href="https://tlverse.org/sl3/reference/loss_functions.html"><code>sl3</code> Loss
Function Reference</a>.</p>
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">washb_task_new</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/sl3_Task.html">make_sl3_Task</a></span><span class="op">(</span>
  data <span class="op">=</span> <span class="va">washb_data</span>,
  covariates <span class="op">=</span> <span class="va">covars</span>,
  outcome <span class="op">=</span> <span class="va">outcome</span>,
  folds <span class="op">=</span> <span class="fu">origami</span><span class="fu">::</span><span class="fu"><a href="http://tlverse.org/origami/reference/make_folds.html">make_folds</a></span><span class="op">(</span><span class="va">washb_data</span>, fold_fun <span class="op">=</span> <span class="va">folds_vfold</span>, V <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="op">)</span>
<span class="va">CVsl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/CV_lrnr_sl.html">CV_lrnr_sl</a></span><span class="op">(</span>
  lrnr_sl <span class="op">=</span> <span class="va">sl_fit</span>, task <span class="op">=</span> <span class="va">washb_task_new</span>, loss_fun <span class="op">=</span> <span class="va">loss_squared_error</span>
<span class="op">)</span>
<span class="co">#&gt; Error in xgboost::xgb.DMatrix(Xmat, label = Y) : </span>
<span class="co">#&gt;   REAL() can only be applied to a 'numeric', not a 'logical'</span>
<span class="co">#&gt; Error in xgboost::xgb.DMatrix(Xmat, label = Y) : </span>
<span class="co">#&gt;   REAL() can only be applied to a 'numeric', not a 'logical'</span>
<span class="va">CVsl</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html">kable</a></span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">4</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">kableExtra</span><span class="fu">:::</span><span class="fu"><a href="https://rdrr.io/pkg/kableExtra/man/kable_styling.html">kable_styling</a></span><span class="op">(</span>fixed_thead <span class="op">=</span> <span class="cn">T</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/pkg/kableExtra/man/scroll_box.html">scroll_box</a></span><span class="op">(</span>width <span class="op">=</span> <span class="st">"100%"</span>, height <span class="op">=</span> <span class="st">"300px"</span><span class="op">)</span></code></pre></div>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; ">
<div class="inline-table"><table class="table" style="margin-left: auto; margin-right: auto;">
<thead><tr>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
learner
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
coefficients
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
risk
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
se
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
fold_sd
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
fold_min_risk
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
fold_max_risk
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
glm
</td>
<td style="text-align:right;">
0.0556
</td>
<td style="text-align:right;">
1.0494
</td>
<td style="text-align:right;">
0.0269
</td>
<td style="text-align:right;">
0.0797
</td>
<td style="text-align:right;">
0.9930
</td>
<td style="text-align:right;">
1.1058
</td>
</tr>
<tr>
<td style="text-align:left;">
polspline
</td>
<td style="text-align:right;">
0.0556
</td>
<td style="text-align:right;">
1.0173
</td>
<td style="text-align:right;">
0.0235
</td>
<td style="text-align:right;">
0.0684
</td>
<td style="text-align:right;">
0.9689
</td>
<td style="text-align:right;">
1.0656
</td>
</tr>
<tr>
<td style="text-align:left;">
enet.5
</td>
<td style="text-align:right;">
0.0556
</td>
<td style="text-align:right;">
1.0239
</td>
<td style="text-align:right;">
0.0241
</td>
<td style="text-align:right;">
0.0719
</td>
<td style="text-align:right;">
0.9731
</td>
<td style="text-align:right;">
1.0748
</td>
</tr>
<tr>
<td style="text-align:left;">
ridge
</td>
<td style="text-align:right;">
0.0556
</td>
<td style="text-align:right;">
1.0271
</td>
<td style="text-align:right;">
0.0242
</td>
<td style="text-align:right;">
0.0680
</td>
<td style="text-align:right;">
0.9791
</td>
<td style="text-align:right;">
1.0752
</td>
</tr>
<tr>
<td style="text-align:left;">
lasso
</td>
<td style="text-align:right;">
0.0556
</td>
<td style="text-align:right;">
1.0243
</td>
<td style="text-align:right;">
0.0242
</td>
<td style="text-align:right;">
0.0724
</td>
<td style="text-align:right;">
0.9731
</td>
<td style="text-align:right;">
1.0755
</td>
</tr>
<tr>
<td style="text-align:left;">
xgboost50
</td>
<td style="text-align:right;">
0.0556
</td>
<td style="text-align:right;">
1.1789
</td>
<td style="text-align:right;">
0.0267
</td>
<td style="text-align:right;">
0.0052
</td>
<td style="text-align:right;">
1.1752
</td>
<td style="text-align:right;">
1.1826
</td>
</tr>
<tr>
<td style="text-align:left;">
randomforest_screen_glm
</td>
<td style="text-align:right;">
0.0556
</td>
<td style="text-align:right;">
1.0324
</td>
<td style="text-align:right;">
0.0239
</td>
<td style="text-align:right;">
0.0594
</td>
<td style="text-align:right;">
0.9904
</td>
<td style="text-align:right;">
1.0744
</td>
</tr>
<tr>
<td style="text-align:left;">
randomforest_screen_polspline
</td>
<td style="text-align:right;">
0.0556
</td>
<td style="text-align:right;">
1.0259
</td>
<td style="text-align:right;">
0.0237
</td>
<td style="text-align:right;">
0.0772
</td>
<td style="text-align:right;">
0.9713
</td>
<td style="text-align:right;">
1.0805
</td>
</tr>
<tr>
<td style="text-align:left;">
randomforest_screen_enet.5
</td>
<td style="text-align:right;">
0.0556
</td>
<td style="text-align:right;">
1.0284
</td>
<td style="text-align:right;">
0.0239
</td>
<td style="text-align:right;">
0.0651
</td>
<td style="text-align:right;">
0.9823
</td>
<td style="text-align:right;">
1.0745
</td>
</tr>
<tr>
<td style="text-align:left;">
randomforest_screen_ridge
</td>
<td style="text-align:right;">
0.0556
</td>
<td style="text-align:right;">
1.0310
</td>
<td style="text-align:right;">
0.0239
</td>
<td style="text-align:right;">
0.0611
</td>
<td style="text-align:right;">
0.9878
</td>
<td style="text-align:right;">
1.0743
</td>
</tr>
<tr>
<td style="text-align:left;">
randomforest_screen_lasso
</td>
<td style="text-align:right;">
0.0556
</td>
<td style="text-align:right;">
1.0284
</td>
<td style="text-align:right;">
0.0239
</td>
<td style="text-align:right;">
0.0651
</td>
<td style="text-align:right;">
0.9824
</td>
<td style="text-align:right;">
1.0745
</td>
</tr>
<tr>
<td style="text-align:left;">
randomforest_screen_xgboost50
</td>
<td style="text-align:right;">
0.0555
</td>
<td style="text-align:right;">
1.1721
</td>
<td style="text-align:right;">
0.0269
</td>
<td style="text-align:right;">
0.0325
</td>
<td style="text-align:right;">
1.1491
</td>
<td style="text-align:right;">
1.1951
</td>
</tr>
<tr>
<td style="text-align:left;">
lasso_screen_glm
</td>
<td style="text-align:right;">
0.0556
</td>
<td style="text-align:right;">
1.0257
</td>
<td style="text-align:right;">
0.0238
</td>
<td style="text-align:right;">
0.0537
</td>
<td style="text-align:right;">
0.9877
</td>
<td style="text-align:right;">
1.0636
</td>
</tr>
<tr>
<td style="text-align:left;">
lasso_screen_polspline
</td>
<td style="text-align:right;">
0.0556
</td>
<td style="text-align:right;">
1.0267
</td>
<td style="text-align:right;">
0.0239
</td>
<td style="text-align:right;">
0.0551
</td>
<td style="text-align:right;">
0.9877
</td>
<td style="text-align:right;">
1.0656
</td>
</tr>
<tr>
<td style="text-align:left;">
lasso_screen_enet.5
</td>
<td style="text-align:right;">
0.0556
</td>
<td style="text-align:right;">
1.0261
</td>
<td style="text-align:right;">
0.0238
</td>
<td style="text-align:right;">
0.0546
</td>
<td style="text-align:right;">
0.9875
</td>
<td style="text-align:right;">
1.0648
</td>
</tr>
<tr>
<td style="text-align:left;">
lasso_screen_ridge
</td>
<td style="text-align:right;">
0.0556
</td>
<td style="text-align:right;">
1.0255
</td>
<td style="text-align:right;">
0.0238
</td>
<td style="text-align:right;">
0.0544
</td>
<td style="text-align:right;">
0.9870
</td>
<td style="text-align:right;">
1.0640
</td>
</tr>
<tr>
<td style="text-align:left;">
lasso_screen_lasso
</td>
<td style="text-align:right;">
0.0556
</td>
<td style="text-align:right;">
1.0262
</td>
<td style="text-align:right;">
0.0238
</td>
<td style="text-align:right;">
0.0546
</td>
<td style="text-align:right;">
0.9875
</td>
<td style="text-align:right;">
1.0648
</td>
</tr>
<tr>
<td style="text-align:left;">
lasso_screen_xgboost50
</td>
<td style="text-align:right;">
0.0555
</td>
<td style="text-align:right;">
1.1519
</td>
<td style="text-align:right;">
0.0258
</td>
<td style="text-align:right;">
0.0433
</td>
<td style="text-align:right;">
1.1213
</td>
<td style="text-align:right;">
1.1826
</td>
</tr>
<tr>
<td style="text-align:left;">
SuperLearner
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0208
</td>
<td style="text-align:right;">
0.0238
</td>
<td style="text-align:right;">
0.0639
</td>
<td style="text-align:right;">
0.9756
</td>
<td style="text-align:right;">
1.0659
</td>
</tr>
</tbody>
</table></div>
</div>
<!-- Explain summary!!!! -->
</div>
<div id="variable-importance-measures-with-sl3" class="section level2 unnumbered">
<h2>Variable Importance Measures with <code>sl3</code><a class="anchor" aria-label="anchor" href="#variable-importance-measures-with-sl3"><i class="fas fa-link"></i></a>
</h2>
<p>Variable importance can be interesting and informative. It can also be
contradictory and confusing. Nevertheless, we like it, and so do our
collaborators, so we created a variable importance function in <code>sl3</code>! The <code>sl3</code>
<code>importance</code> function returns a table with variables listed in decreasing order
of importance (i.e., most important on the first row).</p>
<p>The measure of importance in <code>sl3</code> is based on a risk ratio, or risk
difference, between the learner fit with a removed, or permuted, covariate and
the learner fit with the true covariate, across all covariates. In this manner,
the larger the risk difference, the more important the variable is in the
prediction.</p>
<p>The intuition of this measure is that it calculates the risk (in terms of the
average loss in predictive accuracy) of losing one covariate, while keeping
everything else fixed, and compares it to the risk if the covariate was not
lost. If this risk ratio is one, or risk difference is zero, then losing that
covariate had no impact, and is thus not important by this measure. We do this
across all of the covariates. As stated above, we can remove the covariate and
refit the SL without it, or we just permute the covariate (faster, more risky)
and hope for the shuffling to distort any meaningful information that was
present in the covariate. This idea of permuting instead of removing saves a
lot of time, and is also incorporated in the <code>randomForest</code> variable importance
measures. However, the permutation approach is risky, so the importance
function default is to remove and refit.</p>
<p>Let’s explore the <code>sl3</code> variable importance measurements for the <code>washb</code> data.</p>
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">washb_varimp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/importance.html">importance</a></span><span class="op">(</span><span class="va">sl_fit</span>, loss <span class="op">=</span> <span class="va">loss_squared_error</span>, type <span class="op">=</span> <span class="st">"permute"</span><span class="op">)</span>
<span class="va">washb_varimp</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html">kable</a></span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">4</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">kableExtra</span><span class="fu">:::</span><span class="fu"><a href="https://rdrr.io/pkg/kableExtra/man/kable_styling.html">kable_styling</a></span><span class="op">(</span>fixed_thead <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/pkg/kableExtra/man/scroll_box.html">scroll_box</a></span><span class="op">(</span>width <span class="op">=</span> <span class="st">"100%"</span>, height <span class="op">=</span> <span class="st">"300px"</span><span class="op">)</span></code></pre></div>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; ">
<div class="inline-table"><table class="table" style="margin-left: auto; margin-right: auto;">
<thead><tr>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
X
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
risk_ratio
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
aged
</td>
<td style="text-align:right;">
1.0413
</td>
</tr>
<tr>
<td style="text-align:left;">
momedu
</td>
<td style="text-align:right;">
1.0139
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_refrig
</td>
<td style="text-align:right;">
1.0083
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_chair
</td>
<td style="text-align:right;">
1.0046
</td>
</tr>
<tr>
<td style="text-align:left;">
month
</td>
<td style="text-align:right;">
1.0032
</td>
</tr>
<tr>
<td style="text-align:left;">
momheight
</td>
<td style="text-align:right;">
1.0027
</td>
</tr>
<tr>
<td style="text-align:left;">
elec
</td>
<td style="text-align:right;">
1.0020
</td>
</tr>
<tr>
<td style="text-align:left;">
tr
</td>
<td style="text-align:right;">
1.0020
</td>
</tr>
<tr>
<td style="text-align:left;">
Nlt18
</td>
<td style="text-align:right;">
1.0012
</td>
</tr>
<tr>
<td style="text-align:left;">
momage
</td>
<td style="text-align:right;">
1.0006
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_chouki
</td>
<td style="text-align:right;">
1.0003
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_mobile
</td>
<td style="text-align:right;">
1.0003
</td>
</tr>
<tr>
<td style="text-align:left;">
floor
</td>
<td style="text-align:right;">
1.0002
</td>
</tr>
<tr>
<td style="text-align:left;">
delta_momheight
</td>
<td style="text-align:right;">
1.0001
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_table
</td>
<td style="text-align:right;">
1.0000
</td>
</tr>
<tr>
<td style="text-align:left;">
Ncomp
</td>
<td style="text-align:right;">
1.0000
</td>
</tr>
<tr>
<td style="text-align:left;">
sex
</td>
<td style="text-align:right;">
1.0000
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_moto
</td>
<td style="text-align:right;">
1.0000
</td>
</tr>
<tr>
<td style="text-align:left;">
watmin
</td>
<td style="text-align:right;">
1.0000
</td>
</tr>
<tr>
<td style="text-align:left;">
walls
</td>
<td style="text-align:right;">
1.0000
</td>
</tr>
<tr>
<td style="text-align:left;">
delta_momage
</td>
<td style="text-align:right;">
1.0000
</td>
</tr>
<tr>
<td style="text-align:left;">
roof
</td>
<td style="text-align:right;">
0.9999
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_tv
</td>
<td style="text-align:right;">
0.9999
</td>
</tr>
<tr>
<td style="text-align:left;">
hfiacat
</td>
<td style="text-align:right;">
0.9999
</td>
</tr>
<tr>
<td style="text-align:left;">
fracode
</td>
<td style="text-align:right;">
0.9998
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_wardrobe
</td>
<td style="text-align:right;">
0.9998
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_bike
</td>
<td style="text-align:right;">
0.9998
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_sewmach
</td>
<td style="text-align:right;">
0.9998
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_khat
</td>
<td style="text-align:right;">
0.9997
</td>
</tr>
</tbody>
</table></div>
</div>
<div class="sourceCode" id="cb60"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># plot variable importance</span>
<span class="fu"><a href="https://tlverse.org/sl3/reference/importance_plot.html">importance_plot</a></span><span class="op">(</span>
  <span class="va">washb_varimp</span>,
  main <span class="op">=</span> <span class="st">"sl3 Variable Importance for WASH Benefits Example Data"</span>
<span class="op">)</span></code></pre></div>
<div class="inline-figure">
<img src="06-sl3_files/figure-html/varimp-plot-1.png" width="80%" style="display: block; margin: auto;"><!-- Explain summary!!!! -->
</div>
</div>
<div id="sl3-exercises" class="section level2">
<h2>
<span class="header-section-number">5.10</span> Exercises<a class="anchor" aria-label="anchor" href="#sl3-exercises"><i class="fas fa-link"></i></a>
</h2>
<div id="sl3ex1" class="section level3">
<h3>
<span class="header-section-number">5.10.1</span> Predicting Myocardial Infarction with <code>sl3</code><a class="anchor" aria-label="anchor" href="#sl3ex1"><i class="fas fa-link"></i></a>
</h3>
<p>Follow the steps below to predict myocardial infarction (<code>mi</code>) using the
available covariate data. We thank Prof. David Benkeser at Emory University for
making the this Cardiovascular Health Study (CHS) data accessible.</p>
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># load the data set</span>
<span class="va">db_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/connections.html">url</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span>
    <span class="st">"https://raw.githubusercontent.com/benkeser/sllecture/master/"</span>,
    <span class="st">"chspred.csv"</span>
  <span class="op">)</span>
<span class="op">)</span>
<span class="va">chspred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span>file <span class="op">=</span> <span class="va">db_data</span>, col_names <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>

<span class="co"># take a quick peek</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">chspred</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html">kable</a></span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">4</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">kableExtra</span><span class="fu">:::</span><span class="fu"><a href="https://rdrr.io/pkg/kableExtra/man/kable_styling.html">kable_styling</a></span><span class="op">(</span>fixed_thead <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://rdrr.io/pkg/kableExtra/man/scroll_box.html">scroll_box</a></span><span class="op">(</span>width <span class="op">=</span> <span class="st">"100%"</span>, height <span class="op">=</span> <span class="st">"300px"</span><span class="op">)</span></code></pre></div>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; ">
<div class="inline-table"><table class="table" style="margin-left: auto; margin-right: auto;">
<thead><tr>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
waist
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
alcoh
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
hdl
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
beta
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
smoke
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
ace
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
ldl
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
bmi
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
aspirin
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
gend
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
age
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
estrgn
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
glu
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
ins
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
cysgfr
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
dm
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
fetuina
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
whr
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
hsed
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
race
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
logcystat
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
logtrig
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
logcrp
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
logcre
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
health
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
logkcal
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
sysbp
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
mi
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:right;">
110.164
</td>
<td style="text-align:right;">
0.0000
</td>
<td style="text-align:right;">
66.497
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
114.216
</td>
<td style="text-align:right;">
27.997
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
73.518
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
159.931
</td>
<td style="text-align:right;">
70.3343
</td>
<td style="text-align:right;">
75.008
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.1752
</td>
<td style="text-align:right;">
1.1690
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-0.3420
</td>
<td style="text-align:right;">
5.4063
</td>
<td style="text-align:right;">
2.0126
</td>
<td style="text-align:right;">
-0.6739
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
4.3926
</td>
<td style="text-align:right;">
177.135
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
89.976
</td>
<td style="text-align:right;">
0.0000
</td>
<td style="text-align:right;">
50.065
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
103.777
</td>
<td style="text-align:right;">
20.893
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
61.772
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
153.389
</td>
<td style="text-align:right;">
33.9695
</td>
<td style="text-align:right;">
82.743
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.5717
</td>
<td style="text-align:right;">
0.9011
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.0847
</td>
<td style="text-align:right;">
4.8592
</td>
<td style="text-align:right;">
3.2933
</td>
<td style="text-align:right;">
-0.5551
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
6.2071
</td>
<td style="text-align:right;">
136.374
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
106.194
</td>
<td style="text-align:right;">
8.4174
</td>
<td style="text-align:right;">
40.506
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
165.716
</td>
<td style="text-align:right;">
28.455
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
72.931
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
121.715
</td>
<td style="text-align:right;">
-17.3017
</td>
<td style="text-align:right;">
74.699
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.3517
</td>
<td style="text-align:right;">
1.1797
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-0.4451
</td>
<td style="text-align:right;">
4.5088
</td>
<td style="text-align:right;">
0.3013
</td>
<td style="text-align:right;">
-0.0115
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
6.7320
</td>
<td style="text-align:right;">
135.199
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
90.057
</td>
<td style="text-align:right;">
0.0000
</td>
<td style="text-align:right;">
36.175
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
45.203
</td>
<td style="text-align:right;">
23.961
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
79.119
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
53.969
</td>
<td style="text-align:right;">
11.7315
</td>
<td style="text-align:right;">
95.782
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.5439
</td>
<td style="text-align:right;">
1.1360
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.4807
</td>
<td style="text-align:right;">
5.1832
</td>
<td style="text-align:right;">
3.0243
</td>
<td style="text-align:right;">
-0.5751
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
7.3972
</td>
<td style="text-align:right;">
139.018
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
78.614
</td>
<td style="text-align:right;">
2.9790
</td>
<td style="text-align:right;">
71.064
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
131.312
</td>
<td style="text-align:right;">
10.966
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
69.018
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
94.315
</td>
<td style="text-align:right;">
9.7112
</td>
<td style="text-align:right;">
72.711
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.4916
</td>
<td style="text-align:right;">
1.1028
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.3121
</td>
<td style="text-align:right;">
4.2190
</td>
<td style="text-align:right;">
-0.7057
</td>
<td style="text-align:right;">
0.0053
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
8.2779
</td>
<td style="text-align:right;">
88.047
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
91.659
</td>
<td style="text-align:right;">
0.0000
</td>
<td style="text-align:right;">
59.496
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
171.187
</td>
<td style="text-align:right;">
29.132
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
81.835
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
212.907
</td>
<td style="text-align:right;">
-28.2269
</td>
<td style="text-align:right;">
69.218
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.4621
</td>
<td style="text-align:right;">
0.9529
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.2872
</td>
<td style="text-align:right;">
5.1773
</td>
<td style="text-align:right;">
0.9705
</td>
<td style="text-align:right;">
0.2127
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
5.9942
</td>
<td style="text-align:right;">
69.594
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table></div>
</div>
<ol style="list-style-type: decimal">
<li>Create an <code>sl3</code> task, setting myocardial infarction <code>mi</code> as the outcome and
using all available covariate data.</li>
<li>Make a library of seven relatively fast base learning algorithms (i.e., do
not consider BART or HAL). Customize hyperparameters for one of your
learners. Feel free to use learners from <code>sl3</code> or <code>SuperLearner</code>. You may
use the same base learning library that is presented above.</li>
<li>Incorporate at least one pipeline with feature selection. Any screener and
learner(s) can be used.</li>
<li>Fit the metalearning step with the default metalearner.</li>
<li>With the metalearner and base learners, make the Super Learner (SL) and train
it on the task.</li>
<li>Print your SL fit by calling <code><a href="https://docs.ropensci.org/skimr/reference/print.html">print()</a></code> with <code><a href="https://rdrr.io/r/base/Extract.html">$</a></code>.</li>
<li>Cross-validate your SL fit to see how well it performs on unseen
data. Specify a valid loss function to evaluate the SL.</li>
<li>Use the <code><a href="https://tlverse.org/sl3/reference/importance.html">importance()</a></code> function to identify the “most important” predictor of
myocardial infarction, according to <code>sl3</code> importance metrics.</li>
</ol>
</div>
<div id="sl3ex2" class="section level3">
<h3>
<span class="header-section-number">5.10.2</span> Predicting Recurrent Ischemic Stroke in an RCT with <code>sl3</code><a class="anchor" aria-label="anchor" href="#sl3ex2"><i class="fas fa-link"></i></a>
</h3>
<p>For this exercise, we will work with a random sample of 5,000 patients who
participated in the International Stroke Trial (IST). This data is described in
<a href="https://tlverse.org/tlverse-handbook/data.html#ist">Chapter 3.2 of the <code>tlverse</code>
handbook</a>.</p>
<ol style="list-style-type: decimal">
<li>Train a SL to predict recurrent stroke <code>DRSISC</code> with the available covariate
data (the 25 other variables). Of course, you can consider feature selection
in the machine learning algorithms. In this data, the outcome is
occasionally missing, so be sure to specify <code>drop_missing_outcome = TRUE</code>
when defining the task.</li>
<li>Use the SL-based predictions to calculate the area under the ROC curve (AUC).</li>
<li>Calculate the cross-validated AUC to evaluate the performance of the
SL on unseen data.</li>
<li>Which covariates are the most predictive of 14-day recurrent stroke,
according to <code>sl3</code> variable importance measures?</li>
</ol>
<div class="sourceCode" id="cb62"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ist_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span>
  <span class="st">"https://raw.githubusercontent.com/tlverse/"</span>,
  <span class="st">"tlverse-handbook/master/data/ist_sample.csv"</span>
<span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/fread.html">fread</a></span><span class="op">(</span><span class="op">)</span>

<span class="co"># number 3 help</span>
<span class="va">ist_task_CVsl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/sl3_Task.html">make_sl3_Task</a></span><span class="op">(</span>
  data <span class="op">=</span> <span class="va">ist_data</span>,
  outcome <span class="op">=</span> <span class="st">"DRSISC"</span>,
  covariates <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">ist_data</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">ist_data</span><span class="op">)</span> <span class="op">==</span> <span class="st">"DRSISC"</span><span class="op">)</span><span class="op">]</span>,
  drop_missing_outcome <span class="op">=</span> <span class="cn">TRUE</span>,
  folds <span class="op">=</span> <span class="fu">origami</span><span class="fu">::</span><span class="fu"><a href="http://tlverse.org/origami/reference/make_folds.html">make_folds</a></span><span class="op">(</span>
    n <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span class="op">(</span><span class="va">ist_data</span><span class="op">$</span><span class="va">DRSISC</span><span class="op">)</span><span class="op">)</span>,
    fold_fun <span class="op">=</span> <span class="va">folds_vfold</span>,
    V <span class="op">=</span> <span class="fl">5</span>
  <span class="op">)</span>
<span class="op">)</span></code></pre></div>
<!--
## Super Learning of a Conditional Density

### Super learning of a conditional density

Suppose we want to construct a Super Learner of the conditional probability
distribution $g_0(a\mid W)=P_0(A=a\mid W)$, where $a\in {\cal A}$.
Let's denote the values of $a$ with $\{0,1,\ldots,K\}$. A valid loss function
for the conditional density is
\[
L(g)(O)=-\log g(A\mid W).\]
That is, $g_0=\arg\min_g P_0L(g)$, i.e., $g_0$ is the minimizer of the
expectation of the log-likelihood loss.

**Candidate estimators**

1. Candidate estimators based on multinomial logistic regression: To start
with, one can use existing parametric model based MLE and machine learning
algorithms in `R` that fit a multinomial regression. For example, parametric
model multinomial logistic regression is available in `R` so that one can
already build a rich library of such estimators based on  different candidate
parametric models. In addition, `polyclass()` is a multinomial logistic
regression machine learning algorithm in `R`.

2. Candidate estimators based on machine learning for multinomial logistic
regression: Secondly, one can use a machine learning algorithm such as
`polyclass()` in `R` that data adaptively fits a multinomial logistic
regression, which itself has tuning parameters, again generating a class of
candidate estimators.

3. Incorporating screening: Note that one can also marry any of these choices
with a screening algorithm, thereby creating more candidate estimators of
interest. The screening can be particularly important when there are many
variables.

4. Candidate estimators by fitting separate logistic regressions and using
post-normalization

* Code $A$ in terms of Bernoullis $B_k=I(A=k)$, $k=0,\ldots,K$.
* Construct an estimator $\bar{g}_{nk}$ of $\bar{g}_{0k}(W)\equiv P_0(B_k=1\mid
  W)$ using any of the logistic regression algorithms, for all $k=0,\ldots,K$.
* This implies an estimator
\[
g_n(a\mid W)=\frac{\bar{g}_{na}(W)}{\sum_{k=0}^K \bar{g}_{nk}(W)}.\]
* In other words, we simply normalize these separate logistic regression
estimators so that we obtain a valid conditional distribution.
* This generates an enormous amount of interesting algorithms, since we have
available the whole machine learning literature for binary outcome regression.

5. Candidate estimators by estimating the conditional "hazard" with pooled
logistic regression.
Note that
\[
g_0(a\mid W)=\lambda_0(a\mid W) S_0(a\mid W),\]
where \[
\lambda_0(a\mid W)=P_0(A=a\mid A\geq a,W),\]

and $S_0(a\mid W)=\prod_{s\leq a}(1-\lambda_0(s\mid W))$ is the conditional
survival function $P_0(A>a\mid W)$. So we have now parameterized the
conditional distribution of $A$, given $W$, by a conditional hazard
$\lambda_0(a\mid W)$: $g_0=g_{\lambda_0}$.

* We could now focus on constructing candidate estimators of
$\lambda_0(a\mid W)$, which implies candidate estimators of $g_0$.

* For every observation $A_i$, we can create $A_i+1$ rows of data
$(W,s,I(A_i=s))$, $s=0,\ldots,A_i$, $i=1,\ldots,n$. We now run a logistic
regression estimator based on the pooled data set, ignoring ID, where we
regress the binary outcome $I(A_i=s)$ on the covariates $(W,s)$.

* If one assumes a parametric model, then this is nothing else then using the
maximum likelihood estimator, demonstrating that ignoring the ID is not
inefficient.

* This defines now an estimator of $\lambda_0(s\mid W)=P_0(A=s\mid W,A\geq s)$
as a function of $(s,W)$.

* Different choices of logistic regression based estimators will define
different estimators.

* The pooling across $s$ is not very sensible if $A$ is not an ordered variable
If $A$ is categorical, we recommend to compute  a separate logistic regression
estimator of $\lambda_0(a\mid W)$ for each $a$ (i.e., stratify by $s$ in the
  above pooled data set).

* For non-categorical $A$, one could include both stratified (by level) as well
as pooled (across levels) based logistic regression estimators.


## Exercise 2 -- Estimating the Propensity Score with `sl3` {#sl3ex-pscore}

exercise where we can look at positivity and maybe modify target population,
address issues related to this

## Super Learning of an Optimal Individualized Treatment Rule

* Data $O=(W,A,Y)$, and nonparametric model \mathcal{M} potentially containing
assumptions on the conditional probability distribution of $A$ given $W$
$g_0(A\mid W)$.
* Target: Optimal treatment rule $\psi_0(W)=I(B_0(W)>0)$, where
$B_0(W)=E_0(Y\mid A=1,W)-E_0(Y\mid A=0,W)$, the conditional treatment effect.
* Possible loss function for $\psi_0$ is an IPCW-loss:
\[
L_{g_0}(\psi)=\frac{I(A=\psi(W))}{g(A\mid W)}Y.\]

Indeed, $\psi_0$ is the minimizer of $EL_{g_0}(\psi)$ over all rules $\psi$.
* Construct library of candidate estimators of $\psi_0=I(B_0>0)$. This can
include estimators based on plugging in an estimator of $B_0$.
* One could also include a candidate estimator $I(B_n>0)$ where $B_n$ is a
Super Learner of $B_0$, e.g. based on loss function
\[
L_{g_0}(B)=\big(\frac{2A-1}{/g(A\mid W)}Y-B(W)\big)^2\]
that directly targets $B_0=\arg\min_B P_0L_{g_0}(B)$. This loss function is
still a squared error loss but its minimized by the true $B_0$.
* Estimate $g_0$ if not known.
* Compute cross-validation selector:
\[
k_n=\arg\min_k E_{B_n}P_{n,B_n}^1 L_{\hat{g}(P_{n,B_n}^0)}
(\hat{\Psi}_k(P_{n,B_n}^0)).\]
where $B_n = \{0,1\}^n$ is used for a binary vector of $n$ defining sample
splits, where the validation sample is ${i:B_n(i) = 1}$ and ${i:B_n(i) = 0}$ is
the training sample. The empirical distribution $P_{n,B_n}^0$ corresponds to
the split $B_n$ of the training sample and the empirical distribution of the
validation sample is $P_{n,B_n}^1$.
* Super-learner of optimal rule $\psi_0$: $\hat{\Psi}_{k_n}(P_n)$.

## Exercise 3 -- Estimating the Blip {#sl3ex3}

-->
</div>
</div>
<div id="concluding-remarks" class="section level2">
<h2>
<span class="header-section-number">5.11</span> Concluding Remarks<a class="anchor" aria-label="anchor" href="#concluding-remarks"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li><p>Super Learner (SL) is a general approach that can be applied to a diversity of
estimation and prediction problems which can be defined by a loss function.</p></li>
<li>It would be straightforward to plug in the estimator returned by SL into the
target parameter mapping.
<ul>
<li>For example, suppose we are after the average treatment effect (ATE) of a
binary treatment intervention:
<span class="math inline">\(\Psi_0 = E_{0,W}[E_0(Y|A=1,W) - E_0(Y|A=0,W)]\)</span>.</li>
<li>We could use the SL that was trained on the original data (let’s call
this <code>sl_fit</code>) to predict the outcome for all subjects under each
intervention. All we would need to do is take the average difference
between the counterfactual outcomes under each intervention of interest.</li>
<li>Considering <span class="math inline">\(\Psi_0\)</span> above, we would first need two <span class="math inline">\(n\)</span>-length vectors of
predicted outcomes under each intervention. One vector would represent the
predicted outcomes under an intervention that sets all subjects to
receive <span class="math inline">\(A=1\)</span>, <span class="math inline">\(Y_i|A_i=1,W_i\)</span> for all <span class="math inline">\(i=1,\ldots,n\)</span>. The other vector
would represent the predicted outcomes under an intervention that sets
all subjects to receive <span class="math inline">\(A=0\)</span>, <span class="math inline">\(Y_i|A_i=0,W_i\)</span> for all <span class="math inline">\(i=1,\ldots,n\)</span>.</li>
<li>After obtaining these vectors of counterfactual predicted outcomes, all
we would need to do is average and then take the difference in order to
“plug-in” the SL estimator into the target parameter mapping.</li>
<li>In <code>sl3</code> and with our current ATE example, this could be achieved with
<code>mean(sl_fit$predict(A1_task)) - mean(sl_fit$predict(A0_task))</code>;
where <code>A1_task$data</code> would contain all 1’s (or the level that pertains to
receiving the treatment) for the treatment column in the data (keeping all
else the same), and <code>A0_task$data</code> would contain all 0’s (or the level
that pertains to not receiving the treatment) for the treatment column in
the data.</li>
</ul>
</li>
<li>It’s a worthwhile exercise to obtain the predicted counterfactual outcomes
and create these counterfactual <code>sl3</code> tasks. It’s too biased; however, to
plug the SL fit into the target parameter mapping, (e.g., calling the result
of <code>mean(sl_fit$predict(A1_task)) - mean(sl_fit$predict(A0_task))</code> the
estimated ATE. We would end up with an estimator for the ATE that was
optimized for estimation of the prediction function, and not the ATE!</li>
<li>
<p>At the end of the “analysis day”, we want an estimator that is optimized for
our target estimand of interest. We ultimately care about doing a good job
estimating <span class="math inline">\(\psi_0\)</span>. The SL is an essential step to help us get there. In
fact, we will use the counterfactual predicted outcomes that were explained
at length above. However, SL is not the end of the estimation procedure.
Specifically, the Super Learner would not be an asymptotically linear
estimator of the target estimand; and it is not an efficient substitution
estimator. This begs the question, why is it so important for an estimator to
possess these properties?</p>
<ul>
<li>An asymptotically linear estimator converges to the estimand a
<span class="math inline">\(\frac{1}{\sqrt{n}}\)</span> rate, thereby permitting formal statistical inference
(i.e., confidence intervals and <span class="math inline">\(p\)</span>-values).</li>
<li>Substitution, or plug-in, estimators of the estimand are desirable because
they respect both the local and global constraints of the statistical model
(e.g., bounds), and have they have better finite-sample properties.</li>
<li>
<p>An efficient estimator is optimal in the sense that it has the lowest
possible variance, and is thus the most precise. An estimator is efficient
if and only if is asymptotically linear with influence curve equal to the
canonical gradient.</p>
<ul>
<li>The canonical gradient is a mathematical object that is specific to
the target estimand, and it provides information on the level of
difficulty of the estimation problem. Various canonical gradient are
shown in the chapters that follow.</li>
<li>Practitioner’s do not need to know how to calculate a canonical
gradient in order to understand efficiency and use Targeted Maximum
Likelihood Estimation (TMLE). Metaphorically, you do not need to be
Yoda in order to be a Jedi.</li>
</ul>
</li>
</ul>
</li>
<li>TMLE is a general strategy that succeeds in constructing efficient and
asymptotically linear plug-in estimators.</li>
<li>SL is fantastic for pure prediction, and for obtaining an initial
estimate in the first step of TMLE, but we need the second step of TMLE to
have the desirable statistical properties mentioned above.</li>
<li><p>In the chapters that follow, we focus on the targeted maximum likelihood
estimator and the targeted minimum loss-based estimator, both referred to as
TMLE.</p></li>
</ul>
<!--
We could just plug-in the estimator returned by Super Learner; however, this is
problematic because the Super Learner estimators are trading off bias and
variance in an optimal way and as a result their bias is essentially the rate
of convergence of these algorithms, which is always slower than $1/\sqrt{n}$.
Therefore, if we plug-in the estimator returned by Super Learner into the
target parameter mapping, we would end up with an estimator which has the same
bias as what we plugged in, which is greater than $1/\sqrt{n}$. Thus, we end up
with an estimator which is not asymptotically normal, since it does not
converge to the estimand at $1/\sqrt{n}$ rate.

An asymptotically linear estimator has no meaningful bias ($ < 1/\sqrt{n}$),
and can be written as an empirical mean in first order of a function of the
data, the influence curve, plus some negligible remainder term. Once an
estimator is asymptotically linear with an influence curve it’s normally
distributed, so the standardized estimator converges to a normal distribution
with mean 0 and variance is the variance of the influence curve. Thus, it is
advantageous to construct asymptotically linear estimators since they permit
formal statistical inference. Among the class of regular asymptotically linear
estimators, there is an optimal estimator which is an efficient estimator, and
that’s the one with influence curve equal to the canonical gradient of the
path-wise derivative of the target parameter. The canonical gradient is the
direction of the path through the data distribution where the parameter is
steepest. An estimator is efficient if and only if is asymptotically linear
with influence curve equal to the canonical gradient. One can calculate the
canonical gradient with the statistical model and the statistical target
parameter.  Techniques for calculating the canonical gradient entail projecting
an initial gradient on the tangent space of the model at the particular
distribution in the model in which you want to calculate the canonical
gradient.

Now we know what it takes to construct an efficient estimator. Namely, we need
to construct an estimator which is asymptotically linear with influence curve
the canonical gradient. There are three general classes of estimators which
succeed in constructing asymptotically linear estimators: (1) the one-step
estimator, but it is not a plug-in estimator; (2) the targeted maximum
likelihood estimator, which is a Super Learner targeted towards the target
parameter and it is a plug-in estimator; and (3) estimating equation based
estimators, which use the canonical gradient but as an estimating function in
the target parameter. In the chapters that follow, we focus on the targeted
maximum likelihood estimator and the targeted minimum loss-based estimator,
both referred to as TMLE.
-->
</div>
<div id="appendix" class="section level2 unnumbered">
<h2>Appendix<a class="anchor" aria-label="anchor" href="#appendix"><i class="fas fa-link"></i></a>
</h2>
<div id="sl3ex1-sol" class="section level3">
<h3>
<span class="header-section-number">5.11.1</span> Exercise 1 Solution<a class="anchor" aria-label="anchor" href="#sl3ex1-sol"><i class="fas fa-link"></i></a>
</h3>
<p>Here is a potential solution to the <a href="origami.html#sl3ex1"><code>sl3</code> Exercise 1 – Predicting Myocardial
Infarction with <code>sl3</code></a>.</p>
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">db_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/connections.html">url</a></span><span class="op">(</span>
  <span class="st">"https://raw.githubusercontent.com/benkeser/sllecture/master/chspred.csv"</span>
<span class="op">)</span>
<span class="va">chspred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span>file <span class="op">=</span> <span class="va">db_data</span>, col_names <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>

<span class="co"># make task</span>
<span class="va">chspred_task</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/sl3_Task.html">make_sl3_Task</a></span><span class="op">(</span>
  data <span class="op">=</span> <span class="va">chspred</span>,
  covariates <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">chspred</span><span class="op">)</span>, <span class="op">-</span><span class="fl">1</span><span class="op">)</span>,
  outcome <span class="op">=</span> <span class="st">"mi"</span>
<span class="op">)</span>

<span class="co"># make learners</span>
<span class="va">glm_learner</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glm.html">Lrnr_glm</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span>
<span class="va">lasso_learner</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glmnet.html">Lrnr_glmnet</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
<span class="va">ridge_learner</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glmnet.html">Lrnr_glmnet</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0</span><span class="op">)</span>
<span class="va">enet_learner</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glmnet.html">Lrnr_glmnet</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>
<span class="co"># curated_glm_learner uses formula = "mi ~ smoke + beta + waist"</span>
<span class="va">curated_glm_learner</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glm_fast.html">Lrnr_glm_fast</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>covariates <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"smoke, beta, waist"</span><span class="op">)</span><span class="op">)</span>
<span class="va">mean_learner</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_mean.html">Lrnr_mean</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span> <span class="co"># That is one mean learner!</span>
<span class="va">glm_fast_learner</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glm_fast.html">Lrnr_glm_fast</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span>
<span class="va">ranger_learner</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_ranger.html">Lrnr_ranger</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span>
<span class="va">svm_learner</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_svm.html">Lrnr_svm</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span>
<span class="va">xgb_learner</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_xgboost.html">Lrnr_xgboost</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span>

<span class="co"># screening</span>
<span class="va">screen_cor</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/Lrnr_base.html">make_learner</a></span><span class="op">(</span><span class="va">Lrnr_screener_correlation</span><span class="op">)</span>
<span class="va">glm_pipeline</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/Lrnr_base.html">make_learner</a></span><span class="op">(</span><span class="va">Pipeline</span>, <span class="va">screen_cor</span>, <span class="va">glm_learner</span><span class="op">)</span>

<span class="co"># stack learners together</span>
<span class="va">stack</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/Lrnr_base.html">make_learner</a></span><span class="op">(</span>
  <span class="va">Stack</span>,
  <span class="va">glm_pipeline</span>, <span class="va">glm_learner</span>,
  <span class="va">lasso_learner</span>, <span class="va">ridge_learner</span>, <span class="va">enet_learner</span>,
  <span class="va">curated_glm_learner</span>, <span class="va">mean_learner</span>, <span class="va">glm_fast_learner</span>,
  <span class="va">ranger_learner</span>, <span class="va">svm_learner</span>, <span class="va">xgb_learner</span>
<span class="op">)</span>

<span class="co"># make and train SL</span>
<span class="va">sl</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_sl.html">Lrnr_sl</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>
  learners <span class="op">=</span> <span class="va">stack</span>
<span class="op">)</span>
<span class="va">sl_fit</span> <span class="op">&lt;-</span> <span class="va">sl</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">chspred_task</span><span class="op">)</span>
<span class="va">sl_fit</span><span class="op">$</span><span class="fu">print</span><span class="op">(</span><span class="op">)</span>

<span class="va">CVsl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/CV_lrnr_sl.html">CV_lrnr_sl</a></span><span class="op">(</span><span class="va">sl_fit</span>, <span class="va">chspred_task</span>, <span class="va">loss_loglik_binomial</span><span class="op">)</span>
<span class="va">CVsl</span>

<span class="va">varimp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/importance.html">importance</a></span><span class="op">(</span><span class="va">sl_fit</span>, type <span class="op">=</span> <span class="st">"permute"</span><span class="op">)</span>
<span class="va">varimp</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://tlverse.org/sl3/reference/importance_plot.html">importance_plot</a></span><span class="op">(</span>
    main <span class="op">=</span> <span class="st">"sl3 Variable Importance for Myocardial Infarction Prediction"</span>
  <span class="op">)</span></code></pre></div>
</div>
<div id="sl3ex2-sol" class="section level3">
<h3>
<span class="header-section-number">5.11.2</span> Exercise 2 Solution<a class="anchor" aria-label="anchor" href="#sl3ex2-sol"><i class="fas fa-link"></i></a>
</h3>
<p>Here is a potential solution to <a href="origami.html#sl3ex2"><code>sl3</code> Exercise 2 – Predicting Recurrent
Ischemic Stroke in an RCT with <code>sl3</code></a>.</p>
<div class="sourceCode" id="cb64"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://ipa-tys.github.io/ROCR/">ROCR</a></span><span class="op">)</span> <span class="co"># for AUC calculation</span>

<span class="va">ist_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span>
  <span class="st">"https://raw.githubusercontent.com/tlverse/"</span>,
  <span class="st">"tlverse-handbook/master/data/ist_sample.csv"</span>
<span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/fread.html">fread</a></span><span class="op">(</span><span class="op">)</span>

<span class="co"># stack</span>
<span class="va">ist_task</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/sl3_Task.html">make_sl3_Task</a></span><span class="op">(</span>
  data <span class="op">=</span> <span class="va">ist_data</span>,
  outcome <span class="op">=</span> <span class="st">"DRSISC"</span>,
  covariates <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">ist_data</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">ist_data</span><span class="op">)</span> <span class="op">==</span> <span class="st">"DRSISC"</span><span class="op">)</span><span class="op">]</span>,
  drop_missing_outcome <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span>

<span class="co"># learner library</span>
<span class="va">lrn_glm</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glm.html">Lrnr_glm</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span>
<span class="va">lrn_lasso</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glmnet.html">Lrnr_glmnet</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
<span class="va">lrn_ridge</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glmnet.html">Lrnr_glmnet</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0</span><span class="op">)</span>
<span class="va">lrn_enet</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_glmnet.html">Lrnr_glmnet</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>
<span class="va">lrn_mean</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_mean.html">Lrnr_mean</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span>
<span class="va">lrn_ranger</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_ranger.html">Lrnr_ranger</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span>
<span class="va">lrn_svm</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_svm.html">Lrnr_svm</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span>
<span class="co"># xgboost grid</span>
<span class="va">grid_params</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
  max_depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">5</span>, <span class="fl">8</span><span class="op">)</span>,
  eta <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.01</span>, <span class="fl">0.15</span>, <span class="fl">0.3</span><span class="op">)</span>
<span class="op">)</span>
<span class="va">grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html">expand.grid</a></span><span class="op">(</span><span class="va">grid_params</span>, KEEP.OUT.ATTRS <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="va">params_default</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>nthread <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/options.html">getOption</a></span><span class="op">(</span><span class="st">"sl.cores.learners"</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
<span class="va">xgb_learners</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">grid</span>, MARGIN <span class="op">=</span> <span class="fl">1</span>, <span class="kw">function</span><span class="op">(</span><span class="va">params_tune</span><span class="op">)</span> <span class="op">{</span>
  <span class="fu"><a href="https://rdrr.io/r/base/do.call.html">do.call</a></span><span class="op">(</span><span class="va">Lrnr_xgboost</span><span class="op">$</span><span class="va">new</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">params_default</span>, <span class="fu"><a href="https://rdrr.io/r/base/list.html">as.list</a></span><span class="op">(</span><span class="va">params_tune</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="op">}</span><span class="op">)</span>
<span class="va">learners</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/unlist.html">unlist</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
  <span class="va">xgb_learners</span>, <span class="va">lrn_ridge</span>, <span class="va">lrn_mean</span>, <span class="va">lrn_lasso</span>,
  <span class="va">lrn_glm</span>, <span class="va">lrn_enet</span>, <span class="va">lrn_ranger</span>, <span class="va">lrn_svm</span>
<span class="op">)</span>,
recursive <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span>

<span class="co"># SL</span>
<span class="va">sl</span> <span class="op">&lt;-</span> <span class="va"><a href="https://tlverse.org/sl3/reference/Lrnr_sl.html">Lrnr_sl</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">learners</span><span class="op">)</span>
<span class="va">sl_fit</span> <span class="op">&lt;-</span> <span class="va">sl</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">ist_task</span><span class="op">)</span>

<span class="co"># AUC</span>
<span class="va">preds</span> <span class="op">&lt;-</span> <span class="va">sl_fit</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="op">)</span>
<span class="va">obs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/na.omit.data.table.html">na.omit</a></span><span class="op">(</span><span class="va">ist_data</span><span class="op">$</span><span class="va">DRSISC</span><span class="op">)</span><span class="op">)</span>
<span class="va">AUC</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://ipa-tys.github.io/ROCR/reference/performance.html">performance</a></span><span class="op">(</span><span class="fu"><a href="http://ipa-tys.github.io/ROCR/reference/prediction.html">prediction</a></span><span class="op">(</span><span class="va">sl_preds</span>, <span class="va">obs</span><span class="op">)</span>, measure <span class="op">=</span> <span class="st">"auc"</span><span class="op">)</span><span class="op">@</span><span class="va">y.values</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="http://ipa-tys.github.io/ROCR/reference/performance.html">performance</a></span><span class="op">(</span><span class="fu"><a href="http://ipa-tys.github.io/ROCR/reference/prediction.html">prediction</a></span><span class="op">(</span><span class="va">sl_preds</span>, <span class="va">obs</span><span class="op">)</span>, <span class="st">"tpr"</span>, <span class="st">"fpr"</span><span class="op">)</span><span class="op">)</span>

<span class="co"># CVsl</span>
<span class="va">ist_task_CVsl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/sl3_Task.html">make_sl3_Task</a></span><span class="op">(</span>
  data <span class="op">=</span> <span class="va">ist_data</span>,
  outcome <span class="op">=</span> <span class="st">"DRSISC"</span>,
  covariates <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">ist_data</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">ist_data</span><span class="op">)</span> <span class="op">==</span> <span class="st">"DRSISC"</span><span class="op">)</span><span class="op">]</span>,
  drop_missing_outcome <span class="op">=</span> <span class="cn">TRUE</span>,
  folds <span class="op">=</span> <span class="fu">origami</span><span class="fu">::</span><span class="fu"><a href="http://tlverse.org/origami/reference/make_folds.html">make_folds</a></span><span class="op">(</span>
    n <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span class="op">(</span><span class="va">ist_data</span><span class="op">$</span><span class="va">DRSISC</span><span class="op">)</span><span class="op">)</span>,
    fold_fun <span class="op">=</span> <span class="va">folds_vfold</span>,
    V <span class="op">=</span> <span class="fl">5</span>
  <span class="op">)</span>
<span class="op">)</span>
<span class="va">CVsl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/CV_lrnr_sl.html">CV_lrnr_sl</a></span><span class="op">(</span><span class="va">sl_fit</span>, <span class="va">ist_task_CVsl</span>, <span class="va">loss_loglik_binomial</span><span class="op">)</span>
<span class="va">CVsl</span>

<span class="co"># sl3 variable importance plot</span>
<span class="va">ist_varimp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tlverse.org/sl3/reference/importance.html">importance</a></span><span class="op">(</span><span class="va">sl_fit</span>, type <span class="op">=</span> <span class="st">"permute"</span><span class="op">)</span>
<span class="va">ist_varimp</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://tlverse.org/sl3/reference/importance_plot.html">importance_plot</a></span><span class="op">(</span>
    main <span class="op">=</span> <span class="st">"Variable Importance for Predicting Recurrent Ischemic Stroke"</span>
  <span class="op">)</span></code></pre></div>
<!--
### Exercise 3 Solution {#sl3ex3-sol}

Here's a potential solution to the (Exercise 3)[#sl3ex3].


```r
# TODO
```
-->

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="data.html"><span class="header-section-number">4</span> Meet the Data</a></div>
<div class="next"><a href="tmle3.html"><span class="header-section-number">6</span> The TMLE Framework</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#origami"><span class="header-section-number">5</span> Cross-validation</a></li>
<li><a class="nav-link" href="#learning-objectives-2"><span class="header-section-number">5.1</span> Learning Objectives</a></li>
<li><a class="nav-link" href="#introduction-1"><span class="header-section-number">5.2</span> Introduction</a></li>
<li>
<a class="nav-link" href="#background"><span class="header-section-number">5.3</span> Background</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#introducing-cross-validation"><span class="header-section-number">5.3.1</span> Introducing: cross-validation</a></li></ul>
</li>
<li><a class="nav-link" href="#estimation-roadmap-how-does-it-all-fit-together"><span class="header-section-number">5.4</span> Estimation Roadmap: how does it all fit together?</a></li>
<li><a class="nav-link" href="#example-cross-validation-and-prediction"><span class="header-section-number">5.5</span> Example: cross-validation and prediction</a></li>
<li>
<a class="nav-link" href="#cross-validation-schemes-in-origami"><span class="header-section-number">5.6</span> Cross-validation schemes in origami</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#wash-benefits-study-example">WASH Benefits Study Example</a></li>
<li><a class="nav-link" href="#cross-validation-for-i.i.d.-data"><span class="header-section-number">5.6.1</span> Cross-validation for i.i.d. data</a></li>
<li><a class="nav-link" href="#cross-validation-for-dependent-data"><span class="header-section-number">5.6.2</span> Cross-validation for dependent data</a></li>
<li><a class="nav-link" href="#airpassenger-example">AirPassenger Example</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#general-workflow-of-origami"><span class="header-section-number">5.7</span> General workflow of origami</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#define-folds"><span class="header-section-number">5.7.1</span> (1) Define folds</a></li>
<li><a class="nav-link" href="#define-fold-function"><span class="header-section-number">5.7.2</span> (2) Define fold function</a></li>
<li><a class="nav-link" href="#apply-cross_validate"><span class="header-section-number">5.7.3</span> (3) Apply cross_validate</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#cross-validation-in-action"><span class="header-section-number">5.8</span> Cross-validation in action</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#cross-validation-with-linear-regression"><span class="header-section-number">5.8.1</span> Cross-validation with linear regression</a></li>
<li><a class="nav-link" href="#cross-validation-with-random-forests"><span class="header-section-number">5.8.2</span> Cross-validation with random forests</a></li>
<li><a class="nav-link" href="#cross-validation-with-arima"><span class="header-section-number">5.8.3</span> Cross-validation with arima</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#exercises"><span class="header-section-number">5.9</span> Exercises</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#review-of-key-concepts"><span class="header-section-number">5.9.1</span> Review of Key Concepts</a></li>
<li><a class="nav-link" href="#the-ideas-in-action"><span class="header-section-number">5.9.2</span> The Ideas in Action</a></li>
<li><a class="nav-link" href="#advanced-topics"><span class="header-section-number">5.9.3</span> Advanced Topics</a></li>
</ul>
</li>
<li><a class="nav-link" href="#learning-objectives-3">Learning Objectives</a></li>
<li><a class="nav-link" href="#motivation">Motivation</a></li>
<li>
<a class="nav-link" href="#introduction-2">Introduction</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#general-step-by-step-overview-of-the-super-learner-algorithm">General step-by-step overview of the Super Learner algorithm</a></li>
<li><a class="nav-link" href="#summary-of-super-learners-foundations">Summary of Super Learner’s Foundations</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#sl3-microwave-dinner-implementation">sl3 “Microwave Dinner” Implementation</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#wash-benefits-study-example-1">WASH Benefits Study Example</a></li>
<li><a class="nav-link" href="#load-the-necessary-libraries-and-data">0. Load the necessary libraries and data</a></li>
<li><a class="nav-link" href="#define-the-machine-learning-task">1. Define the machine learning task</a></li>
<li><a class="nav-link" href="#make-a-super-learner">2. Make a Super Learner</a></li>
<li><a class="nav-link" href="#train-the-super-learner-on-the-machine-learning-task">3. Train the Super Learner on the machine learning task</a></li>
<li><a class="nav-link" href="#obtain-predicted-values">4. Obtain predicted values</a></li>
</ul>
</li>
<li><a class="nav-link" href="#cross-validated-super-learner">Cross-validated Super Learner</a></li>
<li><a class="nav-link" href="#variable-importance-measures-with-sl3">Variable Importance Measures with sl3</a></li>
<li>
<a class="nav-link" href="#sl3-exercises"><span class="header-section-number">5.10</span> Exercises</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#sl3ex1"><span class="header-section-number">5.10.1</span> Predicting Myocardial Infarction with sl3</a></li>
<li><a class="nav-link" href="#sl3ex2"><span class="header-section-number">5.10.2</span> Predicting Recurrent Ischemic Stroke in an RCT with sl3</a></li>
</ul>
</li>
<li><a class="nav-link" href="#concluding-remarks"><span class="header-section-number">5.11</span> Concluding Remarks</a></li>
<li>
<a class="nav-link" href="#appendix">Appendix</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#sl3ex1-sol"><span class="header-section-number">5.11.1</span> Exercise 1 Solution</a></li>
<li><a class="nav-link" href="#sl3ex2-sol"><span class="header-section-number">5.11.2</span> Exercise 2 Solution</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/tlverse/tlverse-handbook/blob/master/05-origami.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/tlverse/tlverse-handbook/edit/master/05-origami.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Targeted Learning in R</strong>: Causal Data Science with the tlverse Software Ecosystem" was written by Mark van der Laan, Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips, Alan Hubbard. It was last built on March 11, 2021.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
